<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="csXtmAKXrGoQr2GkIa90aLM9urmzXCZXGcXWMwI-kj0"><meta name="msvalidate.01" content="AF3396A141E1B198CA1BE76915B3969F"><meta name="yandex-verification" content="ee8492bd2e7708db"><meta name="baidu-site-verification" content="code-h6vqPQbqvn"><meta name="sogou_site_verification" content="33FOy4QSNu"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.vivounicorn.xyz",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:{enable:!0,onlypost:!1,loadingImg:"./images/loading.gif",isSPA:!1,preloadRatio:3},pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本文对非线性最小二乘的原理、思路和应用做了简单介绍。"><meta property="og:type" content="article"><meta property="og:title" content="非线性最小二乘(Nonlinear Least Squares)"><meta property="og:url" content="http://www.vivounicorn.xyz/article/2675d8.html"><meta property="og:site_name" content="业精于勤，荒于嬉；行成于思，毁于随。"><meta property="og:description" content="本文对非线性最小二乘的原理、思路和应用做了简单介绍。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://vivounicorn.github.io/images/nls/ls.png"><meta property="og:image" content="https://vivounicorn.github.io/images/nls/regular.png"><meta property="og:image" content="https://vivounicorn.github.io/images/nls/ncc.png"><meta property="article:published_time" content="2022-09-25T05:42:41.000Z"><meta property="article:modified_time" content="2022-10-08T09:33:07.394Z"><meta property="article:author" content="张磊"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="最优化"><meta property="article:tag" content="数学"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://vivounicorn.github.io/images/nls/ls.png"><link rel="canonical" href="http://www.vivounicorn.xyz/article/2675d8.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>非线性最小二乘(Nonlinear Least Squares) | 业精于勤，荒于嬉；行成于思，毁于随。</title><script async src="https://www.googletagmanager.com/gtag/js?id=G-P394BZNEMZ"></script><script>function gtag(){dataLayer.push(arguments)}CONFIG.hostname===location.hostname&&(window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P394BZNEMZ"))</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"><a target="_blank" rel="noopener" href="https://github.com/vivounicorn/" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513;color:#fff;position:absolute;top:0;border:0;right:0" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">业精于勤，荒于嬉；行成于思，毁于随。</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">花晨月夕</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://www.vivounicorn.xyz/article/2675d8.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://vivounicorn.github.io/images/wali.png"><meta itemprop="name" content="张磊"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="业精于勤，荒于嬉；行成于思，毁于随。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">非线性最小二乘(Nonlinear Least Squares)</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-09-25 13:42:41" itemprop="dateCreated datePublished" datetime="2022-09-25T13:42:41+08:00">2022-09-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%95%B0%E5%AD%A6/%E6%9C%80%E4%BC%98%E5%8C%96/" itemprop="url" rel="index"><span itemprop="name">最优化</span></a> </span></span><span id="/article/2675d8.html" class="post-meta-item leancloud_visitors" data-flag-title="非线性最小二乘(Nonlinear Least Squares)" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/article/2675d8.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/article/2675d8.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>9k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>8 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://vivounicorn.github.io/images/nls/ls.png" width="166"> 本文对非线性最小二乘的原理、思路和应用做了简单介绍。 <span id="more"></span></p><h1 id="非线性最小二乘">非线性最小二乘</h1><p>最小二乘是一种数学最优化建模方法，它的一种常见解释是对残差做了满足正态分布的极大似然估计。最小二乘分两类：线性最小二乘和非线性最小二乘，区别是残差函数是否为线性函数，线性最小二乘比较简单，可以直接求解析解，非线性最小二乘比较复杂，需要用迭代式的最优化方法求解。</p><h2 id="最小二乘回顾">最小二乘回顾</h2><p>假设有观测数据集<span class="math inline">\(\{x_i,y_i\}_{i=1}^n\)</span>，某个参数为<span class="math inline">\(w\)</span>的函数<span class="math inline">\(f(x;w)\)</span>描述了观测数据的因变量和自变量的映射关系，即： <span class="math display">\[ \hat{y}_i=f(x_i;w) \]</span> 但数据拟合时一定不是严丝合缝的，会有误差即残差，所以有： <span class="math display">\[ y_i=\hat{y}_i+\epsilon \]</span> 假设这个残差服从偏差为0的正态分布，则有： <span class="math display">\[ \epsilon \sim N(0,\sigma^2) \]</span> 于是有： <span class="math display">\[ p(y_i|x_i,w)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{-(y_i-f(x_i;w))^2}{2\sigma^2}} \]</span></p><p>对于这<span class="math inline">\(n\)</span>个独立的观测样本就会产生<span class="math inline">\(n\)</span>个方程，采用极大似然估计有： <span class="math display">\[ p(y|x,w)=\prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{-(y_i-f(x_i;w))^2}{2\sigma^2}}=\frac{1}{(\sqrt{2\pi}\sigma)^n}e^{-\sum\limits_{i=1}^n\frac{-(y_i-f(x_i;w))^2}{2\sigma^2}} \]</span></p><p>由贝叶斯公式可知： <span class="math display">\[ \begin{align*} p(w|x,y)=&amp;\frac{p(y|x,w)p(w|x)}{p(y|x)}\\ =&amp;\frac{p(w|x)}{p(y|x)}p(y|x,w)\\ \propto&amp;p(y|x,w) \end{align*} \]</span> 所以，利用极大似然求参有： <span class="math display">\[ \begin{align*} arg\max\limits_w p(w|x,y)&amp;=arg\min\limits_w -ln(p(y|x,w))\\ &amp;=n\ln\sqrt\sigma+\sum\limits_{i=1}^n\frac{(y_i-f(x_i;w))^2}{2\sigma^2}\\ &amp;\propto\frac{1}{2\sigma^2}\sum\limits_{i=1}^n (y_i-f(x_i;w))^2 \end{align*} \]</span> 最后有： <span class="math display">\[ w=arg\min\limits_w \sum\limits_{i=1}^n (y_i-f(x_i;w))^2 \]</span></p><h2 id="非线性最小二乘-1">非线性最小二乘</h2><p>当残差函数非线性时，方便起见，我们定义残差函数为：<span class="math inline">\(r(w)=y-f(x;w)\)</span>，对<span class="math inline">\(n\)</span>个观测样本有<span class="math inline">\(n\)</span>个方程： <span class="math display">\[ F(w)=[r_1(w),r_2(w),......,r_n(w)]^T \]</span> 非线性最小二乘问题变成： <span class="math display">\[ \min ||r(w)||^2=r_1(w)^2+r_2(w)^2+......r_n(w)^2 \]</span> 如果此时还有其他约束条件，例如，等式约束<span class="math inline">\(q(w)=0\)</span>的话，以上问题变成了约束非线性最小二乘问题： <span class="math display">\[ \begin{align*} \min &amp;\quad ||r(w)||^2=r_1(w)^2+r_2(w)^2+......r_n(w)^2\\ s.t.&amp; \quad q_1(w)=0\\ &amp;\quad ......\\ &amp;\quad q_m(w)=0 \end{align*} \]</span></p><h3 id="拉格朗日乘数法">拉格朗日乘数法</h3><p>考虑求解通用的约束最优化问题，以最小化问题为： <span class="math display">\[ \begin{align*} \min &amp;\quad f(x)\\ s.t.&amp; \quad q_1(x)=0\\ &amp;\quad ......\\ &amp;\quad q_m(x)=0 \end{align*} \]</span> 几个定义：</p><p>1、<span class="math inline">\(x\)</span>为<span class="math inline">\(n\)</span>维向量，当<span class="math inline">\(x\)</span>满足以上所有约束条件时，被叫做可行解；</p><p>2、所有可行解中，当满足<span class="math inline">\(f(x^*)\leq f(x)\)</span>，则<span class="math inline">\(x^*\)</span>被称作全局最优解；</p><p>3、当可行解只有在一个邻域<span class="math inline">\(R\)</span>中时才满足<span class="math inline">\(f(x^*)\leq f(x)\)</span>，则<span class="math inline">\(x^*\)</span>被称作局部最优解，其中<span class="math inline">\(||x-x^*||\leq R\)</span>。</p><p>为求解上述约束问题，需要将其转变为无约束问题，在<a href="http://www.vivounicorn.xyz/article/ad2261a2.html">机器学习与人工智能技术分享-第四章 最优化原理</a>中有过介绍，定义拉格朗日函数： <span class="math display">\[ \begin{align*} L(x,\lambda)&amp;=f(x)+\lambda_1 q_1(x)+\lambda_2 q_2(x)+...+\lambda_m q_m(x)\\ &amp;=f(x)+\lambda^T q(x) \end{align*} \]</span> 其中：<span class="math inline">\(\lambda=(\lambda_1,\lambda_2,...,\lambda_m)\)</span>为<span class="math inline">\(m\)</span>维的拉格朗日乘子向量，<span class="math inline">\(q(x)=(q_1(x),q_2(x),...,q_m(x))\)</span>为<span class="math inline">\(m\)</span>维的约束函数向量。</p><p>拉格朗日函数的梯度为： <span class="math display">\[ \nabla L(x,\lambda)= \begin{bmatrix} \nabla_x L(x,\lambda)\\ \nabla_\lambda L(x,\lambda) \end{bmatrix} \]</span> 其中： <span class="math display">\[ \begin{align*} \nabla_x L(x,\lambda)&amp;=\nabla f(x)+\lambda_1 \nabla q_1(x)+...+\lambda_m \nabla q_m(x)\\ &amp;=\nabla f(x)+D q(x)^T\lambda\\ \nabla_\lambda L(x,\lambda)&amp;=q(x) \end{align*} \]</span></p><p>如果可行解<span class="math inline">\(x^*\)</span>为局部最优解，则必须满足拉格朗日条件(first-order necessary conditions)，即此条件是必要条件： <span class="math display">\[ \begin{align*} \nabla f(x^*)+D q(x^*)^T\lambda^*&amp;=0\\ q(x^*)&amp;=0 \end{align*} \]</span></p><p>其中： <span class="math display">\[ 𝐷q(𝑥)= \begin{gathered} \begin{bmatrix} \frac{\partial q_1(x)}{\partial x_1} &amp; \cdots &amp; \frac{\partial q_1(x)}{\partial x_n} \\ \vdots &amp; &amp; \vdots\\ \frac{\partial q_m(x)}{\partial x_1} &amp; \cdots &amp; \frac{\partial q_m(x)}{\partial x_n} \\ \end{bmatrix}= \begin{bmatrix} \nabla q_1(x)^T \\ \vdots\\ \nabla q_m(x)^T \\ \end{bmatrix} \end{gathered} \]</span></p><p>需要注意，如果在可行解<span class="math inline">\(x\)</span>下，<span class="math inline">\(𝐷q(𝑥)=\{\nabla q_1(x),...,\nabla g_m(x)\}\)</span>是线性相关的，则拉格朗日乘子不存在，因此无法通过拉格朗日乘数法求解，但此时局部最优解可能是存在的； 反之，如果<span class="math inline">\(𝐷q(𝑥)\)</span>线性无关，则<span class="math inline">\(x\)</span>被称为正则点（regular point），举个例子： <span class="math display">\[ \begin{align*} \min &amp;\quad f(x_1,x_2)=x_1+x_2\\ s.t.&amp; \quad q_1(x_1,x_2)=(x_1-1)^2+x_2^2-1=0\\ &amp;\quad q_2(x_1,x_2)=(x_1-2)^2+x_2^2-4=0 \end{align*} \]</span></p><span class="math inline">\(x^*=(0,0)\)</span>为唯一的可行解，因此它也是最优解，其拉格朗日函数为： <span class="math display">\[ L(x,\lambda)=x_1+x_2+\lambda_1((x_1-1)^2+x_2^2-1)+\lambda_2((x_1-2)^2+x_2^2-4) \]</span> 在<span class="math inline">\(x^*=(0,0)\)</span>处的拉格朗日条件为： <span class="math display">\[ \begin{align*} \nabla_x L(x,\lambda)&amp;=\begin{bmatrix}1\\1\end{bmatrix}+2\lambda_1\begin{bmatrix}x_1-1\\x_2\end{bmatrix}+2\lambda_2\begin{bmatrix}x_1-2\\x_2\end{bmatrix}=0\\ \nabla_\lambda L(x,\lambda)&amp;=\begin{bmatrix}(x_1-1)^2+x_2^2-1=0\\(x_1-2)^2+x_2^2-4=0\end{bmatrix} \end{align*} \]</span> 显然，<span class="math inline">\(\lambda_1\)</span>和<span class="math inline">\(\lambda_2\)</span>都不存在，<span class="math inline">\(x^*=(0,0)\)</span>不是正则点(<span class="math inline">\(\nabla q_1(x)\)</span>与<span class="math inline">\(\nabla q_2(x)\)</span>是线性相关的)，无法使用拉格朗日乘数法求解该问题。<center><img data-src="https://vivounicorn.github.io/images/nls/regular.png" width="600"></center><h3 id="约束非线性最小二乘">约束非线性最小二乘</h3><p><span class="math display">\[ \begin{align*} \min &amp;\quad ||r(w)||^2\\ s.t.&amp; \quad q(w)=0\\ \end{align*} \]</span></p><p>其中<span class="math inline">\(w\)</span>为待求参数，<span class="math inline">\(r(w)=(r_1(w),...,r_n(w))\)</span>为<span class="math inline">\(n\)</span>个样本的残差，<span class="math inline">\(q(w)=(q_1(w),...,q_m(w))\)</span>为<span class="math inline">\(m\)</span>个约束条件。</p><p>转化为拉格朗日函数：<span class="math inline">\(L(w,\lambda)=||r(w)||^2+\lambda^Tq(w)\)</span>，由拉格朗日条件知，如果<span class="math inline">\(w^*\)</span>为最优解，则存在<span class="math inline">\(\lambda^*\)</span>使得： <span class="math display">\[ 2Dr(w^*)^Tr(w^*)+Dq(w^*)^T\lambda^*=0,\quad q(w^*)=0 \]</span></p><p>ps:<span class="math inline">\(Dq(w^*)\)</span>的行向量为线性无关组。</p><p>当<span class="math inline">\(r(w)\)</span>和<span class="math inline">\(q(w)\)</span>都是线性函数时，该问题可以直接求出解析解，否则需要采用迭代法，在<a href="http://www.vivounicorn.xyz/article/ad2261a2.html">机器学习与人工智能技术分享-第四章 最优化原理</a>中我们介绍了由泰勒展开式衍生出的各种一阶和二阶优化算法，例如各种梯度下降法和各种拟牛顿法， 简单地说，优化算法就是在研究怎么找方向和找步长，先找方向再找步长是Line Search方法，先找步长再找方向（也可以看做同时找步长和方向）是Trust Region方法。</p><h3 id="newton-step-based迭代法">Newton Step-based迭代法</h3><p>前面也说到泰勒展开式是大部分最优化方法的“根”，如果展开到二阶，则可以变成各种牛顿法，简单回顾： 求解无约束最小化问题： <span class="math display">\[ \min f(x) \]</span> 在当前迭代<span class="math inline">\(x_k\)</span>点下，做泰勒展开到二阶： <span class="math display">\[ f(x_k+\Delta x_k)=f(x_k)+\nabla f(x_k)^T \Delta x_k+\frac{1}{2}\Delta x_k^T\nabla^2 f(x_k+t\Delta x_k)\Delta x_k \]</span> 其中：<span class="math inline">\(t=(0,1)\)</span>是个缩放因子，迭代式为：<span class="math inline">\(x_{k+1}=x_k+\Delta x_k\)</span>。</p><p>简单起间用<span class="math inline">\(f_k\)</span>代替<span class="math inline">\(f(x_k)\)</span>，用<span class="math inline">\(g_k\)</span>代替<span class="math inline">\(\nabla f(x_k)\)</span>，用<span class="math inline">\(p_k\)</span>代替<span class="math inline">\(\Delta x_k\)</span>有： <span class="math display">\[ f(x_k+p_k)=f_k+g_k^T p_k+\frac{1}{2}p_k^T\nabla^2 f(x_k+tp_k)p_k \]</span> 由于Hessian矩阵<span class="math inline">\(H_k=\nabla^2 f(x_k)\)</span>计算成本很高，所以用一个矩阵<span class="math inline">\(B_k\)</span>去估计<span class="math inline">\(H_k\)</span>，于是上面问题变成： <span class="math display">\[ m_k(p_k) = f_k + g_k^T p_k + \frac{1}{2} p_k^T B_k p_k \]</span> 其中：<span class="math inline">\(m_k (p_k)\)</span>与<span class="math inline">\(f(x_k+p_k)\)</span>之间的误差是<span class="math inline">\(||p_k||^2\)</span>的高阶无穷小，即：<span class="math inline">\(O(||p_k||^2)\)</span>，当<span class="math inline">\(p_k\)</span>很小时这个误差就很小。 由最优值必要条件可知，在第<span class="math inline">\(k\)</span>轮迭代有： <span class="math display">\[ \begin{align*} \nabla m_k(p_k)&amp;=g_k+B_kp_k=0\\ &amp;\Leftrightarrow B_k p_k = −g_k \end{align*} \]</span></p><p>1、如果<span class="math inline">\(B_k=H_k\)</span>且<span class="math inline">\(H_k\)</span>可逆、正定，上面问题就变成了牛顿法；</p><p>2、如果<span class="math inline">\(B_k\approx H_k\)</span>且<span class="math inline">\(B_k\)</span>始终保持正定，就是拟牛顿法，它和牛顿法一样，都具有二次收敛速度，即： 当<span class="math inline">\(x_k\)</span>靠近最优值<span class="math inline">\(x^*\)</span>时，有：<span class="math inline">\(||x_{k+1}-x^*||&lt;\epsilon||x_k-x^*||^2\)</span>，<span class="math inline">\(\epsilon&lt;1\)</span>；</p><p>ps：只有<span class="math inline">\(B_k\)</span>始终保持正定才能保证收敛，因为，对于最小化问题，始终希望搜索方向是一个下降方向，即满足<span class="math inline">\(p_k^Tg_k&lt;0\)</span>，所以： <span class="math display">\[ \begin{align*} p_k^Tg_k&amp;&lt;0\\ B_k p_k &amp;= −g_k\\ &amp;\Leftrightarrow p_k^TB_k p_k &gt;0 \end{align*} \]</span></p><p>3、如果<span class="math inline">\(B_k=I\)</span>，显然单位矩阵不是Hessian矩阵的一个好的估计，但它够简单，于是有：<span class="math inline">\(p_k=-g_k\)</span>，这就是妥妥的梯度下降法了，这时的收敛速度只能到线性速度了，即：<span class="math inline">\(||x_{k+1}-x^*||&lt;\epsilon||x_k-x^*||\)</span>，<span class="math inline">\(\epsilon&lt;1\)</span>；</p><p>4、如果<span class="math inline">\(H_k\)</span>非正定，需要重新定义<span class="math inline">\(B_k=H_k+\lambda I\)</span>，总能找到<span class="math inline">\(\lambda\)</span>使得<span class="math inline">\(B_k\)</span>正定，即<span class="math inline">\(B_k p_k = −g_k \Leftrightarrow (H_k+\lambda I)p_k = −g_k\)</span>，从而总能找到最优<span class="math inline">\(p_k\)</span>，换个角度看这个形式：</p><ul><li>当<span class="math inline">\(\lambda\)</span>很小时，如果<span class="math inline">\(H_k\)</span>正定，上式蜕变为牛顿法；</li><li>当<span class="math inline">\(\lambda\)</span>很大时，出现两个现象： 1、上式蜕变为梯度下降法 2、<span class="math inline">\(||p_k||\)</span>会被减小</li></ul><p>这个优化框架其实就是原始的Levenberg-Marquardt迭代法，即：当前值在距离最优值比较远时通过梯度下降法优化，虽然速度很慢但保证收敛，接近最优值时通过牛顿法以二次收敛速度逼近。 实际上可以证明，即使<span class="math inline">\(B_k\)</span>不正定，只要对<span class="math inline">\(||p_k||\)</span>做合适的限制，就能做到全局收敛，这个思想就是Trust Region（信任域）法。 回看这个问题： <span class="math display">\[ \min m_k(p_k) = f_k + g_k^T p_k + \frac{1}{2} p_k^T B_k p_k \]</span> 当<span class="math inline">\(B_k=H_k\)</span>时，相当于泰勒展开式展开到3阶，此时误差为<span class="math inline">\(O(||p_k||^3)\)</span>，当<span class="math inline">\(||p_k||\)</span>很小时，这个误差非常非常小，所以确定<span class="math inline">\(||p_k||\)</span>这一步可以转化为一个子优化问题： <span class="math display">\[ \begin{align*} \min &amp;\quad m_k(p_k) = f_k + g_k^T p_k + \frac{1}{2} p_k^T B_k p_k \\ s.t.&amp;\quad ||p_k||\leq\Delta_k \end{align*} \]</span> 其中<span class="math inline">\(\Delta_k&gt;0\)</span>，是Trust Region的半径，定义<span class="math inline">\(||.||\)</span>为欧氏距离，则最优解<span class="math inline">\(p*\)</span>在一个半径为<span class="math inline">\(\Delta_k\)</span>的球体内（把约束变个形式就清楚了：<span class="math inline">\(||p_{k}|| \leq \Delta_{k} \Leftrightarrow p_{k}^{T}p_{k} \leq \Delta_{k}^{2}\)</span>），特别是当Hessian矩阵性质不太好（如出现奇异或者病态）时，Trust Region法却能很好的求解。</p><p>ps：由于目标函数和约束条件都是二次方形式，所以求解的计算成本比较低。</p><p><strong>总结对比下Levenberg-Marquardt与Trust Region的区别</strong>：</p><p>当牛顿法不好使时：</p><p>Levenberg-Marquardt：通过对<span class="math inline">\(H_k\)</span>做扰动，求解<span class="math inline">\((H_k+\lambda I)p_k = −g_k\)</span>中的<span class="math inline">\(p_k\)</span>，从而做迭代；</p><p>Trust Region：通过求解子优化问题<span class="math inline">\(\min m_k(p_k) = f_k + g_k^T p_k + \frac{1}{2} p_k^T B_k p_k \quad s.t. ||p_k||\leq\Delta_k\)</span>得到最优<span class="math inline">\(p_k\)</span>，从而做迭代，让当前点<span class="math inline">\(x_k\)</span>迅速进入”兴趣域“。</p>所以Trust Region法可以看做是Levenberg-Marquardt法演化后得到的算法，另外，前者可以很好的处理目标函数是Negative Curvature的情况，后者不行，所以不要将两类算法混为一谈。<center><img data-src="https://vivounicorn.github.io/images/nls/ncc.png" width="600"></center><p>到此为止，Trust Region还有个遗留问题是<span class="math inline">\(\Delta_k\)</span>该怎么取？ 给定<span class="math inline">\(p_k\)</span>，定义： <span class="math display">\[ \rho_k = \frac{f(x_k)-f(x_k+p_k)}{m_k(0)-m_k(p_k)} \]</span></p><p>观察上述定义：</p><p>1、当<span class="math inline">\(\rho_k&lt;0\)</span>时，由于<span class="math inline">\(f(x_k+p_k)\)</span>大于当前值，所以目标函数值上升了，此时的<span class="math inline">\(p_k\)</span>必须丢弃；</p><p>2、如果<span class="math inline">\(\rho_k\)</span>接近1，说明<span class="math inline">\(m_k\)</span>估计的比较好，此时就可以放心的再下次迭代时扩展信任域；</p><p>3、如果<span class="math inline">\(\rho_k&gt;0\)</span>且远小于1，则下次迭代保持信任域不变；</p><p>4、如果<span class="math inline">\(\rho_k\)</span>接近0，则需要在下次迭代时缩减信任域。</p><p>Trust Region伪码如下：</p><p><span class="math display">\[ \begin{align*} &amp;\textbf{Trust Region Algorithm}\\ &amp;\quad \text{给定上界}\hat{\Delta}&gt;0,\Delta_0 \in(0, \hat{\Delta}), \eta \in [0, \frac{1}{4})\\ &amp;\quad \textbf{for } k \text{ in range(0,..)}\\ &amp;\quad \qquad \text{求解}\min m_k(p_k) = f_k + g_k^T p_k + \frac{1}{2} p_k^T B_k p_k \quad s.t. ||p_k||\leq\Delta_k\\ &amp;\quad \qquad \text{得到最佳}p_k\\ &amp;\quad \qquad \text{计算}\rho_k\\ &amp;\quad \qquad \textbf{if }\rho_k&lt;\frac{1}{4}\\ &amp;\quad \qquad \qquad \quad \Delta_{k+1}=\frac{1}{4}\Delta_k\\ &amp;\quad \qquad \textbf{else }\\ &amp;\quad \qquad \qquad \quad \textbf{if }\rho_k&gt;\frac{3}{4}\text{ 且 }||p_k||=\Delta_k\\ &amp;\quad \qquad \qquad \quad \qquad \Delta_{k+1}=\min(2\Delta_k,\hat{\Delta})\\ &amp;\quad \qquad \qquad \quad \textbf{else }\\ &amp;\quad \qquad \qquad \quad \qquad \Delta_{k+1}=\Delta_k\\ &amp;\quad \qquad \textbf{if } \rho_k&gt;\eta\\ &amp;\quad \qquad \qquad \quad x_{k+1}=x_k+p_k\\ &amp;\quad \qquad \textbf{else }\\ &amp;\quad \qquad \qquad \quad x_{k+1}=x_k\\ &amp;\quad \textbf{end } \end{align*} \]</span></p><p>回到之前的问题，为方便后续推理，去掉等式约束（因为通过拉格朗日乘数法可以很容易变成无约束问题），加入迭代轮数标识<span class="math inline">\(k\)</span>，并给目标函数加个系数，即： <span class="math display">\[ \begin{align*} \min &amp;\quad \frac{1}{2}||r(w_k)||^2\\ \end{align*} \]</span> 由泰勒展开式可知： <span class="math display">\[ r(w_k+p_k)=\frac{1}{2}||r(w_k+p_k)||^2\approx\frac{1}{2}||Dr(w_k)p_k+r(w_k)||^2 \]</span></p><p>方便起见用符号<span class="math inline">\(J_k\)</span>表示Jacobian矩阵<span class="math inline">\(Dr(w_k)\)</span>，<span class="math inline">\(r_k\)</span>表示<span class="math inline">\(r(w_k)\)</span>，<span class="math inline">\(q_k\)</span>表示<span class="math inline">\(q(w_k)\)</span>： <span class="math display">\[ r(w_k+p_k)\approx\frac{1}{2}||J_{k} p_k+r_k||^2 \]</span></p><p>利用<strong>Trust Region</strong> 框架，如果<span class="math inline">\(p_k^*\)</span>为上述问题的最优解，则一定存在<span class="math inline">\(\lambda^* \geq 0\)</span>，且满足以下条件： <span class="math display">\[ \begin{align*} (J_k^{T}J_k+\lambda^*I)p_k^*&amp;=-J_k^{T}r_k\\ \lambda^*(\Delta_k-||p_k^*||)&amp;=0 \end{align*} \]</span></p><p>换个角度看，<span class="math inline">\((J^{T}J+\lambda^*I)p_k^*=-J^{T}r_k\)</span>其实就是求解下面这个最小二乘问题： <span class="math display">\[ \min_p\frac{1}{2}||\left [ \begin{matrix} J_k \\ \sqrt{\lambda}I \end{matrix} \right ]p+\left [ \begin{matrix} r_k \\ 0 \end{matrix} \right ]||^2 \]</span></p></div><div class="popular-posts-header">相关文章推荐</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/ad2261a2.html" rel="bookmark">机器学习与人工智能技术分享-第四章 最优化原理</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/d677b2e0.html" rel="bookmark">机器学习与人工智能技术分享-第三章 机器学习中的统一框架</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/d0a635cc.html" rel="bookmark">0-1规划及其现实应用(0-1 Programming)</a></div></li></ul><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="https://vivounicorn.github.io/images/wx.jpeg"><span class="icon"><i class="fab fa-weixin"></i> </span><span class="label">WeChat</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a> <a href="/tags/%E6%9C%80%E4%BC%98%E5%8C%96/" rel="tag"># 最优化</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" rel="tag"># 数学</a></div><div class="post-nav"><div class="post-nav-item"><a href="/article/fe514cfb.html" rel="prev" title="BERTopic主题模型详解"><i class="fa fa-chevron-left"></i> BERTopic主题模型详解</a></div><div class="post-nav-item"></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let e=CONFIG.comments["activeClass"];if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98"><span class="nav-text">非线性最小二乘</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E9%A1%BE"><span class="nav-text">最小二乘回顾</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98-1"><span class="nav-text">非线性最小二乘</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0%E6%B3%95"><span class="nav-text">拉格朗日乘数法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%A6%E6%9D%9F%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98"><span class="nav-text">约束非线性最小二乘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#newton-step-based%E8%BF%AD%E4%BB%A3%E6%B3%95"><span class="nav-text">Newton Step-based迭代法</span></a></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="张磊" src="https://vivounicorn.github.io/images/wali.png"><p class="site-author-name" itemprop="name">张磊</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">18</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">13</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">51</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="sidebar-button motion-element"><i class="fa fa-comment"></i> Chat</div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/vivounicorn" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zhangleisuper@gmail.com" title="E-Mail → mailto:zhangleisuper@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/vivounicorn" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title recent-posts-title"><i class="fa fa-history" aria-hidden="true"></i> 近期文章</div><ul class="links-of-blogroll-list recent-posts-list"><li class="my-links-of-blogroll-item"><a href="/article/2675d8.html" title="非线性最小二乘(Nonlinear Least Squares)" target="" style="display:block;text-align:left">☺ 非线性最小二乘(Nonlinear Least Squares)</a></li><li class="my-links-of-blogroll-item"><a href="/article/fe514cfb.html" title="BERTopic主题模型详解" target="" style="display:block;text-align:left">☺ BERTopic主题模型详解</a></li><li class="my-links-of-blogroll-item"><a href="/article/d0a635cc.html" title="0-1规划及其现实应用(0-1 Programming)" target="" style="display:block;text-align:left">☺ 0-1规划及其现实应用(0-1 Programming)</a></li><li class="my-links-of-blogroll-item"><a href="/article/1b1480ce.html" title="机器学习中的自动微分(Automatic Differentiation)" target="" style="display:block;text-align:left">☺ 机器学习中的自动微分(Automatic Differentiation)</a></li><li class="my-links-of-blogroll-item"><a href="/article/c0a9d987.html" title="机器学习与人工智能技术分享-第十章-Vision Transformers (ViT)" target="" style="display:block;text-align:left">☺ 机器学习与人工智能技术分享-第十章-Vision Transformers (ViT)</a></li></ul></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备2022027092号-1 </a><img src="https://vivounicorn.github.io/images/beian.png" style="display:inline-block"></div><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">张磊</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">589k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">8:56</span></div></div></footer></div><script src="//cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>!function(){var e,t,o,n,r=document.getElementsByTagName("link");if(0<r.length)for(i=0;i<r.length;i++)"canonical"==r[i].rel.toLowerCase()&&r[i].href&&(e=r[i].href);t=(e||window.location.protocol).split(":")[0],e=e||window.location.href,window,o=e,n=document.referrer,/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(o)||(t="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif",n?(t+="?r="+encodeURIComponent(document.referrer),o&&(t+="&l="+o)):o&&(t+="?l="+o),(new Image).src=t)}()</script><script src="/js/local-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{load:["[tex]/mhchem"],source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},packages:{"[+]":["mhchem"]},tags:"ams"},options:{renderActions:{findScript:[10,d=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const a=new d.options.MathItem(e.textContent,d.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),a.start={node:t,delim:"",n:0},a.end={node:t,delim:"",n:0},d.math.push(a)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!1,notify:!0,appId:"m8FPP0CqMpxyTuUvaVOX9qVV-gzGzoHsz",appKey:"Ori6X9PXqQyURvwgl7HT5TJj",placeholder:"赠人玫瑰，手有余香",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>