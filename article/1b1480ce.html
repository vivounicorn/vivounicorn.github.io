<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="-l60HPLrjDNbr3Ni1wLsNkiKiCWUAmxiC_ObB8vNMF0"><meta name="msvalidate.01" content="AF3396A141E1B198CA1BE76915B3969F"><meta name="yandex-verification" content="ee8492bd2e7708db"><meta name="baidu-site-verification" content="code-OBKi1CbRLy"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"vivounicorn.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:{enable:!0,onlypost:!1,loadingImg:"./images/loading.gif",isSPA:!1,preloadRatio:3},pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本文对自动微分机器原理做了简单介绍。"><meta property="og:type" content="article"><meta property="og:title" content="机器学习中的自动微分(Automatic Differentiation)"><meta property="og:url" content="https://vivounicorn.github.io/article/1b1480ce.html"><meta property="og:site_name" content="业精于勤，荒于嬉；行成于思，毁于随。"><meta property="og:description" content="本文对自动微分机器原理做了简单介绍。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://vivounicorn.github.io/images/ad/bp.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ad/error.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ad/sd.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ad/math.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ad/clifford.png"><meta property="article:published_time" content="2022-02-28T05:32:04.000Z"><meta property="article:modified_time" content="2022-03-24T04:43:41.651Z"><meta property="article:author" content="张磊"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="自动微分"><meta property="article:tag" content="Automatic Differentiation"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://vivounicorn.github.io/images/ad/bp.png"><link rel="canonical" href="https://vivounicorn.github.io/article/1b1480ce.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>机器学习中的自动微分(Automatic Differentiation) | 业精于勤，荒于嬉；行成于思，毁于随。</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">业精于勤，荒于嬉；行成于思，毁于随。</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">花晨月夕</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div><div><img itemprop="image" src="https://vivounicorn.github.io/images/background.jpg"></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/article/1b1480ce.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://vivounicorn.github.io/images/wali.png"><meta itemprop="name" content="张磊"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="业精于勤，荒于嬉；行成于思，毁于随。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">机器学习中的自动微分(Automatic Differentiation)</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-02-28 13:32:04" itemprop="dateCreated datePublished" datetime="2022-02-28T13:32:04+08:00">2022-02-28</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a> </span></span><span id="/article/1b1480ce.html" class="post-meta-item leancloud_visitors" data-flag-title="机器学习中的自动微分(Automatic Differentiation)" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/article/1b1480ce.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/article/1b1480ce.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>7.1k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>6 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://vivounicorn.github.io/images/ad/bp.png" width="266"> 本文对自动微分机器原理做了简单介绍。 <span id="more"></span></p><h1 id="机器学习中的自动微分">机器学习中的自动微分</h1><p>计算机求解微分可以分成四类方法：</p><h2 id="手工求解">手工求解</h2><p>在《<a href="https://vivounicorn.github.io/article/ad2261a2.html">机器学习与人工智能技术分享-第四章 最优化原理</a>》中介绍了大量手工求解微分的算法，它们大都是通过泰勒展开式推导出的，只利用梯度求优化问题的叫一阶优化算法，如SGD，利用Hessians矩阵求解的是二阶优化算法，如L-BFGS， 这些算法的特点是能够很灵活自主高效的求解优化问题，包括一些目标函数不可微的问题，研究人员需要有很强的数学背景和代码实现能力，缺点是耗时且容易出错，代码调试也比较复杂。</p><h2 id="数值微分">数值微分</h2><p>原理很简单，就是利用导数的定义求解，所以实现起来也不复杂，形式化描述是： 假设有<span class="math inline">\(n\)</span>元目标函数<span class="math inline">\(f(X)=f(x_1,x_2,....x_n):\mathbb{R} \rightarrow \mathbb{R}\)</span>，求解其梯度，可以对它的每个维度分别使用导数定义求解： <span class="math display">\[\frac{\partial f(X)}{\partial x_i} \approx \frac{f(X+he_i)-f(X)}{h}\]</span> 其中<span class="math inline">\(e_i\)</span>是第<span class="math inline">\(i\)</span>维的单位向量，<span class="math inline">\(0&lt;h\ll 1\)</span>是一个微小步长，最后得到： <span class="math display">\[\nabla f(X)=(\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n})^T\]</span></p><p>例如，求解<span class="math inline">\(f(x_1,x_2)=x_1+x_2^2\)</span>，假设取<span class="math inline">\(h=0.000001\)</span>，则： <span class="math display">\[\begin{equation} \frac{\partial f(X)}{\partial x_i}\approx\left\{ \begin{aligned} \frac{f(x_1+0.000001,x_2)-f(x_1,x_2)}{0.000001}&amp;=1 \\ \frac{f(x_1,x_2+0.000001)-f(x_1,x_2)}{0.000001}&amp;=2x_2+0.000001 \end{aligned} \right. \end{equation} \]</span> 如<span class="math inline">\(f&#39;(1,1)=(1,2.000001)^T\)</span>。</p><p>不过由于这种方法的缺点是：</p><p><strong>1)</strong>、多元函数的每个维度都要算一遍，即<span class="math inline">\(O(n)\)</span>的时间复杂度，尤其在当今的机器学习问题中，这个维度非常大，会导致这种方法完全无法落地；</p><p><strong>2)</strong>、由于这种求解方法天然是病态（ill-conditioned）且不稳定的（比如计算机的计算精度本来就是有限的），所以每个维度的每个<span class="math inline">\(h\)</span>的取值要很小心，否则就会出现较大误差，这种误差一般有两种：截断误差(Truncation error)和舍入误差(Roundoff error)，</p><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Truncation_error">截断误差</a>，简单说就是因为截断操作导致的误差，例如：无穷级数: <span class="math display">\[S_n=\lim_{n \to \infty} \sum_{1}^n\frac{1}{2^n}=1\]</span> 我们只能在有限的步数内做估计，如取：<span class="math inline">\(n=6\)</span>，则<span class="math inline">\(S_6=\frac{63}{64}\)</span>，截断误差为：<span class="math inline">\(0.015625\)</span>。</p><p><a target="_blank" rel="noopener" href="https://mathworld.wolfram.com/RoundoffError.html">舍入误差</a>，简单说就是类似四舍五入这样的操作导致的误差，计算机在表示数字的能力上存在数量级和精度限制，某些数值操作对舍入误差非常敏感，且误差会被累积放大。</p><p>为了缓解上面的误差，人们想了很多办法，例如使用center difference估计法，如下： <span class="math display">\[\frac{\partial f(X)}{\partial x_i} = \frac{f(X+he_i)-f(X-he_i)}{2h}+O(h^2)\]</span></p>以函数<span class="math inline">\(f(x)=64x(1−x)(1−2x)^2(1−8x+8x^2)^2\)</span>为例，两种方法比较如下：<center><img data-src="https://vivounicorn.github.io/images/ad/error.png" width="400"></center><p>其中： <span class="math inline">\(E_{forward} (h, x_0 ) =\left|\frac{f(x_0+h)-f(x_0)}{h}-\frac{d}{dx}f(x)|_{x_0}\right|\)</span>， <span class="math inline">\(E_{center} (h, x_0 )=\left|\frac{f(x_0+h)-f(x_0-h)}{2h}-\frac{d}{dx}f(x)|_{x_0}\right|\)</span>，<span class="math inline">\(x_0=0.2\)</span> ，对截断误差和舍入误差的tradeoff体现在<span class="math inline">\(h\)</span>的取值上，即使是改进后的Center difference，稍有不慎误差也会被放大。</p><h2 id="符号微分">符号微分</h2><p>符号微分，顾名思义就是把微分的基本规则符号化，通过自动操作表达式从而获得各种衍生表达式，例如下面的积分规则： <span class="math display">\[\begin{equation} \left\{ \begin{aligned} &amp;\frac{d}{dx}(f(x)+g(x))\rightarrow\frac{d}{dx}f(x)+\frac{d}{dx}g(x) \\ &amp;\frac{d}{dx}(f(x)g(x))\rightarrow g(x)\frac{d}{dx}f(x)+f(x)\frac{d}{dx}g(x) \end{aligned} \right. \end{equation} \]</span></p><p>有了这些规则后，可以把输入变成一个由一系列符号表达式组成的树形结构，以前比较著名的深度学习框架Theano用的就是这种方式，但也正是由于这种比较“机械式”的展开，而没有通过复用和仅存储中间子表达式值的方式来简化计算，导致出现表达式成指数级膨胀。 例如函数：<span class="math inline">\(h(x) = f (x)g(x)\)</span>，对其应用导数的乘法规则有： <span class="math display">\[ \frac{d}{dx}h(x)= g(x)\frac{d}{dx}f(x)+f(x)\frac{d}{dx}g(x) \]</span> 这个式子中，<span class="math inline">\(g(x)\)</span>与<span class="math inline">\(\frac{d}{dx}g(x)\)</span>是相互独立各算各的，显然一个不小心，它们的公用部分就无法复用，随便一个例子：<span class="math inline">\(g(x)=6+e^x\)</span>，<span class="math inline">\(\frac{d}{dx}g(x)=e^x\)</span>，公共部分重复计算。</p>如果我们更关心输入函数的导数能否准确被算出，而不是它的符号表达本身的话，是可以通过复用及仅存储中间子表达式值的方式来简化计算的，这种思想也是自动微分的基础之一，如下图的例子，对函数<span class="math inline">\(l_{n+1} = 4l_n (1 − l_n ), l_1 = x\)</span>做表达式展开：<center><img data-src="https://vivounicorn.github.io/images/ad/sd.png" width="400"></center><p>其中第三列是以符号微分形式展开，显然随着式子复杂度上升，展开式复杂度急剧上升，第四列是中间字表达式简化后的形式，复杂度比原始形式大大下降。</p><h2 id="自动微分ad">自动微分(AD)</h2><p>通过定义一个有限基本运算的集合，这些基本运算的求导数方法已知，包括一元运算（如：负数、开根号等）、二元运算（如：加、减、乘、除等）、超越函数（如：指数函数、三角函数、反三角函数、对数函数等），利用链式法则结合这些基本运算的导数，通过延迟 计算的方式来计算整个函数的导数，相比符号微分等其他方法，不但能处理封闭表达式（closed-form expressions），还可以支持控制流，如分支、循环、递归和过程调用等，这里解释下什么叫封闭表达式。</p><h3 id="封闭表达式closed-form-expressions">封闭表达式(Closed-Form Expressions)</h3><p>简单说就是能用固定数量操作符表达的式子。</p><p>例如：<span class="math inline">\(y=2+4+6+...+2n\)</span>不是封闭表达式，而<span class="math inline">\(y=\sum\limits_{i=1}^{n}2i=n(n+1)\)</span>就是封闭表达式。常见的封闭形式举例： <span class="math display">\[ \begin{aligned} &amp; \sum\limits_{i=m}^{n}c=(n - m +1)c\\ &amp; \sum\limits_{i=1}^{n}i=\frac{n(n+1)}{2}\\ &amp; \sum\limits_{i=1}^{n}i^2=\frac{n(n+1)(2n+1)}{6}\\ &amp; \sum\limits_{i=0}^{n}a^i=\frac{a^{n+1}-1}{a-1}(a\neq1)\\ &amp; \sum\limits_{i=1}^{n}ia^i=\frac{a-(n+1)a^{n+1}+na^{n+2}}{(a-1)^2}\\ \end{aligned} \]</span></p><p>问题：找到<span class="math inline">\(2 + 2^2 \cdot 7 + 2^3 \cdot 14 +...+ 2^n (n-1)\cdot 7\)</span>的封闭形式。 解： <span class="math display">\[ \begin{aligned} y=&amp; 2 + 2^2 \cdot 7 + 2^3 \cdot 14 +...+ 2^n (n-1)\cdot 7\\ =&amp; 2+\sum\limits_{i=2}^{n}2^i(i-1)\cdot 7\\ =&amp; 2+7\sum\limits_{i=2}^{n}(i-1)2^i\\ =&amp; 2+7\sum\limits_{i=1}^{n-1}i2^{i+1}\\ =&amp; 2+14\sum\limits_{i=1}^{n-1}i2^i\\ =&amp; 2+14(2-n2^n+(n-1)2^{n+1}) \end{aligned} \]</span></p><h3 id="对偶数">对偶数</h3>数学本质上是由人类通过逻辑抽象思维对事物主观定义出结构和模式并以工具形式存在，用于解决实际问题的。而抽象逻辑是需要自洽的，所以在不同应用范围会产生递进的不同工具：<center><img data-src="https://vivounicorn.github.io/images/ad/math.png" width="400"></center><p>例如，复数定义为： <span class="math display">\[z=a+bi\]</span> 其中<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>都是实数且<span class="math inline">\(i^2=1\)</span>，复数在实际中有广泛的应用。(ps：我最喜欢欧拉公式：<span class="math inline">\(e^{ix}=\cos x+i\sin x\)</span>，尤其当<span class="math inline">\(x=\pi\)</span>时，<span class="math inline">\(e^{i\pi}+1=0\)</span>)</p><p>类似复数，在19世纪后期，W. Clifford定义和发展出了对偶数，即： <span class="math display">\[z=a+b\epsilon\]</span> 其中<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>都是实数且<span class="math inline">\(\epsilon^2=0\)</span>。</p><center><img data-src="https://vivounicorn.github.io/images/ad/clifford.png" width="300"></center><p>那么对偶数有什么用呢？看到这个定义，我第一个想到的是微分定义中的无穷小量<span class="math inline">\(dx\)</span>，第二个想到的是，函数的泰勒展开式的2阶及以上的余项部分。 假设<span class="math inline">\(f:\mathbb{R} \rightarrow \mathbb{R}\)</span>是任意函数，那么在<span class="math inline">\(x+\epsilon\)</span>处做泰勒展开，如下： <span class="math display">\[ f(x+\epsilon)=f(x)+f&#39;(x)\epsilon+ O(\epsilon^2) \]</span> 其中<span class="math inline">\(O(\epsilon^2) \rightarrow0\)</span>。显然<span class="math inline">\(f(x)+f&#39;(x)\epsilon\)</span>就是个对偶数，所以有对偶函数： <span class="math display">\[ \hat f(\hat x)=f(x)+f&#39;(x)\epsilon \]</span> 简化表示为： <span class="math display">\[ \hat f(\hat x)=\{f_0,f_1\},\text{where } f_0=f(x) \text{ and }f_1=f&#39;(x). \]</span> 对复合函数<span class="math inline">\(f(g(x))\)</span>，根据链式法则有：<span class="math inline">\((f(g(x)))&#39;=f&#39;(g(x))g&#39;(x)\)</span>有： <span class="math display">\[ \hat f(\hat g)=f(g(x))+(f(g(x)))&#39;\epsilon=f(g(x))+f&#39;(g(x))g&#39;(x)\epsilon \]</span> 简写为： <span class="math display">\[ \hat f(\hat g)=\{f_0(g_0),f_1(g_0)g_1\} \]</span> 对更复杂的函数<span class="math inline">\(h(x)=f(g(u(x)))\)</span>有 <span class="math display">\[ \hat f(\hat g(\hat u))=\{f_0(g_0(u_0)),f_1(g_0(u_0))g_1(u_0)u_1\} \]</span> 也就是只需要执行一次链式求导就能直接求出<span class="math inline">\(h&#39;(x)\)</span>（隐含链式求导是延迟执行的），这就是利用对偶数求解某个函数导数的威力，这个就是自动微分前向模式(Forward Mode of AD)的理论依据。</p><p>再进一步，定义新的对偶数： <span class="math display">\[ \widetilde r=a+b\epsilon_1+c\epsilon_2, \widetilde r=\{a,b,c\} \]</span> 其中<span class="math inline">\(\{a,b,c\}\in \mathbb{R}\)</span>，<span class="math inline">\(i,j\in\{1,2\}\)</span>满足关系： <span class="math display">\[ \begin{equation} \epsilon_i\cdot \epsilon_j=\left\{ \begin{aligned} &amp;0&amp;\text{ if }i+j&gt;2, \\ &amp;2\epsilon_{i+j}&amp;\text{ otherwise.} \end{aligned} \right. \end{equation} \]</span> 把泰勒展开式展开到二阶： <span class="math display">\[ \begin{aligned} f(\widetilde x)=&amp;f(x)+f&#39;(x)\epsilon_1+\frac{1}{2}f&#39;&#39;(x)\epsilon_1^2\\ =&amp;f(x)+f&#39;(x)\epsilon_1+f&#39;&#39;(x)\epsilon_2 \end{aligned} \]</span> 简写为： <span class="math display">\[ \begin{aligned} \widetilde f(\widetilde x)=&amp;\{f(x),f&#39;(x),f&#39;&#39;(x)\}\\ =&amp;\{f_0,f_1,f_2\} \end{aligned} \]</span></p><p>以矩阵形式看，定义： <span class="math display">\[ \begin{aligned} I=&amp;\left[ \begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{matrix} \right]\\ \epsilon_1=&amp;\left[ \begin{matrix} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{matrix} \right]\\ \epsilon_2=&amp;\left[ \begin{matrix} 0 &amp; 0 &amp; 1/2 \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{matrix} \right]\\ \end{aligned} \]</span> <span class="math inline">\(X=xI+\epsilon_1\)</span>，则： <span class="math display">\[ f(X)=f(x)I+f&#39;(x)\epsilon_1+f&#39;&#39;(x)\epsilon_2 \]</span> 同样有： <span class="math display">\[ \widetilde f(\widetilde x)=\{f_0,f_1,f_2\},\text{ and }f_0=f(x),f_1=f&#39;(x),f_2=f&#39;&#39;(x). \]</span> 对复合函数<span class="math inline">\(f(g(x))\)</span>就有： <span class="math display">\[ \widetilde f(\widetilde g)=\{f_0(g_0),f_1(g_0)g_1,f_2(g_0)g_1^2+f_1(g_0)g_2\}. \]</span> 这个式子最核心的价值除了前面说的<strong>只需要执行一次链式求导就能直接求出目标函数的导数（这个导数就是对偶数的第二/对偶部分）</strong>外，导数结果<strong>不存在截断误差和舍入误差</strong>。</p><p>常用的对偶数推论有： <span class="math display">\[ \begin{aligned} 1.&amp;(a+b \epsilon)+(c+d \epsilon)=a+c+(b+d)\epsilon\\ 2.&amp;(a+b \epsilon)\cdot(c+d \epsilon)=ac+(ad+bc)\epsilon\\ 3.&amp;-(a+b \epsilon)=-a-b\epsilon\\ 4.&amp;P(a) = p_0 + p_1a + p_2a^2 + · · · + p_na^n \text{ 在}a+b\epsilon\text{处对偶形式为}p(a+b\epsilon)=p(a)+p&#39;(a)b\epsilon\\ 5.&amp;sin(a+b\epsilon )=sin(a)+cos(a)b\epsilon\\ 6.&amp;cos(a+b\epsilon )=cos(a)-sin(a)b\epsilon\\ 7.&amp;e^{a+b\epsilon}=e^a+be^a\epsilon\\ 8.&amp;log(a+b\epsilon)=log(a)+\frac{b}{a}\epsilon \text{ and }a\neq 0\\ 9.&amp;\sqrt{a+b\epsilon}=\sqrt{a}+\frac{b}{2\sqrt{a}}\epsilon \text{ and }a\neq 0 \end{aligned} \]</span></p><p>举个例子：求函数<span class="math inline">\(f(x)=x-e^{-sin(x)}\)</span>的导数<span class="math inline">\(f&#39;(x)\)</span>，有： <span class="math display">\[ \begin{aligned} f(x+\epsilon)&amp;=x+\epsilon-e^{-sin(x+\epsilon)}\\ &amp;=x+\epsilon-e^{-(sin(x)+cos(x)\epsilon)}\\ &amp;=x-e^{-sin(x)}+(1+cos(x)\cdot e^{-sin(x)})\epsilon \end{aligned} \]</span> 即：<span class="math inline">\(\widetilde f(\widetilde x)=\{x-e^{-sin(x)},1+cos(x)\cdot e^{-sin(x)}\}\)</span> 所以可以取出对偶部，直接得到<span class="math inline">\(f&#39;(x)=1+cos(x)\cdot e^{-sin(x)}\)</span>。</p><h3 id="前向模式自动微分forward-mode-ad">前向模式自动微分(Forward mode AD)</h3><h3 id="反向模式自动微分reverse-mode-ad">反向模式自动微分(Reverse mode AD)</h3><h2 id="参考文献">参考文献</h2><p>《<a target="_blank" rel="noopener" href="https://www.redalyc.org/journal/467/46761359006/html/#redalyc_46761359006_ref33">Dual Numbers for Algorithmic Differentiation</a>》</p><p>《<a target="_blank" rel="noopener" href="https://londmathsoc.onlinelibrary.wiley.com/doi/10.1112/plms/s1-4.1.381">Preliminary sketch of biquaternions</a>》</p></div><div class="popular-posts-header">相关文章推荐</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/d677b2e0.html" rel="bookmark">机器学习与人工智能技术分享-第三章 机器学习中的统一框架</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/307f39c.html" rel="bookmark">机器学习与人工智能技术分享-第二章 建模方法回顾</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/ad2261a2.html" rel="bookmark">机器学习与人工智能技术分享-第四章 最优化原理</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/fb9cd06d.html" rel="bookmark">机器学习与人工智能技术分享-第七章 金融风控</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/b12a240.html" rel="bookmark">机器学习与人工智能技术分享-第九章 语义分割</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a> <a href="/tags/%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86/" rel="tag"># 自动微分</a> <a href="/tags/Automatic-Differentiation/" rel="tag"># Automatic Differentiation</a></div><div class="post-nav"><div class="post-nav-item"><a href="/article/c0a9d987.html" rel="prev" title="机器学习与人工智能技术分享-第十章-Vision Transformers (ViT)"><i class="fa fa-chevron-left"></i> 机器学习与人工智能技术分享-第十章-Vision Transformers (ViT)</a></div><div class="post-nav-item"></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let e=CONFIG.comments["activeClass"];if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86"><span class="nav-text">机器学习中的自动微分</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%89%8B%E5%B7%A5%E6%B1%82%E8%A7%A3"><span class="nav-text">手工求解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%80%BC%E5%BE%AE%E5%88%86"><span class="nav-text">数值微分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%A6%E5%8F%B7%E5%BE%AE%E5%88%86"><span class="nav-text">符号微分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86ad"><span class="nav-text">自动微分(AD)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%81%E9%97%AD%E8%A1%A8%E8%BE%BE%E5%BC%8Fclosed-form-expressions"><span class="nav-text">封闭表达式(Closed-Form Expressions)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E5%81%B6%E6%95%B0"><span class="nav-text">对偶数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E5%90%91%E6%A8%A1%E5%BC%8F%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86forward-mode-ad"><span class="nav-text">前向模式自动微分(Forward mode AD)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E6%A8%A1%E5%BC%8F%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86reverse-mode-ad"><span class="nav-text">反向模式自动微分(Reverse mode AD)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-text">参考文献</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="张磊" src="https://vivounicorn.github.io/images/wali.png"><p class="site-author-name" itemprop="name">张磊</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">15</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">2</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">49</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="sidebar-button motion-element"><i class="fa fa-comment"></i> Chat</div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/vivounicorn" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zhangleisuper@gmail.com" title="E-Mail → mailto:zhangleisuper@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/vivounicorn" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">张磊</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">505k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">7:39</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div></div></footer></div><script src="//cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>!function(){var e,t,o,n,r=document.getElementsByTagName("link");if(0<r.length)for(i=0;i<r.length;i++)"canonical"==r[i].rel.toLowerCase()&&r[i].href&&(e=r[i].href);t=(e||window.location.protocol).split(":")[0],e=e||window.location.href,window,o=e,n=document.referrer,/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(o)||(t="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif",n?(t+="?r="+encodeURIComponent(document.referrer),o&&(t+="&l="+o)):o&&(t+="?l="+o),(new Image).src=t)}()</script><script src="/js/local-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{load:["[tex]/mhchem"],source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},packages:{"[+]":["mhchem"]},tags:"ams"},options:{renderActions:{findScript:[10,d=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const a=new d.options.MathItem(e.textContent,d.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),a.start={node:t,delim:"",n:0},a.end={node:t,delim:"",n:0},d.math.push(a)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!1,notify:!0,appId:"m8FPP0CqMpxyTuUvaVOX9qVV-gzGzoHsz",appKey:"Ori6X9PXqQyURvwgl7HT5TJj",placeholder:"赠人玫瑰，手有余香",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>