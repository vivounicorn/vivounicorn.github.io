<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="-l60HPLrjDNbr3Ni1wLsNkiKiCWUAmxiC_ObB8vNMF0"><meta name="msvalidate.01" content="AF3396A141E1B198CA1BE76915B3969F"><meta name="yandex-verification" content="ee8492bd2e7708db"><meta name="baidu-site-verification" content="code-OBKi1CbRLy"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"vivounicorn.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:{enable:!0,onlypost:!1,loadingImg:"./images/loading.gif",isSPA:!1,preloadRatio:3},pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本章对于机器学习任务的一些通用框架做了介绍，包括经典架构以及AutoML。"><meta property="og:type" content="article"><meta property="og:title" content="机器学习与人工智能技术分享-第十二章 机器学习框架"><meta property="og:url" content="https://vivounicorn.github.io/article/b539fa9.html"><meta property="og:site_name" content="业精于勤，荒于嬉；行成于思，毁于随。"><meta property="og:description" content="本章对于机器学习任务的一些通用框架做了介绍，包括经典架构以及AutoML。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/ml.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/arch.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/automl.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/sim.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79lhrr214or1nrls9c1pj21q9t11.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79mkt3r1h1818pquqhjtm9h01e.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/model.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/tl.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/tt.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7a3p3rekds1ca71b7u1uf8htl3b.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/ex.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/nni.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7aeluhr5ab1fah1iom1gfm6g04g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7af9i68u73g1ldg8u8pd084t.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afap11cas11ov1najdq4150r5a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afdp411us7ve5bepauo1src5n.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afegfu1qfo1jom11hvq3p7nd64.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7affike1bo6k5k5bv36619nu6h.png"><meta property="article:published_time" content="2021-09-12T10:55:35.000Z"><meta property="article:modified_time" content="2021-12-22T07:58:54.091Z"><meta property="article:author" content="张磊"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="第十二章"><meta property="article:tag" content="机器学习框架"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png"><link rel="canonical" href="https://vivounicorn.github.io/article/b539fa9.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>机器学习与人工智能技术分享-第十二章 机器学习框架 | 业精于勤，荒于嬉；行成于思，毁于随。</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">业精于勤，荒于嬉；行成于思，毁于随。</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">花晨月夕</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div><div><img itemprop="image" src="https://vivounicorn.github.io/images/background.jpg"></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/article/b539fa9.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://vivounicorn.github.io/images/wali.png"><meta itemprop="name" content="张磊"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="业精于勤，荒于嬉；行成于思，毁于随。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">机器学习与人工智能技术分享-第十二章 机器学习框架</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-09-12 18:55:35" itemprop="dateCreated datePublished" datetime="2021-09-12T18:55:35+08:00">2021-09-12</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a> </span></span><span id="/article/b539fa9.html" class="post-meta-item leancloud_visitors" data-flag-title="机器学习与人工智能技术分享-第十二章 机器学习框架" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/article/b539fa9.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/article/b539fa9.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>19k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>17 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png" height="266"> 本章对于机器学习任务的一些通用框架做了介绍，包括经典架构以及AutoML。 <span id="more"></span></p><h1 id="机器学习框架">12. 机器学习框架</h1><h2 id="通用机器学习框架">12.1 通用机器学习框架</h2><h3 id="典型场景浅析">12.1.1 典型场景浅析</h3><p>机器学习的应用场景几乎涵盖了生活中的各个领域，最典型的场景有：</p><ul><li><p>面向C端的互联网场景 典型的有搜索、推荐、广告、风控，特点是：</p><p>1、<strong>数据量巨大</strong>，每天的样本量在亿~百亿量级，甚至更高，这个规模对数据处理有极大地挑战，基本都需要分布式存储和计算系统的支持，例如：Hadoop、Spark平台。</p><p>2、<strong>模型复杂、特征维度高、可解释性差</strong>，由于有丰富的数据(如：文本、图像、点击行为、浏览行为、下单行为等等)，所以在此基础上可以提取及交叉生成大量特征，例如，在计算广告中，广告本身的素材、广告的位置、广告的曝光量、广告的出价、用户的Demographic画像、用户的Geographic画像、用户的浏览路径、用户的点击行为、用户所处上下文、用户使用浏览器、广告+用户+上下文环境交叉产生的各种特征。机器学习本质上只揭示相关性不得出因果性，最终的模型每个特征会对这个相关性起到一定作用，所谓三个臭皮匠顶一个诸葛亮，所以理论上数据量越大、特征越丰富、反馈越及时，模型效果越好。当然，正是为了效果而使用了大量类似DNN的模型，导致可解释性变差。</p><p>3、<strong>在线实时性、并发性要求高</strong>，包含两方面：模型效果的实时性和系统响应的实时性。当用户行为能更快的反馈到模型中时，模型出现好效果的概率越大，一方面模型可以实时学习，一方面特征可以实时改变，这样通过反馈数据可以迅速调整模型，就像人一样，正常来说都是吃一堑长一智，通过发生行为-&gt;得到结果-&gt;进行调整-&gt;发生行为......的不断循环而进步。成功的互联网产品流量较高且对用户体验要求很高，势必要求请求量很高时系统依然能保证实时性，所以系统返回结果到用户面前一般都是毫秒级的，这就需要一方面系统并发性要好，一方面特征处理速度要快，另一方面模型单机Inference速度要够快。</p><p>4、<strong>离线模型训练时效性要求高</strong>，即使采用Online Learning，也需要离线模型的支持，一般为保证模型质量，每个模型每天至少训练一次，在特征维度和样本量这么高且实验模型数量可观的场景下(最典型的如：DNN，动辄上千万、上亿、上百亿的参数规模，学一次成本又高，产生的模型又大)，势必会影响模型训练时间，甚至量大了模型训练都跑不起来，而抽样又会破坏数据的真实分布，所以对离线大规模机器学习平台的要求就很高了。</p><p>5、<strong>数据采集和处理速度要求高</strong>，前面也说了，内容给用户展示后势必会产生用户反馈，这个反馈日志要尽快的解析、存储和处理，并及时推给模型训练或特征更新使用，当然这里对日志丢失的容忍度相对较高。</p><p>6、<strong>模型线上试错成本相对较低</strong>，以广告为例，利用E&amp;E算法，通过损失曝光机会进而损失部分收益来测算模型效果，但由于反馈时间短，可以很快的做调整。</p></li><li><p>面向B端的场景</p><p>对于大B端，一类是拥有和互联网C端类似场景的B端，数据量大、样本量大、实时性和并发性高，只是特征维度未必有那么高，但带来的系统挑战一点都不低，另一类是平台提供方，例如阿里云、腾讯云，更多的是通用工程层面和产品层面的挑战。 对于中小B端，一类会上云，利用平台方提供的IaaS、PaaS甚至SaaS，另一类会搭建自己的系统，典型的应用如面向汽车金融、融资租赁的风控平台，其特点是：</p><p>1、<strong>数据量中等但单条数据价值高</strong>，例如，假设汽车融资租赁的客单价为7w，每年卖出100w辆车，以融后资产质量数据为例，原始标注数据量为百万级别，远远小于传统互联网数据量，但极端的看，每条数据是花了7w的成本付出验证出来的。</p><p>2、<strong>模型相对复杂，特征维度一般，可解释性强</strong>，受限于数据量和场景，风控模型特征维度一般不高，但对可解释性要求很高，一方面风控业务向销售以及销售要向客户解释，另一方面风控业务要通过这种解释性反向影响风控政策或调整公司整体策略。</p><p>3、<strong>比较重视外部合规数据合作</strong>，由于平台本身的数据量及场景限制，需要寻找外部数据合作，这种合作可以是数据粒度的也可以是模型粒度的，但一定要保证所有合作数据的授权、获取是合规的，以及用户隐私能够被很好的保护，近年来的联邦学习可能是未来一种主流合作模式。</p><p>4、<strong>数据效果反馈滞后，对欺诈容忍度很低</strong>，金融资产总有个还款周期，例如典型的以“月”为周期，意味着资产被放出后过了1个月才能看到资产质量，如果发生欺诈，则第1~3个MOB就可能会批量出现问题，如果出现逾期也至少要等待1个月，所以客户真实反馈很滞后。</p><p>5、<strong>模型试错成本高</strong>，由于客单价较高，采用传统E&amp;E算法的试错成本会很高，所以其实用性一般较差，只有小额现金贷勉强可以使用此类方法，所以离线模型训练时需要想各种办法尽量模拟真实场景，一类重要的方法是拒绝推断，另一类是订单回放对比。另外模型测试指标要求更高，以AUC为例，在计算广告场景，AUC达到0.8就可以放心上去试跑了，在汽车消费风控场景，AUC超过0.85都心中打鼓。</p><p>6、<strong>系统实时性、并发性要求一般但稳定性要求更高</strong>，一方面业务单量没有那么大，并发性很低，另一方面由于使用外部数据，系统响应时间达到s级都很常见，但由于一个单子就影响到一个销售的业绩和前端竞争，所以稳定性很重要，要尽量保证系统不卡壳。</p></li></ul><h3 id="系统流程">12.1.2 系统流程</h3>一般的建模系统流程如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/ml.png" width="800"></center><p>以广告和推荐系统为例：</p><ul><li><p>数据准备和数据标注 样本生成分两部分：</p><p>1、<strong>离线部分</strong>，主要通过收集用户线上行为日志、已上线模型特征日志数据、业务日志数据而来，实时性要求低，一般会通过日志Stream服务收集到集群(如：hadoop集群)并持久化，所以日志设计非常关键，一方面是内容格式，要求扩展性要好，表达信息清晰而不易混淆，例如：已上线的不同版本模型的特征直接会被记录到日志中，如何区分模型、区分版本而又不会占用过多位是个有讲究的工作；另一方面是传输格式，常用的有非二进制的Xml、Json等和二进制的Pb、Thrift等，前者的好处是可读性好方便调试，但日志内容如果较为复杂传输成本高，隐私安全性低，后者反之，一般来说我们会采用后者。</p><p>2、<strong>在线部分</strong>，除了用日志Stream收集服务外一般还会辅以实时计算服务，实时收集和解析日志并做特征加工，一方面用于更新线上模型的离线特征，一方面为online learning算法提供实时特征，另一方面辅助类似频次控制这样的线上策略实施。</p><p>3、<strong>数据标注</strong>，对标注定义比较简单的场景，可以做到实时且无需人工介入的标注，例如：用户的点击行为、成交行为等，而对于图像分类、分割等复杂场景，需要专门平台甚至专人去做标注。由于目前机器学习的主流依然是监督学习，所以期待未来某天能从“人工+智能”过渡到人工智能，让机器去做人类做不了的事儿。</p></li><li><p>数据预处理及特征工程 我们收集到日志数据并做解析和简单处理后，一方面需要对数据做进一步清洗，例如：缺失值处理、丢弃、数据质检等，另一方面就是利用特征工程生成各种特征以备模型使用，特征要么是算法人员根据先验知识不断做实验打磨出来，要么利用特征生成算法(如：FM系列)或工具(如：FeatureTools)辅助生成，纯粹的End to End并不普遍，尤其是传统机器学习覆盖的场景，这个与原始特征的结构化复杂度有关，比如：图像识别，其原始特征是像素，很单一；一般的自然语言处理，其原子特征是字或词，相对单一，而像CTR预估的传统机器学习场景，其原始特征千差万别。</p></li><li><p>模型训练和融合 依据不同业务目标定义样本和构建模型，利用离线单机或并行机器学习工具训练模型，通过人工先验知识或启发式算法方式调整模型参数，得到最终离线模型。由于每个模型有各自特长，如：有的善于处理分类特征、有的则是连续特征、有的是文本特征等等，很多情况下需要融合这些模型的效果到一个大模型中，相应的可能带来效率上的挑战。当模型满足一定效果指标后(如，AUC)即可有资格到线上做实验，通过AB Test方式辅以E&amp;E策略做线上测试，效果好者逐渐扩大流量。</p></li><li><p>模型线上inference 真正做线上模型预测的服务，一方面取特征或生成特征，另一方面执行y=f(x)并返回结果，同步，日志系统会实时收集效果反馈。</p></li></ul><h3 id="系统架构">12.1.3 系统架构</h3><p>一个典型的机器学习框架如下：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/arch.png" width="550"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84.png" width="800"></center><ul><li>离线日志，数据存储在HDFS等分布式存储介质上，方便使用类似MapReduce方式做离线大规模数据处理，还可以复用自己或其他团队产生的用户画像信息作为特征。</li><li>离线特征工程，对数据做清洗和预处理后，可以利用单机或集群方式生成特征，从类型上说包括计数统计类特征、聚合类特征、单或交叉的Target Encoding特征、Embedding特征、图像特征、利用AutoML技术生成的组合特征等等，从时间切片上说包括实时特征、近实时特征、时间序列特征、T+1特征、T+N特征等等，生成的特征通过导出工具推送到线上特征工程微服务供大家使用，特征层面各个模型尽量复用。</li><li>在线特征工程，利用实时流微服务收集到的日志大多是用户反馈行为类日志，这部分时效性比较强的行为日志适合做实时特征，例如，用户点击了某个内容，同一地址用户短时集中点击了某个内容等等，特征生成后会自动推送到线上特征工程微服务，随后依照不同版本自动流入高响应的kv类存储介质中。</li><li>模型训练，以成熟的大规模机器学习框架及其他成熟机器学习框架为底层框架，中层提供常用算法组件和AutoML训练器，上层提供可视化模型构建平台，让使用者相对低成本做模型。对于大规模数据做训练，一般少不了参数服务器，其大致原理可以看<a target="_blank" rel="noopener" href="https://www.zybuluo.com/vivounicorn/note/446478#432-%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8parameter-server">这里</a>。</li><li>模型管理器，这里对模型的参数配置、版本、效果做管理和监控，训练好的模型会被推送到线上高响应的kv类存储介质中。</li><li>模型应用，以微服务方式，对每个版本的模型提供Inference服务，服务间互相独立且可横向扩展，既保证了稳定性又保证了并发性。</li><li>AB test，应用方的AB测试服务会根据实验策略不同实时配置相应的模型应用。</li></ul><h2 id="nni-automl框架介绍">12.2 NNI AutoML框架介绍</h2><h3 id="automl综述">12.2.1 AutoML综述</h3><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png" width="800"></center><p>上图选自<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1810.13306.pdf">《Taking the Human out of Learning Applications:A Survey on Automated Machine Learning》</a>一文。 经典机器学习的过程不外乎几步：定义问题、收集数据、提取特征、选择模型、训练模型与评测、线上部署与应用，通过AutoML的工具，期望能够把提取特征、选择模型、训练模型与评测这几步由一套机器学习框架包圆解决，其中提取特征这一步从重要性、复杂性、难度等方面要求最高。 形式化定义AutoML如下：</p><p><span class="math display">\[ \begin{eqnarray} \label{eq} \mathop{max}\limits_{config}&amp;\quad&amp;机器学习工具的效率和效果 \nonumber \\ s.t.&amp;\quad&amp;没有或少做人工干预 \nonumber \\ &amp;\quad&amp;可负担的有限计算资源 \nonumber \end{eqnarray} \]</span></p>其框架大致如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/automl.png" width="800"></center><p>在经典机器学习问题中：</p><ul><li><p>特征提取</p>1、简单组合搜索，可以采用事先定义简单组合策略，通过排列组合方式做特征生成，特征生成大多基于统计类方法，经典的工具如FeatureTools，例如：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/sim.png" width="400"></center>2、经典机器学习方法，利用FM、GBDT这类非线性模型作自动特征组合能够产生二阶以上特征，也可以做到特征提取+模型训练一体化，经典的论文如：<a target="_blank" rel="noopener" href="https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf">《Practical Lessons from Predicting Clicks on Ads at Facebook》</a>。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79lhrr214or1nrls9c1pj21q9t11.png" width="400"></center>3、DeepFM等深度学习方法，利用神经网络做更复杂特征的生成，也可以做到特征提取+模型训练一体化，但需要注意tradeoff效率和效果。 以下是DeepFM的经典结构，左边的FM部分是经典的因式分解机模式，可以高效的发现一阶和二阶特征，右边是深度网络部分，是一个前馈神经网络，用来生成二阶以上高阶特征，由于类似CTR预估问题的特征一般维度比较高且特征稀疏，大量类别特征与连续特征混排，所以神经网络的输入层一般会通过Embedding方式处理原始特征。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79mkt3r1h1818pquqhjtm9h01e.png" width="500"></center></li><li><p>模型选择</p>1、不管候选集、贪心还是启发式方法，都需要定义搜索空间，在有限搜索空间内选择并训练不同模型，同时做参数搜索调优，最终得到效果最好的模型，一般框架如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/model.png" width="500"></center>2、直接指定模型，但使用别人已经训练好的不同权重做初始化，即Transfer Learning，一般框架<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/tl.png" width="500"></center></li><li><p>模型训练</p><p>1、基于泰勒展开式的一阶和二阶优化算法，用来做目标函数最优化求解，代表算法：基于梯度的SGD、GD等和基于Hessian矩阵的L-BFGS等，详情可以见<a target="_blank" rel="noopener" href="https://www.zybuluo.com/vivounicorn/note/446478">第四章 最优化原理</a></p>2、非梯度优化算法，典型的有： 坐标下降法(Coordinate Descent)，属于一种非梯度优化的方法，它的每步迭代会沿某一个坐标的方向做一维搜索，通过切换不同坐标来求得目标函数局部最优解，可以看做是把一个优化问题分解为一组优化问题，直观的看：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image.png" width="400"></center>遗传算法，也是一种非梯度优化方法，更多的是利用生物进化思想做最优化求解，一般框架如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/tt.png" width="450"></center></li><li><p>模型评测</p><p>1、监督学习问题 对于分类问题，常用AUC、KS、F-Measure等，对于回归问题常用MSE、RMSE、MAE等。</p><p>2、非监督学习问题 开放性的无监督学习，效果评价一般看实际应用问题情况，也比较需要人工做评测。</p></li></ul><p>在深度学习问题中，最经典的是通过Neural Architecture Search(NAS)的方法寻找最优网络结构，<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/60414004">这里</a>有一个不错的资料。</p><h3 id="nni框架介绍">12.2.2 NNI框架介绍</h3><ul><li>NNI概述 NNI是18年MSRA发布的轻量级AutoML开源框架，Python编写，主要支持自动特征工程、NAS、最优模型参数搜索、模型压缩几个方面。整体设计和代码上比较简洁，上手难度比较低，支持可视化模式和命令行模式，大体情况如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7a3p3rekds1ca71b7u1uf8htl3b.png" width="600"></center><p>1、<strong>机器学习框架方面</strong>，它基本支持市面上所有主流的框架：<a target="_blank" rel="noopener" href="https://github.com/pytorch/pytorch">PyTorch</a>、<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow">TensorFlow</a>、<a target="_blank" rel="noopener" href="https://github.com/keras-team/keras">Keras</a>、<a target="_blank" rel="noopener" href="https://github.com/apache/incubator-mxnet">MXNet</a>、<a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">Caffe2</a>、<a target="_blank" rel="noopener" href="https://github.com/microsoft/CNTK">CNTK</a>、<a target="_blank" rel="noopener" href="http://spark.apache.org/mllib/">Spark MLlib</a>、<a target="_blank" rel="noopener" href="https://chainer.org/">Chainer</a>、<a target="_blank" rel="noopener" href="https://pypi.org/project/Theano/">Theano</a>。</p><p>2、<strong>机器学习库方面</strong>，工业界用的比较多的它都支持，如：<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/">Scikit-learn</a>、<a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a>、<a target="_blank" rel="noopener" href="https://catboost.ai/">CatBoost</a>、<a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a>。</p><p>3、<strong>模型参数搜索方面</strong>，它支持： 暴力搜索算法，包括：<a target="_blank" rel="noopener" href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">Random Search</a>、Grid Search、Batch； 启发式搜索算法，包括：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.01041.pdf">Naïve Evolution</a>、Anneal、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.06560.pdf">Hyperband</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.09846v1">PBT</a>； 贝叶斯优化算法，包括：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.01774">BOHB</a>、<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">TPE</a>、<a target="_blank" rel="noopener" href="https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf">SMAC</a>、<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/publication/metis-robustly-tuning-tail-latencies-cloud-systems/">Metis</a>、<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">Gaussian Process</a>； 基于强化学习的算法，包括：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.06347">PPO</a>。</p><p>4、<strong>NAS方面</strong>，几乎支持所有主流算法：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.03268">ENAS</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.09055">DARTS</a>、P-DARTS、<a target="_blank" rel="noopener" href="https://github.com/microsoft/nni/blob/master/docs/en_US/NAS/CDARTS.md#reference">CDARTS</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.00420">SPOS</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1812.00332.pdf">ProxylessNAS</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.10282">Network Morphism</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1912.10729.pdf">TextNAS</a>。</p><p>5、<strong>模型压缩方面</strong> 模型剪枝：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.01878">AGP Pruner</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1708.06519.pdf">Slim Pruner</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1811.00250.pdf">FPGM Pruner</a>； 模型量化：<a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Jacob_Quantization_and_Training_CVPR_2018_paper.pdf">QAT Quantizer</a>、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.06160">DoReFa Quantizer</a>。</p><p>6、<strong>特征工程方面</strong>，支持<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1908.10382.pdf">基于梯度搜索的算法</a>和<a target="_blank" rel="noopener" href="https://github.com/microsoft/LightGBM">基于LightGBM(一种GBDT实现)的算法</a>。在自动特征工程方面，整体偏弱。</p><p>7、<strong>迭代停止算法方面</strong>，支持<a target="_blank" rel="noopener" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46180.pdf">Medianstop</a>和<a target="_blank" rel="noopener" href="http://aad.informatik.uni-freiburg.de/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf">Curve Fitting</a>，整体上够用。</p><p>8、<strong>部署方面</strong>，支持本地化部署、远程集群部署、基于K8s的部署。</p></li><li><p>逻辑框架</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/ex.png" width="600"></center><p>1、<strong>Configuration</strong>，NNI通过配置文件指定各种策略和运行环境，一个典型的配置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">authorName: zhanglei</span><br><span class="line">experimentName: auto-catboost</span><br><span class="line"><span class="comment"># trial的最大并发数</span></span><br><span class="line">trialConcurrency: <span class="number">10</span></span><br><span class="line"><span class="comment"># 实验最多执行时间</span></span><br><span class="line">maxExecDuration: 1h</span><br><span class="line"><span class="comment"># Trial的个数</span></span><br><span class="line">maxTrialNum: <span class="number">1000</span></span><br><span class="line"><span class="comment"># 训练平台，可选项有: local, remote, pai</span></span><br><span class="line">trainingServicePlatform: local</span><br><span class="line"><span class="comment"># 参数或结构搜索空间定义</span></span><br><span class="line">searchSpacePath: search_space.json</span><br><span class="line"><span class="comment"># 取值为false，则上面的搜索空间json文件需要定义</span></span><br><span class="line"><span class="comment"># 取值为true，则需要在代码中以Annotation方式加入搜索空间定义，例如：</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"><span class="comment"># &quot;&quot;&quot;@nni.variable(nni.choice(0.1, 0.5), name=dropout_rate)&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#        dropout_rate = 0.5</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"><span class="comment"># 表示dropout_rate这个变量有两个取值选择：0.1或0.5</span></span><br><span class="line">useAnnotation: false</span><br><span class="line">tuner:</span><br><span class="line">  <span class="comment"># 参数或结构搜索策略定义，可选项有:</span></span><br><span class="line">  <span class="comment"># TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner, SMAC等，有些需要单独安装</span></span><br><span class="line">  builtinTunerName: TPE</span><br><span class="line">  classArgs:</span><br><span class="line">    <span class="comment"># 选择求解目标函数最大值还是最小值: maximize, minimize</span></span><br><span class="line">    optimize_mode: maximize</span><br><span class="line">trial:</span><br><span class="line">  <span class="comment"># Trial代码所在目录位置、可执行文件及GPU配置</span></span><br><span class="line">  command: python3 catboost_trainer.py</span><br><span class="line">  codeDir: .</span><br><span class="line">  gpuNum: <span class="number">0</span></span><br></pre></td></tr></table></figure><p></p><p>2、<strong>Search Space</strong>，搜索空间定义，一种方式是通过一个json文件定义，一种方式是代码里加Annotation，一个典型的例子如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;num_leaves&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;randint&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">20</span>, <span class="number">150</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;bagging_fraction&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.5</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;feature_fraction&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.5</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;reg_alpha&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;reg_lambda&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;lambda_l1&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">10</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;lambda_l2&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">10</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;bagging_freq&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">10</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>_type为choice，表示参数选择范围是_value指定的候选参数； _type为randint，表示参数选择范围是_value指定的上下界之间的整数； _type为uniform，表示参数选择范围是_value指定的上下界之间通过均匀分布得到的数； _type为uniform，表示参数选择范围是_value指定的上下界，并用均匀分布生成的参数，此外还有quniform、loguniform、qloguniform、normal、qnormal、lognormal、qlognormal几种分布。<p></p><p>3、<strong>Tuner</strong>，是参数或结构的搜索策略，利用它可以为每个Trial生成相应的参数集合，除了内置的Tuner算法外，也可以自定义Tuner，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nni.tuner <span class="keyword">import</span> Tuner</span><br><span class="line"><span class="comment"># 自定义的Tuner需要继承Tuner基类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomizedTuner</span>(<span class="params">Tuner</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ...</span>):</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">receive_trial_result</span>(<span class="params">self, parameter_id, parameters, value, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    返回一个Trial的最终效果指标，可以是字典(但必须由默认key)，也可以是某个值</span></span><br><span class="line"><span class="string">    parameter_id: int类型</span></span><br><span class="line"><span class="string">    parameters: 由&#x27;generate_parameters()&#x27;函数生成</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 你的代码实现</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate_parameters</span>(<span class="params">self, parameter_id, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    生成一个Trial所需的参数，并以序列化方式存储</span></span><br><span class="line"><span class="string">    parameter_id: int类型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 你的代码实现.</span></span><br><span class="line">    <span class="keyword">return</span> your_parameters</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>使用时需要在配置文件的tuner属性中指定，例如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tuner:</span><br><span class="line">  <span class="comment"># 代码目录</span></span><br><span class="line">  codeDir: /home/abc/mytuner</span><br><span class="line">  <span class="comment"># 自定义Tuner类名</span></span><br><span class="line">  classFileName: my_customized_tuner.py</span><br><span class="line">  className: CustomizedTuner</span><br><span class="line">  <span class="comment"># 自定义Tuner的构造函数参数指定</span></span><br><span class="line">  classArgs:</span><br><span class="line">    arg1: value1</span><br></pre></td></tr></table></figure><p></p><p>4、<strong>Trial</strong>，是一次模型学习的尝试，它使用Tuner生成的参数初始化模型，而后做模型训练，并返回最终训练效果，一个CatBoost做AutoML的例子如下：</p><p>1)、定义CatBoost类：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    class CatBoostModel</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> catboost <span class="keyword">as</span> cb</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> cat_fea_cleaner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatBoostModel</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.catboost_params = kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        self.eval_ratio = kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        self.early_stopping_rounds = kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        self.num_boost_round = kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        self.cat_features = kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        self.all_features = kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.selected_features_ = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.y = <span class="literal">None</span></span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y, **kwargs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Paramters</span></span><br><span class="line"><span class="string">        ---------</span></span><br><span class="line"><span class="string">        X : array-like numpy matrix</span></span><br><span class="line"><span class="string">            The training input samples, which shape is [n_samples, n_features].</span></span><br><span class="line"><span class="string">        y : array-like numpy matrix</span></span><br><span class="line"><span class="string">            The target values (class labels in classification, real numbers in</span></span><br><span class="line"><span class="string">            regression). Which shape is [n_samples].</span></span><br><span class="line"><span class="string">        catboost_params : dict</span></span><br><span class="line"><span class="string">            Parameters of lightgbm</span></span><br><span class="line"><span class="string">        eval_ratio : float</span></span><br><span class="line"><span class="string">            The ratio of data size. It&#x27;s used for split the eval data and train data from self.X.</span></span><br><span class="line"><span class="string">        early_stopping_rounds : int</span></span><br><span class="line"><span class="string">            The early stopping setting in lightgbm.</span></span><br><span class="line"><span class="string">        num_boost_round : int</span></span><br><span class="line"><span class="string">            num_boost_round in lightgbm.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = train_test_split(self.X,</span><br><span class="line">                                                            self.y,</span><br><span class="line">                                                            test_size=self.eval_ratio,</span><br><span class="line">                                                            random_state=random.seed(<span class="number">41</span>))</span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_sets=catboost_eval,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_selected_features</span>(<span class="params">self, topk</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        list :</span></span><br><span class="line"><span class="string">                Return the index of imprtant feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> topk &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.selected_features_ = self.feature_importance.argsort()[-topk:][::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.selected_features_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, num_iteration=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.model.predict(X, num_iteration)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_fea_importance</span>(<span class="params">self, clf, columns</span>):</span></span><br><span class="line">        importances = clf.feature_importances_</span><br><span class="line">        indices = np.argsort(importances)[::-<span class="number">1</span>]</span><br><span class="line">        importance_list = []</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columns)):</span><br><span class="line">            importance_list.append((columns[indices[f]], importances[indices[f]]))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % (f + <span class="number">1</span>, <span class="number">30</span>, columns[indices[f]], importances[indices[f]]))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;another feature importances with prettified=True\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(clf.get_feature_importance(prettified=<span class="literal">True</span>))</span><br><span class="line">        importance_df = pd.DataFrame(importance_list, columns=[<span class="string">&#x27;Features&#x27;</span>, <span class="string">&#x27;Importance&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> importance_df</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span>(<span class="params">self, X, y, test_size, random_state=<span class="number">2020</span></span>):</span></span><br><span class="line">        sss = <span class="built_in">list</span>(StratifiedShuffleSplit(</span><br><span class="line">            n_splits=<span class="number">1</span>, test_size=test_size, random_state=random_state).split(X, y))</span><br><span class="line">        X_train = np.take(X, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        X_eval = np.take(X, sss[<span class="number">0</span>][<span class="number">46</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_train = np.take(y, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_eval = np.take(y, sss[<span class="number">0</span>][<span class="number">47</span>], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [X_train, X_eval, y_train, y_eval]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">catboost_model_train</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                        df,</span></span></span><br><span class="line"><span class="params"><span class="function">                        finetune=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        target_name=<span class="string">&#x27;Label&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        id_index=<span class="string">&#x27;Id&#x27;</span></span>):</span></span><br><span class="line">        df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">        feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> self.cat_features:</span><br><span class="line">                <span class="comment">#df[i].fillna(-999, inplace=True)</span></span><br><span class="line">                <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = self.train_test_split(df[feature_name],</span><br><span class="line">                                                          df[target_name].values,</span><br><span class="line">                                                          self.eval_ratio,</span><br><span class="line">                                                          random.seed(<span class="number">41</span>))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               init_model=finetune,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_set=catboost_eval,</span><br><span class="line">                               verbose_eval=<span class="number">50</span>,</span><br><span class="line">                               plot=<span class="literal">True</span>,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line">        metrics = self.model.eval_metrics(data=catboost_eval,metrics=[<span class="string">&#x27;AUC&#x27;</span>],plot=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;AUC values:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.array(metrics[<span class="string">&#x27;AUC&#x27;</span>])))</span><br><span class="line">        <span class="keyword">return</span> self.feature_importance, metrics, self.model</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2)、定义模型训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> bz2</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_svmlight_file</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> nni</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models.auto_catboost.catboost_model <span class="keyword">import</span> CatBoostModel</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> write_feature_importance</span><br><span class="line"><span class="keyword">from</span> feature_engineering.feature_data_processing.dataset_formater <span class="keyword">import</span> read_columns2list</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> name2feature, get_default_parameters, cat_fea_cleaner</span><br><span class="line"><span class="keyword">from</span> tools.CONST <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;auto_catboost&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainer_and_tester_run</span>(<span class="params">feature_file_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                           train_file_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                           test_file_name_list,</span></span></span><br><span class="line"><span class="params"><span class="function">                           feature_imp_name</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    以批量方式训练CatBoost模型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    fea = read_columns2list(feature_file_name, <span class="number">1</span>)</span><br><span class="line">    cat_fea = [item <span class="keyword">for</span> item <span class="keyword">in</span> fea <span class="keyword">if</span> item.startswith(<span class="string">&#x27;C&#x27;</span>)]</span><br><span class="line">    chunker = pd.read_csv(train_file_name,</span><br><span class="line">                          sep=<span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                          chunksize=<span class="number">10000000</span>,</span><br><span class="line">                          low_memory=<span class="literal">False</span>,</span><br><span class="line">                          header=<span class="number">0</span>,</span><br><span class="line">                          usecols=[ColumnType.TARGET_NAME] + fea)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从Tuner获得参数</span></span><br><span class="line">    RECEIVED_PARAMS = nni.get_next_parameter()</span><br><span class="line">    logger.debug(RECEIVED_PARAMS)</span><br><span class="line">    PARAMS = get_default_parameters(<span class="string">&#x27;catboost&#x27;</span>)</span><br><span class="line">    PARAMS.update(RECEIVED_PARAMS)</span><br><span class="line">    logger.debug(PARAMS)</span><br><span class="line"></span><br><span class="line">    cb = CatBoostModel(catboost_params=PARAMS,</span><br><span class="line">                    eval_ratio=<span class="number">0.33</span>,</span><br><span class="line">                    early_stopping_rounds=<span class="number">20</span>,</span><br><span class="line">                    cat_features=cat_fea,</span><br><span class="line">                    all_features=fea,</span><br><span class="line">                    num_boost_round=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is starting...&quot;</span>)</span><br><span class="line">    clf = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 数据量太大需要分片训练</span></span><br><span class="line">    <span class="keyword">for</span> df <span class="keyword">in</span> chunker:</span><br><span class="line">        df = cat_fea_cleaner(df, ColumnType.TARGET_NAME, ColumnType.ID_INDEX, cat_fea)</span><br><span class="line">        feature_imp, val_score, clf = \</span><br><span class="line">            cb.catboost_model_train(df,</span><br><span class="line">                                clf,</span><br><span class="line">                                target_name=ColumnType.TARGET_NAME,</span><br><span class="line">                                id_index=ColumnType.ID_INDEX)</span><br><span class="line"></span><br><span class="line">        logger.info(feature_imp)</span><br><span class="line">        logger.info(val_score)</span><br><span class="line">        write_feature_importance(feature_imp,</span><br><span class="line">                                 feature_file_name,</span><br><span class="line">                                 feature_imp_name, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">del</span> df</span><br><span class="line">    gc.collect()</span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is ended.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(test_file_name_list) == <span class="number">0</span>:</span><br><span class="line">        logger.debug(<span class="string">&quot;No testing file is found.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    av_auc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> test_file_name_list:</span><br><span class="line">        av_auc = av_auc + inference(clf, fea, cat_fea, fname)</span><br><span class="line">    av_auc = av_auc/<span class="built_in">len</span>(test_file_name_list)</span><br><span class="line">    nni.report_final_result(av_auc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">clf, fea, cat_fea, test_file_name</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    线上CatBoost模型预测</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_file_name):</span><br><span class="line">        logger.error(<span class="string">&quot;the file &#123;0&#125; is not exist.&quot;</span>.<span class="built_in">format</span>(test_file_name))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The testing process is starting...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        df = pd.read_csv(test_file_name,</span><br><span class="line">                         sep=<span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                         header=<span class="number">0</span>,</span><br><span class="line">                         usecols=[ColumnType.TARGET_NAME] + fea)</span><br><span class="line"></span><br><span class="line">        df = cat_fea_cleaner(df, ColumnType.TARGET_NAME, ColumnType.ID_INDEX, cat_fea)</span><br><span class="line">        y_pred = clf.predict(df[fea])</span><br><span class="line">        auc = roc_auc_score(df[ColumnType.TARGET_NAME].values, y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;0&#125;&#x27;s auc of prediction:&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(os.path.split(test_file_name)[<span class="number">1</span>], auc))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">&quot;The inference process is ended.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> auc</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        logger.error(<span class="string">&quot;inference error with file:&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(test_file_name))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_offline</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    离线模型训练</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    base_dir = <span class="string">&#x27;/home/liyiran/PycharmProjects/DeepRisk/data/fresh.car/&#x27;</span></span><br><span class="line">    train_file_name = base_dir + <span class="string">&#x27;tt&#x27;</span></span><br><span class="line">    test_file_name_list = [base_dir + <span class="string">&#x27;outer_test_2019-01.tsv&#x27;</span>]</span><br><span class="line">    feature_file_name = base_dir + <span class="string">&#x27;features.dict&#x27;</span></span><br><span class="line">    feature_imp_name = base_dir + <span class="string">&#x27;features.imp&#x27;</span></span><br><span class="line">    trainer_and_tester_run(feature_file_name, train_file_name, test_file_name_list, feature_imp_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run_online()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>5、<strong>Assessor</strong>，使用提前停止迭代策略评估Trial是否可以结束训练。</p></li><li>基本架构<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/nni.png" width="800"></center><p><strong>NNIManager</strong>是管理中枢，负责管理串联Trial、Rest接口服务、中间数据存储、日志调用服务、配置文件服务、训练平台服务等。 <strong>SDK</strong>是一系列核心类的实现，包括MsgDispatcher、通信协议、Tuner、Trial、Assessor等，其中MsgDispatcher是整个消息处理的中心。</p></li><li><p>基本流程</p><p>NNI运转流程可用以下伪码描述：</p><blockquote><p><strong>输入</strong>: 参数搜索空间、Trial类实现、配置文件</p></blockquote><blockquote><p><strong>输出</strong>: 最优模型参数</p></blockquote><blockquote><p><strong>算法</strong>：</p></blockquote><p><span class="math display">\[ \begin{align*} &amp; 1: For \ t = 0, ..., trial个数:\\ &amp; 2: \qquad 超参数 = 从搜索空间选择一组参数\\ &amp; 3: \qquad 最终结果= 用上步给定超参数训练trial并做效果评估\\ &amp; 4: \qquad 将执行结果反馈给nni\\ &amp; 5: \qquad 如果到达最大迭代次数或满足提前停止迭代条件:\\ &amp; 6: \qquad\qquad 结束实验\\ &amp; 7: 返回最优超参数和相应模型权重 \end{align*} \]</span></p></li><li>执行效果<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nnictl stop</span><br><span class="line">nnictl create --config models/auto_catboost/config.yml -p <span class="number">8070</span></span><br></pre></td></tr></table></figure>1、控制台上会显示一次实验的概览以及webUI地址：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7aeluhr5ab1fah1iom1gfm6g04g.png" width="800"></center>2、首页展示实验当前状态，包括参数、运行时长、当前最优模型、效果最好的Top 10 Trial情况。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7af9i68u73g1ldg8u8pd084t.png" width="800"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afap11cas11ov1najdq4150r5a.png" width="800"></center>3、详情页会展示超参数搜索情况、每个Trial执行时间和它的执行日志、参数情况，这里有个缺点是查看日志不方便，需要拷贝日志路径到宿主机上看，另外调试也不太方便。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afdp411us7ve5bepauo1src5n.png" width="800"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afegfu1qfo1jom11hvq3p7nd64.png" width="800"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7affike1bo6k5k5bv36619nu6h.png" width="800"></center></li></ul><p>总的来说，NNI是一个非常优秀的AutoML工具，文档也比较完善，还有中文版，本文抛砖引玉，期望未来框架能更加完善，尤其在自动特征工程方面，也希望大家能贡献自己的力量上去。</p></div><div class="popular-posts-header">相关文章推荐</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/d677b2e0.html" rel="bookmark">机器学习与人工智能技术分享-第三章 机器学习中的统一框架</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/ad2261a2.html" rel="bookmark">机器学习与人工智能技术分享-第四章 最优化原理</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/307f39c.html" rel="bookmark">机器学习与人工智能技术分享-第二章 建模方法回顾</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/b12a240.html" rel="bookmark">机器学习与人工智能技术分享-第九章 语义分割</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/fb9cd06d.html" rel="bookmark">机器学习与人工智能技术分享-第七章 金融风控</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a> <a href="/tags/%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0/" rel="tag"># 第十二章</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" rel="tag"># 机器学习框架</a></div><div class="post-nav"><div class="post-nav-item"><a href="/article/301f2134.html" rel="prev" title="机器学习与人工智能技术分享-第十一章 OCR"><i class="fa fa-chevron-left"></i> 机器学习与人工智能技术分享-第十一章 OCR</a></div><div class="post-nav-item"><a href="/article/a9650e95.html" rel="next" title="机器学习与人工智能技术分享-第十三章 ADAS与自动驾驶">机器学习与人工智能技术分享-第十三章 ADAS与自动驾驶 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let e=CONFIG.comments["activeClass"];if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"><span class="nav-text">12. 机器学习框架</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6"><span class="nav-text">12.1 通用机器学习框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B8%E5%9E%8B%E5%9C%BA%E6%99%AF%E6%B5%85%E6%9E%90"><span class="nav-text">12.1.1 典型场景浅析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E6%B5%81%E7%A8%8B"><span class="nav-text">12.1.2 系统流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84"><span class="nav-text">12.1.3 系统架构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nni-automl%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D"><span class="nav-text">12.2 NNI AutoML框架介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#automl%E7%BB%BC%E8%BF%B0"><span class="nav-text">12.2.1 AutoML综述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nni%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D"><span class="nav-text">12.2.2 NNI框架介绍</span></a></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="张磊" src="https://vivounicorn.github.io/images/wali.png"><p class="site-author-name" itemprop="name">张磊</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">14</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">2</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">46</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="sidebar-button motion-element"><i class="fa fa-comment"></i> Chat</div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/vivounicorn" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zhangleisuper@gmail.com" title="E-Mail → mailto:zhangleisuper@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/vivounicorn" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">张磊</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">492k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">7:27</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div></div></footer></div><script src="//cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>!function(){var e,t,o,n,r=document.getElementsByTagName("link");if(0<r.length)for(i=0;i<r.length;i++)"canonical"==r[i].rel.toLowerCase()&&r[i].href&&(e=r[i].href);t=(e||window.location.protocol).split(":")[0],e=e||window.location.href,window,o=e,n=document.referrer,/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(o)||(t="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif",n?(t+="?r="+encodeURIComponent(document.referrer),o&&(t+="&l="+o)):o&&(t+="?l="+o),(new Image).src=t)}()</script><script src="/js/local-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{load:["[tex]/mhchem"],source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},packages:{"[+]":["mhchem"]},tags:"ams"},options:{renderActions:{findScript:[10,d=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const a=new d.options.MathItem(e.textContent,d.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),a.start={node:t,delim:"",n:0},a.end={node:t,delim:"",n:0},d.math.push(a)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!1,notify:!0,appId:"m8FPP0CqMpxyTuUvaVOX9qVV-gzGzoHsz",appKey:"Ori6X9PXqQyURvwgl7HT5TJj",placeholder:"赠人玫瑰，手有余香",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>