<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><meta name="google-site-verification" content="-l60HPLrjDNbr3Ni1wLsNkiKiCWUAmxiC_ObB8vNMF0"><meta name="msvalidate.01" content="AF3396A141E1B198CA1BE76915B3969F"><meta name="yandex-verification" content="ee8492bd2e7708db"><meta name="baidu-site-verification" content="code-OBKi1CbRLy"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"vivounicorn.github.io",root:"/",scheme:"Muse",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"always",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!0,mediumzoom:!1,lazyload:{enable:!0,onlypost:!1,loadingImg:"./images/loading.gif",isSPA:!1,preloadRatio:3},pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="本章对机器视觉方面的深度神经网络做了历史回顾及原理介绍，由于这方面技术发展很快，所以文章内容主要集中于几个极具代表性的框架。"><meta property="og:type" content="article"><meta property="og:title" content="机器学习与人工智能技术分享-第五章 深度神经网络"><meta property="og:url" content="https://vivounicorn.github.io/article/783e74f9.html"><meta property="og:site_name" content="业精于勤，荒于嬉；行成于思，毁于随。"><meta property="og:description" content="本章对机器视觉方面的深度神经网络做了历史回顾及原理介绍，由于这方面技术发展很快，所以文章内容主要集中于几个极具代表性的框架。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1asuka9jl1u479sd1k7l64l11s2m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1avm00h74gbiodp19bv1sbj19au1j.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bam7ahp49p41r9s1a7pe5g1ags9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a0q0pg13mp31k17d41ni0sabi.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s7tchpjd91hq3j4l1n6n2f11g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s71detai81p86nl3uobg9h13.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbehg11su3pj3ksq92mvj12n.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbvo0ourbp1nesm1eg518no3h.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc08fspt4vju1ql6184d4ci3u.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc818png019o31tckas91d6r4o.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0scomd1143ebfh1iq918jencv5i.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdf86mtg1i5110kv1kc3gl776.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdotesps7177gsg9188bl0p7j.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6io9a0j12rlem41vklu4tjfe13.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6isstg3thaur990dsvn1bjq1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6it7aknd6aabt41sr9i16vj1t.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ito67157a3lji5b1vs4f932a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9e6ve110a1bs81ph1bao1l1n2n.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9fhp91quu11461ljn70418p734.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ja5d7k7pr1ee017s57201jr33h.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77kp1qgjns27t83h1m86cvem.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77m4h5p1kes1nmt1c9068flcr13.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77mrpk7iql1vcd1mtsnnn154l1p.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77rq7l71v78t1f2u6kob1cvm26.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77s7vp8hta1ikg1h041juv1i1c2j.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sfnrui1mvnnnd1l2p1t68nm880.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b72kbakimjb19plrt512qj1t6e16.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0shaditah31jeuur91te010718d.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b8b8u29j17gqo4713s12fsme39.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77tbfq8ml168019l1p6t36i9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aab1kq13lbvgbkfq1e0o1qb1c.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aac0i71ibcppe89e1sh61fv11p.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1baou2biq9uhumh1tm1d95du99.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a4mkcb1m76g9ue2g92jn97v.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb836lcgb616edc351dnct96m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb83e7v01up1olv1r98e68lpf1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbdegnoi6i44cpr7n19r7dhs9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvdmto1d13f3mj8csu94fu1t.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv7v5le1fkv1id5fe5180v17lt9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv8dth1kq99h1vvn1j72ofl13.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvjlvf9g4gl591a301tnn7722a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbj7cd733bns621ibu9p9g8d9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvq8lr81905f8m1do2fta2b59.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bccghn95ouk13mihb18dk1htum.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcgu3avu1dc10dc1gbm1jmdpdt9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch1m72996df6b1aqpjb43ka1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch28tob175blpk1mri13no1gas2a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch6qshn1uu8evo1mek1q04j0j2n.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjstr2317mfjvu1vmk1ks650tp.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjtdpgvo9d4mu1qgvnnf1as816.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcju6o25j461qs419hj175kbv23.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjunpd21l3d15gltbnb3c1flo2g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck0vn7b165t11ic1r8qq4btb32t.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck114mu1q796bt1a1n17oi1ejg47.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck10n9n1oriqt7k915eb1psv3q.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bckd30m886a135elhmf2m125c5u.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcuf44v814n11e17eco10fqha4i.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdfrbd74dti1kpn8b2nho1l9u9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahcfttqvb61mgjjom10f0qjg9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahdkbr71mq0bnoen29g715t3m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahgd34419nmh3l15hk6srpvc1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15as53vqk1k4b1g601kic180s9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd5oqug8c827q01unr1i701lab9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd16cnk617e3160k1uvuar8n032q.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15r350126392fmchslo1uh120.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd8rs6me1krhgtl1jvh164rt1s9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd91d78tsrb1qjl8jk1hio16dnm.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd92vlme2jdpg82ie1nclfa913.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd99affn1qkv1c1roijq4j10l526.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bddsvlg8mt7ejo267fso1pdp1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtd6v182o9m1ua0r1df01dtl1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtavq8vm617es57jul11f7hm.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtjnc2l13p71a88fpv1n001nuj2a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtueg4i30e4p1gbu1oukdc9m.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be4l9h9t1sjrd4b1m3f1bkj1dp29.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be7flg7p1aeu7gi1jo17ulctr9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9mjahe8hj1ceus9q1curia09.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9nrvv21ior1jdamaqea0u4213.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9opsk11bmu1vj5ovf145e85g1g.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9q5nr61700p257kh1ov3j2v1t.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9qg7hf1ssd1e7vukj40f8hb2a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea0k93g3969st1toj1bbs1vde9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea31r2e1oid1cu8t4v3hm1vq99.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea36i8k1oru10st3q1d511qdsm.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1befm4g8r8g6sgh1u8n1dth164kp.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hm83q5rk1ttipqt70r14ga9.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hrcg0a6s1en84ar12k5biqm.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6iba8vp69ju84ta17v1p7q2a.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6idndrpt51ausorpq619rh2n.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6jjcg313ln151n1o74q9ctm73h.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k09d6q3v1d7mq711i3m1ifr3u.png"><meta property="og:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k67a4p9shmi1tgl1l7e7354r.png"><meta property="article:published_time" content="2021-09-05T09:49:19.000Z"><meta property="article:modified_time" content="2022-01-04T01:54:31.262Z"><meta property="article:author" content="张磊"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="第五章"><meta property="article:tag" content="CNN"><meta property="article:tag" content="深度神经网络"><meta property="article:tag" content="模型可视化"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png"><link rel="canonical" href="https://vivounicorn.github.io/article/783e74f9.html"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>机器学习与人工智能技术分享-第五章 深度神经网络 | 业精于勤，荒于嬉；行成于思，毁于随。</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">业精于勤，荒于嬉；行成于思，毁于随。</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">花晨月夕</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div><div><img itemprop="image" src="https://vivounicorn.github.io/images/background.jpg"></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/article/783e74f9.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://vivounicorn.github.io/images/wali.png"><meta itemprop="name" content="张磊"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="业精于勤，荒于嬉；行成于思，毁于随。"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">机器学习与人工智能技术分享-第五章 深度神经网络</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2021-09-05 17:49:19" itemprop="dateCreated datePublished" datetime="2021-09-05T17:49:19+08:00">2021-09-05</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a> </span></span><span id="/article/783e74f9.html" class="post-meta-item leancloud_visitors" data-flag-title="机器学习与人工智能技术分享-第五章 深度神经网络" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/article/783e74f9.html#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/article/783e74f9.html" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>109k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1:39</span></span></div></header><div class="post-body" itemprop="articleBody"><p><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png" width="266"> 本章对机器视觉方面的深度神经网络做了历史回顾及原理介绍，由于这方面技术发展很快，所以文章内容主要集中于几个极具代表性的框架。 <span id="more"></span></p><h1 id="深度神经网络">5. 深度神经网络</h1><p>深度学习是基于多层神经网络的一种对数据进行自动表征学习的框架，能使人逐步摆脱传统的人工特征提取过程，它的基础之一是distributed representation，读论文时注意以下概念区分：</p><ul><li><p>Distributional representation</p><p>Distributional representation是基于某种分布假设和上下文共现的一类表示方法，比如，对于词的表示来说：有相似意义的词具有相似的分布。</p><p>从技术上讲这类方法的缺点是：通常对存储敏感，在representation上也不高效，但是优点是：算法相对简单，甚至像LSA那样简单的线性分解就行。</p><p>几类常见的Distributional representation模型：</p><ul><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Latent_semantic_analysis">Latent semantic analysis</a></p></li><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet allocation</a></p></li><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Self-organizing_map">Self-organizing map</a></p></li><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Hyperspace_Analogue_to_Language">HAL</a></p></li><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Independent_component_analysis">Independent component analysis</a></p></li><li><p><a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Random_indexing">Random indexing</a></p></li></ul></li><li><p>Distributed representation</p><p>Distributed representation是对实体（比如：词、车系编号、微博用户id等等）稠密、低维、实数的向量表示，也就是常说的embedding，它不需要做分布假设，向量的每个维度代表实体在某个空间下的隐含特征。</p><p>从技术上讲它的缺点是：计算代价较高，算法往往不简单直接，通常通过神经网络/深度神经网络实现，优点是：对原始信息的有效稠密压缩表示，不仅仅是考虑“共现”，还会考虑其他信息，比如：“时序”等。</p><p>几类常见的Distributed representation模型：</p><ul><li><p>Collobert and Weston embeddings</p></li><li><p>HLBL embeddings</p></li></ul></li></ul><p>关于Distributional representation和Distributed representation以及几个相关概念，看论文<a target="_blank" rel="noopener" href="http://www.aclweb.org/anthology/P10-1040">Word representations: A simple and general method for semi-supervised learning</a>即可明了。</p><h2 id="反向传播">5.1 反向传播</h2>反向传播是神经网络参数学习的必备工具，以经典的多层前向神经网络为例：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1asuka9jl1u479sd1k7l64l11s2m.png" width="350"></center>整个网络可以认为是以下结构的重复，其中n代表处于第几层：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1avm00h74gbiodp19bv1sbj19au1j.png" width="350"></center><p>假设：</p><p>1、当<span class="math inline">\(n=o\)</span>为输出层时，整个网络的误差表示为：<span class="math inline">\(E^o(X^o,D)\)</span>，其中<span class="math inline">\(D\)</span>为期望输出；</p><p>2、任意层的激活函数表示为<span class="math inline">\(F(x)\)</span>；</p><p>3、第<span class="math inline">\(n\)</span>层输入为上一层输出<span class="math inline">\(X^{n-1}\)</span>，该层权重为<span class="math inline">\(W^n\)</span>，则:</p><p>该层中间输出为：<span class="math inline">\(Y^n=W^nX^{n-1}\)</span> 该层输出为：<span class="math inline">\(X^n=F(Y^n)\)</span>。</p><p>那么误差反向传播原理为：</p><p><span class="math display">\[ \begin{array}{l} \frac{\partial E^o}{\partial Y^n}=F&#39;(Y^n)\frac{\partial E^o}{\partial X^n}\\ \frac{\partial E^o}{\partial W^n}=X^{n-1}\frac{\partial E^o}{\partial Y^n}\\ \frac{\partial E^o}{\partial X^{n-1}}=(W^n)^T\frac{\partial E^o}{\partial Y^n}\\ \end{array} \]</span> 其中，定义<span class="math inline">\(\delta^n=\frac{\partial E^o}{\partial Y^n}\)</span>为误差反向传播时第<span class="math inline">\(n\)</span>层某个节点的“误差敏感度”。</p><p>参数学习过程为：<span class="math inline">\(W_t=W_{t-1}-\eta \frac{\partial E}{\partial W_{t-1}}\)</span>，其中<span class="math inline">\(\eta\)</span>的讨论前文已经做过不在赘述，应用导数的链式传导原理，所有层的权重都将得到更新。</p><h2 id="卷积网络结构演化史">5.2 卷积网络结构演化史</h2>网络结构的发展历程更像是一个<strong>实验科学</strong>的过程，人们通过不断地尝试和实验来得到与验证各种网络结构。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bam7ahp49p41r9s1a7pe5g1ags9.png" width="800"></center><h2 id="cnn基本原理">5.3 CNN基本原理</h2><strong>卷积</strong>神经网络是我认为非常好用的一类神经网络结构，当数据具有局部相关性时是一种比较好选择，在图像、自然语言处理、棋类竞技、新药配方研制等方面有广泛应用。比如，经典的LeNet-5网络结构：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png" width="800"></center><h3 id="sigmoid激活函数">5.3.1 Sigmoid激活函数</h3>激活函数是神经网络必备工具，而Sigmoid激活函数是早期神经网络最普遍的选择。Sigmoid函数是类神奇的函数，广义上所有形为“S”的函数都可叫做Sigmoid函数，从早期的感知机模型中Sigmoid函数就被用来模拟生物细胞的激活反应，所以又被叫做激活函数，从数学角度看，Sigmoid函数对中间信号增益较大而对两侧信号增益小，所以在信号的特征空间映射上效果好。 从生物角度看，中间部分类似神经元的兴奋状态而两侧类似神经元的抑制状态，所以神经网络在学习时，区分度大的重要特征被推向中间而次要特征被推向两侧。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a0q0pg13mp31k17d41ni0sabi.png" width="350"></center><p><span class="math display">\[ logistic(x)=\frac{1}{1+e^{-x}}\\ tanh(x)=2logistic(2x)-1 \]</span></p><p>Logistic函数最早是<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre François Verhulst</a>在研究人口增长问题时提出的，由于其强悍的普适性（从概率角度的理解见前面对Logistic Regression的讲解）而被广泛应用（在传统机器学习中派生出Logistic Regression），但是实践中，它作为激活函数有两个重要缺点：</p><ul><li><p>梯度消失问题（Vanishing Gradient Problem）</p><p>从前面BP的推导过程可以看出：误差从输出层反向传播时，在各层都要乘以当前层的误差敏感度，而误差敏感度又与<span class="math inline">\(Sigmoid&#39;(x)\)</span>有关系，由于<span class="math inline">\(Sigmoid&#39;(x)\in(0,1)\)</span> 且<span class="math inline">\(x\in(0,1) \text{ or }x\in(-1,1)\)</span>，可见误差会从输出层开始呈指数衰减，这样即使是一个4层神经网络可能在靠近输入层的部分都已经无法学习了，更别说“更深”的网络结构了，Hinton提出的逐层贪心预训练方法在一定程度缓解了这个问题但没有真正解决。</p></li><li><p>激活输出非0均值问题</p><p>假设一个样本一个样本的学习，当前层输出非0均值信号给下一层神经元时：如果输入值大于0，则后续通过权重计算出的梯度也大于0，反之亦然，这会导致整个网络训练速度变慢，虽然采用batch的方式训练会缓解这个问题，但毕竟在训练中是拖后腿的，所以Yann LeCun在《Efficient BackPro》一文中也提到了解决的trick。</p></li></ul><p>Tanh函数是另外一种Sigmoid函数，它的输出是0均值的，Yann LeCun给出的一种经验激活函数形式为：<span class="math display">\[f(x)=1.7159 \cdot tanh(\frac{2}{3}x)\]</span>但这个函数依然解决不了梯度消失问题，后续介绍其他网络结构时会看到在激活函数层面上的演化。</p><p>CNN的典型特点是：局部相关性（稀疏连接）、权重与偏置共享及采样，一套典型的结构由输入层、卷积层、采样层、全连接层、输出层组成。</p><h3 id="输入层">5.3.2 输入层</h3>CNN的输入层一般为一个n维矩阵，可以是图像、向量化后的文本等等。比如一幅彩色图像：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s7tchpjd91hq3j4l1n6n2f11g.png" width="400"></center><h3 id="卷积层">5.3.3 卷积层</h3>卷积操作在数学上的定义如下： <span class="math display">\[f*g = \int^{\infty}_{-\infty}(\sum^{\infty}_{-\infty}) f(\tau)g(x-\tau)d\tau \tag{1}\]</span><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s71detai81p86nl3uobg9h13.png" width="800"></center><p>但对于我们正在讲的CNN中的卷积<strong>并不是严格意义的卷积(<a target="_blank" rel="noopener" href="http://mathworld.wolfram.com/Convolution.html">Convolution</a>)</strong>操作，而是变体<a target="_blank" rel="noopener" href="http://mathworld.wolfram.com/Cross-Correlation.html"><strong>Cross-Correlation</strong></a>: <span class="math display">\[f★ g = \int^{\infty}_{-\infty}(\sum^{\infty}_{-\infty}) \bar{f}(\tau)g(x+\tau)d\tau \tag{1}\]</span> 其中<span class="math inline">\(\bar{f}\)</span>为<span class="math inline">\(f\)</span>的<a target="_blank" rel="noopener" href="http://mathworld.wolfram.com/ComplexConjugate.html">Complex Conjugate</a>。</p><p>卷积层的作用：</p><p>当数据及其周边有局部关联性时可以起到滤波、去噪、找特征的作用；</p><p>每一个卷积核做特征提取得到结果称为feature map，利用不同卷积核做卷积会得到一系列feature map，这些feature map大小为长×宽×深度(卷积核的个数)并作为下一层的输入。</p><p>以图像处理为例，卷积可以有至少3种理解：</p><ul><li><p>平滑</p>当设置一个平滑窗口后（如3×3），除了边缘外，图像中每个像素点都是以某个点为中心的窗口中各个像素点的加权平均值，这样由于每个点都考虑了周围若干点的特征，所以本质上它是对像素点的平滑。</li><li><p>滤波</p><p>将信号中特定波段频率过滤的操作，是防干扰的一类方法，如果滤波模板(卷积核)是均匀分布，那么滤波就是等权滑动平均，如果模板是高斯分布，那么滤波就是权重分布为钟形的加权滑动平均，不同的模板能得到图像的不同滤波后特征。</p></li><li><p>投影</p><p>卷积是个内积操作，如果把模板(卷积核)拉直后看做一个基向量，那么滑动窗口每滑动一次就会产生一个向量，把这个向量往基向量上做投影就得到feature map，如果模板有多个，则组成一组基，投影后得到一组feature map。</p></li></ul><p>卷积和权重共享可以在保证效果的基础上大大降低模型复杂度，说明如下：</p>输入层为5×5矩阵，卷积核为3×3矩阵，隐藏层为：3×3矩阵：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbehg11su3pj3ksq92mvj12n.png" width="400"></center><ul><li><p>采用全连接神经网络</p><p>参数个数为：5×5×9=225</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbvo0ourbp1nesm1eg518no3h.png" width="250"></center></li><li><p>采用局部连接神经网络</p>隐藏层只与3×3大小的局部像素相连，参数个数为：3×3×9=81<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc08fspt4vju1ql6184d4ci3u.png" width="250"></center></li><li><p>采用局部连接权重共享神经网络</p>所有隐藏层共享权值，且权值为卷积核，参数个数为：3×3×1=9，共享权重的本质含义是对图片某种统计模式的描述，这种模式与图像位置无关。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc818png019o31tckas91d6r4o.png" width="250"></center></li></ul><h3 id="zero-padding">5.3.4 Zero-Padding</h3>Zero-Padding是一种影响输出层构建的方法，思路比较简单：把输入层边界外围用0填充，当我们希望输出空间维度和输入空间维度大小一样时可以用此方法，例如下图：当输入为4×4，卷积核为3×3时，利用Zero-Padding可以让输出矩阵也是4×4。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0scomd1143ebfh1iq918jencv5i.png" width="250"></center><p>Zero-Padding一方面让你的网络结构设计更灵活，一方面还可以保留边界信息，不至于随着卷积的过程信息衰减的太快。 大家如果使用Tenserflow会知道它的padding参数有两个值：SAME，代表做类似上图的Zero padding，使得输入的feature map和输出的feature map有相同的大小；VALID，代表不做padding操作。</p><h3 id="采样层pooling">5.3.5 采样层(pooling)</h3>通过卷积后。模型的参数规模大幅下降，但对于复杂网络参数个数依然很多，且容易造成过拟合，所以一种自然的方式就是做下采样，采样依然采用滑动窗口方式，常用采样有Max-Pooling（将Pooling窗口中的最大值作为采样值）和Mean-Pooling（将Pooling窗口中的所有值相加取平均，用平均值作为采样值），一个例子如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdf86mtg1i5110kv1kc3gl776.png" width="300"></center>实际上也有人尝试抛弃Pooling层而采用Stride大于1的卷积层，例如，以下例子中Stride=2，效果类似：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdotesps7177gsg9188bl0p7j.png" width="300"></center><p>另外，如果卷积层的下一层是pooling层，那么每个feature map都会做pooling，与人类行为相比，pooling可以看做是观察图像某个特征区域是否有某种特性，对这个区域而言不关心这个特性具体表现在哪个位置（比如：看一个人脸上某个局部区域是否有个痘痘）。</p><h3 id="全连接样层">5.3.6 全连接样层</h3><p>全连接层一般是CNN的最后一层，它是输出层和前面若干层的过渡层，用来组织生成特定节点数的输出层。</p><h3 id="参数求解">5.3.7 参数求解</h3><p>对于多分类任务，假设损失函数采用平方误差： <span class="math display">\[E(x)=\sum_{i=0}^N\sum_{k=0}^C(t^k_i-y^k_i)^2\]</span>，<span class="math inline">\(C\)</span>为分类个数，<span class="math inline">\(N\)</span>为样本数。 下面以一个样本为例推导CNN的原理： <span class="math display">\[E(x)=\sum_{k=0}^C(t^k-y^k)^2\]</span></p><ul><li><p>全连接层</p><p>为方便，假设偏置项<span class="math inline">\(b\)</span>都被放入权重项<span class="math inline">\(W\)</span>中，则对全连接层来说第<span class="math inline">\(n\)</span>层与第<span class="math inline">\(n-1\)</span>层的关系为： <span class="math display">\[ \begin{array}{l} X^n=F(Y^n)\\ Y^n=W^nX^{n-1} \end{array} \]</span> 反向传播定义为：</p><p><span class="math inline">\(\because\)</span> <span class="math display">\[ \begin{array}{l} \delta^n=\frac{\partial E}{\partial Y^n}=F&#39;(Y^n)\frac{\partial E}{\partial X^n}\\ \frac{\partial E}{\partial W^n}=X^{n-1}(\delta^n)^T\\ \frac{\partial E}{\partial X^{n-1}}=(W^n)^T\frac{\partial E^o}{\partial Y^n}\\ \end{array} \]</span> <span class="math inline">\(\therefore\)</span> <span class="math display">\[ \left\{ \begin{aligned} \delta^n = &amp; F&#39;(Y^n)(W^{n+1})^T\delta^{n+1} \\ \delta^L = &amp; F&#39;(Y^L)(t^{n}-y^n) \quad\text{L表示最后一层}\\ \frac{\partial E}{\partial W^n} = &amp; X^{n-1}(\delta^n)^T \end{aligned} \right. \]</span> <span class="math display">\[ \begin{array}{l} \Delta W^n=-\eta \frac{\partial E}{\partial W^n}\\ W^n=W^{n-1}+\Delta W^n \end{array} \]</span></p></li><li><p>卷积层 由于卷积操作、共享权重的存在，这一中间层的输出会被定义为： <span class="math display">\[ \begin{array}{l} X_j^n=F(Y_j^n)\\ Y_j^n=\sum_{i\in M_j}X_i^{n-1}k_{ij}^n+b_j^n \end{array} \]</span> 其中：<span class="math inline">\(n\)</span>为当前卷积层，<span class="math inline">\(j\)</span>为卷积层某个特征，<span class="math inline">\(k\)</span>为卷积核，<span class="math inline">\(b\)</span>为偏置。</p><p><strong>1、当前层为卷积层且下一层为下采样层(pooling)时</strong>，反向传播的原理为：</p><p><span class="math inline">\(\delta^n_j = \beta_j^{n+1}(F&#39;(Y^n)upsampled(\delta^{n+1}_j))\)</span></p><p>下面解释<span class="math inline">\(upsampled\)</span>和<span class="math inline">\(\beta\)</span>操作：</p>卷积层在卷积窗口内的像素与下采样层的像素是多对一的关系，即下采样层的一个神经元节点对应的误差灵敏度对应于上一层卷积层的采样窗口大小的一块像素，下采样层每个节点的误差敏感值由上一层卷积层中采样窗口中节点的误差敏感值联合生成，因此，为了使下采样层的误差敏感度窗口大小和卷积层窗口(卷积核)大小一致，就需要对下采样层的误差敏感度做上采样<span class="math inline">\(upsampled\)</span>操作，相当于是某种逆映射操作，对于max-pooling、mean-polling或者各自的加权版本来说处理方法类似：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6io9a0j12rlem41vklu4tjfe13.png" width="400"></center><p><span class="math display">\[ \begin{array}{l} \delta^n_j=F&#39;(Y^n_j)\frac{\partial E}{\partial X^n_j}\\ \frac{\partial E}{\partial X^{n}_j}=(W^{n+1}_j)^T\frac{\partial E^o}{\partial Y^{n+1}_j}\\ \delta^n_j = \beta_j^{n+1}(F&#39;(Y^n_j)upsampled(\delta^{n+1}_j)) \end{array} \]</span> 第<span class="math inline">\(n\)</span>层为卷积层和第<span class="math inline">\(n+1\)</span>层为下采样层，由于二者维度上的不一致，需要做以下操作来分配误差敏感项，以mean-pooling为例，假设卷积层的核为4×4，pooling的窗口大小为2×2，为简单起见，pooling过程采用每次移动一个窗口大小的方式，显然pooling后的矩形大小为2×2，如果此时pooling后的矩形误差敏感值如下：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6isstg3thaur990dsvn1bjq1g.png" width="100"></center><span class="math inline">\(upsampled\)</span>操作，按照顺序对每个误差敏感项在水平和垂直方向各复制出口大小次：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6it7aknd6aabt41sr9i16vj1t.png" width="200"></center>做误差敏感项归一化，即上面公式里的<span class="math inline">\(\beta\)</span>取值，需要注意，如果采用的是加权平均的话，则窗口内误差敏感项权重是不一样的（不像现在这样是等权的）。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ito67157a3lji5b1vs4f932a.png" width="200"></center><p><strong>2、当前层为卷积层，与其相连的上一层相关核权重及偏置</strong>计算如下：</p><p>假设通过<span class="math inline">\((p,q)\)</span>来标识卷积层任意位置，则：</p><span class="math display">\[ \begin{array}{l} \frac{\partial E}{\partial k_{ij}^n} =\sum_{p,q}(\delta_j^{n})_{pq}(X_{i}^{n-1})_{pq}\\ \frac{\partial E}{\partial b_j}=\sum_{p,q}(\delta_j^{n})_{pq} \end{array} \]</span> 假设第<span class="math inline">\(n-1\)</span>层输入矩阵大小为5×5：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9e6ve110a1bs81ph1bao1l1n2n.png" width="200"></center>第<span class="math inline">\(n\)</span>层误差敏感项矩阵大小为4×4：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9fhp91quu11461ljn70418p734.png" width="200"></center>则核<span class="math inline">\(k_{ij}^n\)</span>的偏导为：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ja5d7k7pr1ee017s57201jr33h.png" width="600"></center><p><span class="math display">\[ \begin{aligned} 75.75=&amp;1*1.25+3*1.25+5*2+7*2+\\ &amp;2*1.25+4*1.25+5*2+6*2+\\ &amp;5*0.75+7*0.75+1*0.5+3*0.5+\\ &amp;1*0.75+2*0.75+3*0.5+5*0.5 \end{aligned} \]</span></p><p>偏置<span class="math inline">\(b_j\)</span>的偏导为误差敏感项矩阵元素之和： <span class="math display">\[ \begin{aligned} 18=1.25*4+0.75*4+2*4+0.5*4 \end{aligned} \]</span></p><p><strong>3、当前层为下采样(pooling)层且下一层为卷积层时</strong>反向传播的原理如下： <span class="math display">\[ \begin{array}{l} \delta^n_j=F&#39;(Y_j^n)\sum_{p,q}(\delta_j^{n+1})_{pq}*(k_{j}^{n+1})_{pq}\\ \end{array} \]</span></p>其中运算符号<span class="math inline">\(*\)</span>为卷积操作。一个简单的例子如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77kp1qgjns27t83h1m86cvem.png" width="400"></center><p>假设下采样(pooling)层处于第<span class="math inline">\(n\)</span>层且feature map大小为3×3，其下一层为卷积层处于第<span class="math inline">\(n+1\)</span>层且通过两个2×2卷积核得到了两个feature map(蓝色虚框框住的网络结构)。</p>2个卷积核为：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77m4h5p1kes1nmt1c9068flcr13.png" width="300"></center>假设第<span class="math inline">\(n+1\)</span>层对两个卷积核的误差敏感项已经计算好：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77mrpk7iql1vcd1mtsnnn154l1p.png" width="300"></center>则对第<span class="math inline">\(n+1\)</span>层的误差敏感项做zero-padding并利用卷积操作（注意：会对卷积核做180度旋转）可以得到第<span class="math inline">\(n\)</span>层的误差敏感项，过程如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77rq7l71v78t1f2u6kob1cvm26.png" width="500"></center>假设<span class="math inline">\(F&#39;(Y_j^n)=1\)</span>，则第<span class="math inline">\(n\)</span>层的误差敏感项为：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77s7vp8hta1ikg1h041juv1i1c2j.png" width="500"></center></li></ul><h3 id="cnn在nlp领域应用实例">5.3.8 CNN在NLP领域应用实例</h3><p>在NLP领域，文本分类是一类常用应用，传统方法是人工提取类似n-gram的各种特征以及各种交叉组合。文本类似图像天然有一种局部相关性，想到利用CNN做一种End to End的分类器，把提特征的工作交给模型。</p><p>对于一个句子，它是一维的，无法像图像一样直接处理，因此需要通过distributed representation learning得到词向量，或者在模型第一层增加一个embedding层起到类似作用，这样一个句子就变成二维的了：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sfnrui1mvnnnd1l2p1t68nm880.png" width="300"></center><p>我们用Tensorflow为后端的Keras搭建这个模型：</p><p>前面说到可以使用两种方法得到词向量：</p><p>1、预先训练好的结果，例如使用已经训练好的word2vec模型，相关资料：<a target="_blank" rel="noopener" href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html">Using pre-trained word embeddings in a Keras model</a>；</p><p>2、模型第一层增加embedding层，我们使用这种方式。</p><p>网络结构如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_embedding_cnn</span>(<span class="params">max_caption_len, vocab_size</span>):</span></span><br><span class="line">    <span class="comment"># 二分类问题</span></span><br><span class="line">    nb_classes = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 词向量维度</span></span><br><span class="line">    word_dim = <span class="number">256</span></span><br><span class="line">    <span class="comment"># 卷积核个数</span></span><br><span class="line">    nb_filters = <span class="number">64</span></span><br><span class="line">    <span class="comment"># 使用max pooling的窗口大小</span></span><br><span class="line">    nb_pool = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 卷积核大小</span></span><br><span class="line">    kernel_size = <span class="number">5</span></span><br><span class="line">    <span class="comment"># 模型结构定义</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    <span class="comment"># 第一层是embedding层</span></span><br><span class="line">    model.add(Embedding(output_dim=word_dim, input_dim=vocab_size, input_length=max_caption_len, name=<span class="string">&#x27;main_input&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment"># 第二层是激活函数为Relu的卷积层</span></span><br><span class="line">    model.add(Convolution1D(nb_filters, kernel_size))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment"># 第三层是max pooling层</span></span><br><span class="line">    model.add(MaxPooling1D(nb_pool))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    <span class="comment"># 第四层是全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">256</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line">    <span class="comment"># 第五层是输出层</span></span><br><span class="line">    model.add(Dense(nb_classes))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="comment"># 损失函数采用交叉熵，优化算法采用adadelta</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                  optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>max_caption_len=100时的网络结构如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b72kbakimjb19plrt512qj1t6e16.png" width="300"></center>运行效果：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0shaditah31jeuur91te010718d.png" width="800"></center><p>详细代码可以参见GitHub：<a target="_blank" rel="noopener" href="https://github.com/vivounicorn/cnn-tc-keras"><strong>Cnn-tc-Keras</strong></a>。</p><h2 id="lenet-5">5.4 LeNet-5</h2>最初的网络结构来源于论文：《<a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-based learning applied to document recognition</a>》(论文里使用原始未做规范化的数据时，INPUT是32×32的)，我用以下结构做说明:<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b8b8u29j17gqo4713s12fsme39.png" width="800"></center><p>LeNet-5一共有8层：1个输入层+3个卷积层(C1、C3、C5)+2个下采样层(S2、S4)+1个全连接层(F6)+1个输出层，每层有多个feature map(自动提取的多组特征)。</p><h3 id="输入层-1">5.4.1 输入层</h3><p>采用keras自带的MNIST数据集，输入像素矩阵为28×28的单通道图像数据。</p><h3 id="c1卷积层">5.4.2 C1卷积层</h3><p>由6个feature map组成，每个feature map由5×5卷积核生成(feature map中每个神经元与输入层的5×5区域像素相连)，考虑每个卷积核的bias，该层需要学习的参数个数为：(5×5+1)×6=<strong>156</strong>个，神经元连接数为：156×24×24=<strong>89856</strong>个。</p><h3 id="s2下采样层">5.4.3 S2下采样层</h3><p>该层每个feature map一一对应上一层的feature map，由于每个单元的2×2感受野采用不重叠方式移动，所以会产生6个大小为12×12的下采样feature map，如果采用Max Pooling/Mean Pooling，则该层需要学习的参数个数为<strong>0</strong>个(如果采用非等权下采样——即采样核有权重，则该层需要学习的参数个数为：(2×2+1)×6=30个)，神经元连接数为：30×12×12=<strong>4320</strong>个。</p><h3 id="c3卷积层">5.4.4 C3卷积层</h3><p>这层略微复杂，S2神经元与C3是多对多的关系，比如最简单方式：用S2的所有feature map与C3的所有feature map做全连接(也可以对S2抽样几个feature map出来与C3某个feature map连接)，这种全连接方式下：6个S2的feature map使用6个独立的5×5卷积核得到C3中1个feature map(生成每个feature map时对应一个bias)，C3中共有16个feature map，所以该层需要学习的参数个数为：(5×5×6+1)×16=<strong>2416</strong>个，神经元连接数为：2416×8×8=<strong>154624</strong>个。</p><h3 id="s4下采样层">5.4.5 S4下采样层</h3><p>同S2，如果采用Max Pooling/Mean Pooling，则该层需要学习的参数个数为<strong>0</strong>个，神经元连接数为：(2×2+1)×16×4×4=<strong>1280</strong>个。</p><h3 id="c5卷积层">5.4.6 C5卷积层</h3><p>类似C3，用S4的所有feature map与C5的所有feature map做全连接，这种全连接方式下：16个S4的feature map使用16个独立的1×1卷积核得到C5中1个feature map(生成每个feature map时对应一个bias)，C5中共有120个feature map，所以该层需要学习的参数个数为：(1×1×16+1)×120=<strong>2040</strong>个，神经元连接数为：<strong>2040</strong>个。</p><h3 id="f6全连接层">5.4.7 F6全连接层</h3><p>将C5层展开得到4×4×120=<strong>1920</strong>个节点，并接一个全连接层，考虑bias，该层需要学习的参数和连接个数为：(1920+1)*84=<strong>161364</strong>个。</p><h3 id="输出层">5.4.8 输出层</h3><p>该问题是个10分类问题，所以有10个输出单元，通过softmax做概率归一化，每个分类的输出单元对应84个输入。</p>Minist(Modified NIST)数据集下使用LeNet-5的训练<a target="_blank" rel="noopener" href="http://shixialiu.com/publications/cnnvis/demo/">可视化</a>：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77tbfq8ml168019l1p6t36i9.png" width="800"></center><p>可以看到其实全连接层之前的各层做的就是特征提取的事儿，且比较通用，对于标准化实物（人、车、花等等）可以复用，后面会单独介绍模型的fine-tuning。</p><h3 id="lenet-5代码实践">5.4.9 LeNet-5代码实践</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist, cifar10</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_LeNet5</span>():</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Convolution2D(<span class="number">6</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), dim_ordering=<span class="string">&#x27;tf&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(Convolution2D(<span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(Convolution2D(<span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">84</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    model = build_LeNet5()</span><br><span class="line">    model.summary()</span><br><span class="line">    plot(model, to_file=<span class="string">&quot;LeNet-5.png&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">    (X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    Y_train = np_utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">    Y_test = np_utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    nb_epoch = <span class="number">1</span></span><br><span class="line">    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">              verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">    score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br><span class="line">    y_hat = model.predict_classes(X_test)</span><br><span class="line">    test_wrong = [im <span class="keyword">for</span> im <span class="keyword">in</span> <span class="built_in">zip</span>(X_test,y_hat,y_test) <span class="keyword">if</span> im[<span class="number">1</span>] != im[<span class="number">2</span>]]</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> ind, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_wrong[:<span class="number">100</span>]):</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">        plt.subplot(<span class="number">10</span>, <span class="number">10</span>, ind + <span class="number">1</span>)</span><br><span class="line">        im = <span class="number">1</span> - val[<span class="number">0</span>].reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        plt.text(<span class="number">0</span>, <span class="number">0</span>, val[<span class="number">2</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">        plt.text(<span class="number">8</span>, <span class="number">0</span>, val[<span class="number">1</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        plt.imshow(im, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    savefig(<span class="string">&#x27;error.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>网络结构<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aab1kq13lbvgbkfq1e0o1qb1c.png" width="300"></center></li><li>错误分类可视化<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aac0i71ibcppe89e1sh61fv11p.png" width="500"></center></li></ul><h2 id="alexnet">5.5 AlexNet</h2><p>AlexNet在ILSVRC-2012的比赛中获得top5错误率15.3%的突破（第二名为26.2%），其原理来源于2012年Alex的论文《<a target="_blank" rel="noopener" href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>》，这篇论文是深度学习火爆发展的一个里程碑和分水岭，加上硬件技术的发展，深度学习还会继续火下去。</p><h3 id="网络结构分析">5.5.1 网络结构分析</h3>由于受限于当时的硬件设备，AlexNet在GPU粒度都做了设计，当时的GTX 580只有3G显存，为了能让模型在大量数据上跑起来，作者使用了两个GPU并行，并对网络结构做了切分，如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1baou2biq9uhumh1tm1d95du99.png" width="600"></center><p>上下两层分别并行的跑在两个GPU上，虚线代表依赖，交叉的虚线代表两个GPU之间需要通信后交换数据。</p><ul><li><p>输入层</p><p>输入为224×224×3的三通道RGB图像，为方便后续计算，实际操作中通过padding做预处理，把图像变成227×227×3。</p></li><li><p>C1卷积层</p><p>该层由：卷积操作 + Max Pooling + LRN（后面详细介绍它）组成。</p><p>(1)、卷积层：由<strong>96</strong>个feature map组成，每个feature map由<strong>11×11</strong>卷积核在<strong>stride=4</strong>下生成，输出feature map为<strong>55×55×48×2</strong>，其中55=(227-11)/4+1，48为分在每 个GPU上的feature map数，2为GPU个数；</p><p>(2)、激活函数：采用ReLU；</p><p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>（文中实验表明采用2×2的非重叠模式的Max Pooling相对更容易过拟合，在top 1和top 5下的错误率分别高0.4%和0.3%），输出feature map为<strong>27×27×48×2</strong>，其中27=(55-3)/2+1，48为分在每个GPU上的feature map数，2为GPU个数；</p><p>(4)、LRN：邻居数设置为5做归一化。 最终输出数据为归一化后的：<strong>27×27×48×2</strong>。</p></li><li><p>C2卷积层</p><p>该层由：卷积操作 + Max Pooling + LRN组成</p><p>(1)、卷积层：由<strong>256</strong>个feature map组成，每个feature map由<strong>5×5</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为2的padding，输出feature map为<strong>27×27×128×2</strong>，其中27=(27-5+2×2)/1+1，128为分在每个GPU上的feature map数，2为GPU个数；</p><p>(2)、激活函数：采用ReLU；</p><p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>，输出feature map为<strong>13×13×128×2</strong>，其中13=(27-3)/2+1，128为分在每个GPU上的feature map数，2为GPU个数；</p><p>(4)、LRN：邻居数设置为5做归一化。</p><p>最终输出数据为归一化后的：<strong>13×13×128×2</strong>。</p></li><li><p>C3卷积层 该层由：卷积操作 + LRN组成（注意，没有Pooling层）</p><p>(0)、输入为<strong>13×13×256</strong>，因为这一层两个GPU会做通信（途中虚线交叉部分）</p><p>(1)、卷积层：之后由<strong>384</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×192×2</strong>，其中13=(13-3+2×1)/1+1，192为分在每个GPU上的feature map数，2为GPU个数；</p><p>(2)、激活函数：采用ReLU；</p><p>最终输出数据为归一化后的：<strong>13×13×192×2</strong>。</p></li><li><p>C4卷积层 该层由：卷积操作 + LRN组成（注意，没有Pooling层）</p><p>(1)、卷积层：由<strong>384</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×192×2</strong>，其中13=(13-3+2×1)/1+1，192为分在每个GPU上的feature map数，2为GPU个数；</p><p>(2)、激活函数：采用ReLU； 最终输出数据为归一化后的：<strong>13×13×192×2</strong>。</p></li><li><p>C5卷积层 该层由：卷积操作 + Max Pooling组成</p><p>(1)、卷积层：由<strong>256</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×128×2</strong>，其中13=(13-3+2×1)/1+1，128为分在每个GPU上的feature map数，2为GPU个数；</p><p>(2)、激活函数：采用ReLU；</p><p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>，输出feature map为<strong>6×6×128×2</strong>，其中6=(13-3)/2+1，128为分在每个GPU上的feature map数，2为GPU个数. 最终输出数据为归一化后的：<strong>6×6×128×2</strong>。</p></li><li><p>F6全连接层 该层为全连接层 + Dropout</p><p>(1)、使用4096个节点；</p><p>(2)、激活函数：采用ReLU；</p><p>(3)、采用参数为0.5的Dropout操作</p><p>最终输出数据为4096个神经元节点。</p></li><li><p>F7全连接层 该层为全连接层 + Dropout</p><p>(1)、使用4096个节点；</p><p>(2)、激活函数：采用ReLU；</p><p>(3)、采用参数为0.5的Dropout操作</p><p>最终输出为4096个神经元节点。</p></li><li><p>F8输出层 该层为全连接层 + Softmax</p><p>(1)、使用1000个输出的Softmax</p><p>最终输出为1000个分类。</p></li></ul><p>AlexNet的亮点如下：</p><h3 id="relu激活函数">5.5.2 ReLu激活函数</h3>AlexNet引入了ReLU激活函数，这个函数是神经科学家Dayan、Abott在《<a target="_blank" rel="noopener" href="http://cns-classes.bu.edu/cn510/Papers/Theoretical%20Neuroscience%20Computational%20and%20Mathematical%20Modeling%20of%20Neural%20Systems%20-%20%20Peter%20Dayan,%20L.%20F.%20Abbott.pdf">Theoretical Neuroscience</a>》一书中提出的更精确的激活模型：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a4mkcb1m76g9ue2g92jn97v.png" width="600"></center><p>其中： <span class="math display">\[ \begin{array}{l} \text{Eq.2.9: }F(L)=G[L-L_0]_+\\ \text{Eq.2.10: }F(L)=\frac{r_{max}}{1+exp(g_1(L_{1/2}-L))}\\ \text{Eq.2.11: }F(L)=r_{max}[tanh (g_2(L-L_0))]_+ \end{array} \]</span></p><p>详情请阅读书中2.2 Estimating Firing Rates这一节。新激活模型的特点是：</p><ul><li><p>激活稀疏性（<span class="math inline">\(L\)</span>小于1时<span class="math inline">\(r\)</span>为0）</p></li><li><p>单边抑制（不像Sigmoid是双边的）</p></li><li><p>宽兴奋边界，非饱和性（ReLU导数始终为1），很大程度缓解了梯度消失问题</p></li></ul><p>1、 原始ReLu</p><p>在这些前人研究的基础上（可参见 Hinton论文：《<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf">Rectified Linear Units Improve Restricted Boltzmann Machines</a>》），类似Eq.2.9的新激活函数被引入： <span class="math display">\[f(x)=max(0,x)\]</span> 这个激活函数把负激活全部清零（模拟上面提到的稀疏性），这种做法在实践中即保留了神经网络的非线性能力，又加快了训练速度。 但是这个函数也有缺点：</p><ul><li><p>在原点不可微</p><p>反向传播的梯度计算中会带来麻烦，所以Charles Dugas等人又提出Softplus来模拟上述ReLu函数（可视作其平滑版）： <span class="math display">\[f(x)=log(1+e^x)\]</span></p>实际上它的导数就是一个logistic-sigmoid函数： <span class="math display">\[f’(x)=\frac{1}{1+e^{-x}}\]</span></li><li><p>过稀疏性 当学习率设置不合理时，即使是一个很大的梯度，在经过ReLu单元并更新参数后该神经元可能永不被激活。</p></li></ul><p>2、 Leaky ReLu</p><p>为了解决上述过稀疏性导致的大量神经元不被激活的问题，<strong>Leaky ReLu</strong>被提了出来： <span class="math display">\[ f(x)=\left\{ \begin{aligned} \alpha x &amp;(x&lt;0) \\ x &amp;(x&gt;=0) \end{aligned} \right. \]</span> 其中<span class="math inline">\(\alpha\)</span>是人工指定的较小值(如：0.1)，它一定程度保留了负激活信息。</p><p>3、Parametric ReLu 上述<span class="math inline">\(\alpha\)</span>值是可以不通过人为指定而学习出的，于是<strong>Parametric ReLu</strong>被提了出来: 利用误差反向传播原理： <span class="math display">\[ \begin{array}{l} \frac{\partial{E}}{\partial{\alpha}}=\sum\frac{\partial{E}}{\partial{f(x)}}\frac{\partial{f(x)}}{\partial{\alpha}} \end{array} \]</span> <span class="math display">\[ \frac{\partial{f(x)}}{\partial{\alpha}}=\left\{ \begin{aligned} x &amp;(x&lt;0) \\ 0 &amp;(x&gt;=0) \end{aligned} \right. \]</span> 当采用动量法更新<span class="math inline">\(\alpha\)</span>权重： <span class="math display">\[ \Delta\alpha=\mu\Delta\alpha+\epsilon\frac{\partial{E}}{\partial{\alpha}} \]</span> 详情请阅读Kaiming He等人的《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》</a>论文。</p><p>4、Randomized ReLu Randomized ReLu 可以看做是leaky ReLu的随机版本，原理是：假设<span class="math display">\[\alpha\text{~}Normal(\mu,\delta)\]</span>然后再做权重调整。 <span class="math display">\[ f(x)=\left\{ \begin{aligned} \alpha x &amp;(x&lt;0) \\ x &amp;(x&gt;=0) \end{aligned} \right. \]</span> 其中：<span class="math display">\[ \alpha\text{~}Normal(\mu,\delta)\text{ and }\mu&lt;\delta\text{ and }\mu,\delta\in[0,1)\]</span></p><h3 id="local-response-normalization">5.5.3 Local Response Normalization</h3><p>LRN利用相邻feature map做特征显著化，文中实验表明可以降低错误率，公式如下： <span class="math display">\[ \begin{array}{l} b_{x,y}^i=a_{x,y}^i/(k+\alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a^i_{x,y})^2)^\beta \end{array} \]</span></p>公式的直观解释如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb836lcgb616edc351dnct96m.png" width="800"></center>由于<span class="math inline">\(a\)</span>都是经过了ReLU的输出，所以一定是大于0的，函数：<span class="math inline">\(\frac{1}{(k+\alpha \sum x^2)^\beta}\)</span>取文中参数的图形如下（横坐标为<span class="math inline">\(\sum x^2\)</span>）：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb83e7v01up1olv1r98e68lpf1g.png" width="400"></center><p>当<span class="math inline">\(\sum x^2\)</span>值较小时，即当前节点和其邻居节点输出值差距不明显且大家的输出值都不太大，可以认为此时特征间竞争激烈，该函数可以使原本差距不大的输出产生显著性差异且此时函数输出不饱和；当<span class="math inline">\(\sum x^2\)</span>值较大时，说明特征本身有显著性差别但输出值太大容易过拟合，该函数可以令最终输出接近0从而缓解过拟合提高了模型泛化性。</p><h3 id="overlapping-pooling">5.5.4 Overlapping Pooling</h3><p>如其名，实验表明有重叠的抽样可以提高泛化性。</p><h3 id="dropout">5.5.5 Dropout</h3><p>Dropout是文章亮点之一，属于提高模型泛化性的方法，操作比较简单，以一定概率随机让某些神经元输出设置为0，既不参与前向传播也不参与反向传播，也可以从正则化角度去看待它。</p><ul><li>从模型集成的角度看<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbdegnoi6i44cpr7n19r7dhs9.png" width="600"></center></li></ul><p>无Dropout网络： <span class="math display">\[ \begin{array}{l} Y^n=W^nX^{n-1}\\ X^n=F(Y^n)\\ \end{array} \]</span></p><p>有Dropout网络： <span class="math display">\[ \begin{array}{l} Y^n=W^nX^{n-1}\\ d^{n-1}\sim Bernoulli (p)\\ X^n=d^{n-1} \odot F(Y^n) \end{array} \]</span> 其中<span class="math inline">\(p\)</span>为Dropout的概率，<span class="math inline">\(n\)</span>为所在层。</p><p>它是极端情况下的Bagging，由于在每步训练中，神经元会以某种概率随机被置为无效，相当于是参数共享的新网络结构，每个模型为了使损失降低会尽可能学最“本质”的特征，“本质”可以理解为由更加独立的、和其他神经元相关性弱的、泛化能力强的神经元提取出来的特征；而如果采用类似SGD的方式训练，每步迭代都会选取不同的数据集，这样整个网络相当于是用不同数据集学习的多个模型的集成组合。</p><p>从数据扩充(Data Augmentation)的角度看：</p><p>机器学习学的就是原始数据的数据分布，而泛化能力强的模型自然不能只针对训练集上的数据正确映射输出，但要想学到好的映射又需要数据越多越好，很多论文已经证明，带领域知识的数据扩充能够提高训练数据对原始真实分布的覆盖度，从而能够提高模型泛化效果。 《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.08700.pdf">Dropout as Data Augmentation</a>》将Dropout看做数据扩充的方法，文中证明了：总能找到一个样本，使得原始神经网络的输出与Dropout神经网络的输出一致(projecting noise back into the input space)。 用论文中符号说明如下： <span class="math display">\[ \begin{array}{l} h(x)=xW+b\\ a(h)=rect(h)\\ \widetilde{a}(h)=M \odot rect(h) \end{array} \]</span> 其中：<span class="math inline">\(x\)</span>为<span class="math inline">\(d_i\)</span>维空间的输入，<span class="math inline">\(h(x)\)</span>为从<span class="math inline">\(d_i\)</span>维空间到<span class="math inline">\(d_h\)</span>维空间的仿射映射，<span class="math inline">\(a(h)\)</span>为激活函数，<span class="math inline">\(\widetilde{a}(h)\)</span>为Dropout版激活函数，<span class="math inline">\(M\sim Bernoulli(p_h)\)</span>，<span class="math inline">\(rect(h)\)</span>为rectifier函数(比如：ReLU): 对任何一个隐层，假设都存在一个输入<span class="math inline">\(x^*\)</span>，满足： <span class="math display">\[ (a\circ h)(x^*)=rect(h(x^*))\approx \vec{m}\odot rect(h(x))=(\widetilde{a} \circ h)(x) \]</span> 注：式子左边为原始神经网络某层，右边为Dropout神经网络某层。 采用SGD优化下面目标函数，总能找到一个输入<span class="math inline">\(x^*\)</span>： <span class="math display">\[min~L(x,x^*)=min~|(a\circ h)(x^*)-(\widetilde{a} \circ h)(x)|^2\]</span></p><p>对于一个<span class="math inline">\(n\)</span>层的神经网络： 原始神经网络表示为： <span class="math display">\[ {f}^{(i)}(x^*)=({a}^{(i)}\circ h^{(i)}\circ ...\circ{a}^{(1)}\circ h^{(1)})(x^*) \]</span></p><p>Dropout神经网络表示为： <span class="math display">\[ \widetilde{f}^{(i)}(x)=(\widetilde{a}^{(i)}\circ h^{(i)}\circ ...\circ\widetilde{a}^{(1)}\circ h^{(1)})(x) \]</span></p><p>采用SGD优化下面目标函数，总能找到一系列输入<span class="math inline">\((x^{(1)*},...,x^{(n)*})\)</span>： <span class="math display">\[ min~L(x,x^{(1)*},...,x^{(n)*})=min~\sum_{i=1}^{n}\lambda_i|{f}^{(i)}(x^{(i)*})-\widetilde{f}^{(i)}(x)|^2 \]</span></p><p>文中附录部分证明不可能找到唯一序列使得：<span class="math inline">\(x^*=x^{(1)*}=...=x^{(n)*}\)</span></p><p>所以每次Dropout都是在生成新的样本。</p><h3 id="数据扩充">5.5.6 数据扩充</h3><p>基本方法 正如前面所说，数据扩充本质是减少过拟合的方法，AlexNet使用的方法计算量较小，所以也不用存储在磁盘，代码实现时，当GPU在训练前一轮图像时，后一轮的图像扩充在CPU上完成，扩充使用了两种方法：</p><p>1、图像平移和图像反射(关于某坐标轴对称)；</p><p>2、通过ImageNet训练集做PCA，用PCA产生的特征值和特征向量及期望为0标准差为0.1的高斯分布改变原图RGB三个通道的强度，该方法使得top-1错误率降低1%。</p><h3 id="多gpu训练">5.5.7 多GPU训练</h3><p>作者使用GTX 580来加速训练，但受限于当时硬件设备的发展，作者需要对网络结构做精细化设计，甚至需要考虑两块GPU之间如何及何时通信，现在的我们比较幸福，基本不用考虑这些。</p><h3 id="alexnet代码实践">5.5.8 AlexNet代码实践</h3><p>使用<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>标准数据集，由6w张32×32像素图片组成，一共10个分类。像这样：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvdmto1d13f3mj8csu94fu1t.png" width="500"></center><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10,mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num*num):</span><br><span class="line">        axes=plt.subplot(num,num,i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#以下结构统一忽略LRN层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_AlexNet</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#第一层，卷积层 + max pooling</span></span><br><span class="line">    model.add(Convolution2D(<span class="number">96</span>, <span class="number">11</span>, <span class="number">11</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, input_shape = s))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment">#第二层，卷积层 + max pooling</span></span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment">#第三层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment">#第四层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">1024</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment">#第五层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">1024</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    <span class="comment">#第六层，全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">3072</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment">#第七层，全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment">#第八层， 输出层</span></span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    //使用第三个GPU卡</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>,                                                                                    allow_growth=<span class="literal">True</span>)</span><br><span class="line">        //只有卡<span class="number">3</span>可见防止tensorflow占用所有卡</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>]=<span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        model = build_AlexNet(s)</span><br><span class="line">        model.summary()</span><br><span class="line"></span><br><span class="line">        plot(model, to_file=<span class="string">&quot;AlexNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#预处理与数据扩充</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">25</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">False</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">                  verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br><span class="line">        y_hat = model.predict_classes(X_test)</span><br><span class="line">        test_wrong = [im <span class="keyword">for</span> im <span class="keyword">in</span> <span class="built_in">zip</span>(X_test,y_hat,y_test) <span class="keyword">if</span> im[<span class="number">1</span>] != im[<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">        <span class="keyword">for</span> ind, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_wrong[:<span class="number">100</span>]):</span><br><span class="line">            plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">            plt.subplot(<span class="number">10</span>, <span class="number">10</span>, ind + <span class="number">1</span>)</span><br><span class="line">            plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">            plt.text(<span class="number">0</span>, <span class="number">0</span>, val[<span class="number">2</span>][<span class="number">0</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">            plt.text(<span class="number">8</span>, <span class="number">0</span>, val[<span class="number">1</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">            plt.imshow(toimage(val[<span class="number">0</span>]))</span><br><span class="line">        savefig(<span class="string">&#x27;Wrong.jpg&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><ul><li>训练数据可视化</li></ul><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv7v5le1fkv1id5fe5180v17lt9.png" width="400"></center><ul><li>网络结构<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv8dth1kq99h1vvn1j72ofl13.png" width="300"></center></li></ul><p>可以看到实践中，AlexNet的参数规模巨大（将近2亿个参数），所以即使在GPU上训练也很慢。</p><ul><li><p>错误分类可视化</p><p>蓝色为实际分类，红色为预测分类。</p></li></ul><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvjlvf9g4gl591a301tnn7722a.png" width="500"></center><h2 id="vgg">5.6 VGG</h2><p>在论文《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>》中提出，通过缩小卷积核大小来构建更深的网络。</p><h3 id="网络结构">5.6.1 网络结构</h3><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbj7cd733bns621ibu9p9g8d9.png" width="600"></center><p>图中D和E分别为VGG-16和VGG-19，是文中两个效果最好的网络结构，VGG网络结构可以看做是AlexNet的加深版，VGG在图像检测中效果很好（如：Faster-RCNN），这种传统结构相对较好的保存了图片的局部位置信息（不像GoogLeNet中引入Inception可能导致位置信息的错乱）。 与AlexNet相比：</p><ul><li><p>相同点</p><ul><li><p>整体结构分五层；</p></li><li><p>除softmax层外，最后几层为全连接层；</p></li><li><p>五层之间通过max pooling连接。</p></li></ul></li><li><p>不同点</p><ul><li><p>使用3×3的小卷积核代替7×7大卷积核，网络构建的比较深；</p></li><li><p>由于LRN太耗费计算资源，性价比不高，所以被去掉；</p></li><li><p>采用了更多的feature map，能够提取更多的特征，从而能够做更多特征的组合。</p></li></ul></li></ul><h3 id="vgg代码实践">5.6.2 VGG代码实践</h3><p>VGG-16/VGG-19</p><p>使用<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a>数据集，ps复杂网络在这种数据集上表现不好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar100,mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num*num):</span><br><span class="line">        axes=plt.subplot(num,num,i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_VGG_16</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    fm = <span class="number">3</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>),input_shape=s))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">100</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_VGG_19</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    fm = <span class="number">3</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>),input_shape=s))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">100</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:2&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>,                                                                                    allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>]=<span class="string">&quot;2&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar100.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> (s)</span><br><span class="line">        model = build_VGG_16(s) <span class="comment">#build_VGG_19(s)</span></span><br><span class="line">        model.summary()</span><br><span class="line"></span><br><span class="line">        plot(model, to_file=<span class="string">&quot;VGG.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">100</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">False</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line">        <span class="comment"># training</span></span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><h2 id="msranet">5.7 MSRANet</h2><p>该网络的亮点有两个：提出PReLU和一种鲁棒性强的参数初始化方法</p><h3 id="prelu">5.7.1 PReLU</h3>前面已经介绍过传统ReLU的一些缺点，PReLU是其中一种解决方案：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvq8lr81905f8m1do2fta2b59.png" width="500"></center><p>如何合理保留负向信息，一种方式是上图中<span class="math inline">\(\alpha\)</span>值是可以不通过人为指定而自动学出来：</p><p>定义Parametric Rectifiers如下： <span class="math display">\[ f(y_i)=\left\{ \begin{aligned} y_i, &amp; \text{if } y_i&gt;0 \\ \alpha_i y_i, &amp; else. \end{aligned} \right. \]</span> 利用误差反向传播原理： <span class="math display">\[ \begin{array}{l} \frac{\partial{E}}{\partial{\alpha_i}}=\sum_{y_i}\frac{\partial{E}}{\partial{f(y_i)}}\frac{\partial{f(y_i)}}{\partial{\alpha_i}} \end{array} \]</span> <span class="math display">\[ \frac{\partial{f(y_i)}}{\partial{\alpha_i}}=\left\{ \begin{aligned} y_i, &amp;(y_i\leq 0) \\ 0, &amp;(y_i&gt;0) \end{aligned} \right. \]</span> 当采用动量法更新<span class="math inline">\(\alpha\)</span>权重： <span class="math display">\[ \Delta\alpha_i=\mu\Delta\alpha_i+\epsilon\frac{\partial{E}}{\partial{\alpha_i}} \]</span> 详情请阅读Kaiming He等人的《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》</a>论文。</p><h2 id="highway-networks">5.8 Highway Networks</h2>Highway Networks在我看来是一种承上启下的结构，来源于论文《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.00387">Highway Networks</a>》借鉴了类似LSTM(后面会介绍)中门(gate)的思想，结构很通用(太通用的结构不一定是件好事儿)，给出了一种建立更深网络的思路：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bccghn95ouk13mihb18dk1htum.png" width="600"></center><p><span class="math display">\[ \begin{array}{l} y=H(x,W_h)\cdot T(x,W_t)+x \cdot C(x,W_c) \end{array} \]</span> 任何一层或几层都可以通过上述方式构建Block，公式中<span class="math inline">\(T\)</span>叫做transform gate，<span class="math inline">\(C\)</span>叫做carry gate，一般简单起见可以让<span class="math inline">\(C=1-T\)</span>，显然公式中<span class="math inline">\(x\)</span>，<span class="math inline">\(y\)</span>，<span class="math inline">\(H(x,W_h)\)</span>，<span class="math inline">\(T(x,W_t)\)</span>需要有相同的维度（比如，可以通过zero-padding或者做映射），通过这种结构可以把网络做到很深(比如100层以上)，并且优化没有那么困难，看着似乎提供了解决“深”网络学习问题的方案(下一节会解释“似乎”这个词)。</p><h2 id="residual-networks">5.9 Residual Networks</h2><p>残差网络在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>》中被第一次提出，作者利用它在ILSVRC 2015的ImageNet 分类、检测、定位任务以及COCO 2015的检测、图像分割任务上均拿到第一名，也证明ResNet是比较通用的框架。</p><h3 id="resnet产生的动机">5.9.1 ResNet产生的动机</h3>我一直说深度学习的研究很大程度是实验科学，ResNet的研究上也比较能体现这点。一个问题：是否能够通过简单的增加网络层数就能学到更好的模型呢？通过实验发现答案是否定的，并且随着层数的增加预测精度会趋于饱和，然后迅速下降，这个现象叫degradation。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcgu3avu1dc10dc1gbm1jmdpdt9.png" width="500"></center>图中可以看到在CIFAR-10数据集上，20层网络在训练集和测试集上的表现都明显好于56层网络，这显然不是过拟合导致的，这个现象也不符合我们的直观映像：按理说多增加一层的模型效果应该好于未增加时的模型，最起码不应该变差（比如直接做<span class="math inline">\(f(x)=x\)</span>恒等映射），于是作者提出原始的残差学习框架（也可以看成是Highway Networks在T=0.5时的特例）：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch1m72996df6b1aqpjb43ka1g.png" width="400"></center><p><span class="math display">\[ \begin{array}{l} y_l=h(x_l)+F(x_l,\{W_l\})\\ x_{l+1}=f(y_l) \end{array} \]</span> 其中<span class="math inline">\(h(x_l)=x_l\)</span>为恒等映射，<span class="math inline">\(f\)</span>为<span class="math inline">\(ReLU\)</span>激活函数，输入和输出的维度是一样的（即使不一样也可以通过zero-padding或再做一次映射变成一样），图中恒等映射是在两层神经网络后，也可以在任意层后。 这个框架的假设是：多层非线性激活的神经网络学习恒等映射的能力比较弱，直接将恒等映射加入可以跳过这个问题。 与Highway Networks相比： - HN的transform gate和carry</p><h3 id="恒等映射">5.9.2 恒等映射</h3>恒等映射在深度残差网络中究竟扮演什么角色呢？在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.05027">Identity Mappings in Deep Residual Networks</a>》中作者做了分析，并提出新的残差block结构，将<span class="math inline">\(h(x_l)=x_l\)</span>和<span class="math inline">\(f(y_l)=y_l\)</span>都改为恒等映射，通过这个变化使得信号在前向和反向传播中都有“干净”的路径（图中灰色部分），a为原始block结构，b为新的结构。。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch28tob175blpk1mri13no1gas2a.png" width="300"></center><p>原始结构： <span class="math display">\[ \begin{array}{l} x_{l+1}=relu(B(W_{i2}^T\cdot relu (B(W_{i1}^T\cdot x_l)))+x_l) \end{array} \]</span></p><p>新结构： <span class="math display">\[ \begin{array}{l} x_{l+1}=W_{i2}^T\cdot relu(B(W_{i1}^T\cdot relu(B(x_l))))+x_l \end{array} \]</span></p><p>其中<span class="math inline">\(B\)</span>为Batch Normalization。</p>在CIFAR-10上用1001层残差网络做测试，效果如下:<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch6qshn1uu8evo1mek1q04j0j2n.png" width="400"></center><p>新的proposed结构比原始结构效果明显： 双恒等映射下，任何一个残差block如下： <span class="math display">\[ \begin{array}{l} x_{l+1}=x_l+F(x_l,\{W_l\}) \end{array} \]</span> 对上述结构做递归展开，任何一个深层block和其所有浅层block的关系为： <span class="math display">\[ \begin{array}{l} x_L=x_l+\sum_{i=l}^{L-1}F(x_i,\{W_i\})\\ x_L=x_0+\sum_{i=0}^{L-1}F(x_i,\{W_i\}) \end{array} \]</span> 这个形式会有很好的计算性质，回想GBDT，是否觉得有点像？在反向传播时同样也有良好的性质： <span class="math display">\[ \begin{array}{l} \frac{\partial E}{\partial x_l}=\frac{\partial E}{\partial x_L}\frac{\partial x_L}{\partial x_l}=\frac{\partial E}{\partial x_L}(1+\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}F(x_i,\{W_i\})) \end{array} \]</span> 前半部分<span class="math inline">\(\frac{\partial E}{\partial x_L}\)</span>传播时完全不用考虑权重层，可以很直接的把误差的梯度信息反向传播给任何一个浅层block，而<span class="math inline">\(\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}F(x_i,\{W_i\})\)</span>在mini-batch时又不太可能总为-1，所以即使权重很小也很难出现梯度消失的问题。假如不采用恒等映射，例如：<span class="math inline">\(h(x_l)=\lambda_lx_l\)</span>，则： <span class="math display">\[ \begin{array}{l} x_{l+1}=\lambda_lx_l+F(x_l,\{W_l\})\\ x_L=(\prod_{i=1}^{L-1}\lambda_i)x_l+\sum_{i=l}^{L-1}(\prod_{j=i+1}^{L-1}\lambda_j)F(x_i,\{W_i\})\\ \frac{\partial E}{\partial x_l}=\frac{\partial E}{\partial x_L}(\prod_{i=1}^{L-1}\lambda_i+\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}(\prod_{j=i+1}^{L-1}\lambda_j)F(x_i,\{W_i\})) \end{array} \]</span> 如果网络比较深，对于参数<span class="math inline">\(\prod_{i=1}^{L-1}\lambda_i\)</span>，当<span class="math inline">\(\lambda_i&gt;1\)</span>时它会很大；当<span class="math inline">\(\lambda_i&lt;1\)</span>时，它会很小甚至消失，此时反向信号会被强制流到block的各个权重层，显然恒等映射的优点完全没有了。</p><h3 id="模型集成角度看残差网络">5.9.3 模型集成角度看残差网络</h3>《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1605.06431">Residual Networks Behave Like Ensembles of Relatively Shallow Networks</a>》中把残差网络做展开，其实会发现以下关系：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjstr2317mfjvu1vmk1ks650tp.png" width="600"></center>如果有<span class="math inline">\(n\)</span>个残差block，展开后会得到<span class="math inline">\(2^n\)</span>个路径，于是残差网络就可以看成这么多模型的集成。那么这些路径之间是否有互相依赖关系呢：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjtdpgvo9d4mu1qgvnnf1as816.png" width="600"></center>可以看到删除VGG任何一层，不管在CIFAR-10还是ImageNet数据集上，准确率立马变得惨不忍睹，而删除残差网络的任何一个block几乎不会影响效果，但删除采样层会对效果影响较大(采样层不存在展开多路径特点)，上面实验表明对残差网络，虽然多路径是联合训练的，但路径间相互没有强依赖性，直观的解释如图：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcju6o25j461qs419hj175kbv23.png" width="500"></center>即使删掉<span class="math inline">\(f_2\)</span>这个节点，还有其它路径存在，而非残差结构的路径则会断掉。 残差网络看做集成模型可以通过下面实验结果得到印证：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjunpd21l3d15gltbnb3c1flo2g.png" width="600"></center><p>模型在运行时的效果与有效路径的个数成正比且关系平滑，左图说明残差网络的效果类似集成模型，右图说明实践中残差网络可以在运行时做网络结构修改。</p><h3 id="残差网络中的短路径">5.9.4 残差网络中的短路径</h3>通过残差block的结构可知展开后的<span class="math inline">\(n\)</span>个路径的长度服从二项分布<span class="math inline">\(X\sim B(n,1/2)\)</span>，(每次选择是否跳过权重层的概率是0.5)，所以其期望为：<span class="math inline">\(n/2\)</span>，下面三幅图是在有54个残差block下的实验，第一幅图为路径分布图，可以看到95%的路径长度都在19~35之间：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck0vn7b165t11ic1r8qq4btb32t.png" width="300"></center>由于路径长短不同，在反向传播时携带的梯度信息量也不同，路径长度与携带梯度信息量成反比，实验结果如下图：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck114mu1q796bt1a1n17oi1ejg47.png" width="300"></center>残差网络中真正有效的路径几乎都是浅层路径，实验中有效路径长度在5~17之间，所以实践中做模型压缩可以先从长路径入手。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck10n9n1oriqt7k915eb1psv3q.png" width="300"></center><p>虽然残差网络没有解决梯度消失问题，只是把它给绕过了，并没有解决深层神经网络的本质问题，但我们应用时更多的看实践效果。</p><h3 id="代码实践">5.9.5 代码实践</h3>下面我们实现在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>》中提到的ResNet-34，并演示在CIFAR-10下的训练效果。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bckd30m886a135elhmf2m125c5u.png" width="400"></center><ul><li><p>resnet.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> add</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Activation, Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Conv2D, MaxPooling2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;残差网络基本模块定义&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">&#x27;resnet&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.name = n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN与ReLU子结构，针对tensorflow&#x27;&#x27;&#x27;</span></span><br><span class="line">        normalize = BatchNormalization(axis=<span class="number">3</span>)(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(normalize)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn_relu_weight</span>(<span class="params">self, filters, kernel_size, strides</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN-&gt;ReLu-&gt;Weight的子结构&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            act = self.bn_relu(<span class="built_in">input</span>)</span><br><span class="line">            conv = Conv2D(filters=filters,</span><br><span class="line">                          kernel_size=kernel_size,</span><br><span class="line">                          strides=strides,</span><br><span class="line">                          padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                          kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                          kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(act)</span><br><span class="line">            <span class="keyword">return</span> conv</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_bn_relu</span>(<span class="params">self, filters, kernel_size, strides</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN-&gt;ReLu-&gt;Weight的子结构&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="keyword">return</span> self.bn_relu(Conv2D(filters=filters,</span><br><span class="line">                                       kernel_size=kernel_size,</span><br><span class="line">                                       strides=strides,</span><br><span class="line">                                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shortcut</span>(<span class="params">self, left, right</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中恒等映射的子结构，分两种情况，输入、输出维度一致&amp;维度不一致&#x27;&#x27;&#x27;</span></span><br><span class="line">        left_shape = K.int_shape(left)</span><br><span class="line">        right_shape = K.int_shape(right)</span><br><span class="line">        stride_width = <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">1</span>] / right_shape[<span class="number">1</span>]))</span><br><span class="line">        stride_height = <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">2</span>] / right_shape[<span class="number">2</span>]))</span><br><span class="line">        equal_channels = left_shape[<span class="number">3</span>] == right_shape[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x_l = left</span><br><span class="line">        <span class="comment"># 如果输入输出维度不一致需要通过映射变一致，否则一致则返回单位矩阵，这个映射发生在两个不同维度block之间(论文中虚线部分)</span></span><br><span class="line">        <span class="keyword">if</span> left_shape != right_shape:</span><br><span class="line">            x_l = Conv2D(filters=right_shape[<span class="number">3</span>],</span><br><span class="line">                         kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                         strides=(<span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">1</span>] / right_shape[<span class="number">1</span>])),</span><br><span class="line">                                  <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">2</span>] / right_shape[<span class="number">2</span>]))),</span><br><span class="line">                         padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">                         kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                         kernel_regularizer=l1_l2(<span class="number">0.01</span>, <span class="number">0.0001</span>))(left)</span><br><span class="line"></span><br><span class="line">        x_l_1 = add([x_l, right])</span><br><span class="line">        <span class="keyword">return</span> x_l_1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">basic_block</span>(<span class="params">self, filters, strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>), is_first_block=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;34层以内的残差网络使用的block，2层一跨&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="comment"># 恒等映射</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> is_first_block:</span><br><span class="line">                conv1 = self.bn_relu_weight(filters=filters,</span><br><span class="line">                                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                            strides=strides)(<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                conv1 = Conv2D(filters=filters, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                               strides=strides,</span><br><span class="line">                               padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">                               kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                               kernel_regularizer=l1_l2(<span class="number">0.01</span>, <span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line">            <span class="comment"># 残差网络</span></span><br><span class="line">            residual = self.bn_relu_weight(filters=filters,</span><br><span class="line">                                           kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(conv1)</span><br><span class="line">            <span class="comment"># 构建一个两层的残差block</span></span><br><span class="line">            <span class="keyword">return</span> self.shortcut(<span class="built_in">input</span>, residual)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">residual_block</span>(<span class="params">self, block_func, filters, repeat_times, is_first_block</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建多层残差block&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeat_times):</span><br><span class="line">                <span class="comment"># 第一个block的第一层，其输入为pooling层</span></span><br><span class="line">                <span class="keyword">if</span> is_first_block:</span><br><span class="line">                    strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">0</span>:  <span class="comment"># 每个残差block的第一层</span></span><br><span class="line">                        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">else</span>:  <span class="comment"># 每个残差block的非第一层</span></span><br><span class="line">                        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                flag = i == <span class="number">0</span> <span class="keyword">and</span> is_first_block</span><br><span class="line">                <span class="built_in">input</span> = block_func(filters=filters,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   is_first_block=flag)(<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">residual_builder</span>(<span class="params">self, input_shape, softmax_num, func_type, repeat_times</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;指定输入、输出、残差block的类型、网络深度并构建残差网络&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">input</span> = Input(shape=input_shape)</span><br><span class="line">        <span class="comment"># 第一层为卷积层</span></span><br><span class="line">        conv1 = self.weight_bn_relu(filters=<span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(<span class="built_in">input</span>)</span><br><span class="line">        <span class="comment"># 第二层为max pooling层</span></span><br><span class="line">        pool1 = MaxPooling2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&quot;same&quot;</span>)(conv1)</span><br><span class="line">        residual_block = pool1</span><br><span class="line">        filters = <span class="number">64</span></span><br><span class="line">        <span class="comment"># 接着16个残差block</span></span><br><span class="line">        <span class="keyword">for</span> i, r <span class="keyword">in</span> <span class="built_in">enumerate</span>(repeat_times):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                residual_block = self.residual_block(func_type,</span><br><span class="line">                                                     filters=filters,</span><br><span class="line">                                                     repeat_times=r,</span><br><span class="line">                                                     is_first_block=<span class="literal">True</span>)(residual_block)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual_block = self.residual_block(func_type,</span><br><span class="line">                                                     filters=filters,</span><br><span class="line">                                                     repeat_times=r,</span><br><span class="line">                                                     is_first_block=<span class="literal">False</span>)(residual_block)</span><br><span class="line">            filters *= <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        residual_block = self.bn_relu(residual_block)</span><br><span class="line">        shape = K.int_shape(residual_block)</span><br><span class="line">        <span class="comment"># average pooling层</span></span><br><span class="line">        pool2 = AveragePooling2D(pool_size=(shape[<span class="number">1</span>], shape[<span class="number">2</span>]),</span><br><span class="line">                                 strides=(<span class="number">1</span>, <span class="number">1</span>))(residual_block)</span><br><span class="line">        flatten1 = Flatten()(pool2)</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        dense1 = Dense(units=softmax_num,</span><br><span class="line">                       kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                       activation=<span class="string">&quot;softmax&quot;</span>)(flatten1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Model(inputs=<span class="built_in">input</span>, outputs=dense1)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p></li><li><p>resnet-cifar-10.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> resnet</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau, CSVLogger, EarlyStopping</span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num * num):</span><br><span class="line">        axes = plt.subplot(num, num, i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line"></span><br><span class="line">        builder = resnet.ResNet(<span class="string">&quot;ResNet-test&quot;</span>)</span><br><span class="line">        resnet_34 = builder.residual_builder(s, class_num, builder.basic_block, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line">        model = resnet_34</span><br><span class="line">        model.summary()</span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;ResNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">100</span></span><br><span class="line">        <span class="comment"># import pdb</span></span><br><span class="line">        <span class="comment"># pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>,</span><br><span class="line">                        save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),</span><br><span class="line">                            steps_per_epoch=X_train.shape[<span class="number">0</span>],</span><br><span class="line">                            validation_data=(X_test, Y_test),</span><br><span class="line">                            epochs=nb_epoch,</span><br><span class="line">                            verbose=<span class="number">1</span>,</span><br><span class="line">                            max_q_size=<span class="number">100</span>,</span><br><span class="line">                            callbacks=[lr_reducer, early_stopper, csv_logger])</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>ps：注意使用keras的plot_model函数需要安装graphviz与pydot_ng，且安装顺序为先graphviz后pydot_ng。<p></p></li><li><p>graphviz安装 yum list available 'graphviz<em>' yum install 'graphviz</em>'</p></li><li><p>pydot_ng安装 pip install pydot_ng</p></li><li>网络结构<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcuf44v814n11e17eco10fqha4i.png" width="300"></center></li></ul><p>可以看到网络结构很复杂但需要训练的参数个数只有21296522个，远小于AlexNet参数个数。</p><ul><li>CIFAR-10训练情况<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdfrbd74dti1kpn8b2nho1l9u9.png" width="600"></center></li></ul><p>迭代100次后，训练集上Acc为：0.8367，测试集上Acc为0.8346。</p><h2 id="maxout-networks">5.10 Maxout Networks</h2><p>Goodfellow等人在《<a target="_blank" rel="noopener" href="http://www.jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a>》一文中提出，这篇论文值得一看。 ### 5.10.1 Maxout激活函数 对于神经网络任意一层可以添加Maxout结构，公式如下： <span class="math display">\[ \begin{array}{l} h_i(x)=max_{j\in [1,k]}z_{ij}\\ z_{ij}=x^TW_{...ij}+b_{ij} \end{array} \]</span> 上面的<span class="math inline">\(W\)</span>和<span class="math inline">\(b\)</span>是要学习的参数，这些参数可以通过反向传播计算，<span class="math inline">\(k\)</span>是事先指定的参数，<span class="math inline">\(x\)</span>是输入节点，假定有以下3层网络结构：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahcfttqvb61mgjjom10f0qjg9.png" width="300"></center><p>Maxout激活可以认为是在输入节点<span class="math inline">\(x\)</span>和输出节点<span class="math inline">\(h\)</span>中间加了<span class="math inline">\(k\)</span>个隐含节点，以上图节点<span class="math inline">\(i\)</span>为例，<strong>上图红色部分</strong>在Maxout结构中被扩展为以下结构：</p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahdkbr71mq0bnoen29g715t3m.png" width="350"></center>实际上图所示的单个Maxout 单元本质是一个分段线性函数，而任意凸函数都可以通过分段线性函数来拟合，这个可以很直观的理解，以抛物线为例：每个<span class="math inline">\(z\)</span>节点都是一个线性函数，上图<span class="math inline">\(z_1\)</span>-<span class="math inline">\(z_4\)</span>节点输出对应下图<span class="math inline">\(k_1\)</span>-<span class="math inline">\(k_4\)</span>线段：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahgd34419nmh3l15hk6srpvc1g.png" width="300"></center><p>从全局上看，ReLU可以看做Maxout的一种特例，Maxout通过网络自动学习激活函数(从这个角度看Maxout也可以看做某种Network-In-Network结构)，不对<span class="math inline">\(k\)</span>做限制，只要两个Maxout 单元就能拟合任意连续函数，关于这部分论文中有更详细的证明，这里不再赘述，实际上它与Dropout配合效果更好，这里可以回想下核方法(Kernel Method)，核方法采用非线性核（如高斯核）也会有类似通过局部线性拟合来模拟非线性行为，但传统核方法会事先指定核函数（如高斯函数），而不是数据驱动的方式算出来，当然也有kernel组合方面的研究，但在我看来最终和神经网络殊途同归，其实都可以在神经网络的大框架下去思考（回想前面的SVM与神经网络的关系）。 凡事都有两面性，Maxout的缺点也是明显的：多了一倍参数、需要人为指定<span class="math inline">\(k\)</span>值、先验假设被学习的激活函数是凸的。</p><h2 id="network-in-network">5.11 Network in Network</h2><p>NIN的思想来源于《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.4400">Network In Network</a>》,其亮点有2个方面：将传统卷积层替换为非线性卷积层以提升特征抽象能力；使用新的pooling层代替传统全连接层，后续出现的各个版本GoogLeNet也很大程度借鉴了这个思想。</p><h3 id="nin卷积层mlp-convolution">5.11.1 NIN卷积层(MLP Convolution)</h3><p>传统卷积操作，例如：<span class="math inline">\(f_{i,j,k}=max(W_k^T \cdot x_{i,j},0)\)</span>，本质是广义线性模型，意味着当数据接近线性可分时模型效果会比较好，反之亦然。Maxout网络在一定程度上解决了这个问题，但它有凸函数的假设，实际当中可能很多情况是非凸的，所以论文提出使用多层感知机(MLP)来拟合，不做任何先验假设。 选择MLP的原因是：</p><ul><li><p>MLP能拟合任意函数，不需要做先验假设(如：线性可分、凸集)；</p></li><li><p>MLP与卷积神经网络结构天然兼容，可以通过BP方便的做训练；</p></li><li><p>MLP本身也能做的较深，且特征能够得到复用；</p></li><li>通过MLP做卷积可以起到feature map级联交叉加权组合的作用，能提升特征抽象能力： <span class="math display">\[ \begin{array}{l} f^1_{i,j,k_1}=max({w^1_{k_1}}^Tx_{i,j}+b_{k_1},0)\\ \quad\quad \quad .\\ \quad\quad \quad .\\ \quad\quad \quad .\\ f^1_{i,j,k_n}=max({w^n_{k_n}}^Tf_{i,j}^{n-1}+b_{k_n},0). \end{array} \]</span><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15as53vqk1k4b1g601kic180s9.png" width="500"></center></li></ul>显然这个结构也等价于传统卷积层接着一个1×1卷积层，简单起见，下面示意图中激活函数使用线性激活（使用ReLU无非是让某些输出可能为0，不影响问题说明）：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd5oqug8c827q01unr1i701lab9.png" width="500"></center><p><span class="math display">\[ \begin{array}{l} O_1=\sum_{i=1}^2\sum_{j=1}^2x_{ij} \cdot W_{ij} \cdot (C_1 \cdot W_{1ij}+ C_2 \cdot W_{ij,2})\\ C1=W_{m11}W_{o31}+W_{m12}W_{o32}\\ C2=W_{m21}W_{o31}+W_{m22}W_{o32} \end{array} \]</span> <span class="math inline">\(O_1\)</span>的前半部分是传统卷积层，后半部分可以看做1×1卷积层。 ### 5.11.2 NIN抽样层(Global Average Pooling) 把传统卷积网络分两部分看待：除全连接层外的各个卷积层看做特征提取器，全连接层看成特征组合器。由于全连接的存在破坏了数据的可解释性并大大增加了可训练参数的个数，NIN通过GAP来避免这两个问题，具体做法是：</p><ul><li>最后一层卷积feature map的个数与分类类别数一致，这种一致性可以产生相对较少的feature map，比如有10个分类和10个n×n的feature map；</li><li>每个feature map对应一个分类，并对整个feature map求平均值，这种方法能提高空间变换的稳定性，但损失了位置信息（例如在目标检测中位置信息很重要），比如10个n×n的feature map会得到10个实数值组成的一维向量；</li><li>用softmax做归一化，注意这里要区分传统CNN下的softmax激活和softmax归一，这一层没有需要优化的参数。 传统CNN与Mlpconv的区别如下图：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd16cnk617e3160k1uvuar8n032q.png" width="600"></center></li></ul>最后整个NIN的网络结构如下图：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15r350126392fmchslo1uh120.png" width="500"></center><h2 id="googlenet-inception-v1">5.12 GoogLeNet Inception V1</h2><p>GoogLeNet是由google的Christian Szegedy等人在2014年的论文《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a>》提出，其最大的亮点是提出一种叫Inception的结构，以此为基础构建GoogLeNet，并在当年的ImageNet分类和检测任务中获得第一，ps：GoogLeNet的取名是为了向YannLeCun的LeNet系列致敬。</p><h3 id="一些思考">5.12.1 一些思考</h3><p>为了提高深度神经网络的性能，最简单粗暴有效的方法是增加网络深度与宽度，但这个方法有两个明显的缺点：</p><ul><li>更深更宽的网络意味着更多的参数，从而大大增加过拟合的风险，尤其在训练数据不是那么多或者某个label训练数据不足的情况下更容易发生；</li><li>增加计算资源的消耗，实际情况下，不管是因为数据稀疏还是扩充的网络结构利用不充分（比如很多权重接近0），都会导致大量计算的浪费。</li></ul><p>解决以上两个问题的基本方法是将全连接或卷积连接改为稀疏连接。不管从生物的角度还是机器学习的角度，稀疏性都有良好的表现，回想Dropout网络以及ReLU激活函数，其本质就是利用稀疏性提高模型泛化性（但需要计算的参数没变少）。 简单解释下稀疏性，当整个特征空间是非线性甚至不连续时：</p><ul><li>学好局部空间的特征集更能提升性能，类似于Maxout网络中使用多个局部线性函数的组合来拟合非线性函数的思想；</li><li>假设整个特征空间由N个不连续局部特征空间集合组成，任意一个样本会被映射到这N个空间中并激活/不激活相应特征维度，如果用C1表示某类样本被激活的特征维度集合，用C2表示另一类样本的特征维度集合，当数据量不够大时，要想增加特征区分度并很好的区分两类样本，就要降低C1和C2的重合度（比如可用Jaccard距离衡量），即缩小C1和C2的大小，意味着相应的特征维度集会变稀疏。</li></ul>尴尬的是，现在的计算机体系结构更善于稠密数据的计算，而在非均匀分布的稀疏数据上的计算效率极差，比如稀疏性会导致的缓存miss率极高，于是需要一种方法既能发挥稀疏网络的优势又能保证计算效率。好在前人做了大量实验（如《<a target="_blank" rel="noopener" href="http://www.bmi.osu.edu/~umit/papers/Catalyurek10-SISC.pdf">On Two-Dimensional Sparse Matrix Partitioning: Models, Methods, and a Recipe</a>》），发现对稀疏矩阵做聚类得到相对稠密的子矩阵可以大幅提高稀疏矩阵乘法性能，借鉴这个思想，作者提出Inception的结构。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd8rs6me1krhgtl1jvh164rt1s9.png" width="500"></center><ul><li>把不同大小卷积核抽象得到的特征空间看做子特征空间，每个子特征空间都是稀疏的，把这些不同尺度特征做融合，相当于得到一个相对稠密的空间；</li><li>采用1×1、3×3、5×5卷积核(不是必须的，也可以是其他大小)，stride取1，利用padding可以方便的做输出特征维度对齐；</li><li>大量事实表明pooling层能有效提高卷积网络的效果，所以加了一条max pooling路径；</li><li>这个结构符合直观理解，视觉信息通过不同尺度的变换被聚合起来作为下一阶段的特征，比如：人的高矮、胖瘦、青老信息被聚合后做下一步判断。</li></ul><p>这个网络的最大问题是5×5卷积带来了巨大计算负担，例如，假设上层输入为：28×28×192：</p><ul><li>直接经过96个5×5卷积层(stride=1，padding=2)后，输出为：28×28×96，卷积层参数量为：192×5×5×96=460800；</li><li>借鉴NIN网络，在5×5卷积前使用32个1×1卷积核做维度缩减，变成28×28×32，之后经过96个5×5卷积层(stride=1，padding=2)后，输出为：28×28×96，但所有卷积层的参数量为：192×1×1×32+32×5×5×96=82944，可见整个参数量是原来的1/5.5，且效果上没有多少损失。 新网络结构为：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd91d78tsrb1qjl8jk1hio16dnm.png" width="500"></center></li></ul><h3 id="googlenet结构">5.12.2 GoogLeNet结构</h3>利用上述Inception模块构建GoogLeNet，实验表明Inception模块出现在高层特征抽象时会更加有效（我理解由于其结构特点，更适合提取高阶特征，让它提取低阶特征会导致特征信息丢失），所以在低层依然使用传统卷积层。整个网路结构如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd92vlme2jdpg82ie1nclfa913.png" width="600"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd99affn1qkv1c1roijq4j10l526.png" width="600"></center><p>网络说明：</p><ul><li><strong>所有卷积层</strong>均使用ReLU激活函数，包括做了1×1卷积降维后的激活；</li><li>移除全连接层，像NIN一样使用Global Average Pooling，使得Top 1准确率提高0.6%，但由于GAP与类别数目有关系，为了方便大家做模型fine-tuning，最后加了一个全连接层；</li><li>与前面的ResNet类似，实验观察到，相对浅层的神经网络层对模型效果有较大的贡献，训练阶段通过对Inception(4a、4d)增加两个额外的分类器来增强反向传播时的梯度信号，但最重要的还是<strong>正则化作用</strong>，这一点在GoogLeNet v3中得到实验证实，并间接证实了GoogLeNet V2中BN的正则化作用，这两个分类器的loss会以0.3的权重加在整体loss上，在模型inference阶段，这两个分类器会被去掉；</li><li>用于降维的1×1卷积核个数为128个；</li><li>全连接层使用1024个神经元；</li><li>使用丢弃概率为0.7的Dropout层；</li></ul><p>网络结构说明：</p><p>输入数据为224×224×3的RGB图像，图中"S"代表做same-padding，"V"代表不做。</p><ul><li>C1卷积层：64个7×7卷积核(stride=2，padding=3)，输出为：112×112×64；</li><li>P1抽样层：64个3×3卷积核(stride=2)，输出为56×56×64，其中：56=(112-3+1)/2+1</li><li>C2卷积层：192个3×3卷积核(stride=1，padding=1)，输出为：56×56×192；</li><li>P2抽样层：192个3×3卷积核(stride=2)，输出为28×28×192，其中：28=(56-3+1)/2+1，接着数据被分出4个分支，进入Inception (3a)</li><li>Inception (3a)：由4部分组成<ul><li>64个1×1的卷积核，输出为28×28×64;</li><li>96个1×1的卷积核做降维，输出为28×28×96，之后128个3×3卷积核(stride=1，padding=1)，输出为：28×28×128</li><li>16个1×1的卷积核做降维，输出为28×28×16，之后32个5×5卷积核(stride=1，padding=2)，输出为：28×28×32</li><li>192个3×3卷积核(stride=1，padding=1)，输出为28×28×192，进行32个1×1卷积核，输出为：28×28×32 最后对4个分支的输出做“深度”方向组合，得到输出28×28×256，接着数据被分出4个分支，进入Inception (3b)；</li></ul></li><li>Inception (3b)：由4部分组成<ul><li>128个1×1的卷积核，输出为28×28×128;</li><li>128个1×1的卷积核做降维，输出为28×28×128，进行192个3×3卷积核(stride=1，padding=1)，输出为：28×28×192</li><li>32个1×1的卷积核做降维，输出为28×28×32，进行96个5×5卷积核(stride=1，padding=2)，输出为：28×28×96</li><li>256个3×3卷积核(stride=1，padding=1)，输出为28×28×256，进行64个1×1卷积核，输出为：28×28×64 最后对4个分支的输出做“深度”方向组合，得到输出28×28×480； 后面结构以此类推。</li></ul></li></ul><h3 id="代码实践-1">5.12.3 代码实践</h3><ul><li><p>googlenet_inception_v1.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Conv2D, Dense, MaxPooling2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout, Flatten, merge, ZeroPadding2D, Reshape, Activation</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> googlenet_custom_layers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_module</span>(<span class="params">name,</span></span></span><br><span class="line"><span class="params"><span class="function">                     input_layer,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_3x3_reduce,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_3x3,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_5x5_reduce,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_p_5x5,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_reduce</span>):</span></span><br><span class="line">    inception_1x1 = Conv2D(name=name+<span class="string">&quot;/inception_1x1&quot;</span>,</span><br><span class="line">                           filters=num_c_1x1,</span><br><span class="line">                           kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_3x3_reduce = Conv2D(name=name+<span class="string">&quot;/inception_3x3_reduce&quot;</span>,</span><br><span class="line">                                  filters=num_c_1x1_3x3_reduce,</span><br><span class="line">                                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                  kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                  activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                  kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_3x3 = Conv2D(name=name+<span class="string">&quot;/inception_3x3&quot;</span>,</span><br><span class="line">                           filters=num_c_3x3,</span><br><span class="line">                           kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_3x3_reduce)</span><br><span class="line"></span><br><span class="line">    inception_5x5_reduce = Conv2D(name=name+<span class="string">&quot;/inception_5x5_reduce&quot;</span>,</span><br><span class="line">                                  filters=num_c_1x1_5x5_reduce,</span><br><span class="line">                                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                  kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                  activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                  kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_5x5 = Conv2D(name=name+<span class="string">&quot;/inception_5x5&quot;</span>,</span><br><span class="line">                           filters=num_p_5x5,</span><br><span class="line">                           kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_5x5_reduce)</span><br><span class="line"></span><br><span class="line">    inception_max_pool = MaxPooling2D(name=name+<span class="string">&quot;/inception_max_pool&quot;</span>,</span><br><span class="line">                                      pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                      strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                      padding=<span class="string">&quot;same&quot;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_max_pool_proj = Conv2D(name=name+<span class="string">&quot;/inception_max_pool_project&quot;</span>,</span><br><span class="line">                                     filters=num_c_1x1_reduce,</span><br><span class="line">                                     kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                     strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                     padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                     kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_max_pool)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> (inception_1x1.get_shape(), inception_3x3.get_shape(), inception_5x5.get_shape(), inception_max_pool_proj.get_shape())</span><br><span class="line"></span><br><span class="line"><span class="comment">#    inception_output = tf.concat(3, [inception_1x1, inception_3x3, inception_5x5, inception_max_pool_proj])</span></span><br><span class="line">    <span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate</span><br><span class="line">    <span class="comment">#注意，由于变态的tensorflow更改了concat函数的参数顺序，需要注意自己的tf和keras版本</span></span><br><span class="line">    <span class="comment">#适时的将/usr/lib/python×××/site-packages/keras/backend/tensorflow_backend.py的1554行的代码由</span></span><br><span class="line">    <span class="comment">#return tf.concat([to_dense(x) for x in tensors], axis) 改为：</span></span><br><span class="line">    <span class="comment">#return tf.concat(axis, [to_dense(x) for x in tensors])</span></span><br><span class="line">    inception_output = concatenate([inception_1x1, inception_3x3, inception_5x5, inception_max_pool_proj])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inception_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">googLeNet_inception_v1_building</span>(<span class="params">input_shape, output_num, fine_tune=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    input_layer = Input(shape=input_shape)</span><br><span class="line">    <span class="comment"># 第一层，卷积层</span></span><br><span class="line">    conv1_7x7 = Conv2D(name=<span class="string">&quot;conv1_7x7/2&quot;</span>,</span><br><span class="line">                       filters=<span class="number">64</span>,</span><br><span class="line">                       kernel_size=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">                       strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                       activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    conv1_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(conv1_7x7)</span><br><span class="line">    <span class="comment"># 第二层，max pooling层</span></span><br><span class="line">    pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool1_3x3/2&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(conv1_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二层，LRN规范化</span></span><br><span class="line">    <span class="comment">#pool1_norm1 = tf.nn.lrn(pool1_3x3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#x27;ax_pool1_3x3/norm1&#x27;)</span></span><br><span class="line">    pool1_norm1 = googlenet_custom_layers.LRN2D(name=<span class="string">&#x27;max_pool1_3x3/norm1&#x27;</span>)(pool1_3x3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第四层，卷积层降维</span></span><br><span class="line">    conv2_3x3_reduce = Conv2D(name=<span class="string">&quot;conv2_3x3_reduce/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">64</span>,</span><br><span class="line">                              kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(pool1_norm1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第五层，卷积层</span></span><br><span class="line">    conv2_3x3 = Conv2D(name=<span class="string">&quot;conv2_3x3/1&quot;</span>,</span><br><span class="line">                       filters=<span class="number">192</span>,</span><br><span class="line">                       kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                       activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(conv2_3x3_reduce)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第六层，LRN规范化</span></span><br><span class="line">    <span class="comment">#conv2_norm2 = tf.nn.lrn(conv2_3x3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#x27;conv2_3x3/norm2&#x27;)</span></span><br><span class="line">    conv2_norm2 = googlenet_custom_layers.LRN2D(name=<span class="string">&#x27;conv2_3x3/norm2&#x27;</span>)(conv2_3x3)</span><br><span class="line"></span><br><span class="line">    conv2_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(conv2_norm2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第七层，max pooling层</span></span><br><span class="line">    pool2_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool2_3x3&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(conv2_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第八层，inception 3a</span></span><br><span class="line">    inception_3a = inception_module(<span class="string">&quot;inception_3a&quot;</span>,pool2_3x3, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    <span class="comment"># 第九层，inception 3b</span></span><br><span class="line">    inception_3b = inception_module(<span class="string">&quot;inception_3b&quot;</span>,inception_3a, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">    inception_3b_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(inception_3b)</span><br><span class="line">    <span class="comment"># 第十层，max pooling层</span></span><br><span class="line">    pool3_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool3_3x3/2&quot;</span>,</span><br><span class="line">                                pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                                padding=<span class="string">&#x27;valid&#x27;</span>)(inception_3b_zero_pad)</span><br><span class="line">    <span class="comment"># 第十一层，inception 4a</span></span><br><span class="line">    inception_4a = inception_module(<span class="string">&quot;inception_4a&quot;</span>,pool3_3x3, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十二层，分支loss1</span></span><br><span class="line">    loss1_ave_pool = AveragePooling2D(name=<span class="string">&quot;loss1/ave_pool&quot;</span>,</span><br><span class="line">                                      pool_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                                      strides=(<span class="number">3</span>, <span class="number">3</span>))(inception_4a)</span><br><span class="line"></span><br><span class="line">    loss1_conv = Conv2D(name=<span class="string">&quot;loss1/conv&quot;</span>,</span><br><span class="line">                        filters=<span class="number">128</span>,</span><br><span class="line">                        kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                        padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                        kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                        kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_ave_pool)</span><br><span class="line"></span><br><span class="line">    loss1_flat = Flatten()(loss1_conv)</span><br><span class="line"></span><br><span class="line">    loss1_fc = Dense(<span class="number">1024</span>,</span><br><span class="line">                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     name=<span class="string">&quot;loss1/fc&quot;</span>,</span><br><span class="line">                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_flat)</span><br><span class="line"></span><br><span class="line">    loss1_drop_fc = Dropout(<span class="number">0.7</span>)(loss1_fc)</span><br><span class="line"></span><br><span class="line">    loss1_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss1/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_drop_fc)</span><br><span class="line"></span><br><span class="line">    loss1_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss1_classifier)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十二层，inception_4b</span></span><br><span class="line">    inception_4b = inception_module(<span class="string">&quot;inception_4b&quot;</span>,inception_4a, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    <span class="comment"># 第十三层，inception_4c</span></span><br><span class="line">    inception_4c = inception_module(<span class="string">&quot;inception_4c&quot;</span>,inception_4b, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    <span class="comment"># 第十四层，inception_4c</span></span><br><span class="line">    inception_4d = inception_module(<span class="string">&quot;inception_4d&quot;</span>,inception_4c, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十五层，分支loss2</span></span><br><span class="line">    loss2_ave_pool = AveragePooling2D(pool_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                                      strides=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                      name=<span class="string">&#x27;loss2/ave_pool&#x27;</span>)(inception_4d)</span><br><span class="line"></span><br><span class="line">    loss2_conv = Conv2D(name=<span class="string">&quot;loss2/conv&quot;</span>,</span><br><span class="line">                        filters=<span class="number">128</span>,</span><br><span class="line">                        kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                        padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                        kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                        kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_ave_pool)</span><br><span class="line"></span><br><span class="line">    loss2_flat = Flatten()(loss2_conv)</span><br><span class="line"></span><br><span class="line">    loss2_fc = Dense(<span class="number">1024</span>,</span><br><span class="line">                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     name=<span class="string">&quot;loss2/fc&quot;</span>,</span><br><span class="line">                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_flat)</span><br><span class="line"></span><br><span class="line">    loss2_drop_fc = Dropout(<span class="number">0.7</span>)(loss2_fc)</span><br><span class="line"></span><br><span class="line">    loss2_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss2/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_drop_fc)</span><br><span class="line"></span><br><span class="line">    loss2_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss2_classifier)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十五层，inception_4e</span></span><br><span class="line">    inception_4e = inception_module(<span class="string">&quot;inception_4e&quot;</span>,inception_4d, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    inception_4e_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(inception_4e)</span><br><span class="line">    <span class="comment"># 第十六层，max pooling层</span></span><br><span class="line">    pool4_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool4_3x3&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(inception_4e_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十七层，inception_5a</span></span><br><span class="line">    inception_5a = inception_module(<span class="string">&quot;inception_5a&quot;</span>,pool4_3x3, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十八层，inception_5b</span></span><br><span class="line">    inception_5b = inception_module(<span class="string">&quot;inception_5b&quot;</span>,inception_5a, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十九层，average pooling层</span></span><br><span class="line">    pool5_7x7 = AveragePooling2D(name=<span class="string">&quot;ave_pool5_7x7&quot;</span>,</span><br><span class="line">                                 pool_size=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">                                 strides=(<span class="number">1</span>, <span class="number">1</span>))(inception_5b)</span><br><span class="line"></span><br><span class="line">    loss3_flat = Flatten()(pool5_7x7)</span><br><span class="line"></span><br><span class="line">    pool5_drop_7x7 = Dropout(<span class="number">0.4</span>)(loss3_flat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二十层，全连接层</span></span><br><span class="line">    loss3_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss3/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(pool5_drop_7x7)</span><br><span class="line"></span><br><span class="line">    loss3_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss3_classifier)</span><br><span class="line"></span><br><span class="line">    googlenet_inception_v1 = Model(name=<span class="string">&quot;googlenet_inception_v1&quot;</span>,</span><br><span class="line">                                   <span class="built_in">input</span>=input_layer,</span><br><span class="line">                                   output=[loss1_classifier_act, loss2_classifier_act, loss3_classifier_act])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> fine_tune:</span><br><span class="line">        googlenet_inception_v1.load_weights(fine_tune)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> googlenet_inception_v1</span><br></pre></td></tr></table></figure><p></p></li><li>googlenet_custom_layers.py<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Layer</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRN2D</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   This code is adapted from pylearn2.</span></span><br><span class="line"><span class="string">    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha=<span class="number">1e-4</span>, k=<span class="number">2</span>, beta=<span class="number">0.75</span>, n=<span class="number">5</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;LRN2D only works with odd n. n provided: &quot;</span> + <span class="built_in">str</span>(n))</span><br><span class="line">        <span class="built_in">super</span>(LRN2D, self).__init__(**kwargs)</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.k = k</span><br><span class="line">        self.beta = beta</span><br><span class="line">        self.n = n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_output</span>(<span class="params">self, train</span>):</span></span><br><span class="line">        X = self.get_input(train)</span><br><span class="line">        b, ch, r, c = K.shape(X)</span><br><span class="line">        half_n = self.n // <span class="number">2</span></span><br><span class="line">        input_sqr = K.square(X)</span><br><span class="line">        extra_channels = K.zeros((b, ch + <span class="number">2</span> * half_n, r, c))</span><br><span class="line">        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],</span><br><span class="line">                                   input_sqr,</span><br><span class="line">                                   extra_channels[:, half_n + ch:, :, :]],</span><br><span class="line">                                  axis=<span class="number">1</span>)</span><br><span class="line">        scale = self.k</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n):</span><br><span class="line">            scale += self.alpha * input_sqr[:, i:i + ch, :, :]</span><br><span class="line">        scale = scale ** self.beta</span><br><span class="line">        <span class="keyword">return</span> X / scale</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">        config = &#123;<span class="string">&quot;name&quot;</span>: self.__class__.__name__,</span><br><span class="line">                  <span class="string">&quot;alpha&quot;</span>: self.alpha,</span><br><span class="line">                  <span class="string">&quot;k&quot;</span>: self.k,</span><br><span class="line">                  <span class="string">&quot;beta&quot;</span>: self.beta,</span><br><span class="line">                  <span class="string">&quot;n&quot;</span>: self.n&#125;</span><br><span class="line">        base_config = <span class="built_in">super</span>(LRN2D, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">list</span>(base_config.items()) + <span class="built_in">list</span>(config.items()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PoolHelper</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PoolHelper, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> x[:, :, <span class="number">1</span>:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">        config = &#123;&#125;</span><br><span class="line">        base_config = <span class="built_in">super</span>(PoolHelper, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">list</span>(base_config.items()) + <span class="built_in">list</span>(config.items()))</span><br></pre></td></tr></table></figure></li><li><p>googlenet_inception_v1-cifar10.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau, CSVLogger, EarlyStopping</span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> googlenet_inception_v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:4&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;4&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line">        model = googlenet_inception_v1.googLeNet_inception_v1_building(s,class_num)</span><br><span class="line">        model.summary()</span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-V1.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># import pdb</span></span><br><span class="line">        <span class="comment"># pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>,</span><br><span class="line">                        save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(nb_epoch):</span><br><span class="line">            batches = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> X_batch, Y_batch <span class="keyword">in</span> datagen.flow(X_train, Y_train, batch_size=<span class="number">64</span>):</span><br><span class="line">                loss = model.train_on_batch(X_batch, [Y_batch,Y_batch,Y_batch]) <span class="comment"># note the three outputs</span></span><br><span class="line">                <span class="built_in">print</span> loss</span><br><span class="line">                <span class="comment">#print &#x27;\r\n&#x27;</span></span><br><span class="line">                <span class="comment">#loss_and_metrics = model.evaluate(X_test, [Y_test,Y_test,Y_test], batch_size=128)</span></span><br><span class="line">                <span class="comment">#model.fit(X_test, [Y_test,Y_test,Y_test], batch_size=64)</span></span><br><span class="line">                batches += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> batches &gt;= <span class="built_in">len</span>(X_train) / <span class="number">64</span>:</span><br><span class="line">                <span class="comment"># we need to break the loop by hand because</span></span><br><span class="line">                <span class="comment"># the generator loops indefinitely</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p></p></li></ul>整个网络结构如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bddsvlg8mt7ejo267fso1pdp1g.png" width="600"></center><p>需要训练的总参数量为10,334,030个。</p><h2 id="googlenet-inception-v2">5.13 GoogLeNet Inception V2</h2><p>GoogLeNet Inception V2在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>》出现，最大亮点是提出了Batch Normalization方法，它起到以下作用：</p><ul><li>使用较大的学习率而不用特别关心诸如梯度爆炸或消失等优化问题；</li><li>降低了模型效果对初始权重的依赖；</li><li>可以加速收敛，一定程度上可以不使用Dropout这种降低收敛速度的方法，但却起到了正则化作用提高了模型泛化性；</li><li>即使不使用ReLU也能缓解激活函数饱和问题；</li><li>能够学习到从当前层到下一层的分布缩放( scaling (方差)，shift (期望))系数。</li></ul><h3 id="一些思考-1">5.13.1 一些思考</h3><p>在机器学习中，我们通常会做一种假设：训练样本独立同分布(iid)且训练样本与测试样本分布一致，如果真实数据符合这个假设则模型效果可能会不错，反之亦然，这个在学术上叫Covariate Shift，所以从样本（外部）的角度说，对于神经网络也是一样的道理。从结构（内部）的角度说，由于神经网络由多层组成，样本在层与层之间边提特征边往前传播，如果每层的输入分布不一致，那么势必造成要么模型效果不好，要么学习速度较慢，学术上这个叫<strong>Internal</strong> Covariate Shift。</p><p>假设：<span class="math inline">\(y\)</span>为样本标注，<span class="math inline">\(X=\{x_1,x_2,x_3,......\}\)</span>为样本<span class="math inline">\(x\)</span>通过神经网络若干层后每层的输入；</p><p>理论上：<span class="math inline">\(p(x,y)\)</span>的联合概率分布应该与集合<span class="math inline">\(X\)</span>中任意一层输入的联合概率分布一致，如：<span class="math inline">\(p(x,y)=p(x_1,y)\)</span>； 但是：<span class="math inline">\(p(x,y)=p(y|x) \cdot p(x)\)</span>，其中条件概率<span class="math inline">\(p(y|x)\)</span>是一致的，即<span class="math inline">\(p(y|x)=p(y|x_1)=p(y|x_2)=......\)</span>，但由于神经网络每一层对输入分布的改变，导致边缘概率是不一致的，即<span class="math inline">\(p(x)\neq p(x_1)\neq p(x_2)......\)</span>，甚至随着网络深度的加深，前面层微小的变化会导致后面层巨大的变化。</p><h3 id="bn原理">5.13.2 BN原理</h3><p>BN整个算法过程如下：</p><p><span class="math display">\[ \begin{align*} &amp; \text{Input: Values of $x$ over a mini-batch: $B=\{x_1...m\}$} \\ &amp; \text{ $\qquad \quad$ Paramters to be learned:$\gamma$,$\beta$} \\ &amp; \text{Output:} \{y_i = BN_{\gamma,\beta}(x_i)\} \\ &amp; \quad \mu_{B} \gets \frac{1}{m} \sum_{i=1}^{m}{x_i} \qquad &amp;&amp;\text{//mini-batch mean}\\ &amp; \quad \sigma^2_B \gets \frac{1}{m} \sum_{i=1}^{m}{(x_i-\mu_B)^2} \qquad &amp;&amp;\text{//mini-batch variance}\\ &amp; \quad \hat{x}_i \gets \frac{x_i-\mu_B}{\sqrt{\sigma_B^2 +\epsilon}} \qquad &amp;&amp;\text{//normalize}\\ &amp; \quad y_i \gets \gamma\hat{x}_i+\beta \equiv BN_{\gamma,\beta}(x_i) \qquad &amp;&amp;\text{//scale and shift}\\ \end{align*} \]</span></p><ul><li>以batch的方式做训练，对m个样本求期望和方差后对训练数据做白化，通过白化操作可以去除特征相关性并把数据缩放在一个球体上，这么做的好处既可以加快优化算法的优化速度也可能提高优化精度，一个直观的解释：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtd6v182o9m1ua0r1df01dtl1g.png" width="400"></center>左边是未做白化的原始可行域，右边是做了白化的可行域；</li><li>当原始输入对模型学习更有利时能够恢复原始输入（和残差网络有点神似）：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtavq8vm617es57jul11f7hm.png" width="400"></center></li></ul><p>这里的参数<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\sigma\)</span>是需要学习的。</p><p>参数学习依然是利用反向传播原理：</p><p><span class="math display">\[ \begin{align*} &amp; \frac{\partial l}{\partial \hat{x}_i}=\frac{\partial l}{\partial \hat{y}_i} \cdot \gamma \\ &amp; \frac{\partial l}{\partial \sigma_B^2}=\sum_{i=1}^{m}\frac{\partial l}{\partial \hat{x}_i} \cdot (x_i-\mu_B) \cdot \frac{-1}{2}(\sigma_B^2+\epsilon)^{-3/2}\\ &amp; \frac{\partial l}{\partial \mu_B}=(\sum_{i=1}^{m}\frac{\partial l}{\partial \hat{x}_i} \cdot \frac{-1}{\sqrt{\sigma_B^2+\epsilon}})+\frac{\partial l}{\partial \sigma_B^2} \cdot \frac{\sum_{i=1}^m -2(x_i-\mu_B)}{m} \\ &amp; \frac{\partial l}{\partial x_i}= \frac{\partial l}{\partial \hat{x}_i} \cdot \frac{1}{\sqrt{\sigma_B^2+\epsilon}} + \frac{\partial l}{\partial \sigma_B^2} \cdot \frac{2(x_i-\mu_B)}{m} + \frac{\partial l}{\partial \mu_B} \cdot \frac{1}{m} \\ &amp; \frac{\partial l}{\partial \gamma}=\sum_{i=1}^m \frac{\partial l}{\partial \hat{y}_i} \cdot \hat{x}_i\\ &amp; \frac{\partial l}{\partial \beta}=\sum_{i=1}^m \frac{\partial l}{\partial \hat{y}_i} \\ \end{align*} \]</span></p><p>对卷积神经网络而言，BN被加在激活函数的非线性变换前，即： <span class="math display">\[y=f(BN(W^Tx +b))\]</span> 由于BN参数<span class="math inline">\(\gamma\)</span>的存在，这里的偏置<span class="math inline">\(b\)</span>可以被去掉，即： <span class="math display">\[y=f(BN(W^Tx))\]</span> 所以在看相关代码实现时大家会发现没有偏置这个参数。</p><p>另外当采用较大的学习率时，传统方法会由于激活函数饱和区的存在导致反向传播时梯度出现爆炸或消失，但采用BN后，参数的尺度变化不影响梯度的反向传播，可以证明： <span class="math display">\[ \begin{array}{l} BN(Wu)=BN((\alpha W)u)\\ \frac{\partial BN((\alpha W)u)}{\partial u}=\frac{\partial BN(Wu)}{\partial u}\\ \frac{\partial BN((\alpha W)u)}{\partial (\alpha W)}=\frac{1}{\alpha}\cdot \frac{\partial BN(Wu)}{\partial W} \end{array} \]</span></p><p>在模型Inference阶段，BN层需要的期望和方差是固定值，由于所有训练集batch的期望和方差已知，可以用这些值对整体训练集的期望和方差做无偏估计修正，修正方法为： <span class="math display">\[ \begin{array}{l} E(x)=E_B(\mu_B)\\ Var(x)=\frac{m}{m-1}E_B(\sigma_B^2)\\ \text{其中B为训练集所有batch（大小都为m）的集合集合.}\\ \end{array} \]</span></p><p>Inference时的公式变为： <span class="math display">\[ \begin{array}{l} y=\frac{\gamma}{\sqrt{Var(x)+\epsilon}}\cdot x+(\beta-\frac{\gamma E(x)}{\sqrt{Var(x)+\epsilon}}) \end{array} \]</span></p><h3 id="卷积神经网络中的bn">5.13.3 卷积神经网络中的BN</h3>卷积网络中采用权重共享策略，每个feature map只有一对<span class="math inline">\(\gamma\)</span>，<span class="math inline">\(\sigma\)</span>需要学习。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtjnc2l13p71a88fpv1n001nuj2a.png" width="800"></center><h3 id="代码实践-2">5.13.4 代码实践</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist, cifar10</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_LeNet5</span>():</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(Convolution2D(<span class="number">96</span>, <span class="number">11</span>, <span class="number">11</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>), dim_ordering=<span class="string">&#x27;tf&#x27;</span>))</span><br><span class="line"><span class="comment">#注释1    model.add(BatchNormalization())</span></span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="comment">#注释2    model.add(BatchNormalization())</span></span><br><span class="line">    model.add(Activation(<span class="string">&quot;tanh&quot;</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Convolution2D(<span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line"><span class="comment">#注释3    model.add(BatchNormalization())</span></span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line"><span class="comment">#注释4    model.add(Dense(10))</span></span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line">    model = build_LeNet5()</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    plot_model(model, to_file=<span class="string">&quot;LeNet-5.png&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    (X_train, y_train), (X_test, y_test) = cifar10.load_data()<span class="comment">#mnist.load_data()</span></span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    Y_train = np_utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">    Y_test = np_utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">    datagen = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">        samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">        featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">        samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">        zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">        rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">        width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">        height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">        horizontal_flip=<span class="literal">False</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">        vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">    datagen.fit(X_train)</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    nb_epoch = <span class="number">8</span></span><br><span class="line">    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">              verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">    score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>三组实验对比：</p><ul><li>第一组：放开所有注释</li><li>第二组：放开注释4</li><li>第三组：注释掉所有BN<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtueg4i30e4p1gbu1oukdc9m.png" width="500"></center></li></ul><h2 id="googlenet-inception-v3">5.14 GoogLeNet Inception V3</h2><p>GoogLeNet Inception V3在《Rethinking the Inception Architecture for Computer Vision》中提出（注意，在这篇论文中作者把该网络结构叫做v2版，我们以最终的v4版论文的划分为标准），该论文的亮点在于：</p><ul><li>提出通用的网络结构设计准则</li><li>引入卷积分解提高效率</li><li>引入高效的feature map降维</li></ul><h3 id="网络结构设计的准则">5.14.1 网络结构设计的准则</h3><p>前面也说过，深度学习网络的探索更多是个实验科学，在实验中人们总结出一些结构设计准则，但说实话我觉得不一定都有实操性：</p><ul><li>避免特征表示上的瓶颈，尤其在神经网络的前若干层 神经网络包含一个自动提取特征的过程，例如多层卷积，直观并符合常识的理解：如果在网络初期特征提取的太粗，细节已经丢了，后续即使结构再精细也没法做有效表示了；举个极端的例子：在宇宙中辨别一个星球，正常来说是通过由近及远，从房屋、树木到海洋、大陆板块再到整个星球之后进入整个宇宙，如果我们一开始就直接拉远到宇宙，你会发现所有星球都是球体，没法区分哪个是地球哪个是水星。所以feature map的大小应该是随着层数的加深逐步变小，但为了保证特征能得到有效表示和组合其通道数量会逐渐增加。 下图违反了这个原则，刚开就始直接从35×35×320被抽样降维到了17×17×320，特征细节被大量丢失，即使后面有Inception去做各种特征提取和组合也没用。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be4l9h9t1sjrd4b1m3f1bkj1dp29.png" width="200"></center></li><li>对于神经网络的某一层，通过更多的激活输出分支可以产生互相解耦的特征表示，从而产生高阶稀疏特征，从而加速收敛，注意下图的1×3和3×1激活输出：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be7flg7p1aeu7gi1jo17ulctr9.png" width="400"></center></li><li>合理使用维度缩减不会破坏网络特征表示能力反而能加快收敛速度，典型的例如通过两个3×3代替一个5×5的降维策略，不考虑padding，用两个3×3代替一个5×5能节省1-（3×3+3×3）/(5×5)=28%的计算消耗。<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9mjahe8hj1ceus9q1curia09.png" width="600"></center>以及一个n×n卷积核通过顺序相连的两个1×n和n×1做降维（有点像矩阵分解），如果n=3，计算性能可以提升1-(3+3)/9=33%，但如果考虑高性能计算性能，这种分解可能会造成L1 cache miss率上升。</li></ul><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9nrvv21ior1jdamaqea0u4213.png" width="600"></center><ul><li>通过合理平衡网络的宽度和深度优化网络计算消耗（这句话尤其不具有实操性）。</li><li>抽样降维，传统抽样方法为pooling+卷积操作，为了防止出现特征表示的瓶颈，往往需要更多的卷积核，例如输入为n个d×d的feature map，共有k个卷积核，pooling时stride=2，为不出现特征表示瓶颈，往往k的取值为2n，通过引入inception module结构，即降低计算复杂度，又不会出现特征表示瓶颈，实现上有如下两种方式：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9opsk11bmu1vj5ovf145e85g1g.png" width="600"></center></li></ul><h3 id="平滑样本标注">5.14.2 平滑样本标注</h3><p>对于多分类的样本标注一般是one-hot的，例如[0,0,0,1]，使用类似交叉熵的损失函数会使得模型学习中对ground truth标签分配过于置信的概率，并且由于ground truth标签的logit值与其他标签差距过大导致，出现过拟合，导致降低泛化性。一种解决方法是加正则项，即对样本标签给个概率分布做调节，使得样本标注变成“soft”的，例如[0.1,0.2,0.1,0.6]，这种方式在实验中降低了top-1和top-5的错误率0.2%。</p><h3 id="网络结构-1">5.14.3 网络结构</h3><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9q5nr61700p257kh1ov3j2v1t.png" width="400"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9qg7hf1ssd1e7vukj40f8hb2a.png" width="600"></center><h3 id="代码实践-3">5.14.4 代码实践</h3><p>为了能在单机跑起来，对feature map做了缩减，为适应cifar10的输入大小，对输入的stride做了调整，代码如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Dropout, Dense, Lambda, Flatten, Activation, merge</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D, Conv2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate, add</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> CSVLogger, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping</span><br><span class="line"></span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">filter_control = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Helper to build a BN -&gt; relu block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    norm = BatchNormalization()(<span class="built_in">input</span>)</span><br><span class="line">    <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(norm)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">before_inception</span>(<span class="params">input_shape, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line">    <span class="keyword">if</span> small_mode:</span><br><span class="line">        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    before_conv1_3x3 = Conv2D(name=<span class="string">&quot;before_conv1_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    before_conv2_3x3 = Conv2D(name=<span class="string">&quot;before_conv2_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv1_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv3_3x3 = Conv2D(name=<span class="string">&quot;before_conv3_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    before_pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;before_pool1_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(before_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv4_3x3 = Conv2D(name=<span class="string">&quot;before_conv4_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">80</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv5_3x3 = Conv2D(name=<span class="string">&quot;before_conv3_3x3/2&quot;</span>,</span><br><span class="line">                              filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=strides,</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv4_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv6_3x3 = Conv2D(name=<span class="string">&quot;before_conv6_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> before_conv6_3x3</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_A</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line">    <span class="comment"># (20,20,288)</span></span><br><span class="line"></span><br><span class="line">    inception_A_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv2_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv3_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_A_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">48</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv5_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv5_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv4_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_A_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                    pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                    padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv6_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv6_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_A_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_merge1 = concatenate([inception_A_conv3_3x3, inception_A_conv5_3x3, inception_A_conv6_1x1, inception_A_conv7_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_A_merge1)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_B</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    inception_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv2_1x7 = Conv2D(name=<span class="string">&quot;inception_A_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv3_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv3_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv2_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_conv4_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv4_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv3_7x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv5_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv5_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv4_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_conv6_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv6_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv7_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv7_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv6_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv8_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv8_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv7_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_B_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                             padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv9_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv9_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_B_conv10_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv10_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_merge1 = concatenate(</span><br><span class="line">        [inception_B_conv5_7x1, inception_B_conv8_7x1, inception_B_conv9_1x1, inception_B_conv10_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_B_merge1)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_C</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    inception_C_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">448</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv2_3x3 = Conv2D(name=<span class="string">&quot;inception_C_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv3_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_conv4_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv4_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_merge1 = concatenate([inception_C_conv3_1x3, inception_C_conv4_3x1])</span><br><span class="line"></span><br><span class="line">    inception_C_conv5_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv5_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv6_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv6_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv7_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv7_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_merge2 = concatenate([inception_C_conv6_1x3, inception_C_conv7_3x1])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    inception_C_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_C_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                             padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv8_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv8_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_conv9_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv9_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">320</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_merge3 = concatenate(</span><br><span class="line">        [inception_C_merge1, inception_C_merge2, inception_C_conv8_1x1, inception_C_conv9_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_C_merge3)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inception_v3</span>(<span class="params">input_shape, nb_classes=<span class="number">10</span>, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    x = before_inception(input_layer, small_mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3 x Inception A</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        x = inception_A(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5 x Inception B</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        x = inception_B(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2 x Inception C</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = inception_C(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    x = AveragePooling2D((<span class="number">8</span>, <span class="number">8</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dropout</span></span><br><span class="line">    x = Dropout(<span class="number">0.8</span>)(x)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output</span></span><br><span class="line">    out = Dense(output_dim=nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    model = Model(input_layer, output=out, name=<span class="string">&#x27;Inception-v3&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line">        (x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reorder dimensions for tensorflow</span></span><br><span class="line">        x_train = np.transpose(x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        x_test = np.transpose(x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line">        <span class="built_in">print</span>(x_train.shape[<span class="number">0</span>], <span class="string">&#x27;train samples&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(x_test.shape[<span class="number">0</span>], <span class="string">&#x27;test samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">        y_train = np_utils.to_categorical(y_train)</span><br><span class="line">        y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">        s = x_train.shape[<span class="number">1</span>:]</span><br><span class="line">        batch_size = <span class="number">128</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        nb_classes = <span class="number">10</span></span><br><span class="line">        model = create_inception_v3(s, nb_classes)</span><br><span class="line">        model.summary()</span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-V3.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        model.fit(x_train, y_train,</span><br><span class="line">                  batch_size=batch_size, nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                  validation_data=(x_test, y_test), shuffle=<span class="literal">True</span>,</span><br><span class="line">                  callbacks=[])</span><br><span class="line">        <span class="comment"># Model saving callback</span></span><br><span class="line">        checkpointer = ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                       verbose=<span class="number">0</span>,</span><br><span class="line">                                       save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Using real-time data augmentation.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        datagen_train = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">0</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line">        datagen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">        history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=<span class="literal">True</span>),</span><br><span class="line">                                      samples_per_epoch=x_train.shape[<span class="number">0</span>],</span><br><span class="line">                                      nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                                      validation_data=(x_test, y_test),</span><br><span class="line">                                      callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p></p><h2 id="googlenet-inception-v4resnet-v1v2">5.15 GoogLeNet Inception V4/ResNet V1/V2</h2><p>这三种结构在《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》一文中提出，论文的亮点是：提出了效果更好的GoogLeNet Inception v4网络结构；与残差网络融合，提出效果不逊于v4但训练速度更快的结构。</p><h3 id="googlenet-inception-v4网络结构">5.15.1 GoogLeNet Inception V4网络结构</h3><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea0k93g3969st1toj1bbs1vde9.png" width="600"></center><h3 id="googlenet-inception-resnet网络结构">5.15.2 GoogLeNet Inception ResNet网络结构</h3><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea31r2e1oid1cu8t4v3hm1vq99.png" width="600"></center><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea36i8k1oru10st3q1d511qdsm.png" width="400"></center><h3 id="代码实践-4">5.15.3 代码实践</h3><p>GoogLeNet Inception ResNet V2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Dropout, Dense, Lambda, Flatten, Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D, Conv2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate, add</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> CSVLogger, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping</span><br><span class="line"></span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">filter_control = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Helper to build a BN -&gt; relu block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    norm = BatchNormalization()(<span class="built_in">input</span>)</span><br><span class="line">    <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(norm)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_stem</span>(<span class="params">input_shape, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> small_mode:</span><br><span class="line">        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    stem_conv1_3x3 = Conv2D(name=<span class="string">&quot;stem_conv1_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    stem_conv2_3x3 = Conv2D(name=<span class="string">&quot;stem_conv2_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv1_3x3)</span><br><span class="line"></span><br><span class="line">    stem_conv3_3x3 = Conv2D(name=<span class="string">&quot;stem_conv3_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    stem_pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;stem_pool1_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(stem_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    stem_conv4_3x3 = Conv2D(name=<span class="string">&quot;stem_conv4_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    stem_merge1 = concatenate([stem_pool1_3x3, stem_conv4_3x3])</span><br><span class="line"></span><br><span class="line">    stem_conv5_1x1 = Conv2D(name=<span class="string">&quot;stem_conv5_1x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge1)</span><br><span class="line"></span><br><span class="line">    stem_conv6_3x3 = Conv2D(name=<span class="string">&quot;stem_conv6_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    stem_conv7_1x1 = Conv2D(name=<span class="string">&quot;stem_conv7_1x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge1)</span><br><span class="line"></span><br><span class="line">    stem_conv8_7x1 = Conv2D(name=<span class="string">&quot;stem_conv8_7x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv7_1x1)</span><br><span class="line"></span><br><span class="line">    stem_conv9_1x7 = Conv2D(name=<span class="string">&quot;stem_conv8_1x7/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv8_7x1)</span><br><span class="line"></span><br><span class="line">    stem_conv10_3x3 = Conv2D(name=<span class="string">&quot;stem_conv10_3x3/1&quot;</span>,</span><br><span class="line">                             filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                             kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                             kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                             activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv9_1x7)</span><br><span class="line"></span><br><span class="line">    stem_merge2 = concatenate([stem_conv6_3x3, stem_conv10_3x3])</span><br><span class="line"></span><br><span class="line">    stem_pool2_3x3 = MaxPooling2D(name=<span class="string">&quot;stem_pool2_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(stem_merge2)</span><br><span class="line"></span><br><span class="line">    stem_conv11_3x3 = Conv2D(name=<span class="string">&quot;stem_conv11_3x3/2&quot;</span>,</span><br><span class="line">                             filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                             kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=strides,</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                             kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                             activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge2)</span><br><span class="line"></span><br><span class="line">    stem_merge3 = concatenate([stem_pool2_3x3, stem_conv11_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(stem_merge3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_A</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    init = <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">    inception_A_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_A_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line">    inception_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv3_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_A_conv5_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv5_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">48</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv4_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv6_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv6_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    inception_merge1 = concatenate([inception_A_conv1_1x1, inception_A_conv3_3x3, inception_A_conv6_3x3])</span><br><span class="line"></span><br><span class="line">    inception_A_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(inception_merge1)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_A_conv7_1x1])</span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_B</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    init = <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">    inception_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_B_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_B_conv3_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv3_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">160</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_B_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv4_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv4_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_B_conv3_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_merge = concatenate([inception_B_conv1_1x1, inception_B_conv4_7x1])</span><br><span class="line"></span><br><span class="line">    inception_B_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">1154</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(inception_B_merge)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_B_conv7_1x1])</span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_C</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    inception_C_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_C_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv3_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">224</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_C_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv3_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_C_conv3_1x3)</span><br><span class="line"></span><br><span class="line">    ir_merge = concatenate([inception_C_conv1_1x1, inception_C_conv3_3x1])</span><br><span class="line"></span><br><span class="line">    inception_C_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">2048</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(ir_merge)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_C_conv4_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduction_A</span>(<span class="params"><span class="built_in">input</span>, k=<span class="number">192</span>, l=<span class="number">224</span>, m=<span class="number">256</span>, n=<span class="number">384</span></span>):</span></span><br><span class="line">    pool_size = (<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    reduction_A_pool1 = MaxPooling2D(name=<span class="string">&quot;reduction_A_pool1/2&quot;</span>,</span><br><span class="line">                                     pool_size=pool_size,</span><br><span class="line">                                     strides=strides,</span><br><span class="line">                                     padding=<span class="string">&#x27;valid&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv1_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv1_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=n // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv2_1x1 = Conv2D(name=<span class="string">&quot;reduction_A_conv2_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=k // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv2_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv2_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=l // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_A_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv3_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=m // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_A_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    reduction_A_merge = concatenate([reduction_A_pool1, reduction_A_conv1_3x3, reduction_A_conv3_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reduction_A_merge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduction_B</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    pool_size = (<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    reduction_B_pool1 = MaxPooling2D(name=<span class="string">&quot;reduction_B_pool1/2&quot;</span>,</span><br><span class="line">                                     pool_size=pool_size,</span><br><span class="line">                                     strides=strides,</span><br><span class="line">                                     padding=<span class="string">&#x27;valid&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv3_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv2_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv2_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv3_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv3_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv4_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv4_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv3_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv5_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv5_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv5_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv5_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv6_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv6_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">320</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    reduction_B_merge = concatenate(</span><br><span class="line">        [reduction_B_pool1, reduction_B_conv2_3x3, reduction_B_conv4_3x3, reduction_B_conv6_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reduction_B_merge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inception_resnet_v2</span>(<span class="params">input_shape, nb_classes=<span class="number">10</span>, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    x = inception_resnet_stem(input_layer, small_mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10 x Inception Resnet A</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        x = inception_resnet_v2_A(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reduction A</span></span><br><span class="line">    x = reduction_A(x, k=<span class="number">256</span>, l=<span class="number">256</span>, m=<span class="number">384</span>, n=<span class="number">384</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 20 x Inception Resnet B</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        x = inception_resnet_v2_B(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对32*32*3的数据可以更改pooling层</span></span><br><span class="line">    aout = AveragePooling2D((<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">3</span>, <span class="number">3</span>))(x)</span><br><span class="line">    aout = Conv2D(name=<span class="string">&quot;conv1_1x1/1&quot;</span>,</span><br><span class="line">                  filters=<span class="number">128</span>,</span><br><span class="line">                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                  activation=<span class="string">&#x27;relu&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    aout = Conv2D(name=<span class="string">&quot;conv1_5x5/1&quot;</span>,</span><br><span class="line">                  filters=<span class="number">768</span>,</span><br><span class="line">                  kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                  activation=<span class="string">&#x27;relu&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    aout = Flatten()(aout)</span><br><span class="line">    aout = Dense(nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reduction Resnet B</span></span><br><span class="line">    x = reduction_B(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10 x Inception Resnet C</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        x = inception_resnet_v2_C(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 需要视情况更改</span></span><br><span class="line">    x = AveragePooling2D((<span class="number">4</span>, <span class="number">4</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dropout</span></span><br><span class="line">    x = Dropout(<span class="number">0.8</span>)(x)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output</span></span><br><span class="line">    out = Dense(output_dim=nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 简单起见去掉附加目标函数</span></span><br><span class="line">    <span class="comment"># model = Model(input_layer, output=[out, aout], name=&#x27;Inception-Resnet-v2&#x27;)</span></span><br><span class="line">    model = Model(input_layer, output=out, name=<span class="string">&#x27;Inception-Resnet-v2&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line">        (x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reorder dimensions for tensorflow</span></span><br><span class="line">        x_train = np.transpose(x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        x_test = np.transpose(x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line">        <span class="built_in">print</span>(x_train.shape[<span class="number">0</span>], <span class="string">&#x27;train samples&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(x_test.shape[<span class="number">0</span>], <span class="string">&#x27;test samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">        y_train = np_utils.to_categorical(y_train)</span><br><span class="line">        y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">        s = x_train.shape[<span class="number">1</span>:]</span><br><span class="line">        batch_size = <span class="number">128</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        nb_classes = <span class="number">10</span></span><br><span class="line">        model = create_inception_resnet_v2(s, nb_classes, <span class="literal">False</span>, <span class="literal">True</span>)</span><br><span class="line">        model.summary()</span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-Resnet-V2.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Model saving callback</span></span><br><span class="line">        checkpointer = ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                       verbose=<span class="number">0</span>,</span><br><span class="line">                                       save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Using real-time data augmentation.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        datagen_train = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">0</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line">        datagen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">        history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=<span class="literal">True</span>),</span><br><span class="line">                                      samples_per_epoch=x_train.shape[<span class="number">0</span>],</span><br><span class="line">                                      nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                                      validation_data=(x_test, y_test),</span><br><span class="line">                                      callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer])</span><br></pre></td></tr></table></figure><p></p><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1befm4g8r8g6sgh1u8n1dth164kp.png" width="800"></center><h2 id="模型可视化">5.16 模型可视化</h2><h3 id="一些说明">5.16.1 一些说明</h3><p>神经网络本身包含了一系列特征提取器，理想的feature map应该是稀疏的以及包含典型的局部信息，通过模型可视化能有一些直观的认识并帮助我们调试模型，比如：feature map与原图很接近，说明它没有学到什么特征；或者它几乎是一个纯色的图，说明它太过稀疏，可能是我们feature map数太多了。可视化有很多种，比如：feature map可视化、权重可视化等等，我以feature map可视化为例。</p><p>利用keras，采用在imagenet 1000分类的数据集上预训练好的googLeNet inception v3做实验，以下面两张图作为输入。</p><ul><li>输入图片 奥迪A7及其分类结果：<a href="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6huue31l0815eh1kh18c53b213.png">原图</a><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hm83q5rk1ttipqt70r14ga9.png" width="600"></center>北汽绅宝D50及其分类结果：<a href="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6i0g22bdk1upgod01turv7l1g.png">原图</a><center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hrcg0a6s1en84ar12k5biqm.png" width="600"></center></li><li>feature map可视化 取网络的前15层，每层取前3个feature map。 奥迪A7 feature map：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6iba8vp69ju84ta17v1p7q2a.png" width="600"></center>北汽绅宝D50 feature map：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6idndrpt51ausorpq619rh2n.png" width="600"></center></li></ul><p>从左往右看，可以看到整个特征提取的过程，有的分离背景、有的提取轮廓，有的提取色差，但也能发现10、11层中间两个feature map是纯色的，可能这一层feature map数有点多了，另外北汽绅宝D50的光晕对feature map中光晕的影响也能比较明显看到。</p><ul><li>Hypercolumns 通常我们把神经网络最后一个fc全连接层作为整个图片的特征表示，但是这一表示可能过于粗糙（从上面的feature map可视化也能看出来），没法精确描述局部空间上的特征，而网络的第一层空间特征又太过精确，缺乏语义信息（比如后面的色差、轮廓等），于是论文《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1411.5752v2.pdf">Hypercolumns for Object Segmentation and Fine-grained Localization</a>》提出一种新的特征表示方法：Hypercolumns——将一个像素的 hypercolumn 定义为所有 cnn 单元对应该像素位置的激活输出值组成的向量），比较好的tradeoff了前面两个问题，直观地看如图：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6jjcg313ln151n1o74q9ctm73h.png" width="500"></center>把奥迪A7 第1、4、7层的feature map以及第1, 4, 7, 10, 11, 14, 17层的feature map分别做平均，可视化如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k09d6q3v1d7mq711i3m1ifr3u.png" width="600"></center>把北汽绅宝D50 第1、4、7层的feature map以及第1, 4, 7, 10, 11, 14, 17层的feature map分别做平均，可视化如下：<center><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k67a4p9shmi1tgl1l7e7354r.png" width="600"></center></li></ul><h3 id="代码实践-5">5.16.2 代码实践</h3><p>需要安装opencv，注意它与python的版本兼容性，test_opencv函数可以测试是否安装成功。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> InceptionV3</span><br><span class="line"><span class="keyword">from</span> keras.applications.inception_v3 <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_opencv</span>():</span></span><br><span class="line">    <span class="comment"># 加载摄像头</span></span><br><span class="line">    cam = VideoCapture(<span class="number">0</span>)  <span class="comment"># 0 -&gt; 摄像头序号，如果有两个三个四个摄像头，要调用哪一个数字往上加嘛</span></span><br><span class="line">    <span class="comment"># 抓拍 5 张小图片</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">        s, img = cam.read()</span><br><span class="line">        <span class="keyword">if</span> s:</span><br><span class="line">            imwrite(<span class="string">&quot;o-&quot;</span> + <span class="built_in">str</span>(x) + <span class="string">&quot;.jpg&quot;</span>, img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_original</span>(<span class="params">img_path</span>):</span></span><br><span class="line">    <span class="comment"># 把原始图片压缩为 299*299大小</span></span><br><span class="line">    im_original = cv2.resize(cv2.imread(img_path), (<span class="number">299</span>, <span class="number">299</span>))</span><br><span class="line">    im_converted = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)</span><br><span class="line">    plt.figure(<span class="number">0</span>)</span><br><span class="line">    plt.subplot(<span class="number">211</span>)</span><br><span class="line">    plt.imshow(im_converted)</span><br><span class="line">    <span class="keyword">return</span> im_original</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_fine_tune_googlenet_v3</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="comment"># 加载fine-tuning googlenet v3模型，并做预测</span></span><br><span class="line">    model = InceptionV3(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    x = image.img_to_array(img)</span><br><span class="line">    x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">    x = preprocess_input(x)</span><br><span class="line">    preds = model.predict(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted:&#x27;</span>, decode_predictions(preds))</span><br><span class="line">    plt.subplot(<span class="number">212</span>)</span><br><span class="line">    plt.plot(preds.ravel())</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> model, x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">ins, layer_id, filters, layer_num</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取指定模型指定层指定数目的feature map并输出到一幅图上.</span></span><br><span class="line"><span class="string">    :param ins: 模型实例</span></span><br><span class="line"><span class="string">    :param layer_id: 提取指定层特征</span></span><br><span class="line"><span class="string">    :param filters: 每层提取的feature map数</span></span><br><span class="line"><span class="string">    :param layer_num: 一共提取多少层feature map</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(ins) != <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;parameter error:(model, instance)&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    model = ins[<span class="number">0</span>]</span><br><span class="line">    x = ins[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(layer_id) == <span class="built_in">type</span>(<span class="number">1</span>):</span><br><span class="line">        model_extractfeatures = Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(index=layer_id).output)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model_extractfeatures = Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(name=layer_id).output)</span><br><span class="line"></span><br><span class="line">    fc2_features = model_extractfeatures.predict(x)</span><br><span class="line">    <span class="keyword">if</span> filters &gt; <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;layer number error.&#x27;</span>, <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]),<span class="string">&#x27;,&#x27;</span>,filters)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(filters):</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">        plt.subplot(filters, layer_num, layer_id + <span class="number">1</span> + i * layer_num)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]):</span><br><span class="line">            plt.imshow(fc2_features[<span class="number">0</span>, :, :, i])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 层数、模型、卷积核数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_batch</span>(<span class="params">layer_num, model, filters</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    批量提取特征</span></span><br><span class="line"><span class="string">    :param layer_num: 层数</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param filters: feature map数</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    plt.figure(figsize=(filters, layer_num))</span><br><span class="line">    plt.subplot(filters, layer_num, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layer_num):</span><br><span class="line">        extract_features(model, i, filters, layer_num)</span><br><span class="line"></span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_with_layers</span>(<span class="params">layers_extract</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取hypercolumn并可视化.</span></span><br><span class="line"><span class="string">    :param layers_extract: 指定层列表</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    hc = extract_hypercolumn(x[<span class="number">0</span>], layers_extract, x[<span class="number">1</span>])</span><br><span class="line">    ave = np.average(hc.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">    plt.imshow(ave)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_hypercolumn</span>(<span class="params">model, layer_indexes, instance</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取指定模型指定层的hypercolumn向量</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param layer_indexes: 层id</span></span><br><span class="line"><span class="string">    :param instance: 模型</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    feature_maps = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> layer_indexes:</span><br><span class="line">        feature_maps.append(Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(index=i).output).predict(instance))</span><br><span class="line">    hypercolumns = []</span><br><span class="line">    <span class="keyword">for</span> convmap <span class="keyword">in</span> feature_maps:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> convmap[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]:</span><br><span class="line">            upscaled = sp.misc.imresize(convmap[<span class="number">0</span>, :, :, i], size=(<span class="number">299</span>, <span class="number">299</span>), mode=<span class="string">&quot;F&quot;</span>, interp=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">            hypercolumns.append(upscaled)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.asarray(hypercolumns)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    img_path = <span class="string">&#x27;d:\car3.jpg&#x27;</span></span><br><span class="line">    img = load_original(img_path)</span><br><span class="line">    x = load_fine_tune_googlenet_v3(img)</span><br><span class="line"></span><br><span class="line">    extract_features_batch(<span class="number">15</span>, x, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    extract_features_with_layers([<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>])</span><br><span class="line">    extract_features_with_layers([<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">14</span>, <span class="number">17</span>])</span><br></pre></td></tr></table></figure><p></p></div><div class="popular-posts-header">相关文章推荐</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/d677b2e0.html" rel="bookmark">机器学习与人工智能技术分享-第三章 机器学习中的统一框架</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/307f39c.html" rel="bookmark">机器学习与人工智能技术分享-第二章 建模方法回顾</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/b12a240.html" rel="bookmark">机器学习与人工智能技术分享-第九章 语义分割</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/fb9cd06d.html" rel="bookmark">机器学习与人工智能技术分享-第七章 金融风控</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/article/ad2261a2.html" rel="bookmark">机器学习与人工智能技术分享-第四章 最优化原理</a></div></li></ul><footer class="post-footer"><div class="post-tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a> <a href="/tags/%E7%AC%AC%E4%BA%94%E7%AB%A0/" rel="tag"># 第五章</a> <a href="/tags/CNN/" rel="tag"># CNN</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"># 深度神经网络</a> <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag"># 模型可视化</a></div><div class="post-nav"><div class="post-nav-item"><a href="/article/ad2261a2.html" rel="prev" title="机器学习与人工智能技术分享-第四章 最优化原理"><i class="fa fa-chevron-left"></i> 机器学习与人工智能技术分享-第四章 最优化原理</a></div><div class="post-nav-item"><a href="/article/8dd65dea.html" rel="next" title="机器学习与人工智能技术分享-第六章 循环神经网络与Transformers">机器学习与人工智能技术分享-第六章 循环神经网络与Transformers <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let e=CONFIG.comments["activeClass"];if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-text">5. 深度神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-text">5.1 反向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%BC%94%E5%8C%96%E5%8F%B2"><span class="nav-text">5.2 卷积网络结构演化史</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cnn%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="nav-text">5.3 CNN基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sigmoid%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-text">5.3.1 Sigmoid激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E5%B1%82"><span class="nav-text">5.3.2 输入层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-text">5.3.3 卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#zero-padding"><span class="nav-text">5.3.4 Zero-Padding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%87%E6%A0%B7%E5%B1%82pooling"><span class="nav-text">5.3.5 采样层(pooling)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E8%BF%9E%E6%8E%A5%E6%A0%B7%E5%B1%82"><span class="nav-text">5.3.6 全连接样层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%B1%82%E8%A7%A3"><span class="nav-text">5.3.7 参数求解</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cnn%E5%9C%A8nlp%E9%A2%86%E5%9F%9F%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B"><span class="nav-text">5.3.8 CNN在NLP领域应用实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lenet-5"><span class="nav-text">5.4 LeNet-5</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E5%B1%82-1"><span class="nav-text">5.4.1 输入层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#c1%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-text">5.4.2 C1卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#s2%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82"><span class="nav-text">5.4.3 S2下采样层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#c3%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-text">5.4.4 C3卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#s4%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82"><span class="nav-text">5.4.5 S4下采样层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#c5%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-text">5.4.6 C5卷积层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#f6%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="nav-text">5.4.7 F6全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E5%B1%82"><span class="nav-text">5.4.8 输出层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lenet-5%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5"><span class="nav-text">5.4.9 LeNet-5代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#alexnet"><span class="nav-text">5.5 AlexNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90"><span class="nav-text">5.5.1 网络结构分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#relu%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-text">5.5.2 ReLu激活函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#local-response-normalization"><span class="nav-text">5.5.3 Local Response Normalization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#overlapping-pooling"><span class="nav-text">5.5.4 Overlapping Pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dropout"><span class="nav-text">5.5.5 Dropout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85"><span class="nav-text">5.5.6 数据扩充</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9Agpu%E8%AE%AD%E7%BB%83"><span class="nav-text">5.5.7 多GPU训练</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alexnet%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5"><span class="nav-text">5.5.8 AlexNet代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#vgg"><span class="nav-text">5.6 VGG</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">5.6.1 网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#vgg%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5"><span class="nav-text">5.6.2 VGG代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#msranet"><span class="nav-text">5.7 MSRANet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#prelu"><span class="nav-text">5.7.1 PReLU</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#highway-networks"><span class="nav-text">5.8 Highway Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#residual-networks"><span class="nav-text">5.9 Residual Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#resnet%E4%BA%A7%E7%94%9F%E7%9A%84%E5%8A%A8%E6%9C%BA"><span class="nav-text">5.9.1 ResNet产生的动机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%81%92%E7%AD%89%E6%98%A0%E5%B0%84"><span class="nav-text">5.9.2 恒等映射</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90%E8%A7%92%E5%BA%A6%E7%9C%8B%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C"><span class="nav-text">5.9.3 模型集成角度看残差网络</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%9F%AD%E8%B7%AF%E5%BE%84"><span class="nav-text">5.9.4 残差网络中的短路径</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5"><span class="nav-text">5.9.5 代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#maxout-networks"><span class="nav-text">5.10 Maxout Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#network-in-network"><span class="nav-text">5.11 Network in Network</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#nin%E5%8D%B7%E7%A7%AF%E5%B1%82mlp-convolution"><span class="nav-text">5.11.1 NIN卷积层(MLP Convolution)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#googlenet-inception-v1"><span class="nav-text">5.12 GoogLeNet Inception V1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83"><span class="nav-text">5.12.1 一些思考</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#googlenet%E7%BB%93%E6%9E%84"><span class="nav-text">5.12.2 GoogLeNet结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5-1"><span class="nav-text">5.12.3 代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#googlenet-inception-v2"><span class="nav-text">5.13 GoogLeNet Inception V2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83-1"><span class="nav-text">5.13.1 一些思考</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bn%E5%8E%9F%E7%90%86"><span class="nav-text">5.13.2 BN原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84bn"><span class="nav-text">5.13.3 卷积神经网络中的BN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5-2"><span class="nav-text">5.13.4 代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#googlenet-inception-v3"><span class="nav-text">5.14 GoogLeNet Inception V3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%87%86%E5%88%99"><span class="nav-text">5.14.1 网络结构设计的准则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%B3%E6%BB%91%E6%A0%B7%E6%9C%AC%E6%A0%87%E6%B3%A8"><span class="nav-text">5.14.2 平滑样本标注</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-1"><span class="nav-text">5.14.3 网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5-3"><span class="nav-text">5.14.4 代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#googlenet-inception-v4resnet-v1v2"><span class="nav-text">5.15 GoogLeNet Inception V4&#x2F;ResNet V1&#x2F;V2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#googlenet-inception-v4%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">5.15.1 GoogLeNet Inception V4网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#googlenet-inception-resnet%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="nav-text">5.15.2 GoogLeNet Inception ResNet网络结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5-4"><span class="nav-text">5.15.3 代码实践</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">5.16 模型可视化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E8%AF%B4%E6%98%8E"><span class="nav-text">5.16.1 一些说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E8%B7%B5-5"><span class="nav-text">5.16.2 代码实践</span></a></li></ol></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="张磊" src="https://vivounicorn.github.io/images/wali.png"><p class="site-author-name" itemprop="name">张磊</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">15</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">2</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">49</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="sidebar-button motion-element"><i class="fa fa-comment"></i> Chat</div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/vivounicorn" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zhangleisuper@gmail.com" title="E-Mail → mailto:zhangleisuper@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://weibo.com/vivounicorn" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;vivounicorn" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">张磊</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-chart-area"></i> </span><span title="站点总字数">521k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">7:53</span></div><div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动</div></div></footer></div><script src="//cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js"></script><script src="//cdn.bootcdn.net/ajax/libs/jquery/3.6.0/jquery.min.js"></script><script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script>!function(){var e,t,o,n,r=document.getElementsByTagName("link");if(0<r.length)for(i=0;i<r.length;i++)"canonical"==r[i].rel.toLowerCase()&&r[i].href&&(e=r[i].href);t=(e||window.location.protocol).split(":")[0],e=e||window.location.href,window,o=e,n=document.referrer,/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(o)||(t="https"===String(t).toLowerCase()?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif",n?(t+="?r="+encodeURIComponent(document.referrer),o&&(t+="&l="+o)):o&&(t+="?l="+o),(new Image).src=t)}()</script><script src="/js/local-search.js"></script><script>"undefined"==typeof MathJax?(window.MathJax={loader:{load:["[tex]/mhchem"],source:{"[tex]/amsCd":"[tex]/amscd","[tex]/AMScd":"[tex]/amscd"}},tex:{inlineMath:{"[+]":[["$","$"]]},packages:{"[+]":["mhchem"]},tags:"ams"},options:{renderActions:{findScript:[10,d=>{document.querySelectorAll('script[type^="math/tex"]').forEach(e=>{var t=!!e.type.match(/; *mode=display/);const a=new d.options.MathItem(e.textContent,d.inputJax[0],t);t=document.createTextNode("");e.parentNode.replaceChild(t,e),a.start={node:t,delim:"",n:0},a.end={node:t,delim:"",n:0},d.math.push(a)})},"",!1],insertedScript:[200,()=>{document.querySelectorAll("mjx-container").forEach(e=>{let t=e.parentNode;"li"===t.nodeName.toLowerCase()&&t.parentNode.classList.add("has-jax")})},"",!1]}}},function(){var e=document.createElement("script");e.src="//cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.5/es5/tex-mml-chtml.js",e.defer=!0,document.head.appendChild(e)}()):(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset())</script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!1,notify:!0,appId:"m8FPP0CqMpxyTuUvaVOX9qVV-gzGzoHsz",appKey:"Ori6X9PXqQyURvwgl7HT5TJj",placeholder:"赠人玫瑰，手有余香",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>