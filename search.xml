<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>机器学习与人工智能技术分享-第三章 机器学习中的统一框架</title>
    <url>/article/d677b2e0.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1ap8fa5ue1egnr91dlm19n1r7hm.png" width=266 /> 本章介绍了机器学习中一些“上帝视角”，包括对目标函数的理解、统一的神经网络框架等。 <span id="more"></span></p>
<h1 id="机器学习中的统一框架">3. 机器学习中的统一框架</h1>
<p>很多机器学习问题都可以放在一个统一框架下讨论，这样大家在理解各种模型时就是相互联系的。</p>
<h2 id="目标函数">3.1 目标函数</h2>
<p>回忆一下目标函数的定义：</p>
<p><span class="math display">\[w^*=\operatorname*{argmin}\limits_{w} \sum_{i=1}^N\underbrace{L(m_i(w))}_{Bias}+\underbrace{\lambda Reg(w)}_{Variance}\]</span></p>
<p>很多模型可以用这种形式框起来，比如linear regression、logistic regression、SVM、additive models、k-means，neural networks 等等。其中损失函数部分用来控制模型的拟合能力，期望降低偏差，正则项部分用来提升模型泛化能力，期望降低方差，最优模型是对偏差和方差的最优折中。</p>
<h3 id="损失函数">3.1.1 损失函数</h3>
损失函数反应了模型对历史数据的学习程度，我们期望模型能尽可能学到历史经验，得到一个低偏差模型。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1ap8fa5ue1egnr91dlm19n1r7hm.png" width="400" />
</center>
<p>Q：大家想想横坐标是什么？</p>
<p><span class="math display">\[
\begin{array}{l}
\text{0-1 loss: }&amp;L_{01}(m_i(w))=\amalg(m_{i}(w) \le 0)\\
\text{squared loss: }&amp;L_{2}(m_i(w))=\frac{1}{2}(m_{i}(w) -1)^2\\
\text{hinge loss: }&amp;L_{hinge}(m_i(w))=max(0,1-m_{i}(w))\\
\text{log loss: }&amp;L_{log}(m_i(w))=log(1+e^{-m_{i}(w)})\\
&amp;\text{where $m$ is called &#39;margin&#39;.}
\end{array}
\]</span></p>
<p>实践当中很少直接使用0-1损失做优化（当然也有这么用的如：<a href="https://papers.nips.cc/paper/5214-direct-0-1-loss-minimization-and-margin-maximization-with-boosting.pdf">Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a> 和 <a href="http://www.jmlr.org/proceedings/papers/v28/nguyen13a.pdf">Algorithms for Direct 0–1 Loss Optimization in Binary Classification</a>，但总的来说应用有限），原因如下：</p>
<blockquote>
<ul>
<li>0-1损失的优化是组合优化问题且为NP-hard，无法在多项式时间内求得；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>损失函数非凸非光滑，很多优化方法无法使用；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>对权重的更新可能会导致损失函数大的变化，即变化不光滑；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>只能使用<span class="math inline">\(L_0\)</span>正则，其他正则形式都不起作用；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>即使使用<span class="math inline">\(L_0\)</span>正则，依然是非凸非光滑，优化求解困难。</li>
</ul>
</blockquote>
<p>由于0-1损失的问题，所以以上损失函数都是对它的近似。原理细节可以参考：<a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding Machine Learning: From Theory to Algorithms</a></p>
不同损失函数在相同数据集下的直观表现如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1ap8g4c7s17bs1ffh1taedhjvr61g.png" width="400"/>
</center>
<h3 id="正则化项">3.1.2 正则化项</h3>
<p>正则化项影响的是模型在未知样本上的表现，我们希望通过它能降低模型方差提高泛化性。</p>
<p>如果有数据集:</p>
<p><span class="math display">\[D=\{(x_i,y_i)|i=1,2,3,...N\}\]</span> 在给定假设下，通常采用极大似然估计(MLE)求解参数：</p>
<p><span class="math display">\[w^*=\operatorname*{argmin}\limits_{w} \prod_{i=1}^N{-p(y_i|x_i;w)}=\operatorname*{argmin}\limits_{w} \sum_{i=1}^N{-log~p(y_i|x_i;w)}\]</span></p>
<p>假设模型参数也服从某种概率分布： <span class="math inline">\(w \sim p(w)\)</span>， 可以采用极大后验概率估计(MAP)求解参数。 <span class="math display">\[
\begin{array}{l}
 w^*=\operatorname*{argmin}\limits_{w} \prod_{i=1}^N{-p(w|x_i,y_i)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(w|x_i,y_i)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(x_i,y_i|w)p(w)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(x_i,y_i|w)-log~p(w)}\\
  ~~~~= \left\{ \begin{array}{1}
     \text{generative model} &amp; \operatorname*{argmin}\limits_{w}\sum_{i=1}^N[{\underbrace{-log~p(x_i,y_i|w)}_{Bias}-\underbrace{log~p(w)}_{Variance}}] \\
      \text{discriminative model} &amp; \operatorname*{argmin}\limits_{w}\sum_{i=1}^N[{\underbrace{-log~p(y_i|x_i;w)}_{Bias}-\underbrace{log~p(w)}_{Variance}}]
      \end{array} \right.
\end{array}
\]</span></p>
<h3 id="l2-正则">3.1.3 L2 正则</h3>
<p>假设 <span class="math inline">\(w_j \sim N(0,\delta_j^2)\)</span> <span class="math display">\[
\begin{array}{l}
\because p(w_j)=\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{w^2}{2\delta^2}}\\
\therefore Reg(w)=\sum_{i=1}^mw_i^2,\text{ m is the number of weights.}
\end{array}
\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa4p07h1h51j2aiv91klv8r21g.png" width="400"/>
</center>
<h3 id="l1-正则">3.1.4 L1 正则</h3>
<p>假设 <span class="math inline">\(w_j \sim Laplace(0,b_j)\)</span></p>
<p><span class="math display">\[
\begin{array}{l}
\because p(w_j)=\frac{1}{2b}e^{-\frac{|w_j|}{b}}\\
\therefore Reg(w)=\sum_{i=1}^m|w_i|,\text{ m is the number of weights.}
\end{array}
\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa4gt6gce5vqn1lc19jm1bhm.png" width="400"/>
</center>
<h3 id="正则化的几何解释">3.1.5 正则化的几何解释</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa5eiaehd01u531gcv1s5oem21t.png" width="400" />
</center>
<center>
L1 and L2 Regularization
</center>
<p>给定向量<span class="math inline">\(w = (w_1,..., w_n)\)</span>, 定义 <span class="math inline">\(L_q\)</span>正则，其中 <span class="math inline">\(n &gt; 0\)</span>：</p>
<p><span class="math display">\[
\begin{array}{l}
\parallel w \parallel_q=\sqrt[q]{\sum_{i=1}^n|w_i|^q}\\
\text{when $q=0$ we define $l_0$-norm to be the number of non-zero elements of the vector:}\\
\parallel w \parallel_0=\#~(i|x_i \ne 0)\\
\end{array}
\]</span></p>
不同q的取值下正则项的几何表现如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/l.png" width="300" />
</center>
<center>
from <a href="https://commons.wikimedia.org/wiki/File:Norm-vergleich.gif">wiki</a>
</center>
<h3 id="dropout正则化与数据扩充">3.1.6 Dropout正则化与数据扩充</h3>
<p>这两类方法在神经网络中比较常用，后面会专门介绍。</p>
<h2 id="神经网络框架">3.2 神经网络框架</h2>
<p>很多模型可以看做是神经网络，例如：感知机、线性回归、支持向量机、逻辑回归等</p>
<h3 id="linear-regression">3.2.1 Linear Regression</h3>
线性回归可以看做是激活函数为<span class="math inline">\(f(x)=x\)</span>的单层神经网络：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apae0i741rsj1a0r1ns22k9eis2n.png" width="400" />
</center>
<h3 id="logistic-regression">3.2.2 Logistic Regression</h3>
逻辑回归可以看做是激活函数为<span class="math inline">\(f(x)=\frac{1}{1+e^{-x}}\)</span>的单层神经网络：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apadm18v2cl4rf1dik16uu1nsc2a.png" width="500"/>
</center>
</center>
<h3 id="support-vector-machine">3.2.3 Support Vector Machine</h3>
采用核方法后的支持向量机可以看做是含有一个隐层的3层神经网络：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apag746u1qhdd1r1ku6tv01v423u.png" width="400" />
</center>
<h3 id="bootstrap-neural-networks">3.2.4 Bootstrap Neural Networks</h3>
采用bagging方式的组合神经网络：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apagfhml1hg719r15ukv7m7ro55.png" width="400" />
</center>
<h3 id="boosting-neural-network">3.2.5 Boosting Neural Network</h3>
采用boosting方式的组合神经网络：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apaghfqm75bu4l1n2m164e17d25i.png" width="400" />
</center>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>第三章</tag>
        <tag>机器学习</tag>
        <tag>Bagging</tag>
        <tag>Boosting</tag>
        <tag>正则化</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第二章 建模方法回顾</title>
    <url>/article/307f39c.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoqq68m81tb5rsd1k71llid5k13.png" width=266 /> 本章对方差和偏差、损失函数、常用的机器学习模型（包括：线性回归、支持向量机、逻辑回归、GBDT、CatBoost、RF）等做了回顾。 <span id="more"></span></p>
<h1 id="建模方法回顾">2. 建模方法回顾</h1>
<p>以通用的监督学习为例，基本包含4个部分:</p>
<p><span class="math display">\[
\begin{array}{l}
\text{1. Prediction:  }y_i=f(x_i|w),~i=1,2,.....\\
\text{2. Parameters:  }w=\{w_i|i=1,2,...,dim\}\\
\text{3. Objective function:  }obj(w)=loss(w)+reg(w)\\
\text{4. Optimization:  }min~obj(w) \text{ with(out) constraint.}\\
\end{array}
\]</span></p>
<h2 id="偏差与方差">2.0 偏差与方差</h2>
<blockquote>
<ul>
<li>在机器学习算法中，偏差是由先验假设的不合理带来的模型误差，高偏差会导致<strong>欠拟合</strong>： 所谓欠拟合是指对特征和标注之间的因果关系学习不到位，导致模型本身没有较好的学到历史经验的现象；</li>
<li>方差表征的是模型误差对样本发生一定变化时的敏感度，高方差会导致<strong>过拟合</strong>：模型对训练样本中的随机噪声也做了拟合学习，导致在未知样本上应用时出现效果较差的现象；</li>
<li>机器学习模型的核心之一在于其推广能力，即在未知样本上的表现。</li>
</ul>
</blockquote>
对方差和偏差的一种直观解释:
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoqq68m81tb5rsd1k71llid5k13.png" width="400" />
</center>
<p>一个例子，假如我们有预测模型:</p>
<p><span class="math display">\[
\begin{array}{l}
y=f(x)+\epsilon\\
\epsilon \sim N(0,\sigma)
\end{array}
\]</span></p>
<p>我们希望用 <span class="math inline">\(f^{e}(x)\)</span> 估计 <span class="math inline">\(f(x)\)</span>，如果使用基于square loss 的线性回归，则误差分析如下: <span class="math display">\[
\begin{align*}
Err(x)&amp;=E[(y-f^{e}(x))^2]\\
&amp;=E[(f(x)-f^{e}(x))^2]+\sigma_e^2\\
&amp;=[f(x)]^2-2f(x)E[f^{e}(x)]+E[f^{e}(x)^2]+\sigma_e^2\\
&amp;=E[f^{e}(x)]^2-2f(x)E[f^{e}(x)]+[f(x)]^2\\
&amp;+E[f^{e}(x)^2]-2E[f^{e}(x)]^2+E[f^{e}(x)]^2+\sigma_e^2\\
&amp;=E[f^{e}(x)]^2-2f(x)E[f^{e}(x)]+[f(x)]^2\\
&amp;+E[f^{e}(x)^2-2f^{e}(x)E[f^{e}(x)]+E[f^{e}(x)]^2]+\sigma_e^2\\
&amp;=\underbrace{(E[f^{e}(x)]-f(x))^2}_{Bias^2}+\underbrace{E[(f^{e}(x)-E[f^{e}(x)])^2]}_{Variance}+\sigma_e^2\\
\end{align*}
\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoqrsu9k1u936ff1gps16anac61g.png" width="400"/>
</center>
<p>所以大家可以清楚的看到模型学习过程其实就是对偏差和方差的折中过程。</p>
<h2 id="线性回归-linear-regression">2.1 线性回归-Linear Regression</h2>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoif9nr11ft1j95hca71a1a9dm.png" width="400"  />
</center>
<center>
简单线性回归
</center>
<h3 id="模型原理">2.1.1 模型原理</h3>
<p>标准线性回归通过对自变量的线性组合来预测因变量，组合自变量的权重通过最小化训练集中所有样本的预测平方误差和来得到，原理如下。</p>
<ul>
<li>预测函数</li>
</ul>
<p><span class="math display">\[ \tilde y_i=\sum_{i=1}^N w^Tx_i\]</span></p>
<ul>
<li>参数学习－采用最小二乘法</li>
</ul>
<p><span class="math display">\[min~\frac{1}{2}\sum_{i=1}^N(y_i-\tilde y_i)^2\]</span></p>
<p>所有机器学习模型的成立都会有一定的先验假设，线性回归也不例外，它对数据做了以下强假设:</p>
<ul>
<li><p>自变量相互独立，无多重共线性</p></li>
<li><p>因变量是自变量的线性加权组合：</p></li>
</ul>
<p><span class="math display">\[y=w^Tx+\epsilon\]</span></p>
<ul>
<li>所有样本独立同分布(iid)，且误差项服从以下分布：</li>
</ul>
<p><span class="math display">\[\epsilon \sim N(0,\sigma^2)\]</span></p>
<p>最小二乘法与以上假设的关系推导如下: <span class="math display">\[
\begin{array}{l}
\because y=w^Tx+\epsilon,~~~~~\epsilon \sim N(0,\sigma^2)\\
\therefore p(y|x) = N(w^Tx,\sigma^2)\\
\Rightarrow p(y|x) = \frac{1}{\sqrt {2\pi}\sigma} e^{-\frac{(y-w^Tx)^2}{2\sigma^2}}
\end{array}
\]</span></p>
<p>使用MLE(极大似然法)估计参数如下: <span class="math display">\[
\begin{array}{l}
w=arg~max_w\sum_{i=1}^Nlog~p(y_i|x_i)\\
\Leftrightarrow w=arg~min_w\frac{1}{2}\sum_{i=1}^N{(y_i-w^Tx_i)^2}
\end{array}
\]</span></p>
<p>线性回归有两个重要变体：</p>
<ul>
<li>Lasso Regression:采用L1正则并使用MAP做参数估计</li>
<li>Ridge Regression:采用L2正则并使用MAP做参数估计</li>
</ul>
<p>关于正则化及最优化后续会做介绍。</p>
<h3 id="损失函数">2.1.2 损失函数</h3>
<p><strong>损失函数1 —— Least Square Loss</strong></p>
<p><span class="math display">\[loss(x)=\frac{1}{2}\sum_{i=1}^N(y_i-\tilde y_i)^2\]</span></p>
<p>进一步阅读可参考：<a href="https://en.wikipedia.org/wiki/Least_squares">Least Squares</a></p>
<p>Q: 模型和损失的关系是什么?</p>
<h2 id="支持向量机-support-vector-machine">2.2 支持向量机-Support Vector Machine</h2>
<p>支持向量机通过寻找一个分类超平面使得(相对于其它超平面)它与训练集中任何一类样本中最接近于超平面的样本的距离最大。虽然从实用角度讲(尤其是针对大规模数据和使用核函数)并非最优选择，但它是大家理解机器学习的最好模型之一，涵盖了类似偏差和方差关系的泛化理论、最优化原理、核方法原理、正则化等方面知识。</p>
<h3 id="模型原理-1">2.2.1 模型原理</h3>
<p>SVM原理可以从最简单的解析几何问题中得到：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aonhhgoo83ei2ca021k5vfc11j.png" width="400"  />
</center>
<p>超平面的定义如下: <span class="math display">\[
\begin{array}{l}
y=f(x)=w^Tx+b\\
f(x)=0
\end{array}
\]</span></p>
<p>从几何关系上来看，超平面与数据点的关系如下(以正样本点为例)： <span class="math display">\[
\begin{array}{l}
x_i=p_i+\gamma_i\frac{w}{\Arrowvert w\Arrowvert}\\
\text{where the p is point  x&#39;s projection on the hyperplane.}\\
\Leftrightarrow w^Tx_i+b=w^Tp_i+b+\gamma_i\frac{w^Tw}{\Arrowvert w\Arrowvert}\\
\because f(p_i)=0\\
\therefore f(x_i)=\gamma_i\Arrowvert w\Arrowvert\\
\Rightarrow \gamma_i=\frac{f(x_i)}{\Arrowvert w\Arrowvert}\\
\text{consider two cases(label=}\pm1\text{)}\\
\Rightarrow \gamma_i=\frac{y_if(x_i)}{\Arrowvert w\Arrowvert}\\
\text{set}~~\tilde{\gamma_i}=y_if(x_i)\\
\Rightarrow \gamma_i=\frac{\tilde{\gamma_i}}{\Arrowvert w\Arrowvert}
\end{array}
\]</span></p>
<p>定义几何距离和函数距离分别如下： <span class="math display">\[
\begin{array}{l}
\text{relative geometric margin:}~~~~\tilde{\gamma}=min_1^N\tilde{\gamma_i}\\
\text{relative functional margin:}~~~~\gamma=min_1^N\gamma_i
\end{array}
\]</span></p>
<p>由于超平面的大小对于SVM求解并不重要，重要的是其方向，所以根据SVM的定义,得到约束最优化问题： <span class="math display">\[
\begin{array}{l}
max~~\gamma\\
~~~st.~y_i\frac{f(x_i)}{\Arrowvert w\Arrowvert}\ge \gamma,~~i=1,2....N\\
\Leftrightarrow \\
max~\frac{\tilde{\gamma}}{\Arrowvert w\Arrowvert}\\
~~~st.~y_if(x_i)\ge \tilde{\gamma},~~i=1,2....N\\
\text{the value of } \tilde{\gamma}\text{ does not affect the solution of the problem.}\\
\text{to set } \tilde{\gamma}=1.\\
\Leftrightarrow \\
min~\frac{1}{2}\Arrowvert w\Arrowvert^2\\
~~~st.~y_if(x_i)-1\ge 0,~~i=1,2....N\\
\end{array}
\]</span></p>
现实当中我们无法保证数据是线性可分的，强制要求所有样本能正确分类是不太可能的，即使做了核变换也只是增加了这种可能性，因此我们又需要做折中，允许误分的情况出现，对误分的样本根据其严重性做惩罚，所以引入松弛变量，将上述问题变成软间隔优化问题。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aont3ghm1g1e18qk18b492k1nd20.png" width="400" />
</center>
<p>新的优化问题： <span class="math display">\[
\begin{align*}
min&amp;~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^Ng(\xi_i)\\
st.&amp;~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
&amp;\xi_i\ge 0,~~i=1,2....N\\
&amp;g(\xi)=\xi \text{ or } g(\xi)=\xi^2.....\\
\end{align*}
\]</span></p>
<p>如果选择： <span class="math display">\[g(\xi)=\xi\]</span></p>
<p>那么优化问题变成： <span class="math display">\[
\begin{array}{l}
min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\end{array}
\]</span></p>
<h3 id="损失函数-1">2.2.2 损失函数</h3>
<p><strong>损失函数2 —— Hinge Loss</strong></p>
<p><span class="math display">\[loss(x)=\sum_{i=1}^N[1-y_if(x_i)]_+\]</span></p>
<p>使用hinge loss将SVM套入机器学习框架，让它更容易理解。此时原始约束最优化问题变成损失函数是hinge loss且正则项是L2正则的无约束最优化问题：</p>
<p><span class="math display">\[
\begin{array}{l}
(1)min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\Leftrightarrow \\
(2)min~\sum_{i=1}^N[1-y_if(x_i)]_++\lambda \Arrowvert w\Arrowvert^2
\end{array}
\]</span></p>
<p>下面我证明以上问题(1)和问题(2)是等价的(反之亦然)：</p>
<p><span class="math display">\[
\begin{array}{l}
&amp;&amp; \because 1-y_if(x_i)\leq \xi_i \text{ and }0 \leq \xi_i\\
&amp;&amp; \text{if }1-y_if(x_i)\geq 0 \text{ then}\\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~~\Leftrightarrow \\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N1-y_if(x_i)\\
&amp;&amp; \text{if }1-y_if(x_i)&lt;0\text{ then}\\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~~\Leftrightarrow \\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2\\
&amp;&amp; \therefore\\
&amp;&amp; min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
&amp;&amp; ~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\Leftrightarrow \\
&amp;&amp; min~\sum_{i=1}^N[1-y_if(x_i)]_++\lambda \Arrowvert w\Arrowvert^2\\
\end{array}
\]</span></p>
<p>到此为止，SVM和普通的判别模型没什么两样，也没有support vector的概念，它之所以叫SVM就得说它的对偶形式了，通过拉格朗日乘数法对原始问题做对偶变换：</p>
<p><span class="math display">\[
\begin{align*}
min&amp;~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
st.&amp;~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
&amp;~\xi_i\ge 0,~~i=1,2....N\\
\Rightarrow&amp; \\
&amp;L(w,b,\xi,\alpha,\mu)=\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum\limits_{i=1}^{N}\xi_i\\
&amp;-\sum\limits_{i=1}^{N}\alpha_i(y_i(w^Tx_i+b)-1+\xi_i)-\sum\limits_{i=1}^{N}\mu_i\xi_i\\
&amp;\text{(KKT conditions)}\\
&amp;\frac{\partial{L}}{\partial{w}}=w-\sum\limits_{i=1}^{n}y_i\alpha_i x_i=0\\
&amp;\frac{\partial{L}}{\partial{b}}=\sum\limits_{i=1}^{n}y_i\alpha_i=0\\
&amp;\frac{\partial L}{\partial \xi}=C-\alpha-\mu=0\\
&amp;\text{(Complementary Slackness condition)}\\
&amp;\alpha_i(y_i(w^Tx_i+b)- 1+\xi_i)=0\\
&amp;\mu_i\xi_i=(\alpha_i-C)\xi_i=0\\
&amp;\alpha_i\geq 0\\
&amp;\xi_i\geq 0\\
&amp;\mu_i\geq 0\\
&amp;\text{(Replace inner product with the kernel function)}\\
\\
&amp;\Rightarrow \\
max&amp;~\sum\limits_{i=1}^{N}\alpha_i-\frac{1}{2}\sum\limits_{i,j=1}^{N}{y_iy_j\alpha_i\alpha_j(K(x_i,x_j))}\\
st.&amp;~\sum\limits_{i=1}^{n}y_i\alpha_i=0\\
&amp;0 \leq \alpha_i \leq C\\
\end{align*}
\]</span></p>
<p>从互补松弛条件可以得到以下信息：</p>
<p>当<span class="math inline">\(\alpha_i=C\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>不为零，此时其几何间隔小于<span class="math inline">\(1/\Arrowvert w\Arrowvert\)</span>，对应样本点就是误分点；当<span class="math inline">\(\alpha_i=0\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>为零，此时其几何间隔大于<span class="math inline">\(1\Arrowvert w\Arrowvert\)</span>，对应样本点就是内部点，即分类正确而又远离最大间隔分类超平面的那些样本点；而<span class="math inline">\(0 &lt; \alpha_i &lt;C\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>为零，此时其几何间隔等于<span class="math inline">\(1/ \Arrowvert w\Arrowvert\)</span>，对应<strong>样本点</strong>就是<strong>支持向量</strong>。<span class="math inline">\(\alpha_i\)</span>的取值一定是<span class="math inline">\([0,C]\)</span>，这意味着向量<span class="math inline">\(\alpha\)</span>被限制在了一个边长为<span class="math inline">\(C\)</span>的盒子里。 详细说明可参考:<a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/22/1913538.html29le/image_1asr9qkai1mseu8n13i8ele1sf89.png">SVM学习——软间隔优化</a>。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1asr9qkai1mseu8n13i8ele1sf89.png" width="500" />
</center>
<center>
<span class="math inline">\(C\)</span>越大表明你越不想放弃离群点，分类超平面越向离群点移动
</center>
<p>当以上问题求得最优解<span class="math inline">\(\alpha^*\)</span>后，几何间隔变成如下形式： <span class="math display">\[\gamma=(\sum\limits_{i,j \in \{support~vectors\}}y_iy_j\alpha_i^*\alpha_j^*K(x_i,x_j))^{-1/2}\]</span> 它只与有限个样本有关系，这些样本被称作支持向量，从这儿也能看出此时模型参数个数与样本个数有关系，这是典型的非参学习过程。</p>
<h3 id="核方法">2.2.3 核方法</h3>
<p>上面对将内积<span class="math inline">\(x_i^Tx_j\)</span>用一个核函数<span class="math inline">\(K(x_i,x_j)\)</span>做了代替，实际上这种替换不限于SVM，所有出现样本间内积的地方都可以考虑这种核变换，本质上它就是通过某种隐式的空间变换在新空间(有限维或无限维兼可)做样本相似度衡量，采用核方法后的模型都可以看做是无固定参数的基于样本的学习器，属于非参学习，核方法与SVM这类模型的发展是互相独立的。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1astp4htfueu10v51ciq1ab32sr9.png" width="500" />
</center>
<center>
from <a href="http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html">Kernel Trick</a>
</center>
<p>这里不对原理做展开，可参考：</p>
<p>1、<a href="https://www.amazon.com/gp/product/0521813972/qid=1137139342/sr=11-1/ref=sr_11_1/002-7679689-7393625?n=283155">Kernel Methods for Pattern Analysis</a></p>
<p>2、<a href="https://papers.nips.cc/paper/1862-the-kernel-trick-for-distances.pdf">the kernel trick for distances</a></p>
<p>一些可以应用核方法的模型：</p>
<blockquote>
<ul>
<li>SVM</li>
<li>Perceptron</li>
<li>PCA</li>
<li>Gaussian processes</li>
<li>Canonical correlation analysis</li>
<li>Ridge regression</li>
<li>Spectral clustering</li>
</ul>
</blockquote>
<p>在我看来核方法的意义在于： 1、对样本进行空间映射，以较低成本隐式的表达样本之间的相似度，改善样本线性可分的状况，但不能保证线性可分； 2、将线性模型变成非线性模型从而提升其表达能力，但这种升维的方式往往会造成计算复杂度的上升。</p>
<p>一些关于SVM的参考资料:</p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/02/1894311.html">SVM学习——线性学习器</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/06/1897702.html">SVM学习——求解二次规划问题</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/13/1904720.html">SVM学习——核函数</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/18/1909709.html">SVM学习——统计学习理论</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2010/12/22/1913538.html">SVM学习——软间隔优化</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2011/01/13/1934296.html">SVM学习——Coordinate Desent Method</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2011/06/01/2067496.html">SVM学习——Sequential Minimal Optimization</a></p>
<p><a href="http://www.cnblogs.com/vivounicorn/archive/2011/08/25/2152824.html">SVM学习——Improvements to Platt’s SMO Algorithm</a></p>
<h2 id="逻辑回归-logistic-regression">2.3 逻辑回归-Logistic Regression</h2>
<p>逻辑回归恐怕是互联网领域用的最多的模型之一了，很多公司做算法的同学都会拿它做为算法系统进入模型阶段的baseline。</p>
<h3 id="模型原理-2">2.3.1 模型原理</h3>
<p>逻辑回归是一种判别模型，与线性回归类似，它有比较强的先验假设 :</p>
<ul>
<li>假设因变量服从贝努利分布</li>
</ul>
<p><span class="math display">\[
 \begin{align*}
 p(y|x)&amp;=Bernoulli(\pi)\\
 &amp;=p(y=1|x)^y(1-p(y=1|x))^{1-y},y\in\{0,1\}
 \end{align*}
 \]</span></p>
<ul>
<li>假设训练样本服从<strong>钟形分布</strong>，例如高斯分布：</li>
</ul>
<p><span class="math display">\[p(x_i|y=y_k)=Gaussian(\mu_{ik},\sigma_i)\]</span></p>
<ul>
<li><p><span class="math inline">\(y\)</span> 是样本标注，布尔类型，取值为0或1；</p></li>
<li><p><span class="math inline">\(x\)</span> 是样本的特征向量。</p></li>
</ul>
<p>逻辑回归是判别模型，所以我们直接学习<span class="math inline">\(p(y|x)\)</span>，以高斯分布为例:</p>
<p><span class="math display">\[p(y=1|x)=\frac{1}{1+e^{-(w^Tx+b)}}\]</span></p>
<p><span class="math display">\[p(y=0|x)=\frac{1}{1+e^{(w^Tx+b)}}\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap1pq34s184n18stpt413bq12at9.png" width="400"  />
</center>
<p>整个原理部分的推导过程如下：</p>
<p><span class="math display">\[
\begin{align*}
p(y=1|x)&amp;=\frac{p(x|y=1)p(y=1)}{p(x)}\\
&amp;=\frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1)+p(x|y=0)p(y=0)}\\
&amp;=\frac{1}{1+\frac{p(x|y=0)p(y=0)}{p(x|y=1)p(y=1)}}\\
&amp;=\frac{1}{1+\frac{p(x|y=0)(1-p(y=1))}{p(x|y=1)p(y=1)}}~~\text {to set p(y=1)=}\pi\\
&amp;=\frac{1}{1+\frac{p(x|y=0)(1-\pi)}{p(x|y=1)\pi}}\\
&amp;=\frac{1}{1+e^{ln\frac{1-\pi}{\pi}+ln\frac{p(x|y=0)}{p(x|y=1)}}}\\
&amp;=\frac{1}{1+e^{ln\frac{1-\pi}{\pi}+\sum_iln\frac{p(x_i|y=0)}{p(x_i|y=1)}}}\\
\end{align*}
\]</span> <span class="math display">\[
\begin{align*}
&amp;\because p(x_i|y_k)=\frac{1}{\sigma_{ik}\sqrt{2\pi}}e^{-\frac{(x_i-\mu_{ik})^2}{2\sigma_{ik}^2}}\\
&amp;\therefore p(y=1|x)=\frac{1}{1+e^{-(ln\frac{\pi-1}{\pi}+\sum_i(\frac{\mu_{i1}-\mu_{i0}}{\sigma_i^2}x_i+\frac{\mu_{i0}^2-\mu_{i1}^2}{2\sigma_i^2}))}}\\
&amp;\qquad\qquad\qquad =\frac{1}{1+e^{-(\sum_iw_ix_i+b)}},i=1,2,...,dim\\
&amp;\text{where}\\
&amp;\qquad\qquad\qquad b=\sum_i\frac{\mu_{i0}^2-\mu_{i1}^2}{2\sigma_i^2}+ln\frac{\pi-1}{\pi}\\
&amp;\qquad\qquad\qquad w_i=\frac{\mu_{i1}-\mu_{i0}}{\sigma_i^2}
\end{align*}
\]</span></p>
<p>采用 MLE 或者 MAP 做参数求解:</p>
<p><span class="math display">\[
\begin{array}{l}
w=arg~max_w\sum_{i=1}^Nln~p(y_i|x_i)\\
\Leftrightarrow \\
w=arg~min_w\sum_{i=1}^N{y_iln~p(y_i=1|x_i)+(1-y_i)ln~p(y_i=0|x_i)}
\end{array}
\]</span></p>
<h3 id="损失函数-2">2.3.2 损失函数</h3>
<p><strong>损失函数3 —— Cross Entropy Loss</strong></p>
<p><span class="math display">\[
\begin{array}{l}
loss(x)=H_p(q)=\sum_{i=1}^N\sum_y(\int_y) p(y|x_i)ln\frac{1}{q(y|x_i)}\\
\text{especially for bernoulli distribution:}\\
loss(x)=\sum_{i=1}^Ny_i ln ~p(y_i|x_i)+(1-y_i)(1-ln~p(y_i|x_i))
\end{array}
\]</span></p>
<p>简单理解，从概率角度：Cross Entropy损失函数衡量的是两个概率分布<span class="math inline">\(p\)</span>与<span class="math inline">\(q\)</span>之间的相似性，对真实分布估计的越准损失越小；从信息论角度：用编码方式<span class="math inline">\(q\)</span>对由编码方式<span class="math inline">\(p\)</span>产生的信息做编码，如果两种编码方式越接近，产生的信息损失越小。与Cross Entropy相关的一个概念是Kullback–Leibler divergence，后者是衡量两个概率分布接近程度的标量值，定义如下： <span class="math display">\[D_q(p) = \sum_x(\int_x) p(x)\log_2\left(\frac{p(x)}{q(x)} \right)\]</span> 当两个分布完全一致时其值为0，显然Cross Entropy与Kullback–Leibler divergence的关系是： <span class="math display">\[H_p(q)=H(p)+D_q(p)\]</span></p>
<p>关于交叉熵及其周边原理，有一篇文章写得特别好：<strong><a href="http://colah.github.io/posts/2015-09-Visual-Information/">Visual Information Theory</a></strong>。</p>
<h2 id="bagging-and-boosting框架">2.4 Bagging and Boosting框架</h2>
<p>Bagging和Boosting是两类最常用以及好用的模型融合框架，殊途而同归。</p>
<h3 id="bagging框架">2.4.1 Bagging框架</h3>
Bagging(Breiman, 1996) 方法是通过对训练样本和特征做有放回的抽样，并拟合若干个基础模型进而通过投票方式做最终分类决策的框架。每个基础分类器（可以是树形结构、神经网络等等任何分类模型）的特点是<strong>低偏差、高方差</strong>，框架通过(加权)投票方式降低方差，使得整体趋于<strong>低偏差、低方差</strong>。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2hfjae8q6nta1ppd10l1fkv1g.png" width="600" />
</center>
<p>分析如下：</p>
<p>假设任务是学习一个模型 <span class="math inline">\(y=f(x)\)</span> ，我们通过抽样生成生成<span class="math inline">\(N\)</span> 个数据集，并训练得到<span class="math inline">\(N\)</span>个基础分类器<span class="math inline">\(c_i......c_N\)</span>。</p>
<p><span class="math display">\[
\begin{array}{l}
\text{define}:\\
\qquad\qquad (1). y=f(x), \text{prediction function}\\
\qquad\qquad (2). o_i(x)=c_i(x), \text{ $c_i$ is the i-th classifier}\\
\qquad\qquad (3). \overline{o}(x)=\sum_{i=1}^Nw_io_i(x), \text{ where } \sum_{i=1}^Nw_i=1\\
\qquad\qquad (4). v_i(x)=[o_i(x)-\overline{o}(x)]^2\\
\qquad\qquad (5). \overline{v}(x)=\sum_{i=1}^Nw_iv_i(x)=\sum_{i=1}^Nw_i[o_i(x)-\overline{o}(x)]^2\\
\qquad\qquad (6). \overline{\epsilon}(x)=\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2]\\
\qquad\qquad 7). e(x)=(f(x)-\overline{o}(x))^2 \\
\because \overline{v}(x)=\sum_{i=1}^Nw_i[o_i(x)-\overline{o}(x)]^2\\
\qquad\qquad =\sum_{i=1}^Nw_i[(f(x)-o_i(x))-(f(x)-\overline{o}(x))]^2\\
\qquad\qquad =\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2+(f(x)-\overline{o}(x))^2\\
\qquad\qquad  -2(f(x)-o_i(x))(f(x)-\overline{o}(x))]\\
\qquad\qquad =\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2]-(f(x)-\overline{o}(x))^2\\
\therefore e(x)=\overline{\epsilon}(x)-\overline{v}(x)
\end{array}
\]</span></p>
<p>从结论可以发现多分类器投票机制的引入可以降低模型方差从而降低分类错误率，大家可以多理解理解这一系列推导。</p>
<h3 id="boosting框架">2.4.2 Boosting框架</h3>
Boosting(Freund &amp; Shapire, 1996) 通过迭代方式训练若干基础分类器，每个分类器依据上一轮分类器产生的残差做权重调整，每轮的分类器需要够“简单”，具有<strong>高偏差、低方差</strong>的特点，框架再辅以(加权)投票方式降低偏差，使得整体趋于<strong>低偏差、低方差</strong>。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2e2geqo3a11ur18od2b413ek13.png" width="600" />
</center>
<p>一个简单的总结: <span class="math display">\[
\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
\text{where:}\\
\qquad f_i\text{ is the base classier }i\\
\qquad  w_i \text{ is the weight of classier }i\\
\qquad x \text{ is the feature vector of example}\\
\text{define:}\\
\qquad \text{(1). margin of an example(x,y) with respect to the classier is yF(x)}\\
\qquad \text{(2). cost function of $N$ examples is $C(F)=\frac{1}{N}\sum_{i=1}^NC(y_iF(x_i))$}\\
\text{Now we wish to find a new $f$ to add to F so that $C(F+\alpha f)$ can be decreased}\\
\because C(F+\alpha f)=C(F)+\alpha\langle\nabla{C(F)},f\rangle\\
\therefore \text{the greatest reduction of $C$ will satisfied: }\\
\qquad\qquad\qquad f=Max~-\langle\nabla{C(F)},f\rangle
\end{array}
\]</span></p>
<p>AnyBoost Algorithm</p>
<p>Boost算法是个框架，很多模型都能往进来套。 <span class="math display">\[
\begin{array}{l}
F_0(x)=0\\
\text{for $i$=0 to T:}\\
\qquad f_{t+1}=classifier(F_t)\\
\qquad if~~-\langle\nabla{C(F)},f_{t+1}\rangle \le0:\\
\qquad\qquad return~F_t\\
\qquad choose~w_{t+1}\\
\qquad F_{t+1}=F_t+w_{t+1}f_{t+1}\\
return~F_{T+1}
\end{array}
\]</span></p>
<p>Q: boosting 和 margin的关系是什么（机器学习中margin的定义为<span class="math inline">\(yf(x)\)</span>）？</p>
<p>Q: 类似bagging，为什么boosting能够通过reweight及投票方式降低整体偏差？</p>
<h2 id="additive-tree-模型">2.5 Additive Tree 模型</h2>
<p>Additive tree models (ATMs)是指基础模型是树形结构的一类融合模型，可做分类、回归，很多经典的模型可以被看做ATM模型，比如Random forest 、Adaboost with trees、GBDT等。</p>
<p>ATM 对N棵决策树做加权融合，其判别函数为：</p>
<p><span class="math display">\[
\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
\text{where }f_i\text{ is the output of tree }i\\
\qquad\qquad\qquad w_i \text{ is the weight of tree }i\\
\qquad\qquad\qquad x \text{ is the feature vector of instance}
\end{array}
\]</span></p>
<h3 id="random-forests">2.5.1 Random Forests</h3>
Random Forest 属于bagging类模型，每棵树会使用各自随机抽样样本和特征被独立的训练。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2m8teo1kqg1up8mtvccpfns2a.png" width="400" />
</center>
<p><span class="math display">\[
\begin{array}{l}
\text{for $t$ = 1 to $T$:}\\
\qquad \text{(1). Sample $n$ instances from the dataset with replacement}\\
\qquad \text{(2). Randomization:}\\
\qquad \qquad\text{$\bullet$ Bootstrap samples.}\\
\qquad \qquad\text{$\bullet$ Random selection of $K\le p$ split variables.}\\
\qquad \qquad\text{$\bullet$ Random selection of threshold.}\\
\qquad \text{(2). Train an low-bias unpruned decision or regression tree $f_t$ on the sampled instances }\\
\\
\text{The final is the average of the outputs from all the trees:}\\
F(x)=\sum_{i=1}^Tw_if_i(x)\\
~~~where~\sum_{i=1}^Tw_i=1,~(such~ as ~w_i=\frac{1}{T})
\end{array}
\]</span></p>
<h3 id="adaboost-with-trees">2.5.2 AdaBoost with trees</h3>
<p>AdaBoost with trees通过训练多个弱分类器来组合得到一个强分类器，每次迭代会生成一棵<strong>高偏差、低方差</strong>的树形弱分类器，每一轮的训练会更关注上一轮被分类器分错的样本，为其加大权重，训练过程如下：</p>
<p><span class="math display">\[
\begin{array}{l}
f_0(x)=0\\
\text{for $i$=1 to $T$:}\\
\qquad minimize~\sum_{i=1}^NL(y_i,F_t(x_i)+\alpha_tf_t(x_i))\\
\qquad F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\\
\\
\text{The final is weighted average of the outputs from all the weak classifiers:}\\
F(x)=\sum_{i=1}^T\alpha_if_i(x)\\
\end{array}
\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2oflv078q1h631peataq13ih2n.png" width="500" />
</center>
<center>
From Bishop(2006)
</center>
<h3 id="gradient-boosting-decision-tree">2.5.3 Gradient Boosting Decision Tree</h3>
<p>Gradient boosted 是一类boosting的技术，不同于Adaboost加大误分样本权重的策略，它每次迭代加的是上一轮梯度更新值： <span class="math display">\[\sum_{i=1}^NL(y_i,F_t(x_i)+\alpha_tf_t(x_i))\]</span></p>
<p>其训练过程如下:</p>
<p><span class="math display">\[
\begin{array}{l}
F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\\
f_t(x_i)\thickapprox -\frac{\partial L(y_i,F_t(x_i))}{\partial F_t(x_i)}\\
\qquad \text{where $\alpha_t$ is the learning rate.}
\end{array}
\]</span></p>
GBDT是基础分类器为决策树的可做分类和回归的模型。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/gbdt.png" width="400" />
</center>
目前我认为最好的GBDT的实现是XGBoost: 其回归过程的示例图如下，通过对样本落到每棵树的叶子节点的权重值做累加来实现回归(或分类)：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap5297q1nte1tkpb3u1lfr1pk45c.png" width="500"  />
</center>
<center>
Regression Tree Ensemble from chentianqi
</center>
<p>其原理推导如下：</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Prediction model: }F(x)=\sum_{i=1}^Tw_if_i(x)\\
\text{Objective: }obj^t=\sum_{i=1}^NL(y_i,F_i^t(x_i))+\Omega(f_t)\\
\qquad \text{where N is instance numbers and t is current trees.}\\
\because obj^t=\sum_{i=1}^NL(y_i,F_i^t(x_i))+\Omega(f_t)\\
\qquad =\sum_{i=1}^NL(y_i,F_i^{t-1}(x_i)+w_tf_t(x_i))+\Omega(f_t)\\
\text{Recall: }f(x+\Delta x)\thickapprox f(x)+\nabla f(x)\Delta x+\frac{1}{2}\nabla^2 f(x)\Delta x^2\\
\therefore obj^t\thickapprox\sum_{i=1}^N[L(y_i,F_i^{t-1}(x_i))+\nabla _{F_{t-1}}L(y_i,F_i^{t-1}(x_i))w_tf_t(x_i)\\
\qquad \qquad \frac{1}{2}\nabla _{F_{t-1}}^2L(y_i,F_i^{t-1}(x_i))w_t^2f_t^2(x_i)]+\Omega(f_t)\\
\text{set $g_i=\nabla _{F_{t-1}}L(y_i,F_i^{t-1}(x_i))$}\\
\qquad h_i=\nabla _{F_{t-1}}^2L(y_i,F_i^{t-1}(x_i))\\
\qquad obj^t\thickapprox \sum_{i=1}^N[L(y_i,F_i^{t-1}(x_i))+g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)\\
\because L(y_i,F_i^{t-1}(x_i)) \text{ is constant.}\\
\therefore \text{Our objective function is:}\\
\qquad obj^t=\sum_{i=1}^N[g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)+C\\
\text{Define tree by a vector of scores in leafs,any instance will be mapped to a leaf:}\\
f_t(x)=m_q(x),~~m\in R^T,~~q:R^d\rightarrow\{1,2,3,...,T\}\\
\Omega(f_t)=\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2,\\
\text{where $T$ is total number of leaf nodes of $t$ trees}\\
\qquad \qquad \text{$m_j$ is the weight of j-th leaf node.}\\
\text{Define the instance set in leaf $j$ as $I_j=\{i|j=q(x_i)\}$}\\
\text{Our new objective function is:}\\
obj^t=\sum_{i=1}^N[g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)\\
\qquad =\sum_{i=1}^N[g_iw_tm_q(x_i)+\frac{1}{2}h_iw_t^2m_q^2(x_i)]+\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2\\
\qquad =\sum_{j=1}^T[(\sum_{i \in I_j}g_i)w_tm_j+\frac{1}{2}(\sum_{i \in I_j}h_iw_t^2+\lambda )m_j^2]+\gamma T\\
\text{Define $G_j=\sum_{i \in I_j}g_i$ and $H_j=\sum_{i \in I_j}h_i$ then}\\
obj^t=\sum_{j=1}^T[G_jw_tm_j+\frac{1}{2}(H_jw_t^2+\lambda)m_j^2]+\gamma T\\
\text{For a quadratic function optimization problems:}\\
m_j^*=-\frac{G_j^2w_t}{H_jw_t^2+\lambda}\\
obj^*=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2w_t^2}{H_jw_t^2+\lambda}+\gamma T\\
\text{If we set $w_t=1$ then}\\
m_j^*=-\frac{G_j}{H_j+\lambda}\\
obj^*=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda}+\gamma T\\
\text{So when we add a split, our obtained gain is:}\\
gain=\underbrace{\frac{G_L^2}{H_L+\lambda}}_{left ~child}+\underbrace{\frac{G_R^2}{H_R+\lambda}}_{right~child}-\underbrace{\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}}_{do~not~split}-\gamma~~~~(thinking~why?)
\end{array}
\]</span></p>
<p>对GBDT来说依然避免不了过拟合，所以与传统机器学习一样，通过正则化策略可以降低这种风险：</p>
<ul>
<li>提前终止（Early Stopping）</li>
</ul>
<p>通过观察模型在验证集上的错误率，如果它变化不大则可以提前结束训练，控制迭代轮数（即树的个数）；</p>
<ul>
<li>收缩（Shrinkage）</li>
</ul>
<p><span class="math inline">\(F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\)</span> 从迭代的角度可以看成是学习率（learning rate），从融合（ensemble）的角度可以看成每棵树的权重，<span class="math inline">\(\alpha\)</span>的大小经验上可以取0.1，它是对模型泛化性和训练时长的折中；</p>
<ul>
<li>抽样（Subsampling）</li>
</ul>
<p>借鉴Bagging的思想，GBDT可以在每一轮树的构建中使用训练集中无放回抽样的样本，也可以对特征做抽样，模拟真实场景下的样本分布波动；</p>
<ul>
<li>目标函数中显式的正则化项</li>
</ul>
<p><span class="math inline">\(\Omega(f_t)=\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2\)</span> 通过对树的叶子节点个数、叶子节点权重做显式的正则化达到缓解过拟合的效果；</p>
<ul>
<li>参数放弃（Dropout）</li>
</ul>
模拟深度学习里随机放弃更新权重的方法，可以在每新增一棵树的时候拟合随机抽取的一些树的残差，相关方法可以参考：<a href="http://jmlr.org/proceedings/papers/v38/korlakaivinayak15.pdf">DART: Dropouts meet Multiple Additive Regression Trees</a>，文中对该方法和Shrinkage的方法做了比较：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1b0s1udkl1att1v8o1hfs11im1eepm.png" width="400" />
</center>
<p>XGBoost源码在: https://github.com/dmlc中，其包含非常棒的设计思想和实现，建议大家都去学习一下，一起添砖加瓦。原理部分我就不再多写了，看懂一篇论文即可，但特别需要注意的是文中提到的<strong>weighted quantile sketch</strong>算法，它用来解决当样本集权重分布不一致时如何选择分裂节点的问题：<a href="https://arxiv.org/pdf/1603.02754.pdf">XGBoost: A Scalable Tree Boosting System</a>。</p>
<h3 id="简单的例子">2.5.4 简单的例子</h3>
<p>下面是关于几个常用机器学习模型的对比，从中能直观地体会到不同模型的运作区别，数据集采用libsvm作者整理好的fourclass_scale数据集，机器学习工具采用sklearn，代码中模型未做任何调参，仅使用默认参数设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">matplotlib.use(<span class="string">&#x27;Agg&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> proj3d</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> sklearn.externals.joblib <span class="keyword">import</span> Memory</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_svmlight_file</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> cm</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> LinearLocator, FormatStrFormatter</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense,Dropout,Activation</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">outpath</span>):</span></span><br><span class="line">  filename=outpath+<span class="string">&quot;/fourclass_scale&quot;</span></span><br><span class="line">  <span class="keyword">if</span> os.path.exists(filename) == <span class="literal">False</span>:</span><br><span class="line">    urllib.urlretrieve(<span class="string">&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/fourclass_scale&quot;</span>,filename)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_building</span>():</span></span><br><span class="line">  dtrain = load_svmlight_file(<span class="string">&#x27;fourclass_scale&#x27;</span>)</span><br><span class="line">  train_d=dtrain[<span class="number">0</span>].toarray()</span><br><span class="line">  train_l=dtrain[<span class="number">1</span>]</span><br><span class="line">  x1 = train_d[:,<span class="number">0</span>]</span><br><span class="line">  x2 = train_d[:,<span class="number">1</span>]</span><br><span class="line">  y = train_l</span><br><span class="line">  px1 = []</span><br><span class="line">  px2 = []</span><br><span class="line">  pl = []</span><br><span class="line">  nx1 = []</span><br><span class="line">  nx2 = []</span><br><span class="line">  nl = []</span><br><span class="line">  idx = <span class="number">0</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> y:</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">      px1.append(x1[idx]-<span class="number">0.5</span>)</span><br><span class="line">      px2.append(x2[idx]+<span class="number">0.5</span>)</span><br><span class="line">      pl.append(i)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      nx1.append(x1[idx]+<span class="number">0.8</span>)</span><br><span class="line">      nx2.append(x2[idx]-<span class="number">0.8</span>)</span><br><span class="line">      nl.append(i)</span><br><span class="line">    idx = idx + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  x_axis, y_axis = np.meshgrid(np.linspace(x1.<span class="built_in">min</span>(), x1.<span class="built_in">max</span>(), <span class="number">100</span>), np.linspace(x2.<span class="built_in">min</span>(), x2.<span class="built_in">max</span>(), <span class="number">100</span>))</span><br><span class="line">  <span class="keyword">return</span> x_axis, y_axis, px1, px2, nx1, nx2, train_d, train_l</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">paint</span>(<span class="params">name, x_axis, y_axis, px1, px2, nx1, nx2, z</span>):</span></span><br><span class="line">  fig = plt.figure()</span><br><span class="line">  ax = Axes3D(fig)</span><br><span class="line">  ax=plt.subplot(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">  ax.scatter(px1,px2,c=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">  ax.scatter(nx1,nx2,c=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">  ax.plot_surface(x_axis, y_axis,z.reshape(x_axis.shape), rstride=<span class="number">8</span>, cstride=<span class="number">8</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">  ax.contourf(x_axis, y_axis, z.reshape(x_axis.shape), zdir=<span class="string">&#x27;z&#x27;</span>, offset=-<span class="number">100</span>, cmap=cm.coolwarm)</span><br><span class="line">  ax.contourf(x_axis, y_axis, z.reshape(x_axis.shape), levels=[<span class="number">0</span>,<span class="built_in">max</span>(z)], cmap=cm.hot)</span><br><span class="line">  ax.set_xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">  ax.set_ylabel(<span class="string">&#x27;Y&#x27;</span>)</span><br><span class="line">  ax.set_zlabel(<span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">  fig.savefig(name+<span class="string">&quot;.png&quot;</span>, <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svc</span>(<span class="params">x_axis, y_axis, x,y</span>):</span></span><br><span class="line">  clf = svm.SVC()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr</span>(<span class="params">x_axis, y_axis, x,y</span>):</span></span><br><span class="line">  clf = LogisticRegression()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ridge</span>(<span class="params">x_axis, y_axis, x,y</span>):</span></span><br><span class="line">  clf = Ridge()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dt</span>(<span class="params">x_axis, y_axis, x,y</span>):</span></span><br><span class="line">  clf = GradientBoostingClassifier()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nn</span>(<span class="params">x_axis, y_axis, x,y</span>):</span></span><br><span class="line">  model = Sequential()</span><br><span class="line">  model.add(Dense(<span class="number">20</span>, input_dim=<span class="number">2</span>))</span><br><span class="line">  model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">  model.add(Dense(<span class="number">20</span>))</span><br><span class="line">  model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">  model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">  model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,</span><br><span class="line">                optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">                metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  model.fit(x,y,batch_size=<span class="number">20</span>, nb_epoch=<span class="number">50</span>, validation_split=<span class="number">0.2</span>)</span><br><span class="line">  y = model.predict(np.c_[x_axis.ravel(), y_axis.ravel()],batch_size=<span class="number">20</span>)</span><br><span class="line">  <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  download(<span class="string">&quot;/root&quot;</span>)</span><br><span class="line">  x_axis, y_axis, px1, px2, nx1, nx2, train_d, train_l = data_building()</span><br><span class="line">  z = svc(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(<span class="string">&quot;svc&quot;</span>, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = lr(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(<span class="string">&quot;lr&quot;</span>, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = ridge(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(<span class="string">&quot;ridge&quot;</span>, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = dt(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(<span class="string">&quot;gbdt&quot;</span>, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = nn(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(<span class="string">&quot;nn&quot;</span>, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1apkqel8gmtlervoud3k1ad2m.png" width="900" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1apme7kvi5klumr1cig181c2vm9.png" width="300" />
</center>
<h3 id="catboost">2.5.5 CatBoost</h3>
<p>基于不同的工程实现方式，目前常用的GBDT框架有3种，分别为：XGBoost（天奇）、LightGBM（微软）、CatBoost（Yandex）。三种实现在效果上并没有特别大的区别，区别主要在特征的处理尤其是类别特征上和建树过程上。</p>
<ul>
<li>类别特征</li>
</ul>
<p>在机器学习中有一大类特征叫类别特征，这类特征主要有两个特点：</p>
<blockquote>
<p>类别取值是离散的</p>
</blockquote>
<blockquote>
<p>每个类别取值非数值类型</p>
</blockquote>
<p>例如，“性别”这个特征，它一般有3个取值：“女”，“男”，“未知”，在特征处理阶段会被编码为离散的实数值或向量，然后进入模型。 - 类别特征编码 将类别取值编码为实数值有很多方法，大致如下：</p>
<p>1、 <strong>Label Encoding</strong></p>
<pre><code>每个类别赋值一个整数值。例如，性别“女”=0，“男”=1，“未知”=2，实践中这种编码方法用处有限。</code></pre>
<p>2、 <strong>One-Hot Encoding</strong></p>
<pre><code>创建一个维度与类别取值个数相同的向量，每个向量位置对应一个类别取值，当前类别取值为1，其他为0,这种编码最大问题是类别取值太多时，向量维度很高很稀疏，对模型学习效果和内存占用都是挑战（比如，NLP里几十万的词典表）。</code></pre>
<p>例如，性别特征编码：</p>
<table>
<thead>
<tr class="header">
<th>性别</th>
<th style="text-align: center;">编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>女</td>
<td style="text-align: center;">100</td>
</tr>
<tr class="even">
<td>男</td>
<td style="text-align: center;">010</td>
</tr>
<tr class="odd">
<td>未知</td>
<td style="text-align: center;">001</td>
</tr>
</tbody>
</table>
<p>3、 <strong>Distributed Representation</strong></p>
<pre><code>类别取值会被表示为一个实数向量，这个向量维度远小于取值个数。最经典的是NLP里常用的word2vec，一举三得：实现向量表示、实现降维、向量具有隐语义。</code></pre>
<p>4、<strong>Target Encoding</strong></p>
<pre><code>本质上它是一种反馈类特征，利用了标注数据，在实践中，要提升效果，反馈类特征一定是你要最优先考虑的。
但使用时需要特别注意**Target Leakage**，例如：

1)、在训练集使用标注信息生成特征的方式，在测试集上无法实现

2)、在训练集使用了未来的信息做特征，如，使用了测试集信息

3)、特征生成时样本的统计意义不足，如，广告曝光不足
......</code></pre>
<p><strong>Target Encoding</strong>有很多版本：</p>
<p>1)、<strong>Greedy Target Statistics</strong></p>
<p>编码方式为：</p>
<p><span class="math display">\[f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}\]</span> 其中:</p>
<p><span class="math inline">\((f_{i,j}^k,y_i)\quad \{ 0\leq i \leq N,0\leq j \leq M,0\leq k \leq L\}\)</span>：为训练数据集，如果<span class="math inline">\(f\)</span>是类别特征，则<span class="math inline">\(f_{i,j}^k\)</span>为第<span class="math inline">\(i\)</span>个样本第<span class="math inline">\(j\)</span>个特征的第<span class="math inline">\(k\)</span>种取值，<span class="math inline">\(y_i\)</span>为标注且<span class="math inline">\(y_i \in \{0,1\}\)</span>。</p>
<p><span class="math inline">\(N\)</span>：样本总量，<span class="math inline">\(M\)</span>：特征总量，<span class="math inline">\(L\)</span>：某类别特征下可取值总数</p>
<p><span class="math inline">\(f_{i,j}^{&#39;k}\)</span>：为第<span class="math inline">\(i\)</span>个样本第<span class="math inline">\(j\)</span>个特征的第<span class="math inline">\(k\)</span>种取值编码后的结果</p>
<p><span class="math inline">\(\mathrm{I}\{\cdot\}\)</span>：为指示函数</p>
<p>大白话是：以训练样本中的某一特征对样本GroupBy，计算每个Group（即当前类的所有取值）内标注的均值为新的特征。 例如，有以下广告曝光及点击样本：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>分组计算：</p>
<p>“女”：<span class="math inline">\(ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(ctr=\frac{2}{4}=0.5\)</span></p>
<p>“未知”：<span class="math inline">\(ctr=\frac{1}{3}=0.3\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
</tbody>
</table>
<p>2)、<strong>Greedy Target Statistics with Smoothes</strong></p>
<p>为了降低原始Greedy Target Statistics方法对处理低频特征值的劣势，通常会对它做平滑操作。 例如，有以下广告曝光及点击样本：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>分组计算：</p>
<p>“女”：<span class="math inline">\(ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(ctr=\frac{0}{4}=0\)</span></p>
<p>“未知”：<span class="math inline">\(ctr=\frac{0}{3}=0\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>显然，这种编码方式，将来做模型训练大概率会过拟合，可以加一个正则项来缓解，编码方式改为：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=
\lambda^k \frac{\sum_{i=0}^{N}y_i}{N} + (1-\lambda^k)\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}
 \]</span></p>
<p>其中，<span class="math inline">\(0\leq \lambda \leq 1\)</span></p>
<p>变换一种形式：</p>
<p><span class="math display">\[f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}+\alpha^k}\]</span> 其中，<span class="math inline">\(p^k=\frac{\sum_{i=0}^{N}y_i}{N}\)</span>，<span class="math inline">\(\alpha^k=\frac{\sum_{i=0}^{N}\lambda^k \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}{1-\lambda^k}\)</span>(显然<span class="math inline">\(0\leq\alpha\leq 1\)</span>)</p>
<p>大白话：用性别这个特征的平均ctr来平滑每个类别取值的ctr，假设，“女”的<span class="math inline">\(\lambda=0\)</span>，“男”的<span class="math inline">\(\lambda=0.5\)</span>，“未知”的<span class="math inline">\(\lambda=0.6\)</span>，则：</p>
<p>分组计算：</p>
<p>平均ctr：<span class="math inline">\(\overline{ctr} =\frac{3}{12}=0.25\)</span></p>
<p>“女”：<span class="math inline">\(0 \cdot \overline{ctr} + 1 \cdot ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(0.5 \cdot \overline{ctr} + 0.5 \cdot ctr=0.5 \cdot 0.25+\frac{0}{4}=0.125\)</span></p>
<p>“未知”：<span class="math inline">\(0.6 \cdot \overline{ctr} + 0.4 \cdot ctr=0.6 \cdot 0.25+\frac{0}{3}=0.15\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
</tbody>
</table>
<p>这种方法的特点是简单，适用于内置到Boosting框架中，但缺点是会出现<strong>Target Leakage</strong>现象，例如： 假设类别特征依然是“性别”，如果在训练集上</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>平均ctr：<span class="math inline">\(\overline{ctr} =\frac{2}{4}=0.5\)</span></p>
<p>“女”：<span class="math inline">\(p(y=1|女)=0.5\)</span></p>
<p>“男”：<span class="math inline">\(p(y=1|男)=0.5\)</span></p>
<p>编码：<span class="math inline">\(f_i^k=\frac{y_i+\alpha \overline{ctr}}{1+\alpha}\)</span></p>
<p>显然，在训练集上<span class="math inline">\(f_i^k=\frac{0.5+\alpha\overline{ctr}}{1+\alpha}\)</span>是最佳分割点，意味着在未来测试集上，不管特征分布是如何，“性别”这个类别特征所有取值下的编码一定是：</p>
<p><span class="math inline">\(f_i^k=\frac{0.5+\alpha\overline{ctr}}{1+\alpha}=\frac{0.5+\alpha0.5}{1+\alpha}=0.5\)</span>，显然模型过拟合了。</p>
<p>3)、<strong>Target Encoding with Beta Distribution</strong></p>
<p>通过加权平均方式，可以很好的平滑特征，但是缺点之一是超参数需要人工拍且不可解释，由于实际当中大部分分类问题是二分类（或可以转化为二分类），而二分类问题大多可以通过Bernoulli Distribution建模，而Bernoulli Distribution又有一个很好的正交分布Beta Distribution，因此利用贝叶斯MAP框架，可以假设参数服从Beta Distribution，即：</p>
<ul>
<li><p>点击率CTR：<span class="math inline">\(r \sim Beta (\alpha, \beta),P(r|\alpha,\beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}r^{\alpha-1}(1-r)^{\beta-1}\)</span></p></li>
<li><p>点击Clicks：<span class="math inline">\(C \sim Binomial(I,r),P(c|I,r)\propto{r^{C}}{(1-r)^{I-C}}\)</span></p></li>
</ul>
<p>其中<span class="math inline">\(C\)</span>为点击数，<span class="math inline">\(I\)</span>为曝光数，<span class="math inline">\(r\)</span>为点击率</p>
<p>则：</p>
<p><span class="math display">\[
 \begin{equation*}
 \begin{aligned}
 P(C_i,...C_N|I_i,...I_N,\alpha,\beta)&amp;=\prod_{i=1}^{N}P(C_i|I_i,\alpha,\beta) \\
 &amp;=\prod_{i=1}^{N}\int_{r_i} P(C_i,r_i|I_i,\alpha,\beta)dr_i \\
 &amp;=\prod_{i=1}^{N}\int_{r_i} P(C_i|I_i,r_i)\cdot P(r_i|\alpha,\beta)dr_i \\
 &amp;\propto \prod_{i=1}^{N}\int_{r_i}r_i^{C_i}(1-r_i)^{I_i-C_i}r_i^{\alpha-1}(1-r_i)^{\beta-1} \\
 &amp;=\propto \prod_{i=1}^{N}\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(C_i+\alpha)}{\Gamma(\alpha)}\frac{\Gamma(I_i-C_i+\beta)}{\Gamma(\beta)}
 \end{aligned}
 \end{equation*}
 \]</span></p>
<p>做参数估计，得到<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>的估计<span class="math inline">\(\hat{\alpha}\)</span>和<span class="math inline">\(\hat{\beta}\)</span>，则平滑后的点击率<span class="math inline">\(\hat{r_i}\)</span>为：</p>
<p><span class="math display">\[
 \begin{equation*}
 \begin{aligned}
 \hat{r_i}&amp;=\frac{C_i+\hat{\alpha_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \\
 &amp;=\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \cdot \frac{\hat{\alpha_i}}{\hat{\alpha_i}+\hat{\beta_i}} +\frac{I_i}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \cdot \frac{C_i}{I_i} \\
 &amp;=\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}}\cdot \frac{\hat{\alpha_i}}{\hat{\alpha_i}+\hat{\beta_i}} + (1-\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}}) \cdot \frac{C_i}{I_i} \\
 &amp;=\lambda_i \cdot \overline{ctr}+(1-\lambda_i) \cdot ctr_i
 \end{aligned}
 \end{equation*}
 \]</span></p>
<p>最终，新的编码方式如下：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=
\lambda^k \frac{\sum_{i=0}^{N}y_i}{N} + (1-\lambda^k)\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}
 \]</span></p>
<p>其中<span class="math inline">\(\lambda^k=\frac{\hat{\alpha}+\hat{\beta}}{\mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}+\hat{\alpha}+\hat{\beta}}\)</span></p>
<p>这种方法实践效果更好，尤其在特征工程阶段，但它计算复杂，相当于在用一个模型生成特征，且不适合内置在Boost类框架中。</p>
<p>4)、<strong>Handout Target Statistics</strong></p>
<p>针对Greedy Target Statistics with Smoothes遇到的问题，一种改进是将训练集分成两部分，一部分用来生成TS特征，一部分用来训练，但显然可用训练数据变少了，尤其在标注样本不是那么rich的场景下。</p>
<p>5)、<strong>Leave-one-out Target Statistics</strong></p>
<p>一般会和交叉验证配合使用，简单说就是训练集留1个样本做测试，其他样本做训练，假设<span class="math inline">\(f_{i,j}^k\)</span>为当前被“leave”的样本，则其编码后结果为：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-y_k +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-1+\alpha^k}
 \]</span></p>
<p>训练集最佳分裂点是：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-0.5 +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-1+\alpha^k}
 \]</span> 显然，发生了“Target Leakage”导致模型过拟合。</p>
<p>假设类别特征依然是“性别”，如果在训练集上</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>“女”编码为：<span class="math inline">\(p(y=1|女)=\frac{1-1+ap}{4-1+a}=\frac{ap}{3+a}\)</span></p>
<p>“女”编码为：<span class="math inline">\(p(y=0|女)=\frac{1-0+ap}{4-1+a}=\frac{1+ap}{3+a}\)</span></p>
<p>显然“女”的最佳分割点是：<span class="math inline">\(\frac{0.5+ap}{3+a}\)</span></p>
<p>“男”编码为：<span class="math inline">\(p(y=1|男)=\frac{3-1+ap}{4-1+a}=\frac{2+ap}{3+a}\)</span></p>
<p>“男”编码为：<span class="math inline">\(p(y=0|男)=\frac{3-0+ap}{4-1+a}=\frac{3+ap}{3+a}\)</span></p>
<p>显然“男”的最佳分割点是：<span class="math inline">\(\frac{2.5+ap}{3+a}\)</span></p>
<p>出现过拟合！</p>
<p>6)、<strong>Ordered Target Statistics</strong></p>
<p>借鉴Online Learning的方式，所有样本的TS特征生成只依赖当前时间线之前的历史样本，如果样本没有时间属性，则利用某个分布生成随机数，为所有样本赋予"顺序"。为了降低模型方差，每步Gradient Boosting迭代会重新为样本赋予“顺序”。</p>
<ul>
<li>Oblivious Decision Trees</li>
</ul>
基于Oblivious Tree的决策树，Oblivious有人翻译为对称，有人翻译为遗忘，前者体现了结构上的特点，后者体现了行为上的特点。 从结构上讲，只有一个入度为0的节点且为根节点，所有叶子节点(出度为0)为分类节点，其他节点为中间节点，任意一条从根节点到叶子节点的路径，每个中间节点只出现一次，中间节点，即internal或test node为分类变量，每一层的中间节点变量一样，<strong>注意，每层的每个分类变量一样但判断条件可以不一样</strong>，所以结构上看是对称的，似乎叫Symmetric Tree更合适。 作者把它称为Oblivious，我认为是基于它行为上的特点，即每个分类变量(中间节点)的触发与整个路径上的所有变量的顺序及它们所处的层次决定，而不是由该变量节点本身决定，所以对比传统决策树，似乎“遗忘”了历史的判断行为，每次都要依着从根节点开始的路径对每个分类变量逐个做判断。典型的结构如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e366blci7k512pq1vduq2v6519.png" width="600" />
</center>
注意看，在age这个属性上，不同的路径可以有不同的判断条件，这种结构在特征选择上比较高效。再一个，每个到达叶子节点的路径上的分类变量都是一样的，这些变量一定是所有输入变量的子集，从这个角度看，其实是在做<strong>维度缩减</strong>。此外Oblivious Tree也可以看做是Oblivious Oblivious Read-Once Decision Graphs的展开形式，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e364p1q9rkocvq1juo1cs96jq9.png" width="600" />
</center>
<p>详情可以看《<strong>Bottom-Up Induction of Oblivious Read-Once Decision Graphs</strong>》一文。</p>
<ul>
<li>Decision Table</li>
</ul>
<p>决策表是一种古老但是非常高效的规则匹配方法。用于基于规则的决策系统，如早期的专家系统，匹配模式形如：<strong>if A then B</strong>，最典型的有两类：</p>
<pre><code>* Condition-Action Rules

A为条件，B为动作，例如：if x发了工资 then x去银行还月供。

* Logical Rules

A和B为一阶逻辑表达式，例如：if x是男人 then x是哺乳动物。</code></pre>
<p>利用Decision Table可以做分类器，例如最常用的Decision Table Majority，它有两个组成部分：</p>
<pre><code>* Schema，所有决策表中要用到特征的集合。

* Body，依据训练数据得到的命中模式的集合。</code></pre>
<p>典型的例子如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e36utda26u3k4712t5d8d10001g.png" width="600" />
</center>
<p>回顾Oblivious Decision Trees的结构，非常适合实现一个DTM，定义某个损失函数，构造ODT，最终保留下的中间分类节点集合为Schema，从根节点到叶子节点的所有路径组成的集合是Body。</p>
<ul>
<li>CatBoost简介</li>
</ul>
<p>CatBoost是Yandex在2017年推出的一个GBDT实现框架，论文见：《<a href="https://papers.nips.cc/paper/7898-catboost-unbiased-boosting-with-categorical-features.pdf">CatBoost: unbiased boosting with categorical features</a>》，它的基础学习器是Oblivious Decision Trees，结构上平衡、不容易过拟合、Inference速度极快，支持自动将类别特征处理为数值特征并做特征交叉，为提高模型精度和泛化性能，在Prediction Shift和Gradient Bias上做了理论分析和解决。</p>
<p>1、<strong>Prediction Shift</strong></p>
<p>简单回顾第二章Boosting相关内容： <span class="math display">\[
\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
其中:\\
\quad \quad f_i是第i轮迭代得到的基础分类器\\
\quad \quad w_i是第i个分类器的权重\\
\quad \quad x是样本特征集\\
定义:\\
\quad \quad \text{(1). 样本总数为 $N$,损失函数定义为$C(F)$,例如： $C(F(x))=\frac{1}{N}\sum_{i=1}^NC(y_iF(x_i))$}\\
\quad \quad \text{(2). $g^t=g^t(x,y)=\frac{\partial C(y,s)}{\partial s}|_{s=F^{t-1}(x)}$,$h^t=h^t(x,y)=\frac{\partial ^2C(y,s)}{\partial s^2}|_{s=F^{t-1}(x)}$}\\
\text{现在我们希望当前轮迭代能够找到一个函数 $f(x)$ ,使得在新分类器$F^t(x)=F^{t-1}(x)+\alpha f(x)$下的损失函数值 $C(F^{t-1}(x)+\alpha f(x))$ 能够下降}\\
依据泰勒展开式:\\
\because C(F^t(x))=C(F^{t-1}(x)+\alpha f(x))=C(F^{t-1}(x))+\alpha {g^t} f+\frac{1}{2}h^t(\xi)f^2\\
\therefore 根据拉格朗日定理得到:\\
f=-\alpha g^t\\
由于f是个函数，所以通常用利用最小二乘法对其做拟合:\\
f^t=\mathop{argmin}\limits_{f \in F}~ \mathbb{E}(-f(x)-g^t(x,y))^2
\end{array}
\]</span> 这里会有三个问题，即所谓shift，导致最终模型泛化能力下降：</p>
<blockquote>
<p>1、训练样本和测试样本梯度值的分布可能不一致；</p>
</blockquote>
<blockquote>
<p>2、采用类似最小二乘法做函数拟合可能出现偏差，因为背后的假设是梯度值分布服从正态分布，可能与真实世界里的分布不一致；</p>
</blockquote>
<blockquote>
<p>3、如果每步迭代都使用相同数据集，则得到的模型是有偏的且偏差与数据集大小成反比；反之，如果每步迭代使用相互独立的数据集，则得到的训练模型是无偏的。</p>
</blockquote>
<p>以上shift最终造成预测时出现Prediction Shift，假设我们有无限大的标注数据集，那就简单了，每步迭代都独立的抽一个数据集出来，可以训练出无偏模型，但实际上不可能，所以这个问题只可以缓解不能解决，因为你永远不能准确知道真实样本的完美分布，只能摸着石头过河，广告、推荐和搜索里把这个方法叫做E&amp;E(Exploitation &amp; Exploration)，本质上Boostng Tree的生成过程就是通过E&amp;E方法迭代生成：使用某个样本集exploit得到当前“最优”的模型，即<span class="math inline">\(F^{t-1}(x)\)</span>，用这个模型explore另外一个样本集，根据结果和某种策略优化模型得到新的“最优”模型<span class="math inline">\(F^t(x)\)</span>，如此往复，直到找到Exploitation &amp; Exploration的最佳trade-off点。</p>
<p>2、 <strong>Ordered boosting</strong></p>
<p>为了缓解Prediction Shift，一个取巧的方法是：</p>
<p>• 用随机排序函数<span class="math inline">\(\sigma\)</span>对所有样本重排序</p>
<p>• 维护<span class="math inline">\(n\)</span>个独立的模型，每个模型<span class="math inline">\(M_i\)</span>由排序后的前<span class="math inline">\(i\)</span>个训练样本生成</p>
<p>• 对第<span class="math inline">\(j\)</span>个样本的残差用模型<span class="math inline">\(M_{j-1}\)</span>来估计</p>
<p>• 原来每个迭代使用由相同样本得到的模型F求梯度的方式改为用辅助模型M估计：</p>
<span class="math display">\[g^t:=\frac{\partial L(y,s)}{s}|_{s=F^{t-1}(x)}\Rightarrow g^t:=\frac{\partial L(y,s)}{s}|_{s=M^{t-1}(x)}\]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3er90lfo882vu1v234415gu1j.png" width="400" />
</center>
<p><strong>Algorithm 1:</strong> <strong>Ordered Boosting</strong></p>
<blockquote>
<p><strong><em>input:</em></strong> <span class="math inline">\(\{(x_k,y_k)\}_{k=1}^n为所有样本,且由\sigma函数重新随机排序, T为树的个数\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(M_i \leftarrow 0 \quad for \quad i=1..n,n为模型个数\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(for \quad t\leftarrow1 \quad to \quad T \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad for \quad i\leftarrow1 \quad to \quad n \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad for \quad j\leftarrow1 \quad to \quad i \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad \quad\quad g_j\leftarrow\frac{\partial L(y_j,s)}{s}|_{s=M_{j-1}(x_j)}(采用最小二乘损失函数:g_j\leftarrow y_j-M_{j-1}(x_j)\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad \Delta M\leftarrow LearnModel(x_j,g_j)\quad for \quad j=1..i\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad M_i=M_i+\Delta M\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(return \quad M_n\)</span></p>
</blockquote>
<p>由于要训练<span class="math inline">\(n\)</span>个模型，时间和空间复杂度都上升了<span class="math inline">\(n\)</span>倍，所以这个算法实操性较低。 CatBoost对建树算法做了改进，有对<strong>Algorithm 1</strong>算法效率改进的Ordered模式和类似于传统GBDT的Plain模式，其中Ordered模式在小数据集上优势明显。</p>
<p>建树的算法<strong>Algorithm 2</strong>说明如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/a2.png" width="800"  />
</center>
<p>在Ordered模式下，计算梯度的时间复杂度是<span class="math inline">\(O(sn^2)\)</span>，包含选择排序函数的时间、扫描样本生成辅助函数的时间、扫描样本生成梯度的时间，CatBoost在实现时用了几个技巧：</p>
<p>1、不维护全部<span class="math inline">\(M_{r,j}(i)\)</span>，转而只维护<span class="math inline">\(M^{&#39;}_{r,j}(i)=M_{r,2^j}(i),j=1,...,\lceil log_2^n\rceil,\sigma_r(i)\leq2^{j+1}\)</span>，这样时间复杂度会降到<span class="math inline">\(O(sn)\)</span></p>
<p>2、每次迭代时对样本做抽样，这个方法能有效降低过拟合</p>
<p>3、由产生样本过程导致的bias，例如，排第一页的广告比第100页的广告更容易被用户看到、点到，那第100页的广告如果被点击了，这条样本的含金量明显更高，所以位置bias产生的样本可以通过给样本权重的方式或把位置作为特征等方法校正，相关论文可以看：</p>
<p>《<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/04/main-1.pdf">Model Ensemble for Click Prediction in Bing Search Ads</a>》</p>
<p>《<a href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45286.pdf">Learning to Rank with Selection Bias in Personal Search</a>》</p>
<p>《<a href="https://www.researchgate.net/publication/335771749_PAL_a_position-bias_aware_learning_framework_for_CTR_prediction_in_live_recommender_systems">PAL: a position-bias aware learning framework for CTR prediction in live recommender systems</a>》</p>
<p>《<a href="https://projecteuclid.org/euclid.aos/1176345338">The bayesian bootstrap</a>》</p>
<p>3、<strong>完整算法描述</strong></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3jn8bq91vlofsk3tc1lb516h22c.png" width="800"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3jnra3u19v71ec21djqff31mtt2p.png" width="800" />
</center>
<p>4、<strong>代码实践</strong></p>
<p>CatBoost官网上有大量教程，这里给个简单例子：</p>
<p>1、定义Model类 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    class CatBoostModel</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> catboost <span class="keyword">as</span> cb</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatBoostModel</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]       <span class="comment"># 定义模型参数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]            <span class="comment"># 定义训练集划分比例</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>] <span class="comment"># 缓解过拟合，提前结束迭代参数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]       <span class="comment"># 控制树的个数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;cat_features&#x27;</span>]          <span class="comment"># 类别特征列表</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;all_features&#x27;</span>]          <span class="comment"># 所有特征列表</span></span><br><span class="line"></span><br><span class="line">        self.catboost_params = kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        self.eval_ratio = kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        self.early_stopping_rounds = kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        self.num_boost_round = kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        self.cat_features = kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        self.all_features = kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.selected_features_ = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.y = <span class="literal">None</span></span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_selected_features</span>(<span class="params">self, topk</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        list :</span></span><br><span class="line"><span class="string">                Return the index of imprtant feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> topk &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.selected_features_ = self.feature_importance.argsort()[-topk:][::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.selected_features_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, num_iteration=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.model.predict(X, num_iteration)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_fea_importance</span>(<span class="params">self, clf, columns</span>):</span></span><br><span class="line">        importances = clf.feature_importances_</span><br><span class="line">        indices = np.argsort(importances)[::-<span class="number">1</span>]</span><br><span class="line">        importance_list = []</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columns)):</span><br><span class="line">            importance_list.append((columns[indices[f]], importances[indices[f]]))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % (f + <span class="number">1</span>, <span class="number">30</span>, columns[indices[f]], importances[indices[f]]))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;another feature importances with prettified=True\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(clf.get_feature_importance(prettified=<span class="literal">True</span>))</span><br><span class="line">        importance_df = pd.DataFrame(importance_list, columns=[<span class="string">&#x27;Features&#x27;</span>, <span class="string">&#x27;Importance&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> importance_df</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span>(<span class="params">self, X, y, test_size, random_state=<span class="number">2020</span></span>):</span></span><br><span class="line">        sss = <span class="built_in">list</span>(StratifiedShuffleSplit(</span><br><span class="line">            n_splits=<span class="number">1</span>, test_size=test_size, random_state=random_state).split(X, y))</span><br><span class="line">        X_train = np.take(X, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        X_eval = np.take(X, sss[<span class="number">0</span>][<span class="number">1</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_train = np.take(y, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_eval = np.take(y, sss[<span class="number">0</span>][<span class="number">1</span>], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [X_train, X_eval, y_train, y_eval]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">catboost_model_train</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                        df,</span></span></span><br><span class="line"><span class="params"><span class="function">                        finetune=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        target_name=<span class="string">&#x27;Label&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        id_index=<span class="string">&#x27;Id&#x27;</span></span>):</span></span><br><span class="line">        df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">        feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> self.cat_features:</span><br><span class="line">                <span class="comment">#df[i].fillna(-999, inplace=True)</span></span><br><span class="line">                <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = self.train_test_split(df[feature_name],</span><br><span class="line">                                                          df[target_name].values,</span><br><span class="line">                                                          self.eval_ratio,</span><br><span class="line">                                                          random.seed(<span class="number">41</span>))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               init_model=finetune,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_set=catboost_eval,</span><br><span class="line">                               verbose_eval=<span class="number">50</span>,</span><br><span class="line">                               plot=<span class="literal">True</span>,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line">        metrics = self.model.eval_metrics(data=catboost_eval,metrics=[<span class="string">&#x27;AUC&#x27;</span>],plot=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;AUC values:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.array(metrics[<span class="string">&#x27;AUC&#x27;</span>])))</span><br><span class="line">        <span class="keyword">return</span> self.feature_importance, metrics, self.model</span><br></pre></td></tr></table></figure> 2、定义catboost trainer（里面涉及nni的部分先忽略，后面再讲）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> bz2</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_svmlight_file</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> nni</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> CatBoostModel</span><br><span class="line"><span class="keyword">from</span> catboost.datasets <span class="keyword">import</span> adult</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;auto_gbdt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">TARGET_NAME = <span class="string">&#x27;income&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_default_parameters</span>():</span></span><br><span class="line">    params_cb = &#123;</span><br><span class="line">       <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;Ordered&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;CrossEntropy&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&#x27;AUC&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;custom_metric&#x27;</span>: [<span class="string">&#x27;AUC&#x27;</span>, <span class="string">&#x27;Accuracy&#x27;</span>],</span><br><span class="line">       <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">       <span class="string">&#x27;random_seed&#x27;</span>: <span class="number">2020</span>,</span><br><span class="line">       <span class="string">&#x27;depth&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">       <span class="string">&#x27;l2_leaf_reg&#x27;</span>: <span class="number">3.8</span>,</span><br><span class="line">       <span class="string">&#x27;thread_count&#x27;</span>: <span class="number">16</span>,</span><br><span class="line">       <span class="string">&#x27;use_best_model&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">       <span class="string">&#x27;verbose&#x27;</span>: <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params_cb</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_features_name</span>():</span></span><br><span class="line">    alls = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>, <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>,  <span class="string">&#x27;capital-loss&#x27;</span>,  <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>]</span><br><span class="line">    cats = [<span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>, <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> alls, cats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_prepare_cleaner</span>(<span class="params">target</span>):</span></span><br><span class="line">    train_df, test_df = adult()</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    le.fit(train_df[target])</span><br><span class="line">    train_df[target] = le.transform(train_df[target])</span><br><span class="line"></span><br><span class="line">    le.fit(test_df[target])</span><br><span class="line">    test_df[target] = le.transform(test_df[target])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_df, test_df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cat_fea_cleaner</span>(<span class="params">df, target_name, id_index, cat_features</span>):</span></span><br><span class="line">    df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">    feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cat_features:</span><br><span class="line">            <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainer_and_tester_run</span>(<span class="params">train_df, test_df, all_features, cat_features</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># get parameters from tuner</span></span><br><span class="line">    RECEIVED_PARAMS = nni.get_next_parameter()</span><br><span class="line">    logger.debug(RECEIVED_PARAMS)</span><br><span class="line">    PARAMS = get_default_parameters()</span><br><span class="line">    PARAMS.update(RECEIVED_PARAMS)</span><br><span class="line">    logger.debug(PARAMS)</span><br><span class="line"></span><br><span class="line">    cb = CatBoostModel(catboost_params=PARAMS,</span><br><span class="line">                    eval_ratio=<span class="number">0.33</span>,</span><br><span class="line">                    early_stopping_rounds=<span class="number">20</span>,</span><br><span class="line">                    cat_features=cat_features,</span><br><span class="line">                    all_features=all_features,</span><br><span class="line">                    num_boost_round=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is starting...&quot;</span>)</span><br><span class="line">    train_df = cat_fea_cleaner(train_df, TARGET_NAME, <span class="string">&#x27;index&#x27;</span>, cat_features)</span><br><span class="line">    test_df = cat_fea_cleaner(test_df, TARGET_NAME, <span class="string">&#x27;index&#x27;</span>, cat_features)</span><br><span class="line">    feature_imp, val_score, clf = \</span><br><span class="line">    cb.catboost_model_train(df=train_df,</span><br><span class="line">                            target_name=TARGET_NAME,</span><br><span class="line">                            id_index=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    logger.info(feature_imp)</span><br><span class="line">    logger.info(val_score)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> train_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is ended.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    av_auc = inference(clf, test_df, all_features, cat_features)</span><br><span class="line">    nni.report_final_result(av_auc)</span><br><span class="line">    <span class="keyword">del</span> test_df</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">clf, test_df, fea, cat_fea</span>):</span></span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The testing process is starting...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        y_pred = clf.predict(test_df[fea])</span><br><span class="line">        auc = roc_auc_score(test_df[TARGET_NAME].values, y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;auc of prediction:&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(auc))</span><br><span class="line">        <span class="keyword">del</span> test_df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">&quot;The inference process is ended.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> auc</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_offline</span>():</span></span><br><span class="line">    alls, cats = get_features_name()</span><br><span class="line">    <span class="built_in">print</span>(alls, cats)</span><br><span class="line">    train_df, test_df = data_prepare_cleaner(TARGET_NAME)</span><br><span class="line">    <span class="built_in">print</span>(train_df)</span><br><span class="line">    <span class="built_in">print</span>(test_df)</span><br><span class="line">    trainer_and_tester_run(train_df, test_df, alls, cats)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run_offline()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@GPU-AI01 cat_test]# python3 catboost_trainer.py</span><br><span class="line">[&#x27;age&#x27;, &#x27;workclass&#x27;, &#x27;fnlwgt&#x27;, &#x27;education&#x27;, &#x27;education-num&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;, &#x27;hours-per-week&#x27;, &#x27;native-country&#x27;] [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</span><br><span class="line">        age         workclass    fnlwgt   education  education-num      marital-status         occupation  ...   race     sex capital-gain  capital-loss  hours-per-week  native-country income</span><br><span class="line">0      39.0         State-gov   77516.0   Bachelors           13.0       Never-married       Adm-clerical  ...  White    Male       2174.0           0.0            40.0   United-States      0</span><br><span class="line">1      50.0  Self-emp-not-inc   83311.0   Bachelors           13.0  Married-civ-spouse    Exec-managerial  ...  White    Male          0.0           0.0            13.0   United-States      0</span><br><span class="line">2      38.0           Private  215646.0     HS-grad            9.0            Divorced  Handlers-cleaners  ...  White    Male          0.0           0.0            40.0   United-States      0</span><br><span class="line">3      53.0           Private  234721.0        11th            7.0  Married-civ-spouse  Handlers-cleaners  ...  Black    Male          0.0           0.0            40.0   United-States      0</span><br><span class="line">4      28.0           Private  338409.0   Bachelors           13.0  Married-civ-spouse     Prof-specialty  ...  Black  Female          0.0           0.0            40.0            Cuba      0</span><br><span class="line">...     ...               ...       ...         ...            ...                 ...                ...  ...    ...     ...          ...           ...             ...             ...    ...</span><br><span class="line">32556  27.0           Private  257302.0  Assoc-acdm           12.0  Married-civ-spouse       Tech-support  ...  White  Female          0.0           0.0            38.0   United-States      0</span><br><span class="line">32557  40.0           Private  154374.0     HS-grad            9.0  Married-civ-spouse  Machine-op-inspct  ...  White    Male          0.0           0.0            40.0   United-States      1</span><br><span class="line">32558  58.0           Private  151910.0     HS-grad            9.0             Widowed       Adm-clerical  ...  White  Female          0.0           0.0            40.0   United-States      0</span><br><span class="line">32559  22.0           Private  201490.0     HS-grad            9.0       Never-married       Adm-clerical  ...  White    Male          0.0           0.0            20.0   United-States      0</span><br><span class="line">32560  52.0      Self-emp-inc  287927.0     HS-grad            9.0  Married-civ-spouse    Exec-managerial  ...  White  Female      15024.0           0.0            40.0   United-States      1</span><br><span class="line"></span><br><span class="line">[32561 rows x 15 columns]</span><br><span class="line">        age     workclass    fnlwgt     education  education-num      marital-status  ...     sex capital-gain capital-loss hours-per-week  native-country  income</span><br><span class="line">0      25.0       Private  226802.0          11th            7.0       Never-married  ...    Male          0.0          0.0           40.0   United-States       0</span><br><span class="line">1      38.0       Private   89814.0       HS-grad            9.0  Married-civ-spouse  ...    Male          0.0          0.0           50.0   United-States       0</span><br><span class="line">2      28.0     Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse  ...    Male          0.0          0.0           40.0   United-States       1</span><br><span class="line">3      44.0       Private  160323.0  Some-college           10.0  Married-civ-spouse  ...    Male       7688.0          0.0           40.0   United-States       1</span><br><span class="line">4      18.0           NaN  103497.0  Some-college           10.0       Never-married  ...  Female          0.0          0.0           30.0   United-States       0</span><br><span class="line">...     ...           ...       ...           ...            ...                 ...  ...     ...          ...          ...            ...             ...     ...</span><br><span class="line">16276  39.0       Private  215419.0     Bachelors           13.0            Divorced  ...  Female          0.0          0.0           36.0   United-States       0</span><br><span class="line">16277  64.0           NaN  321403.0       HS-grad            9.0             Widowed  ...    Male          0.0          0.0           40.0   United-States       0</span><br><span class="line">16278  38.0       Private  374983.0     Bachelors           13.0  Married-civ-spouse  ...    Male          0.0          0.0           50.0   United-States       0</span><br><span class="line">16279  44.0       Private   83891.0     Bachelors           13.0            Divorced  ...    Male       5455.0          0.0           40.0   United-States       0</span><br><span class="line">16280  35.0  Self-emp-inc  182148.0     Bachelors           13.0  Married-civ-spouse  ...    Male          0.0          0.0           60.0   United-States       1</span><br><span class="line"></span><br><span class="line">[16281 rows x 15 columns]</span><br><span class="line">[03/29/2020, 04:36:35 PM] WARNING (nni) Requesting parameter without NNI framework, returning empty dict</span><br><span class="line">[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;] [&#x27;age&#x27;, &#x27;workclass&#x27;, &#x27;fnlwgt&#x27;, &#x27;education&#x27;, &#x27;education-num&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;, &#x27;hours-per-week&#x27;, &#x27;native-country&#x27;]</span><br><span class="line">&lt;IPython.core.display.HTML object&gt;</span><br><span class="line">MetricVisualizer(layout=Layout(align_self=&#x27;stretch&#x27;, height=&#x27;500px&#x27;))</span><br><span class="line">0:      test: 0.8316184 best: 0.8316184 (0)     total: 79ms     remaining: 1m 18s</span><br><span class="line">50:     test: 0.9020779 best: 0.9020779 (50)    total: 942ms    remaining: 17.5s</span><br><span class="line">100:    test: 0.9081992 best: 0.9081992 (100)   total: 1.71s    remaining: 15.2s</span><br><span class="line">150:    test: 0.9108707 best: 0.9108707 (150)   total: 2.48s    remaining: 13.9s</span><br><span class="line">200:    test: 0.9133666 best: 0.9133666 (200)   total: 3.27s    remaining: 13s</span><br><span class="line">250:    test: 0.9161119 best: 0.9161119 (250)   total: 4.05s    remaining: 12.1s</span><br><span class="line">300:    test: 0.9181722 best: 0.9181726 (299)   total: 4.8s     remaining: 11.2s</span><br><span class="line">350:    test: 0.9191926 best: 0.9191926 (350)   total: 5.56s    remaining: 10.3s</span><br><span class="line">400:    test: 0.9205207 best: 0.9205207 (400)   total: 6.3s     remaining: 9.41s</span><br><span class="line">450:    test: 0.9210106 best: 0.9210106 (450)   total: 7.05s    remaining: 8.59s</span><br><span class="line">500:    test: 0.9215160 best: 0.9215160 (500)   total: 7.81s    remaining: 7.78s</span><br><span class="line">550:    test: 0.9221193 best: 0.9221193 (550)   total: 8.59s    remaining: 7s</span><br><span class="line">600:    test: 0.9227742 best: 0.9227742 (600)   total: 9.37s    remaining: 6.22s</span><br><span class="line">650:    test: 0.9232136 best: 0.9232136 (650)   total: 10.1s    remaining: 5.41s</span><br><span class="line">700:    test: 0.9234202 best: 0.9234202 (700)   total: 10.8s    remaining: 4.61s</span><br><span class="line">750:    test: 0.9238425 best: 0.9238428 (749)   total: 11.6s    remaining: 3.83s</span><br><span class="line">800:    test: 0.9242466 best: 0.9242466 (800)   total: 12.4s    remaining: 3.07s</span><br><span class="line">850:    test: 0.9244801 best: 0.9244826 (849)   total: 13.1s    remaining: 2.3s</span><br><span class="line">900:    test: 0.9246592 best: 0.9246633 (899)   total: 13.8s    remaining: 1.52s</span><br><span class="line">950:    test: 0.9248365 best: 0.9248397 (949)   total: 14.6s    remaining: 752ms</span><br><span class="line">999:    test: 0.9250032 best: 0.9250045 (998)   total: 15.3s    remaining: 0us</span><br><span class="line"></span><br><span class="line">bestTest = 0.9250045138</span><br><span class="line">bestIteration = 998</span><br><span class="line"></span><br><span class="line">Shrink model to first 999 iterations.</span><br><span class="line"> 1) capital-gain                   30.102152</span><br><span class="line"> 2) relationship                   21.504190</span><br><span class="line"> 3) capital-loss                   11.414022</span><br><span class="line"> 4) age                            10.377241</span><br><span class="line"> 5) education-num                  7.234561</span><br><span class="line"> 6) occupation                     6.331733</span><br><span class="line"> 7) hours-per-week                 4.476134</span><br><span class="line"> 8) marital-status                 4.354055</span><br><span class="line"> 9) sex                            1.146389</span><br><span class="line">10) education                      1.092454</span><br><span class="line">11) workclass                      0.776362</span><br><span class="line">12) fnlwgt                         0.577348</span><br><span class="line">13) native-country                 0.382720</span><br><span class="line">14) race                           0.230639</span><br><span class="line">another feature importances with prettified=True</span><br><span class="line"></span><br><span class="line">        Feature Id  Importances</span><br><span class="line">0     capital-gain    30.102152</span><br><span class="line">1     relationship    21.504190</span><br><span class="line">2     capital-loss    11.414022</span><br><span class="line">3              age    10.377241</span><br><span class="line">4    education-num     7.234561</span><br><span class="line">5       occupation     6.331733</span><br><span class="line">6   hours-per-week     4.476134</span><br><span class="line">7   marital-status     4.354055</span><br><span class="line">8              sex     1.146389</span><br><span class="line">9        education     1.092454</span><br><span class="line">10       workclass     0.776362</span><br><span class="line">11          fnlwgt     0.577348</span><br><span class="line">12  native-country     0.382720</span><br><span class="line">13            race     0.230639</span><br><span class="line">&lt;IPython.core.display.HTML object&gt;</span><br><span class="line">MetricVisualizer(layout=Layout(align_self=&#x27;stretch&#x27;, height=&#x27;500px&#x27;))</span><br><span class="line">AUC values:[0.83161836 0.85856642 0.85813673 0.86103314 0.86071689 0.86121893</span><br><span class="line"> 0.86441522 0.86505078 0.8784926  0.87975055 0.88290187 0.88250307</span><br><span class="line"> 0.88799037 0.8881507  0.89029036 0.88999382 0.88988625 0.89090279</span><br><span class="line"> 0.89101198 0.89160979 0.89201995 0.89295319 0.89335747 0.89347394</span><br><span class="line"> 0.89391874 0.89388563 0.89537425 0.89577286 0.89558464 0.89714728</span><br><span class="line"> 0.89720971 0.89743348 0.89766614 0.89780103 0.89835231 0.89859723</span><br><span class="line"> 0.89845935 0.89914869 0.89911805 0.89974913 0.89990595 0.90033138</span><br><span class="line"> 0.90038467 0.90098889 0.90072697 0.90107988 0.90084311 0.90124622</span><br><span class="line"> 0.90129837 0.90169675 0.90207794 0.90213554 0.90252241 0.90278218</span><br><span class="line"> 0.90291333 0.90347889 0.90362643 0.90369515 0.90384743 0.90364836</span><br><span class="line"> 0.90427544 0.90441459 0.90463238 0.90473693 0.90474323 0.9047752</span><br><span class="line"> 0.90479827 0.90473968 0.90509671 0.9052363  0.90524989 0.90552186</span><br><span class="line"> 0.90563292 0.90562407 0.90597002 0.90596054 0.90612973 0.90613532</span><br><span class="line"> 0.90626529 0.90624885 0.90629925 0.9065094  0.90687207 0.90713255</span><br><span class="line"> 0.90713464 0.90714229 0.90716147 0.90720291 0.90736582 0.9074965</span><br><span class="line"> 0.90754282 0.90756655 0.907661   0.90770332 0.9077639  0.90790968</span><br><span class="line"> 0.9079417  0.90798504 0.90802753 0.90811397 0.90819922 0.90826913</span><br><span class="line"> 0.90827529 0.90832273 0.90834522 0.90836268 0.90852687 0.90865518</span><br><span class="line"> 0.90867734 0.90877048 0.9088641  0.90892809 0.90899198 0.90898232</span><br><span class="line"> 0.90901235 0.90917898 0.90931463 0.90933462 0.90946639 0.90955688</span><br><span class="line"> 0.90957899 0.90955768 0.9096148  0.90963834 0.90960947 0.9097182</span><br><span class="line"> 0.90968601 0.90968109 0.90973949 0.90986055 0.90987831 0.90990626</span><br><span class="line"> 0.90988658 0.90996061 0.9100206  0.91016861 0.9102051  0.91031329</span><br><span class="line"> 0.91035212 0.91039234 0.91038859 0.91055811 0.91059551 0.91060905</span><br><span class="line"> 0.91068851 0.91069095 0.91070089 0.91075133 0.9107646  0.91083661</span><br><span class="line"> 0.91087072 0.91088294 0.91089601 0.9109779  0.91109368 0.91112637</span><br><span class="line"> 0.91117719 0.91131483 0.91133695 0.91135528 0.91138891 0.91139388</span><br><span class="line"> 0.91141477 0.91143149 0.91147063 0.91155253 0.91162016 0.91166083</span><br><span class="line"> 0.91172069 0.91181031 0.91196481 0.91200488 0.91207325 0.91211531</span><br><span class="line"> 0.91215074 0.91216651 0.91216438 0.91216644 0.91217042 0.91222321</span><br><span class="line"> 0.91224604 0.91226224 0.91238903 0.91245311 0.91250443 0.9125005</span><br><span class="line"> 0.91256733 0.9126408  0.91267537 0.9127926  0.91283471 0.91296865</span><br><span class="line"> 0.91309914 0.91321599 0.9132311  0.91326122 0.91331664 0.9133272</span><br><span class="line"> 0.91333757 0.91335631 0.91336663 0.91339323 0.91351306 0.91353504</span><br><span class="line"> 0.91364762 0.91371905 0.91374356 0.91382455 0.91383544 0.91387963</span><br><span class="line"> 0.9138874  0.9139162  0.9139656  0.91401361 0.91409119 0.91417138</span><br><span class="line"> 0.91415125 0.91426151 0.91427733 0.91430731 0.91443747 0.91448261</span><br><span class="line"> 0.91453059 0.91459567 0.91462631 0.91465691 0.91466103 0.91475955</span><br><span class="line"> 0.91475329 0.91484831 0.91488644 0.9149258  0.91522573 0.91525917</span><br><span class="line"> 0.91535504 0.91542878 0.91546454 0.91549223 0.91553097 0.91555825</span><br><span class="line"> 0.91559304 0.91562558 0.91568611 0.91569478 0.91571794 0.9157357</span><br><span class="line"> 0.91576043 0.91577251 0.9158588  0.91609757 0.91611192 0.91617368</span><br><span class="line"> 0.91615905 0.91616662 0.91621344 0.91624148 0.91624617 0.916279</span><br><span class="line"> 0.91631196 0.91642947 0.91647835 0.91652667 0.91651392 0.91652581</span><br><span class="line"> 0.91653713 0.91655006 0.91665427 0.91667051 0.916788   0.91681452</span><br><span class="line"> 0.91685526 0.91696372 0.91706001 0.91709748 0.91709928 0.91717672</span><br><span class="line"> 0.91719126 0.91729565 0.91739161 0.91742034 0.9174929  0.91750469</span><br><span class="line"> 0.91754306 0.9175746  0.91757541 0.91759738 0.91761036 0.91759407</span><br><span class="line"> 0.91763139 0.91772489 0.91776103 0.9179556  0.9179898  0.91801864</span><br><span class="line"> 0.91801737 0.91803603 0.91805739 0.91813814 0.91814534 0.91817263</span><br><span class="line"> 0.9181722  0.91824609 0.91827275 0.91829577 0.91829899 0.91831358</span><br><span class="line"> 0.91837373 0.91842195 0.91842025 0.91844374 0.91845804 0.91856584</span><br><span class="line"> 0.91857612 0.91863774 0.91862941 0.91863533 0.91871476 0.91873683</span><br><span class="line"> 0.91873685 0.91873453 0.91876589 0.91877062 0.91877522 0.91875817</span><br><span class="line"> 0.91876122 0.9187661  0.91875142 0.91882763 0.91882948 0.91885122</span><br><span class="line"> 0.91885425 0.91883814 0.91885245 0.91885491 0.91889654 0.91892941</span><br><span class="line"> 0.91899658 0.91898947 0.91903944 0.91905251 0.91906383 0.91905976</span><br><span class="line"> 0.91905803 0.91906125 0.91911411 0.91912297 0.91911189 0.9191422</span><br><span class="line"> 0.91916427 0.91918881 0.91919262 0.9192038  0.91922066 0.91922383</span><br><span class="line"> 0.91924121 0.91924974 0.91929625 0.91931439 0.9193681  0.91936356</span><br><span class="line"> 0.9194005  0.91940401 0.91942551 0.91941168 0.91949196 0.91950447</span><br><span class="line"> 0.91950522 0.91950731 0.91951408 0.91954548 0.919564   0.91956135</span><br><span class="line"> 0.91961966 0.91962117 0.91961662 0.91963093 0.91963782 0.9197918</span><br><span class="line"> 0.91981146 0.91984902 0.91987796 0.91986474 0.91986896 0.91988572</span><br><span class="line"> 0.91999293 0.91999407 0.9200143  0.92006417 0.920051   0.92006654</span><br><span class="line"> 0.92015715 0.92027774 0.92028039 0.92028351 0.92029304 0.9203403</span><br><span class="line"> 0.92041614 0.9204284  0.920495   0.92051366 0.92052067 0.92052967</span><br><span class="line"> 0.92054984 0.92056874 0.92059948 0.9206144  0.92060015 0.92060062</span><br><span class="line"> 0.9206     0.92060142 0.92060772 0.92063425 0.92063752 0.92064007</span><br><span class="line"> 0.92064424 0.92065741 0.92066167 0.92067399 0.92068185 0.92068403</span><br><span class="line"> 0.92072576 0.92073774 0.92074077 0.92074873 0.92073982 0.92076398</span><br><span class="line"> 0.92077724 0.92078624 0.92078373 0.92078809 0.92077483 0.92077691</span><br><span class="line"> 0.92080732 0.92081864 0.92082224 0.92081307 0.92081577 0.92081407</span><br><span class="line"> 0.9208495  0.92085911 0.92088312 0.92088725 0.92088677 0.92088559</span><br><span class="line"> 0.92089568 0.92089648 0.92090354 0.92092367 0.92092732 0.92094607</span><br><span class="line"> 0.92101058 0.92102503 0.92103919 0.92102465 0.92103474 0.92103725</span><br><span class="line"> 0.92102598 0.92102195 0.92102607 0.92103857 0.92103682 0.92103957</span><br><span class="line"> 0.92106103 0.92107088 0.92107722 0.92108452 0.92108708 0.92114306</span><br><span class="line"> 0.92115324 0.92119644 0.9212017  0.92121074 0.92122964 0.92124253</span><br><span class="line"> 0.92124826 0.92127222 0.92129136 0.92131528 0.92131712 0.92132233</span><br><span class="line"> 0.9213274  0.92132897 0.92131902 0.92132323 0.92133725 0.92138855</span><br><span class="line"> 0.92138997 0.92144297 0.92145268 0.92144453 0.92144766 0.92148863</span><br><span class="line"> 0.92148243 0.92148764 0.92149299 0.92150881 0.92149493 0.92149905</span><br><span class="line"> 0.92150045 0.92151196 0.92151603 0.92152768 0.92153251 0.92151722</span><br><span class="line"> 0.92152228 0.92152569 0.92153124 0.92162734 0.92162582 0.92164117</span><br><span class="line"> 0.9216549  0.92165462 0.92171068 0.92171977 0.92172706 0.92172754</span><br><span class="line"> 0.92173966 0.92175084 0.92175719 0.92175633 0.92175221 0.92176424</span><br><span class="line"> 0.92176529 0.92177016 0.92177178 0.92178025 0.92176628 0.92184211</span><br><span class="line"> 0.9218522  0.92185713 0.92185623 0.92186669 0.92191529 0.92194717</span><br><span class="line"> 0.92195285 0.92197383 0.92197056 0.92197052 0.92197658 0.92198013</span><br><span class="line"> 0.92196483 0.92197075 0.92197885 0.92198245 0.92199188 0.92204175</span><br><span class="line"> 0.92204227 0.92209778 0.92210214 0.92210863 0.92211934 0.92216049</span><br><span class="line"> 0.92216462 0.92216983 0.92217963 0.92217537 0.92221117 0.92241212</span><br><span class="line"> 0.92241638 0.92242576 0.92243073 0.92243177 0.92244111 0.92245001</span><br><span class="line"> 0.92246045 0.9224605  0.92249186 0.92249266 0.9225063  0.92253676</span><br><span class="line"> 0.92254249 0.92254519 0.92255234 0.92255675 0.9225657  0.92257275</span><br><span class="line"> 0.92256906 0.92257072 0.92255637 0.92255892 0.922562   0.92256087</span><br><span class="line"> 0.92257162 0.92257129 0.92257129 0.92257015 0.92255466 0.92255267</span><br><span class="line"> 0.92254007 0.92253922 0.92254197 0.92254647 0.92254566 0.9225891</span><br><span class="line"> 0.9225908  0.92258696 0.92259497 0.92259644 0.92275269 0.9227705</span><br><span class="line"> 0.92277424 0.92276742 0.92277045 0.92277491 0.92278784 0.92278968</span><br><span class="line"> 0.9227921  0.92279944 0.92280498 0.92281464 0.92282772 0.92282279</span><br><span class="line"> 0.92295612 0.92295963 0.92295584 0.92297024 0.92295882 0.92296086</span><br><span class="line"> 0.92295636 0.92296015 0.92296214 0.92297611 0.92297597 0.92297367</span><br><span class="line"> 0.92297282 0.9229821  0.92299015 0.92299285 0.92299162 0.92299494</span><br><span class="line"> 0.92304206 0.92307967 0.92308431 0.92310553 0.92310695 0.92310871</span><br><span class="line"> 0.92310894 0.9231188  0.92311927 0.92312131 0.92313343 0.92313457</span><br><span class="line"> 0.92313679 0.92313154 0.92313566 0.92314866 0.92315825 0.92315967</span><br><span class="line"> 0.92320145 0.92320557 0.92321357 0.92322352 0.92323133 0.92323763</span><br><span class="line"> 0.92323815 0.92324663 0.92324834 0.92325137 0.92325492 0.92325402</span><br><span class="line"> 0.92325374 0.92326515 0.92327003 0.92327538 0.92326444 0.92326927</span><br><span class="line"> 0.92326937 0.92325672 0.92327946 0.92327837 0.92327979 0.92328097</span><br><span class="line"> 0.92328386 0.92329125 0.92329248 0.92329977 0.92330783 0.92330854</span><br><span class="line"> 0.92331124 0.92331299 0.92334018 0.92333804 0.92333752 0.92334894</span><br><span class="line"> 0.92334851 0.92334979 0.92335064 0.92335164 0.92336736 0.92336869</span><br><span class="line"> 0.92337068 0.9233623  0.92336433 0.92336395 0.92336964 0.92337428</span><br><span class="line"> 0.92338446 0.92339521 0.92339592 0.92340004 0.92342017 0.92341999</span><br><span class="line"> 0.92342126 0.92342264 0.92341984 0.92341984 0.92341833 0.92340795</span><br><span class="line"> 0.92341307 0.92342212 0.92346853 0.92346801 0.92349373 0.92351225</span><br><span class="line"> 0.92351931 0.92352476 0.92356085 0.92356151 0.92356483 0.92357894</span><br><span class="line"> 0.92361887 0.92361683 0.92362503 0.92362484 0.92364317 0.92366462</span><br><span class="line"> 0.92366391 0.92366415 0.92366709 0.92367481 0.92368707 0.92368769</span><br><span class="line"> 0.92368816 0.92368991 0.92368925 0.92369735 0.92372847 0.92372814</span><br><span class="line"> 0.92372667 0.92373089 0.92373169 0.92373538 0.92376077 0.92376134</span><br><span class="line"> 0.92377977 0.9238052  0.92380307 0.92382703 0.92383556 0.92384276</span><br><span class="line"> 0.92384248 0.92384338 0.92384195 0.92384991 0.92384778 0.92385673</span><br><span class="line"> 0.92385702 0.92385579 0.92388179 0.92390358 0.92390452 0.92392219</span><br><span class="line"> 0.92393938 0.9239624  0.92396657 0.92397055 0.92397022 0.92398855</span><br><span class="line"> 0.92398784 0.92399916 0.92401161 0.92402559 0.92402535 0.92412785</span><br><span class="line"> 0.92413405 0.92415006 0.92416323 0.92416356 0.92416346 0.9241593</span><br><span class="line"> 0.92415797 0.92415541 0.92415636 0.92415508 0.92415357 0.9241574</span><br><span class="line"> 0.92417905 0.92419297 0.92420628 0.92421429 0.92421362 0.92421457</span><br><span class="line"> 0.92422599 0.92422475 0.92422423 0.92422291 0.92422414 0.9242293</span><br><span class="line"> 0.92423915 0.92424469 0.92424659 0.92424834 0.9242482  0.92426392</span><br><span class="line"> 0.92426804 0.9242796  0.92428093 0.92429978 0.92430196 0.92430196</span><br><span class="line"> 0.92432313 0.92432455 0.9243191  0.92431726 0.9243156  0.9243146</span><br><span class="line"> 0.92432185 0.924339   0.92433824 0.92435922 0.92436339 0.92436391</span><br><span class="line"> 0.92437964 0.92437731 0.92438267 0.92438025 0.92437954 0.92437973</span><br><span class="line"> 0.92441307 0.92441795 0.92441701 0.92442023 0.9244314  0.92442975</span><br><span class="line"> 0.92442918 0.92442804 0.92442899 0.92443202 0.92443264 0.92443145</span><br><span class="line"> 0.92444026 0.92445457 0.92445348 0.92445267 0.92445163 0.92445144</span><br><span class="line"> 0.92446295 0.92447209 0.92446982 0.92448261 0.92448014 0.92448966</span><br><span class="line"> 0.92450439 0.92450236 0.92450188 0.92450184 0.92449956 0.92451074</span><br><span class="line"> 0.92451017 0.9245222  0.92452661 0.92452457 0.92453395 0.92453172</span><br><span class="line"> 0.92454541 0.92454967 0.92454584 0.92454304 0.92454058 0.92454039</span><br><span class="line"> 0.92453722 0.92455214 0.92455304 0.92454953 0.92456061 0.92457629</span><br><span class="line"> 0.9245798  0.92457681 0.92459439 0.92460656 0.92462025 0.92461693</span><br><span class="line"> 0.92462337 0.92461906 0.92463341 0.9246309  0.92463697 0.92463474</span><br><span class="line"> 0.92463332 0.92463242 0.92462896 0.92462574 0.92463891 0.92464047</span><br><span class="line"> 0.92464241 0.92464023 0.92464147 0.92465189 0.92465809 0.9246633</span><br><span class="line"> 0.92465923 0.92466605 0.92466898 0.92467012 0.92466695 0.92466572</span><br><span class="line"> 0.92467879 0.92468964 0.92471355 0.92472397 0.92472525 0.9247262</span><br><span class="line"> 0.92473302 0.92472966 0.92473449 0.92473468 0.92473392 0.92473316</span><br><span class="line"> 0.92473132 0.92472805 0.92472582 0.92472492 0.92472293 0.9247263</span><br><span class="line"> 0.92473454 0.92473511 0.92473743 0.92473648 0.92475415 0.92476172</span><br><span class="line"> 0.92475898 0.92477077 0.92479057 0.92479355 0.92479284 0.92480303</span><br><span class="line"> 0.9248143  0.92481302 0.92482448 0.92482211 0.92482301 0.92482368</span><br><span class="line"> 0.92482808 0.92482638 0.92482931 0.92483178 0.92483741 0.92483784</span><br><span class="line"> 0.9248386  0.92483969 0.92483646 0.9248404  0.92485238 0.92485067</span><br><span class="line"> 0.92486796 0.92488321 0.92488009 0.92487786 0.92487805 0.92488516</span><br><span class="line"> 0.92488994 0.92489098 0.92490003 0.92490704 0.92490391 0.92491362</span><br><span class="line"> 0.92492802 0.92493299 0.9249463  0.92494289 0.92493906 0.92493816</span><br><span class="line"> 0.92494223 0.92493996 0.9249382  0.92493849 0.9249491  0.92494697</span><br><span class="line"> 0.92494711 0.92495838 0.92495838 0.92497013 0.92498078 0.92497794</span><br><span class="line"> 0.92497695 0.92497827 0.92497619 0.924976   0.92498211 0.92498495</span><br><span class="line"> 0.92499078 0.92500338 0.92500087 0.92500049 0.92499874 0.92499874</span><br><span class="line"> 0.92499883 0.92499935 0.92500451]</span><br><span class="line">AUC of prediction:0.8603217542453206</span><br></pre></td></tr></table></figure>
<h2 id="人工神经网络-neural-network">2.6 人工神经网络-Neural Network</h2>
神经网络在维基百科上的定义是：NN is a network inspired by biological neural networks (the central nervous systems of animals, in particular the brain) which are used to estimate or approximate functions that can depend on a large number of inputs that are generally unknown.(from wikipedia)
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap79lfscsq013g11c4g1aqu1jb4m.png" width="300"  />
</center>
<h3 id="神经元">2.6.1 神经元</h3>
神经元是神经网络和SVM这类模型的基础模型和来源，它是一个具有如下结构的线性模型：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap6vqg8k1nursgn1kv541nevd9.png" width="300" />
</center>
<p>其输出模式为：</p>
<blockquote>
<p><span class="math display">\[
\begin{array}{l}
output &amp; = &amp; \left\{ \begin{array}{1}
0 &amp; if~ \sum_j w_j x_j + b \leq 0 \\
1 &amp; if~ \sum_j w_j x_j + b&gt; 0
\end{array} \right.
\end{array}
\]</span></p>
</blockquote>
示意图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap79nd0j1m5cuhbv0ltog1ao313.png" width="400" />
</center>
<h3 id="神经网络的常用结构">2.6.2 神经网络的常用结构</h3>
神经网络由一系列神经元组成，典型的神经网络结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7b1i9s156h8n91noe1v0b1kk41g.png" width="500" />
</center>
<p>其中最左边是输入层，包含若干输入神经元，最右边是输出层，包含若干输出神经元，介于输入层和输出层的所有层都叫隐藏层，由于神经元的作用，任何权重的微小变化都会导致输出的微小变化，即这种变化是平滑的。</p>
神经元的各种组合方式得到性质不一的神经网络结构 :
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7hp4el195d12al1d2119h3r8e46.png" width="350"  />
</center>
<center>
前馈神经网络
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1asuka9jl1u479sd1k7l64l11s2m.png" width="350"  />
</center>
<center>
反向传播神经网络
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7k2i4u1qeq14871ge613np5r5d.png" width="350"  />
</center>
<center>
循环神经网络
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7i6rfq1ua917bf12llgol1vcs50.png" width="450"  />
</center>
<center>
卷积神经网络
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7kf21k8c2me14dr1sd1t5d67.png" width="350" />
</center>
<center>
自编码器
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7kod2dpkn1cqu1oksvmd3ms6t.png" width="600" />
</center>
<center>
Google DeepMind 记忆神经网络(用于AlphaGo)
</center>
<h3 id="一个简单的神经网络例子">2.6.3 一个简单的神经网络例子</h3>
<p>假设随机变量 <span class="math inline">\(x \sim N(0,1)\)</span>, 使用3层神经网络拟合该分布： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib</span><br><span class="line">matplotlib.use(&#x27;Agg&#x27;)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import random</span><br><span class="line">import math</span><br><span class="line">import keras</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers.core import Dense,Dropout,Activation</span><br><span class="line"></span><br><span class="line">def gd(x,m,s):</span><br><span class="line">  left=1/(math.sqrt(2*math.pi)*s)</span><br><span class="line">  right=math.exp(-math.pow(x-m,2)/(2*math.pow(s,2)))</span><br><span class="line">  return left*right</span><br><span class="line"></span><br><span class="line">def pt(x, y1, y2):</span><br><span class="line">  if len(x) != len(y1) or len(x) != len(y2):</span><br><span class="line">    print &#x27;input error.&#x27;</span><br><span class="line">    return</span><br><span class="line">  plt.figure(num=1, figsize=(20, 6))</span><br><span class="line">  plt.title(&#x27;NN fitting Gaussian distribution&#x27;, size=14)</span><br><span class="line">  plt.xlabel(&#x27;x&#x27;, size=14)</span><br><span class="line">  plt.ylabel(&#x27;y&#x27;, size=14)</span><br><span class="line">  plt.plot(x, y1, color=&#x27;b&#x27;, linestyle=&#x27;--&#x27;, label=&#x27;Gaussian distribution&#x27;)</span><br><span class="line">  plt.plot(x, y2, color=&#x27;r&#x27;, linestyle=&#x27;-&#x27;, label=&#x27;NN fitting&#x27;)</span><br><span class="line">  plt.legend(loc=&#x27;upper left&#x27;)</span><br><span class="line">  plt.savefig(&#x27;ann.png&#x27;, format=&#x27;png&#x27;)</span><br><span class="line"></span><br><span class="line">def ann(train_d, train_l, prd_d):</span><br><span class="line">  if len(train_d) == 0 or len(train_d) != len(train_l):</span><br><span class="line">    print &#x27;training data error.&#x27;</span><br><span class="line">    return</span><br><span class="line">  model = Sequential()</span><br><span class="line">  model.add(Dense(30, input_dim=1))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line">  model.add(Dense(30))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line"></span><br><span class="line">  model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line">  model.compile(loss=&#x27;mse&#x27;,</span><br><span class="line">              optimizer=&#x27;rmsprop&#x27;,</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">  model.fit(train_d,train_l,batch_size=250, nb_epoch=50, validation_split=0.2)</span><br><span class="line">  p = model.predict(prd_d,batch_size=250)</span><br><span class="line">  return p</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">  x = np.linspace(-5, 5, 10000)</span><br><span class="line">  idx = random.sample(x, 900)</span><br><span class="line">  train_d = []</span><br><span class="line">  train_l = []</span><br><span class="line">  for i in idx:</span><br><span class="line">    train_d.append(x[i])</span><br><span class="line">    train_l.append(gd(x[i],0,1))</span><br><span class="line"></span><br><span class="line">  y1 = []</span><br><span class="line">  y2 = []</span><br><span class="line">  for i in x:</span><br><span class="line">    y1.append(gd(i,0,1))</span><br><span class="line"></span><br><span class="line">  y2 = ann(np.array(train_d).reshape(len(train_d), 1), np.array(train_l), np.array(x).reshape(len(x), 1))</span><br><span class="line">  pt(x, y1, y2.tolist())</span><br></pre></td></tr></table></figure></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap87o3no141a1tnvid984h1vnv7n.png" width="600"  />
</center>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Bagging</tag>
        <tag>Boosting</tag>
        <tag>第二章</tag>
        <tag>LR</tag>
        <tag>SVM</tag>
        <tag>ATM</tag>
        <tag>RF</tag>
        <tag>GBDT</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第四章 最优化原理</title>
    <url>/article/ad2261a2.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1atg85ts8kff2erd551fss2s39.png" width=266 /> 最优化是机器学习的永恒话题，本章主要对基于梯度或Hessian矩阵的最优化方法做了公式推导和原理方面的介绍。 <span id="more"></span></p>
<h1 id="最优化原理">4. 最优化原理</h1>
<h2 id="泰勒定理">4.1 泰勒定理</h2>
<p>满足一定条件的函数可以通过泰勒展开式对其做近似：</p>
<h3 id="泰勒展开式">4.1.1 泰勒展开式</h3>
<p>泰勒展开式原理如下，主要采用分部积分推导： <span class="math display">\[
\begin{align*}
f(x+\Delta x)&amp;=f(x)+\int_{x}^{x+\Delta x}\nabla f(t)dt\\
&amp;=f(x)+((x+\Delta x) \nabla f(x+\Delta x)-xf(x))-\int_{x}^{x+\Delta x}t\nabla^2f(t)dt\\
&amp;=f(x)+(x+\Delta x)(\nabla f(x)+\int_{x}^{x+\Delta x}\nabla^2f(t)dt)-x\nabla f(x)-\int_{x}^{x+\Delta x}t\nabla^2f(t)dt\\
&amp;=f(x)+\nabla f(x)\Delta x +\int_{x}^{x+\Delta x}(x+\Delta x-t) \nabla^2f(t)dt\\
&amp;......\\
&amp;=f(x)+\nabla f(x)\Delta x+\frac{1}{2}\nabla^2 f(x)\Delta x^2+...\frac{1}{n!}\nabla^nf(x)\Delta x^n  \\
&amp;+ \int_{x}^{x+\Delta x}\frac{\nabla^{n+1}f(t)}{n!}(x+\Delta x-t) dt
\end{align*}
\]</span></p>
<!--more-->
<h3 id="泰勒中值定理">4.1.2 泰勒中值定理</h3>
<p>需要注意泰勒中值定理是一个严格的等式： <span class="math display">\[
\begin{array}{l}
f(x+\Delta x)=f(x)+\nabla f(x)\Delta x+\frac{1}{2}\nabla^2 f(x)\Delta x^2
+
...\frac{1}{n!}\nabla^nf(x)\Delta x^n \\
+\frac{1}{(n+1)!}\nabla^{n+1}f(\xi)\Delta x^{n+1} ,\text{where } \xi \in(0,\Delta x)
\end{array}
\]</span></p>
<h2 id="梯度下降法">4.2 梯度下降法</h2>
<h3 id="基本原理">4.2.1 基本原理</h3>
<p>梯度下降是一种简单、好用、经典的使用一阶信息的最优化方法（意味着相对低廉的计算成本），其基本原理可以想象为一个下山问题，当下降方向与梯度方向一致时，目标函数的方向导数最大，即此时目标函数在当前起点位置的下降速度最快。</p>
<p><strong>1、一个小例子</strong></p>
假设有单变量实值函数<span class="math inline">\(y=f(x)\)</span>，其图形如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjaso1ni41lk7nofbbnba9m.png" width="300" />
</center>
<p>实值函数y=f(x)在点x_0的导数f'(x)的意义是该函数在x=x_0 处的瞬时变化率，即：</p>
<p><span class="math inline">\(f&#39;(x_0)=\lim_{\Delta x-&gt;0}\frac{f(x_0+\Delta x)-f(x_0)}{\Delta x}\)</span></p>
<p>在自变量x发生微小变化时，目标函数值的变化可以这么描述：</p>
<p><span class="math inline">\(dy=f&#39;(x)dx\)</span></p>
<p>针对上图有以下三种情况：</p>
<p>(1)、<span class="math inline">\(x_1\)</span>点位置，此时<span class="math inline">\(f&#39;(x_1)&gt;0\)</span>，在<span class="math inline">\(x_1\)</span> 点做微小正向变化：<span class="math inline">\(dx&gt;0\)</span>，显然有<span class="math inline">\(dy&gt;0\)</span>，这说明在<span class="math inline">\(x_1\)</span>点往<span class="math inline">\(x\)</span>轴正向有可以使目标函数<span class="math inline">\(y=f(x)\)</span>值增大点存在；</p>
<p>(2)、<span class="math inline">\(x_2\)</span>点位置，此时<span class="math inline">\(f&#39;(x_2)&lt;0\)</span>，在<span class="math inline">\(x_2\)</span> 点做微小负向变化：<span class="math inline">\(dx&lt;0\)</span>，显然有<span class="math inline">\(dy&gt;0\)</span>，这说明在<span class="math inline">\(x_2\)</span>点往<span class="math inline">\(x\)</span>轴负向有可以使目标函数<span class="math inline">\(y=f(x)\)</span>值增大点存在；</p>
<p>(3)、<span class="math inline">\(x_0\)</span>点位置，此时<span class="math inline">\(f&#39;(x_0)=0\)</span>，不管在<span class="math inline">\(x_0\)</span> 点做微小负向变化还是正向变化都有<span class="math inline">\(dy=0\)</span>，这说明在<span class="math inline">\(x_0\)</span>点是一个最优解。</p>
<p>实际上，在一维情况下目标函数的梯度就是<span class="math inline">\(f&#39;(x)\)</span>，它表明了目标函数值变化方向。</p>
<p><strong>2、梯度与方向导数</strong></p>
<ul>
<li><p>方向导数 以二元函数：<span class="math inline">\(y=f(x_0,x_1)\)</span>为例，设它在点<span class="math inline">\(p(x_0,x_1)\)</span>的某个邻域<span class="math inline">\(U(p)\)</span>内有定义，以点<span class="math inline">\(p(x_0,x_1)\)</span>出发引射线l，<span class="math inline">\(p&#39;(x_0+\Delta x_0,x_1+\Delta x_1)\)</span>为<span class="math inline">\(l\)</span>上的且在邻域<span class="math inline">\(U(p)\)</span>内的任意点，则方向导数的定义为： <span class="math display">\[\frac{\partial f}{\partial l} = \lim_{\rho-&gt;0^+} {\frac{f(x_0+\Delta x_0,x_1+\Delta x_1)-f(x_0,x_1)}{\rho}} \]</span> 其中<span class="math inline">\(\rho\)</span>表示<span class="math inline">\(p\)</span>和<span class="math inline">\(p&#39;\)</span>两点之间的欧氏距离：<span class="math inline">\(\rho = \sqrt{(\Delta x_0)^2 + (\Delta x_1)^2}\)</span> 从这个式子可以看到：方向导数与某个方向<span class="math inline">\(l\)</span>有联系、方向导数是个极限值、方向导数与偏导数似乎有联系。 实际上，如果<span class="math inline">\(y=f(x_0,x_1)\)</span>在点<span class="math inline">\(p(x_0,x_1)\)</span>可微，则： <span class="math display">\[\frac{\partial f}{\partial l} = \frac{\partial f}{\partial x_0} \cos\alpha +\frac{\partial f}{\partial x_1} \cos\beta  \]</span> 其中<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>分别是两个维度上的方向角 这里需要注意的一个细节是：沿某个维度的方向导数存在时，其偏导数不一定存在，原因就是方向导数只要求半边极限存在(<span class="math inline">\(\rho-&gt;{0^+}\)</span>)，而偏导数则要求双边都存在。</p></li>
<li>梯度 把方向导数变换一下形式： <span class="math display">\[\frac{\partial f}{\partial l} = \frac{\partial f}{\partial x_0} \cos\alpha +\frac{\partial f}{\partial x_1} \cos\beta =(\frac{\partial f}{\partial x_0},  \frac{\partial f  }{\partial x_1}) \cdot (\cos\alpha, \cos\beta)\]</span> 函数<span class="math inline">\(y=f(x_0,x_1)\)</span>在点<span class="math inline">\(p(x_0,x_1)\)</span>的梯度就被定义为向量： <span class="math display">\[gradf(x_0,x_1)=\frac{\partial f}{\partial x_0}\cdot i + \frac{\partial f  }{\partial x_1}\cdot j\]</span> 与射线l同方向的单位向量被定义为： <span class="math inline">\(e=\cos \alpha \cdot i+ \cos \beta\cdot j\)</span> 于是方向导数变成了： <span class="math display">\[\frac{\partial f}{\partial l} = gradf(x_0,x_1)\cdot e=|gradf(x_0,x_1)|\cdot \cos&lt;gradf(x_0,x_1), e&gt;\]</span> 我的理解是：方向导数描述了由各个维度方向形成的合力方向上函数变化的程度，当这个合力方向与梯度向量的方向相同时，函数变化的最剧烈，我想这就是为什么在梯度上升算法或者梯度下降算法中选择梯度方向或者负梯度方向的原因吧。换句话说就是：函数在某点的梯度是这样一个向量，它的方向与取得最大方向导数的方向一致，而它的模为方向导数的最大值。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjbvq0t14gvsisstr1uufcpm13.png" width="300" />
</center>
<center>
某个函数和它的等高线，图中标出了a点的梯度上升方向
</center></li>
</ul>
<p><strong>3、多维无约束问题</strong></p>
<p>将开篇的那个小例子扩展到多维的情况，目标函数值将会成为一个向量，向任意个维度方向做微小变动都将对目标函数值产生影响，假设有n个维度，可以用下面的式子描述：</p>
<p><span class="math display">\[dy=(dy_0,....,dy_n)=grad f\cdot (dx_0,...,dx_n)^T=gradf\cdot dx=|grad f|\cdot |dx|\cdot \cos&lt;grad f , dx&gt;\]</span></p>
<p>令<span class="math inline">\(\alpha = \angle &lt;grad f , dx&gt;\)</span></p>
<p>(1)、当<span class="math inline">\(0\leq \alpha&lt;\frac{\pi}{2}\)</span>，此时<span class="math inline">\(dy&gt;0\)</span>，因此可以从点<span class="math inline">\(x\)</span>移动使得目标函数值增加；</p>
<p>(2)、当<span class="math inline">\(\frac{\pi}{2}&lt; \alpha\leq \pi\)</span>，此时<span class="math inline">\(dy&lt;0\)</span>，因此可以从点<span class="math inline">\(x\)</span>移动使得目标函数值减少；</p>
<p>(3)、当 <span class="math inline">\(\alpha=\frac{\pi}{2}\)</span>，梯度向量和<span class="math inline">\(dx\)</span>正交（任一向量为0也视为正交），不管从点<span class="math inline">\(x\)</span>怎样移动都找不到使目标函数值发生变化的点，于是x点就是目标函数的最优解。 由于<span class="math inline">\(dx\)</span>可以是任意方向向量，只要点x的梯度向量不为零，从点x出发总可以找到一个变化方向使得目标函数值向我们希望的方向变化（比如就找梯度方向，此时能引起目标函数值最剧烈地变化），理论上当最优解<span class="math inline">\(x^*\)</span>出现时就一定有<span class="math inline">\(gradf (x^*)=0\)</span>（实际上允许以某个误差<span class="math inline">\(\epsilon\)</span>结束），比如，对于梯度下降算法，当<span class="math inline">\(gradf (x^*)=0\)</span>时迭代结束，此时的<span class="math inline">\(x^*\)</span>为最优解（可能是全局最优解也可能是局部最优解） <span class="math display">\[x_{n+1}=x_n - \alpha \cdot gradf(x_n)\]</span></p>
<p>总结来说，基于梯度的优化算法通常有两个核心元素：搜索方向和搜索步长，并且一般都会和泰勒定理有某种联系，从泰勒中值定理可以得到下面的等式：</p>
<p><span class="math display">\[
\begin{align*}
f(x_{n+1})&amp;=f(x_n)+\nabla f(x_n)(x_{n+1}-x_n)+\frac{1}{2}\nabla^2 f(\xi)(x_{n+1}-x_n)^2\\
&amp;~~~~~~~~~~~~~~~\text{where } \xi \in(x_n,x_{n+1})\\
\because &amp; \nabla f(x_{n+1})=g_n+\nabla^2\\
&amp;f(\xi)(x_{n+1}-x_n)=0\\
\therefore &amp; x_{n+1}=x_n-\underbrace{\nabla^2 f(\xi)^{-1}}_{\eta :~\text{learning rate  }} \underbrace{\nabla f(x_n)}_{ d:~\text{gradient}}\\
\end{align*}
\]</span></p>
<p>抽象出迭代框架如下：</p>
<p><span class="math display">\[
\begin{align*}
x_{n+1}&amp;=x_n-\eta \nabla f(x_n)\\
&amp;~~~~~~~~\text{    where $f(x)$ is objective function.}\\
&amp;or\\
x_{n+1}&amp;=x_n-\Delta x_n\\
\Delta x_n&amp;=\eta \nabla f(x_n)
\end{align*}
\]</span></p>
<h3 id="拉格朗日乘数法和kkt条件">4.2.2 拉格朗日乘数法和KKT条件</h3>
<p>假设目标函数和约束在某点可微，用符号<span class="math inline">\(\nabla f\)</span>代替符号<span class="math inline">\(grad f\)</span>。</p>
<p><strong>1、等式约束</strong></p>
<span class="math display">\[\begin{eqnarray*}
 &amp;&amp;\min f(x) \\
&amp;&amp;s.t.  h(x)=0, \quad
\end{eqnarray*}\]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjcq0mg8c11h511kmivm11far1g.png" width="300" />
</center>
<p>在约束条件的作用下，与点<span class="math inline">\(x\)</span>（它是个向量）可移动方向相关的向量<span class="math inline">\(dx\)</span>就不像无约束问题那样随便往哪个方向都能移动了，此时<span class="math inline">\(dx\)</span>只能沿着约束曲线移动，例如，在<span class="math inline">\(x1\)</span>、<span class="math inline">\(x2\)</span>处，<span class="math inline">\(\nabla f(x)\)</span>和<span class="math inline">\(dx\)</span>不正交，说明还有使目标函数值更小的等高线存在，所以点<span class="math inline">\(x\)</span>还有移动的余地，当移动到<span class="math inline">\(x0\)</span>位置时<span class="math inline">\(\nabla f(x)\)</span>和<span class="math inline">\(dx\)</span>正交，得到最优解<span class="math inline">\(x0\)</span>。那么在最优解处<span class="math inline">\(\nabla f(x)\)</span>和约束有什么关系呢？因为此时<span class="math inline">\(h(x)=0\)</span>，<span class="math inline">\(\nabla h(x) \cdot dx=0\)</span>，显然此时有<span class="math inline">\(\lambda \cdot \nabla h(x)=\nabla f(x)\)</span>（其中<span class="math inline">\(\lambda\)</span>是常数），也就是说约束的梯度向量与目标函数的梯度向量在最优解处一定平行。 想到求解此类优化问题时最常用的方法——拉格朗日乘数法，先要构造拉格朗日函数：</p>
<p><span class="math display">\[L(x,\lambda) = f(x) - \lambda h(x)  \]</span> 其中<span class="math inline">\(\lambda \geq0\)</span>，是常数</p>
<p>为什么求解拉格朗日函数得到的最优解就是原问题的最优解呢？</p>
<p><span class="math display">\[\frac{\partial L(x,\lambda)}{\partial x}=\nabla f(x)-\lambda \nabla h(x) \frac{\partial L(x,\lambda)}{\partial \lambda}= h(x)\]</span></p>
<p>假设<span class="math inline">\(x^*\)</span>、<span class="math inline">\(\lambda^*\)</span>为<span class="math inline">\(L(x,\lambda)\)</span>的最优解，那么就需要满足：</p>
<p><span class="math display">\[
\begin{eqnarray*}
   \\ \nabla f(x^*)-\lambda^* \nabla h(x^*)&amp;=&amp; 0\\
  \\    h(x^*)&amp;=&amp;0\\
  \end{eqnarray*}
 \]</span></p>
<p>第一个式子印证了约束的梯度向量与目标函数的梯度向量在最优解处一定平行，第二个式子就是等式约束本身。</p>
<p>于是：</p>
<p><span class="math display">\[
\begin{eqnarray*}
&amp;&amp;L(x,\lambda) &amp;\geq &amp;L(x^*,\lambda^*)\\
\Rightarrow&amp;&amp; f(x)-\lambda h(x) &amp;\geq &amp;f(x^*)-\lambda^* h(x^*) \\
\Rightarrow &amp;&amp;f(x) &amp;\geq &amp; f(x^*)
\end{eqnarray*}
\]</span></p>
<p><strong>2、不等式约束</strong></p>
<p>实际情况中，约束条件可能是等式约束也可能是不等式约束或者同时包含这两种约束，下面描述为更一般地情况：</p>
<p><span class="math display">\[
\begin{eqnarray*}
&amp; \min &amp;f(x)\\
&amp; s.t.&amp; h_i(x)=0 \quad (i=0 ... n)\\
&amp;&amp;g_j(x) \leq 0 \quad (j=0...m)
\end{eqnarray*}
\]</span></p>
<p>依然使用拉格朗日乘数法，构造拉格朗日函数：</p>
<p><span class="math display">\[L(x,\alpha ,\beta) = f(x) + \sum\limits_{i=0}^n \alpha_i \cdot h_i(x) + \sum\limits_{j=0}^m \beta_j\cdot g_j(x)  \]</span> 其中<span class="math inline">\(\alpha_i \geq 0\)</span>且<span class="math inline">\(\beta_j \geq 0\)</span></p>
<p>在这里不得不说一下Fritz John 定理了，整个证明就不写了（用局部极小必要条件定理、Gordan 引理可以证明）。</p>
<p><strong>定理1：</strong></p>
<p>依然假设<span class="math inline">\(x^*\)</span>为上述问题的极小值点，问题中涉及到的各个函数一阶偏导都存在，则存在不全为零的_i使得下组条件成立：</p>
<p><span class="math display">\[ \lambda_0 \nabla f(x^*) + \sum\limits_{i=0}^n \lambda_i \cdot \nabla h_i(x^*) + \sum\limits_{j=0}^m \lambda_j\cdot \nabla g_j(x^*)=0 \lambda_j \cdot g_j(x^*) = 0  ,j=0,...m
 \lambda_j \geq 0,j=0,...m\]</span></p>
<p>这个定理第一项的形式类似于条件极值必要条件的形式，如果<span class="math inline">\(\lambda_0=0\)</span>则有效约束 <span class="math inline">\(\nabla g_j(x)\)</span>会出现正线性相关，由Gordan 引理知道此时将存在可行方向，就是<span class="math inline">\(x^*\)</span>将不是原问题的极值点，因此令 <span class="math inline">\(\nabla g_j(x)\)</span>则线性无关则<span class="math inline">\(\lambda_0&gt;0\)</span> 。</p>
<p><span class="math inline">\(\lambda_j \cdot g_j(x^*) = 0 ,j=1,...m\)</span>这个条件又叫互不松弛条件（Complementary Slackness），SVM里的支持向量就是从这个条件得来的。</p>
<p>由Fritz John 定理可知 <span class="math inline">\(\nabla g_j(x)\)</span>线性无关则<span class="math inline">\(\lambda_0&gt;0\)</span> ，让每一个拉格朗日乘子除以<span class="math inline">\(\lambda_0\)</span>，即<span class="math inline">\(\mu_i=\lambda_i/\lambda_0\)</span>，得到下面这组原问题在点<span class="math inline">\(x^*\)</span>处取得极小值一阶必要条件。</p>
<p><strong>定理2：</strong></p>
<p>假设<span class="math inline">\(x^*\)</span>为上述问题的极小值点，问题中涉及到的各个函数一阶偏导都存在，有效约束 <span class="math inline">\(\nabla g_j(x)\)</span>线性无关，则下组条件成立：</p>
<p><span class="math display">\[\frac{\partial L(x,\mu_i,\mu_j)}{\partial x} =\nabla f(x^*) + \sum\limits_{i=0}^n \mu^*_i \cdot \nabla h_i(x^*) + \sum\limits_{j=0}^m \mu^*_j\cdot \nabla g_j(x^*)=0
\\
 \mu_j^* \cdot g_j(x^*) = 0  ,j=0,...m
 \\
 \mu^*_j \geq 0,j=0,...m
 \\
h_i(x^*)=0,i=0,..,n
\\
g_j(x^*) \leq 0,j=0,...m\]</span></p>
<p>这组条件就是Karush-Kuhn-Tucker条件，满足KKT条件的点就是KKT点，需要注意的是KKT条件是必要条件（当然在某些情况下会升级为充要条件，比如凸优化问题）。 由此也可以想到求解SVM最大分类间隔器时，不管是解决原问题还是解决对偶问题，不管是用SMO方法或其它方法，优化的过程就是找到并优化违反KKT条件的最合适的乘子。 KKT条件与对偶理论有密切的关系，依然是解决下面这个问题：</p>
<p><span class="math display">\[
\begin{eqnarray*}
&amp; \min &amp;f(x)\\
&amp; s.t.&amp; h_i(x)=0 \quad (i=0 ... n)\\
&amp;&amp;g_j(x) \leq 0 \quad (j=0...m)
\end{eqnarray*}
\]</span></p>
<p>构造拉格朗日函数：</p>
<p><span class="math display">\[ L(x,\alpha ,\beta) = f(x) + \sum\limits_{i=0}^n \alpha_i \cdot h_i(x) + \sum\limits_{j=0}^m \beta_j\cdot g_j(x)\]</span> 其中<span class="math inline">\(\alpha_i \geq 0\)</span>且<span class="math inline">\(\beta_j \geq 0\)</span>，它们都是拉格朗日乘子</p>
<p>令<span class="math inline">\(O_p(x)=\max\limits_{\alpha ,\beta} L(x,\alpha,\beta)\)</span>，原问题可以表示为下面这个形式：</p>
<p><span class="math display">\[
O_p(x)=
 \left\{
   \begin{array}{c}
   &amp;f(x)&amp; if \quad x \quad satisfies \quad primal \quad constraints&amp;\\
  &amp; \infty&amp; otherwise.&amp;\\
   \end{array}
  \right.
  \]</span></p>
<p>这个式子比较容易理解，当x违反原问题约束条件时有：</p>
<p><span class="math display">\[
O_p(x)=\max\limits_{\alpha ,\beta} L(x,\alpha ,\beta) = \max\limits_{\alpha, \beta} f(x) + \sum\limits_{i=0}^n \alpha_i \cdot h_i(x) + \sum\limits_{j=0}^m \beta_j\cdot g_j(x)=\infty
\]</span></p>
<p>于是原问题等价为下面这个问题：</p>
<p><span class="math display">\[ \min\limits_x O_p(x)=\min\limits_x \max\limits_{\alpha ,\beta} L(x,\alpha,\beta) \]</span> 它的最优解记为<span class="math inline">\(p^*\)</span></p>
<p>令<span class="math inline">\(O_d(\alpha,\beta)=\min\limits_{x} L(x,\alpha,\beta)\)</span>，则有以下形式：</p>
<p><span class="math display">\[\max\limits_{\alpha,\beta} O_d(\alpha,\beta)=\max\limits_{\alpha,\beta} \min\limits_{x} L(x,\alpha,\beta)\]</span></p>
<p>它的最优解记为<span class="math inline">\(d^*\)</span>，上面这两个形式很像，区别只在于<span class="math inline">\(min\)</span>和<span class="math inline">\(max\)</span>的顺序，实际上<span class="math inline">\(O_p(x)\)</span>和<span class="math inline">\(O_d(\alpha,\beta)\)</span>互为对偶问题。</p>
<p>因为<span class="math inline">\(\max\min \leq \min \max\)</span>，打个不太恰当的比喻，这就像瘦死的骆驼比马大，具体的证明就不写了；</p>
<p>所以<span class="math inline">\(d^* \leq p*\)</span>，这个就是弱对偶性，此时存在对偶间隙，它被定义为：<span class="math inline">\(gap=p^*-d^*\)</span>。</p>
<p>有弱对偶性就有强对偶性，它指的是在某些条件下有<span class="math inline">\(d^* = p*\)</span>，比如在以下条件下满足强对偶性：</p>
<p>目标函数和所有不等式约束函数是凸函数，等式约束函数是仿射函数(形如<span class="math inline">\(y=w^tx+b\)</span>)，且所有不等式约束都是严格的约束(大于或小于)。</p>
<p>KKT条件和强对偶性的关系是：</p>
<blockquote>
<p>KKT条件是强对偶性成立的必要条件，特别的，当原问题是凸优化问题时，KKT条件就是充要条件，强对偶性存在时KKT点既是原问题的解也是对偶问题的解，这个时候对偶间隙为0。</p>
</blockquote>
<h3 id="批量梯度下降">4.2.3 批量梯度下降</h3>
<p>按照上面等式，每次迭代，为计算梯度值都需要把所有样本扫描一遍，收敛曲线类似下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/bgd.png" width="500" />
</center>
<center>
From <a href="https://plot.ly/~michaeljancsy/419.embed">michaeljancsy</a>
</center>
<p>它的优点如下： - 模型学习与收敛过程通常是平滑的和稳定的； - 关于收敛条件有成熟完备的理论； - 针对它有不少利用二阶信息加速收敛的技术，例如conjugate gradient； - 对样本噪声点相对不敏感。</p>
<p>它的缺点如下：</p>
<ul>
<li>收敛速度慢；</li>
<li>对初始点敏感；</li>
<li>数据集的变化无法被学习到； captured.</li>
<li>不太适用于大规模数据。</li>
</ul>
<h3 id="随机梯度下降">4.2.4 随机梯度下降</h3>
<p>完全随机梯度下降（Stochastic Gradient Descent，可以想想这里为什么用Stochastic而不用Random？）每次选择一个样本更新权重，这样会带来一些噪声，但可能得到更好的解，试想很多问题都有大量局部最优解，传统批量梯度下降由于每次收集所有样后更新梯度值，当初始点确定后基本会落入到离它最近的洼地，而随机梯度下降由于噪声的引入会使它有高概率跳出当前洼地，选择变多从而可能找到更好的洼地。 收敛曲线类似下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/sgd.png" width="500" />
</center>
<center>
From <a href="https://plot.ly/~michaeljancsy/419.embed">michaeljancsy</a>
</center>
<p>完全随机梯度下降和批量梯度下降的优缺点几乎可以互换： - SGD的收敛速度更快； - SGD相对来说对初始点不敏感，容易找到更优方案； - SGD相对适合于大规模训练数据； - SGD能够捕捉到样本数据的变化； - 噪声样本可能导致权重波动从而造成无法收敛到局部最优解，步长的设计对其非常重要。</p>
<p>实践当中，很多样本都有类似的模式，所以SGD可以使用较少的抽样样本学习得到局部最优解，当然完全的批量学习和完全的随机学习都太极端，所以往往采用对两者的折中。</p>
<h3 id="小批量梯度下降">4.2.5 小批量梯度下降</h3>
<p>小批量梯度下降（Mini-batch Gradient Descent）是对SGD和BGD的折中，采用相对小的样本集学习，样本集大小随着学习过程保持或逐步加大，这样既能有随机带来的好处，又能使用二阶优化信息加速收敛，目前主流机器学习工具几乎都支持小批量学习。 小批量学习收敛过程如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/msgd.png" width="500" />
</center>
<center>
From <a href="https://plot.ly/~michaeljancsy/419.embed">michaeljancsy</a>
</center>
<p>梯度下降的另外一个任务是寻找合适的学习率，关于它有很多方法，介绍如下：</p>
<h3 id="牛顿法">4.2.6 牛顿法</h3>
<p>从泰勒展开式可以得到带最优步长的迭代式：</p>
<p><span class="math display">\[
\begin{array}{l}
\Delta x_n=-\nabla^2 f(\xi)^{-1}\nabla f(x_n)\\
x_{n+1}=x_n+\Delta x_n
\end{array}
\]</span></p>
<p>但最优的学习率需要计算hessian矩阵，计算复杂度为<span class="math inline">\(O(n^3)\)</span>，所以这种方法不怎么用。</p>
<p><strong>为方便起见，使用 <span class="math inline">\(g_n\)</span> 代替 <span class="math inline">\(\nabla f(x_n)\)</span>.</strong></p>
<h3 id="momentum">4.2.7 Momentum</h3>
<p>SGD的一大缺点是<span class="math inline">\(\Delta x_n\)</span> 只和当前样本有关系，如果样本存在噪声则会导致权重波动，一种自然的想法就是即考虑历史梯度又考虑新样本的梯度：</p>
<p><span class="math display">\[
\begin{array}{l}
\Delta x_n=\rho \Delta x_{n-1}-\eta g_n\\
x_{n+1}=x_n+\Delta x_n\\
\rho \text{ is usually set to a small value }\le 0.9
\end{array}
\]</span></p>
<p>对动量的运行过程说明如下:</p>
<ul>
<li><p>在初始阶段，历史梯度信息会极大加速学习过程（比如n=2时）；</p></li>
<li><p>当准备穿越函数波谷时，差的学习率会导致权重向相反方向更新，于是学习过程会发生回退，这时有动量项的帮助则有可能越过这个波谷；</p></li>
<li><p>最后在梯度几乎为0的时候，动量项的存在又可能会使它跳出当前局部最小值，于是可能找到更好的最优值点。</p></li>
</ul>
Nesterov accelerated gradient 是对动量法的一种改进，具体做法是：首先在之前的方向上迈一大步（棕色向量），之后计算在该点的梯度（红色向量），然后计算两个向量的和，得到的向量（绿色向量）作为最终优化方向。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/nesterov_update_vector.png" width="350" />
</center>
<center>
From <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">G. Hinton's lecture 6c</a>
</center>
<p><span class="math display">\[
\begin{array}{l}
\Delta x_n=\rho \Delta x_{n-1}-\eta \nabla f(x_n-\rho \Delta x_{n-1})\\
x_{n+1}=x_n+\Delta x_n\\
\rho \text{ is usually set to a small value }\le 0.9
\end{array}
\]</span></p>
<h3 id="adagrad">4.2.8 AdaGrad</h3>
<p>Adagrad同样是基于梯度的方法，对每个参数给一个学习率，因此对于常出现的权重可以给个小的更新，而不常出现的则给予大的更新，于是对于稀疏数据集就很有效，这个方法常用于大规模神经网络，Google的FTRL-Proximal也使用了类似方法，可参见：<a href="https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf">Google Ad Click Prediction a View from the Trenches</a>和<a href="http://www.jmlr.org/proceedings/papers/v15/mcmahan11b/mcmahan11b.pdf">Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization</a>。</p>
<p><span class="math display">\[
\begin{array}{l}
\Delta x_n=-\frac{\eta}{\sqrt{\sum_{i=1}^{n}g_i^2}+\beta}g_n\\
x_{n+1}=x_n+\Delta x_n\\
\beta \text{ is usually set to a small value.}
\end{array}
\]</span></p>
<p>这个方法有点像L2正则，其运作原理如下：</p>
<ul>
<li><p>在学习前期，梯度比较小regularizer比较大，所以梯度会被放大；</p></li>
<li><p>在学习后期，梯度比较大regularizer比较小，所以梯度会被缩小。</p></li>
</ul>
<p>但它的缺点是，当初始权重过大或经过几轮训练后会导致正则化太小，所以训练将被提前终止。</p>
<h3 id="adadelta">4.2.9 AdaDelta</h3>
<p>Adadelta是对Adagrad的改进，解决了以下短板：</p>
<ul>
<li><p>经过几轮的训练会导致正则化太小；</p></li>
<li><p>需要设置一个全局学习率；</p></li>
<li><p>当我们更新<span class="math inline">\(\Delta x\)</span>,等式左边和右边的单位不一致。</p></li>
</ul>
<p>对于第一个短板，设置一个窗口<span class="math inline">\(w\)</span>，仅使用最近几轮的梯度值去更新正则项但计算<span class="math inline">\(E[\nabla f(x)_{1\sim n}]\)</span> 太复杂，所以使用类似动量法的策略：</p>
<p><span class="math display">\[
\begin{array}{l}
E[g^{2}]_{n}=\rho E[g^{2}]_{n-1}+(1-\rho )g_{n}^{2}\\
\Delta x_n=-\frac{\eta}{\sqrt{E[g^2]_n+\beta}}g_n\\
x_{n+1}=x_n+\Delta x_n\\
\beta \text{ is usually set to a small value.}\\
\rho \text{ is decay coefficient.}
\end{array}
\]</span></p>
<p>对其他短板，AdaDelta通过以下方法解决。</p>
<p>对SGD与Momentum(里面的注释是理解这个变换的关键)：</p>
<p><span class="math display">\[
\text{unit of }\Delta x \propto \text{unit of }g \propto \frac{\partial f}{\partial x} \propto \frac{1}{\text{unit of }x}\\
(\text{When $f$ is negative log likelihood function }\frac{\partial f}{\partial x} \propto \frac{\partial logf}{\partial x} =\frac{\frac{\partial f}{\partial x}}{f})
\]</span></p>
<p>对牛顿法： <span class="math display">\[
\text{unit of }\Delta x \propto \text{unit of }H^{-1}g\propto \frac{\frac{\partial f}{\partial x}}{\frac{\partial^{2}f}{\partial x^{2}}}\propto \frac{\frac{1}{x}}{\frac{1}{x}.\frac{1}{x}}\propto \text{unit of }x
\]</span></p>
<p>所以二阶方法有正确的单位且快于一阶方法。</p>
<p>来源于Becker 和 LeCuns' 的hessian估计法：</p>
<p><span class="math display">\[
 \begin{array}{l}
 \Delta x_{n} \approx  \frac{\frac{\partial f}{\partial x}}{\frac{\partial^{2}f}{\partial x^{2}}}=\frac{1}{\frac{\partial^{2}f}{\partial x^{2}}}\cdot \frac{\partial f}{\partial x}=\frac{1}{\frac{\partial^{2}f}{\partial x^{2}}}\cdot g_n\\
 define:RMS[g]_{n}=\sqrt{E[g^{2}]_{n}+\epsilon }\\
 \because \frac{1}{\frac{\partial^{2}f}{\partial x^{2}}}=\frac{\Delta x}{\frac{\partial f}{\partial x}}\approx -\frac{RMS[\Delta x]_{n-1}}{RMS[g]_{n}}\\
 \therefore \Delta x_{n}=-\frac{RMS[\Delta x]_{n-1}}{RMS[g_n]}\cdot g_n
\end{array}
\]</span></p>
完整的算法描述如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/adadelta.png" width="400" />
</center>
<center>
From <a href="http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf">Zeiler</a>
</center>
<p>对以上算法的比较如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/compare.png" width="600" />
</center>
<center>
From <a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/trainers.html">Karpathy</a>
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/contours_evaluation_optimizers.gif" width="400" />
</center>
<center>
From <a href="http://sebastianruder.com/optimizing-gradient-descent/">SGD optimization on loss surface contours</a>
</center>
<h3 id="adam">4.2.10 Adam</h3>
<p>Adam是对Adadelta的改进，原理如下：</p>
<p><span class="math display">\[
 \begin{align*}
&amp;Recall:
\Delta x_n=-\frac{\eta}{\sqrt{\sum_{i=1}^{n}g_i^2}+\epsilon}g_n\\
&amp;\text{Keeping an exponentially decaying average of past gradients:}\\
&amp;m_n = \beta_1 m_{n-1} + (1 - \beta_1) g_n\\
&amp;v_n = \beta_2 v_{n-1} + (1 - \beta_2) g_n^2\\
&amp;\because m_n=(1-\beta_1)\sum_{i=1}^n\beta_1^{n-i}g_i\\
&amp;~~~~v_n=(1-\beta_2)\sum_{i=1}^n\beta_2^{n-i}g_i^2\\
&amp;\therefore E[m_n]=E[(1-\beta_1)\sum_{i=1}^n\beta_1^{n-i}g_i]=E[g_n](1-\beta_1^n)\\
&amp;~~~~E[v_n]=E[g_n^2](1-\beta_2^n)\\
&amp;\\
&amp;\text{if set: }\\
&amp;\hat{m}_n = \dfrac{m_n}{1 - \beta^n_1}\\
&amp;\hat{v}_n = \dfrac{v_n}{1 - \beta^n_2}\\
&amp;\text{then we get the bias-corrected first and second moment estimates: }\\
&amp;E[\hat{m_n}]=m_n \text{ and } E[\hat{v_n}]=v_n\\
&amp;\\
&amp;\text{So the equation is:}\\
&amp;\Delta x_n=- \dfrac{\eta}{\sqrt{\hat{v}_n} + \epsilon} \hat{m}_n\\
&amp;x_{n+1} = x_{n} +\Delta x_n\\
&amp;\text{The authors propose default values of 0.9 for $\beta_1$, 0.999 for $\beta_2$, and $10^{-8}$ for $\epsilon$.}
\end{align*}
\]</span></p>
算法伪代码如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apn008f514vrvrf12mmjo31qrrm.png" alt="image_1apn008f514vrvrf12mmjo31qrrm.png-222.1kB" />
</center>
<h2 id="并行sgd">4.3 并行SGD</h2>
<p>SGD相对简单并且被证明有较好的收敛性质和精度，所以自然而然就想到将其扩展到大规模数据集上，就像Hadoop/Spark的基本框架是MapReduce，并行机器学习的常见框架有两种： AllReduce 和 Parameter Server（PS）。</p>
<h3 id="allreduce">4.3.1 AllReduce</h3>
<p>AllReduce的思想来源于MPI，它可以被看做Reduce操作+Broadcast操作，例如：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/allreduce1.png" alt="allreduce1.png-15.8kB" />
</center>
<center>
From <a href="http://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/">MPI Tutorials</a>
</center>
<p>其他AllReduce的拓扑结构如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1app04foe100116b7vf6rblrqn9.png" alt="image_1app04foe100116b7vf6rblrqn9.png-74kB" />
</center>
<center>
From <a href="https://arxiv.org/pdf/1312.3020.pdf">Huasha Zhao &amp; John Canny</a>
</center>
非常好的开源实现有<a href="http://hunch.net/~jl/"><strong>John Langford</strong></a>的<a href="https://github.com/JohnLangford/vowpal_wabbit/"><strong>vowpal wabbit</strong></a>和<a href="http://homes.cs.washington.edu/~tqchen/"><strong>陈天奇</strong></a>的<a href="https://github.com/dmlc/rabit"><strong>Rabit</strong></a>（轻量级、可容错）。并行计算的关键之一是如何在大规模数据集下计算目标函数的梯度值，AllReduce框架很适合这种任务，比如：vw通过构建一个二叉树来管理机器节点，其中一个节点会被当做master，其他节点作为slave，master管理着slave并定期接受它们的心跳，每个子节点的计算结果会被其父节点收集，到达根节点后累加并广播到其所有子节点，一个简单的例子如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apo0jjdvq6v8h011kq1useljp15.png" alt="image_1apo0jjdvq6v8h011kq1useljp15.png-11.6kB" />
</center>
<p>使用mini-batch的并行SGD算法伪代码如下：</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Algorithm 2: parallelizing SGD with mini-batch}\\
\text{If we have examples $X=\{x_0,x_1,...x_m\}$, machines $n$, threads of each machine $p$,} \\
\text{iterations T, batch b, local iterations t.}\\
\\
\textbf{Require}:\eta&gt;0,m&gt;1,n&gt;1,p&gt;1,T&gt;0,b&gt;1,t&gt;0\\
\quad1.\;\;\;\;\textbf{define}~H=\lfloor \frac{m}{n} \rfloor,h=\lfloor \frac{H}{p} \rfloor\\
\quad2.\;\;\;\;\text{randomly partition examples $X$,giving $H$ examples to each machine}\\
\quad3.\;\;\;\;w=0\\
\quad4.\;\;\;\;\textbf{for all }i = 1, ... T \text{ and $w$ not convenged} \textbf{ do}\\
\quad5.\;\;\quad\quad\textbf{for all }j \in \{1, ..., n\} \textbf{ parallel do}\\
\quad6.\;\;\quad\quad\quad\quad\text{randomly partition examples $h$ on machine j to each thread.}\\
\quad7.\;\;\quad\quad\quad\quad\textbf{for all }k \in \{1, ..., p\} \textbf{ parallel do}\\
\quad8.\;\;\quad\quad\quad\quad\quad\quad\text{randomly shuffle examples on thread k}\\
\quad9.\;\;\quad\quad\quad\quad\quad\quad w_0^k=0\\
\quad10.\quad\quad\quad\quad\quad\quad\textbf{for all }q = 1, ... t \textbf{ do}\\
\quad11.\quad\quad\quad\quad\quad\quad\quad\quad \textbf{choose }\text{examples $b$ uniformly at random}\\
\quad12.\quad\quad\quad\quad\quad\quad\quad\quad \textbf{update }w_{q+1}^k=w_{q}^k+\eta g_q^k\\
\quad13.\quad\quad\quad\quad\textbf{reduce }w_j=\frac{1}{p}\sum_{k=1}^p w_q^k\\
\quad14.\quad\quad\textbf{AllReduce (reduce $w_j$)}\\
\quad15.\quad\quad w=\frac{1}{n}\sum_{i=1}^n w_j^i\\
\quad16.\quad\quad\textbf{AllReduce (broadcast $w$)}\\
\quad17.\quad\textbf{return }w
\end{array}
\]</span></p>
<h3 id="参数服务器parameter-server">4.3.2 参数服务器(Parameter Server)</h3>
参数服务器强调模型训练时参数的并行异步更新，最早是由Google的Jeffrey Dean团队提出，为了解决深度学习的参数学习问题，其基本思想是：将数据集划分为若干子数据集，每个子数据集所在的节点都运行着一个模型的副本，通过独立 部署的参数服务器组织模型的所有权重，其基本操作有：Fatching：每隔n次迭代，从参数服务器获取参数权重，Pushing：每隔m次迭代，向参数服务器推送本地梯度更新值，之后参数服务器会更新相关参数权重，其基本架构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1appb6oak1iu3eptmi51dvhjmhm.png" alt="image_1appb6oak1iu3eptmi51dvhjmhm.png-33.9kB" />
</center>
<center>
From <a href="https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf">Jeffrey Dean: Large Scale Distributed Deep Networks</a>
</center>
<p>每个模型的副本都是，为减少通信开销，每个模型副本在迭代<span class="math inline">\(n_{fetch}\)</span>次后向参数服务器请求参数跟新，反过来本地模型每迭代<span class="math inline">\(n_{push}\)</span>次后向参数服务器推送一次梯度更新值，当然，为了折中速度和效果，梯度的更新可以选择异步也可以是同。 参数服务器是一个非常好的机器学习框架，尤其在深度学习的应用场景中，有篇不错的文章： <a href="http://chuansong.me/n/2161528">参数服务器——分布式机器学习的新杀器</a>。开源的实现中比较好的是<a href="https://github.com/petuum/bosen"><strong>bosen</strong></a>项目和<a href="http://www.cs.cmu.edu/~muli/"><strong>李沐</strong></a>的<a href="https://github.com/dmlc/ps-lite"><strong>ps-lite</strong></a>（现已集成到<a href="https://github.com/dmlc">DMLC</a>项目中）。</p>
<p>下面是一个Go语言实现的多线程版本的参数服务器（用于Ftrl算法的优化），源码位置：<a href="https://github.com/vivounicorn/goline"><strong>Goline</strong></a>： <figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// data structure of ftrl solver.</span></span><br><span class="line"><span class="keyword">type</span> FtrlSolver <span class="keyword">struct</span> &#123;</span><br><span class="line">	Alpha   <span class="keyword">float64</span> <span class="string">`json:&quot;Alpha&quot;`</span></span><br><span class="line">	Beta    <span class="keyword">float64</span> <span class="string">`json:&quot;Beta&quot;`</span></span><br><span class="line">	L1      <span class="keyword">float64</span> <span class="string">`json:&quot;L1&quot;`</span></span><br><span class="line">	L2      <span class="keyword">float64</span> <span class="string">`json:&quot;L2&quot;`</span></span><br><span class="line">	Featnum <span class="keyword">int</span>     <span class="string">`json:&quot;Featnum&quot;`</span></span><br><span class="line">	Dropout <span class="keyword">float64</span> <span class="string">`json:&quot;Dropout&quot;`</span></span><br><span class="line">	N []<span class="keyword">float64</span> <span class="string">`json:&quot;N&quot;`</span></span><br><span class="line">	Z []<span class="keyword">float64</span> <span class="string">`json:&quot;Z&quot;`</span></span><br><span class="line">	Weights util.Pvector <span class="string">`json:&quot;Weights&quot;`</span></span><br><span class="line">	Init <span class="keyword">bool</span> <span class="string">`json:&quot;Init&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// data structure of parameter server.</span></span><br><span class="line"><span class="keyword">type</span> FtrlParamServer <span class="keyword">struct</span> &#123;</span><br><span class="line">	FtrlSolver</span><br><span class="line">	ParamGroupNum <span class="keyword">int</span></span><br><span class="line">	LockSlots     []sync.Mutex</span><br><span class="line">	log           log4go.Logger</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// fetch parameter group for update n and z value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(fps *FtrlParamServer)</span> <span class="title">FetchParamGroup</span><span class="params">(n []<span class="keyword">float64</span>, z []<span class="keyword">float64</span>, group <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !fps.FtrlSolver.Init &#123;</span><br><span class="line">		fps.log.Error(<span class="string">&quot;[FtrlParamServer-FetchParamGroup] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">&quot;[FtrlParamServer-FetchParamGroup] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> start <span class="keyword">int</span> = group * ParamGroupSize</span><br><span class="line">	<span class="keyword">var</span> end <span class="keyword">int</span> = util.MinInt((group+<span class="number">1</span>)*ParamGroupSize, fps.FtrlSolver.Featnum)</span><br><span class="line"></span><br><span class="line">	fps.LockSlots[group].Lock()</span><br><span class="line">	<span class="keyword">for</span> i := start; i &lt; end; i++ &#123;</span><br><span class="line">		n[i] = fps.FtrlSolver.N[i]</span><br><span class="line">		z[i] = fps.FtrlSolver.Z[i]</span><br><span class="line">	&#125;</span><br><span class="line">	fps.LockSlots[group].Unlock()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// fetch parameter from server.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(fps *FtrlParamServer)</span> <span class="title">FetchParam</span><span class="params">(n []<span class="keyword">float64</span>, z []<span class="keyword">float64</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !fps.FtrlSolver.Init &#123;</span><br><span class="line">		fps.log.Error(<span class="string">&quot;[FtrlParamServer-FetchParam] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">&quot;[FtrlParamServer-FetchParam] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; fps.ParamGroupNum; i++ &#123;</span><br><span class="line">		err := fps.FetchParamGroup(n, z, i)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			fps.log.Error(fmt.Sprintf(<span class="string">&quot;[FtrlParamServer-FetchParam] Initialize fast ftrl solver error.&quot;</span>, err.Error()))</span><br><span class="line">			<span class="keyword">return</span> errors.New(fmt.Sprintf(<span class="string">&quot;[FtrlParamServer-FetchParam] Initialize fast ftrl solver error.&quot;</span>, err.Error()))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// push parameter group for upload n and z value.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(fps *FtrlParamServer)</span> <span class="title">PushParamGroup</span><span class="params">(n []<span class="keyword">float64</span>, z []<span class="keyword">float64</span>, group <span class="keyword">int</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !fps.FtrlSolver.Init &#123;</span><br><span class="line">		fps.log.Error(<span class="string">&quot;[FtrlParamServer-PushParamGroup] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">&quot;[FtrlParamServer-PushParamGroup] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> start <span class="keyword">int</span> = group * ParamGroupSize</span><br><span class="line">	<span class="keyword">var</span> end <span class="keyword">int</span> = util.MinInt((group+<span class="number">1</span>)*ParamGroupSize, fps.FtrlSolver.Featnum)</span><br><span class="line"></span><br><span class="line">	fps.LockSlots[group].Lock()</span><br><span class="line">	<span class="keyword">for</span> i := start; i &lt; end; i++ &#123;</span><br><span class="line">		fps.FtrlSolver.N[i] += n[i]</span><br><span class="line">		fps.FtrlSolver.Z[i] += z[i]</span><br><span class="line">		n[i] = <span class="number">0</span></span><br><span class="line">		z[i] = <span class="number">0</span></span><br><span class="line">	&#125;</span><br><span class="line">	fps.LockSlots[group].Unlock()</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// push weight update to parameter server.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(fw *FtrlWorker)</span> <span class="title">PushParam</span><span class="params">(param_server *FtrlParamServer)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> !fw.FtrlSolver.Init &#123;</span><br><span class="line">		fw.log.Error(<span class="string">&quot;[FtrlWorker-PushParam] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span> errors.New(<span class="string">&quot;[FtrlWorker-PushParam] Initialize fast ftrl solver error.&quot;</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; fw.ParamGroupNum; i++ &#123;</span><br><span class="line">		err := param_server.PushParamGroup(fw.NUpdate, fw.ZUpdate, i)</span><br><span class="line">		<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">			fw.log.Error(fmt.Sprintf(<span class="string">&quot;[FtrlWorker-PushParam] Initialize fast ftrl solver error.&quot;</span>, err.Error()))</span><br><span class="line">			<span class="keyword">return</span> errors.New(fmt.Sprintf(<span class="string">&quot;[FtrlWorker-PushParam] Initialize fast ftrl solver error.&quot;</span>, err.Error()))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// to do update for all weights.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(fw *FtrlWorker)</span> <span class="title">Update</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">	x util.Pvector,</span></span></span><br><span class="line"><span class="params"><span class="function">	y <span class="keyword">float64</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">	param_server *FtrlParamServer)</span> <span class="title">float64</span></span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> !fw.FtrlSolver.Init &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0.</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> weights util.Pvector = <span class="built_in">make</span>(util.Pvector, fw.FtrlSolver.Featnum)</span><br><span class="line">	<span class="keyword">var</span> gradients []<span class="keyword">float64</span> = <span class="built_in">make</span>([]<span class="keyword">float64</span>, fw.FtrlSolver.Featnum)</span><br><span class="line">	<span class="keyword">var</span> wTx <span class="keyword">float64</span> = <span class="number">0.</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(x); i++ &#123;</span><br><span class="line">		item := x[i]</span><br><span class="line">		<span class="keyword">if</span> util.UtilGreater(fw.FtrlSolver.Dropout, <span class="number">0.0</span>) &#123;</span><br><span class="line">			rand_prob := util.UniformDistribution()</span><br><span class="line">			<span class="keyword">if</span> rand_prob &lt; fw.FtrlSolver.Dropout &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">var</span> idx <span class="keyword">int</span> = item.Index</span><br><span class="line">		<span class="keyword">if</span> idx &gt;= fw.FtrlSolver.Featnum &#123;</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">var</span> val <span class="keyword">float64</span> = fw.FtrlSolver.GetWeight(idx)</span><br><span class="line">		weights = <span class="built_in">append</span>(weights, util.Pair&#123;idx, val&#125;)</span><br><span class="line">		gradients = <span class="built_in">append</span>(gradients, item.Value)</span><br><span class="line">		wTx += val * item.Value</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> pred <span class="keyword">float64</span> = util.Sigmoid(wTx)</span><br><span class="line">	<span class="keyword">var</span> grad <span class="keyword">float64</span> = pred - y</span><br><span class="line">	util.VectorMultiplies(gradients, grad)</span><br><span class="line">	<span class="keyword">for</span> k := <span class="number">0</span>; k &lt; <span class="built_in">len</span>(weights); k++ &#123;</span><br><span class="line">		<span class="keyword">var</span> i <span class="keyword">int</span> = weights[k].Index</span><br><span class="line">		<span class="keyword">var</span> g <span class="keyword">int</span> = i / ParamGroupSize</span><br><span class="line">		<span class="keyword">if</span> fw.ParamGroupStep[g]%fw.FetchStep == <span class="number">0</span> &#123;</span><br><span class="line">			param_server.FetchParamGroup(</span><br><span class="line">				fw.FtrlSolver.N,</span><br><span class="line">				fw.FtrlSolver.Z,</span><br><span class="line">				g)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">var</span> w_i <span class="keyword">float64</span> = weights[k].Value</span><br><span class="line">		<span class="keyword">var</span> grad_i <span class="keyword">float64</span> = gradients[k]</span><br><span class="line">		<span class="keyword">var</span> sigma <span class="keyword">float64</span> = (math.Sqrt(fw.FtrlSolver.N[i]+grad_i*grad_i) - math.Sqrt(fw.FtrlSolver.N[i])) / fw.FtrlSolver.Alpha</span><br><span class="line">		fw.FtrlSolver.Z[i] += grad_i - sigma*w_i</span><br><span class="line">		fw.FtrlSolver.N[i] += grad_i * grad_i</span><br><span class="line">		fw.ZUpdate[i] += grad_i - sigma*w_i</span><br><span class="line">		fw.NUpdate[i] += grad_i * grad_i</span><br><span class="line">		<span class="keyword">if</span> fw.ParamGroupStep[g]%fw.PushStep == <span class="number">0</span> &#123;</span><br><span class="line">			param_server.PushParamGroup(fw.NUpdate, fw.ZUpdate, g)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		fw.ParamGroupStep[g] += <span class="number">1</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> pred</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="二阶优化方法">4.4 二阶优化方法</h2>
<h3 id="概览">4.4.1 概览</h3>
<p>大部分的优化算法都是基于梯度的迭代方法，其迭代式来源为泰勒展开式，迭代的一般式为：</p>
<p><span class="math display">\[
\begin{array}{l}
x_{k+1}=x_{k}+\alpha_kp_k
\end{array}
\]</span></p>
<p>其中<span class="math inline">\(\alpha_k&gt;0\)</span> 被称作步长，向量<span class="math inline">\(p_k\)</span> 被称作搜索方向，它一般要求是一个能使目标函数值（最小化问题）下降的方向，即满足：</p>
<p><span class="math display">\[
\begin{array}{l}
p_{k}^T\nabla f(x_k)&lt;0
\end{array}
\]</span></p>
<p>进一步说，<span class="math inline">\(p_k\)</span> 的通项式有以下形式：</p>
<p><span class="math display">\[
\begin{array}{l}
p_{k}=-B_{k}^{-1}\nabla f(x_k)
\end{array}
\]</span></p>
<p><span class="math inline">\(B_k\)</span> 是一个对称非奇异矩阵（大家请问为什么？）。</p>
<ul>
<li><p>在 Steepest Descent 法中 <span class="math inline">\(B_k\)</span> 是一个单位矩阵；</p></li>
<li><p>在 Newton 法中，<span class="math inline">\(B_k\)</span> 是一个精确的Hessian 矩阵 <span class="math inline">\(\nabla^2 f(x_k)\)</span>；</p></li>
<li><p>在 Quasi-Newton 法中， <span class="math inline">\(B_k\)</span> 是对Hessian矩阵的估计。</p></li>
</ul>
<p><span class="math display">\[
\begin{array}{l}
\because
p_{k}^T\nabla f(x_k)=-\nabla f(x_k)^TB_{k}^{-1}\nabla f(x_k)&lt;0\\
\therefore \text{$B_k$ is must positive definite.}
\end{array}
\]</span></p>
<p>这类优化方法大体分两种，要么是先确定优化方向后确定步长（line search），要么是先确定步长后确定优化方向（trust region）。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1atg85ts8kff2erd551fss2s39.png" width="500" />
</center>
<p>以常用的line search为例，如何找到较好的步长 <span class="math inline">\(\alpha\)</span>呢？好的步长它需要满足以下条件：</p>
<ul>
<li>Armijo 条件</li>
</ul>
<p>充分下降条件，即要使步长<span class="math inline">\(\alpha_k\)</span>在非精确一维搜索中能保证目标函数 <span class="math inline">\(f\)</span>下降，则它需要满足以下不等式：</p>
<p><span class="math inline">\(f(x_k+\alpha p_k) \le f(x_k) + c_1\alpha \nabla f_k^Tp_k\)</span></p>
<p><span class="math inline">\(c_1\)</span> 一般选取一个较小的值，例如：<span class="math inline">\(c_1=10^{−4}\)</span>。</p>
<p>Armijo 条件的几何解释如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apq85tf71ff74affhh8uh16na2a.png" width="400" />
</center>
<p>常用求解方法如下：</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Algorithm 3.Backtracking Line search}\\
\textbf{Require:}\;\; \rho \in (0,1), c \in (0,1)\\
\quad1.\;\;\textbf{choose }\hat{\alpha}&gt;0,\text{set $\alpha=\hat{\alpha}$}\\
\quad2.\;\;\textbf{repeat }\text{until }f(x_k+\alpha p_k) \le f(x_k) + c\alpha \nabla f_k^Tp_k\\
\quad3.\quad\quad\alpha=\rho\alpha\\
\quad4.\;\;\textbf{end(repeat)}\\
\quad5.\;\;\text{return }\alpha
\end{array}
\]</span></p>
<ul>
<li>Curvature 条件</li>
</ul>
<p>不只要求步长能使目标函数下降，还要求其程度，这个要求有点严格，一般只要做到Armijo条件就好了，不等式如下：</p>
<p><span class="math inline">\(\nabla f(x_k+\alpha p_k)^Tp_k \ge c_2 \nabla f_k^Tp_k, c_2 \in(c_1,1)\)</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apq8gg70htn1p57gv9qbj6k79.png" width="450" />
</center>
<ul>
<li>Wolfe 条件</li>
</ul>
<p>步长同时满足Armijo 条件和Curvature 条件则被称为其满足Wolfe 条件。</p>
<h3 id="牛顿法newton-method">4.4.2 牛顿法(Newton Method)</h3>
<ul>
<li><p>以<span class="math inline">\(x_0\)</span>点开始寻找<span class="math inline">\(f(x)=0\)</span>的解，在该点做切线，得到新的起点： <span class="math inline">\(x_1=x_0-\frac{f(x_0)}{f&#39;(x_0)}\)</span></p></li>
<li><p>迭代，直到满足精度条件得到<span class="math inline">\(f(x)=0\)</span>的最优解.</p></li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apq53v8s1567rgu1t1v14eaqjb13.png" alt="image_1apq53v8s1567rgu1t1v14eaqjb13.png-21.7kB" />
</center>
<p>从泰勒展开式得到牛顿法的基本迭代式：</p>
<p><span class="math display">\[
\begin{array}{l}
f(x_{n+1})=f(x_n)+\nabla f(x_n)(x_{n+1}-x_n)+\frac{1}{2}\nabla^2 f(x_n)(x_{n+1}-x_n)^2\\
\because \nabla f(x_{n+1})=\nabla f(x_n)+\nabla^2
f(x_n)(x_{n+1}-x_n)=0\\
\therefore x_{n+1}=x_n-\nabla^2 f(x_n)^{-1}\nabla f(x_n)\\
\end{array}
\]</span></p>
<p>对牛顿法的改进之一是使用自适应步长 <span class="math inline">\(\alpha\)</span>：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apq7j7prao3qfa1k6es0l83o1g.png" width="800" />
</center>
<p>但总的来说牛顿法由于需要求解Hessian 矩阵，所以计算代价过大，对问题规模较大的优化问题力不从心。</p>
<h3 id="拟牛顿法quasi-newton-method">4.4.3 拟牛顿法(Quasi-Newton Method)</h3>
<p>为解决Hessian 矩阵计算代价的问题，想到通过一阶信息去估计它的办法，于是涌现出一类方法，其中最有代表性的是DFP和BFGS(L-BFGS)，其原理如下：</p>
<p><span class="math display">\[
\begin{array}{l}
\text{We set $f(x_k)=f_k$ and  $\nabla f(x_k)$=$\nabla f_k$}\\
\because \nabla f_{k+1}\approx\nabla f_{k}+\nabla^2 f_{k}(x_{k+1}-x_k)\\
\therefore \nabla^2 f_{k}(x_{k+1}-x_k)\approx\nabla f_{k+1}-\nabla f_{k}\\
\text{our task is to approximate hessian matrix $\nabla^2 f_{k}$}\\
\textbf{set } s_k=x_{k+1}-x_k,y_k=\nabla f_{k+1}-\nabla f_k\\
\text{and the low-rank approximating of hessian matrix is $B_{k+1}$ then}\\
1.B_{k+1}s_k=y_k \quad \quad \\
2.\text{$B_{k+1}$must be symmetric.}\\
3.\text{We hope the new matrix can be stable and does not change wildly from iteration to iteration.}\\
\text{so we have a optimization problem:}\\
* \textbf{DFP}.\\
min ||B-B_{k}||_W\\
s.t.\;B=B^T\\
\quad \quad Bs_k=y_k\\
where\; ||B-B_{k}||_W=||W^{1/2}(B-B_k)W^{1/2}||\\
\text{W is any matrix satisfying } Wy_k=s_k\\
\text{The solution of this problem is:}\\
B_{k+1}=(I-(y_k^Ts_k)^{-1}y_ks_k^T)B_k(I-(y_k^Ts_k)^{-1}s_ky_k^T)+(y_k^Ts_k)^{-1}y_ky_k^T\\
\text{Note that if the initial Hessian approximation B_0 is positive definite then B_k will be positive definite}\\
\text{This algorithm is called DFP, named after Davidson, who discovered it in 1959, and Fletcher and Powell.}\\
\\
* \textbf{BFGS}.\\
\text{If we directly approximate Hessian&#39;s inverse $H_k=B_k^{-1}$ then we have a optimization problem:}\\
min ||H-H_{k}||_W\\
s.t.\;H=H^T\\
\quad \quad Hy_k=s_k\\
where\; ||H-H_{k}||_W=||W^{1/2}(H-H_k)W^{1/2}||\\
\text{W is any matrix satisfying } Ws_k=y_k\\
\text{The solution of this problem is:}\\
H_{k+1}=(I-(y_k^Ts_k)^{-1}s_ky_k^T)H_k(I-(y_k^Ts_k)^{-1}y_ky_s^T)+(y_k^Ts_k)^{-1}s_ks_k^T\\
\end{array}
\]</span></p>
<p>一些有用的资料：</p>
<ul>
<li>最优化相关书籍首推：《Numerical Optimization 2nd ed (Jorge Nocedal, Stephen J.Wright)》</li>
<li>vw源码：<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">vowpal_wabbit</a></li>
<li><a href="http://hunch.net/~jl/">John Langford</a>的<a href="http://hunch.net/">博客</a></li>
</ul>
思考一个问题：为什么通常二阶优化方法收敛速度快于一阶方法？
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1apsoja5s1iao1v9b22c17ie18hp9.png" width="400" />
</center>
<h2 id="owl-qn算法">4.5 OWL-QN算法</h2>
<h3 id="bfgs算法回顾">4.5.1 BFGS算法回顾</h3>
<p>算法思想如下：</p>
<p><strong>Step1:</strong> 取初始点<span class="math inline">\(x^{(0)}\)</span> ，初始正定矩阵<span class="math inline">\(H_0\)</span>，允许误差<span class="math inline">\(\epsilon&gt;0\)</span>，令<span class="math inline">\(k=0\)</span></p>
<p><strong>Step2:</strong> 计算: <span class="math display">\[p^{(k)}=-H_k \nabla f(x^{(k)})\]</span></p>
<p><strong>Step3:</strong> 计算<span class="math inline">\(\alpha_k&gt;0\)</span>，使得: <span class="math display">\[f(x^{(k)}+\alpha_kp^{(k)})=\min\limits_{\alpha \geq 0} f(x^{(k)}+\alpha p^{(k)})\]</span></p>
<p><strong>Step4:</strong> 令: <span class="math display">\[x^{(k+1)}=x^{(k)}+\alpha_k p^{(k)}\]</span></p>
<p><strong>Step5:</strong> 如果<span class="math display">\[||\nabla f(x^{(k+1)})|| \leq \epsilon\]</span>，则取<span class="math inline">\(x^{(k+1)}\)</span>为近似最优解；否则转下一步</p>
<p><strong>Step6:</strong> 计算：</p>
<p><span class="math display">\[s_k=x^{(k+1)}-x^{(k)}\]</span></p>
<p><span class="math display">\[y_k=\nabla f(x^{(k+1)})-\nabla f(x^{(k)})\]</span></p>
<p><span class="math display">\[H_{k+1}=H_k+\frac{1}{s_k^Ty_k}(1+\frac{y_k^TH_ky_k}{s_k^Ty_k})s_ks_k^T-\frac{1}{s_k^Ty_k}(s_ky_k^TH_k+H_ky_ks_k)\]</span></p>
<p>令<span class="math inline">\(k=k+1\)</span>，转<strong>Step2</strong>.</p>
<p>优点：</p>
<p>1、不用直接计算Hessian矩阵；</p>
<p>2、通过迭代的方式用一个近似矩阵代替Hessian矩阵的逆矩阵。</p>
<p>缺点：</p>
<p>1、矩阵存储量为<span class="math inline">\(n^2\)</span>，因此维度很大时内存不可接受；</p>
<p>2、矩阵非稀疏会导致训练速度慢。</p>
<h3 id="l-bfgs算法">4.5.2 L-BFGS算法</h3>
<p>针对BFGS的缺点，主要在于如何合理的估计出一个Hessian矩阵的逆矩阵，L-BFGS的基本思想是只保存最近的m次迭代信息，从而大大降低数据存储空间。对照BFGS，我重新整理一下用到的公式：</p>
<p><span class="math display">\[\rho_k=\frac{1}{y_{k}^T s_k}
 s_k=x_k-x_{k-1}
y_k\\
=\nabla{f(x_k)}-\nabla{f(x_{k-1})}
V_k\\
=I-\rho_{k}y_{k}s_{k}^T
\]</span></p>
<p>于是估计的Hessian矩阵逆矩阵如下：</p>
<p><span class="math display">\[
H_k=(I-\rho_{k-1}s_{k-1}y_{k-1}^T)H_{k-1}(I-\rho_{k-1}y_{k-1}s_{k-1}^T)+s_{k-1}\rho_{k-1}s_{k-1}^T  \\                                   =V_{k-1}^TH_{k-1}V_{k-1}+ s_{k-1}\rho_{k-1}s_{k-1}^T
\]</span></p>
<p>把 <span class="math display">\[
H_{k-1}=V_{k-2}^TH_{k-2}V_{k-2}+ s_{k-2}\rho_{k-2}s_{k-2}^T\]</span></p>
<p>带入上式，得：</p>
<p><span class="math display">\[H_k=V_{k-1}^TV_{k-2}^TH_{k-2}V_{k-2}V_{k-1}+ V_{k-1}^Ts_{k-2}\rho_{k-2}s_{k-2}^T V_{k-1}+s_{k-1}\rho_{k-1}s_{k-1}^T \]</span></p>
<p>假设当前迭代为<span class="math inline">\(k\)</span>，只保存最近的<span class="math inline">\(m\)</span>次迭代信息，（即：从<span class="math inline">\(k-m~k-1\)</span>），依次带入<span class="math inline">\(H\)</span>，得到：</p>
<p><strong>公式1：</strong></p>
<p><span class="math display">\[H_k=(V_{k-1}^TV_{k-2}^T\ldots V_{k-m}^T) H_k^{0}(V_{k-m}\ldots V_{k-2}V_{k-1})
 + (V_{k-1}^TV_{k-2}^T\ldots V_{k-m+1}^T) S_{k-m}\rho_{k-m}S_{k-m}^T (V_{k-m}\ldots V_{k-2}V_{k-1})\\
 + (V_{k-1}^TV_{k-2}^T\ldots V_{k-m+2}^T) S_{k-m+1}\rho_{k-m+1}S_{k-m+1}^T (V_{k-m+1}\ldots V_{k-2}V_{k-1})\\
+\ldots
+V_{k-1}^T s_{k-2}\rho_{k-2} s_{k-2}^TV_{k-1}
          +s_{k-1}\rho_{k-1}s_{k-1}^T
\]</span></p>
<p>算法第二步表明了上面推导的最终目的：找到第k次迭代的可行方向，满足：</p>
<p><span class="math display">\[ p_k=-H_k\nabla f(x_k)\]</span></p>
<p>为了求可行方向<span class="math inline">\(p\)</span>，有下面的:</p>
<p>two-loop recursion算法：</p>
<p><span class="math display">\[
\begin{align*}
&amp;q=\nabla f(x_k) \\
&amp;for (i=1 \ldots m)  \quad do \\
 &amp;\quad \alpha_i=\rho_{k-i}s_{k-i}^Tq\\
 &amp;\quad q=q-\alpha_iy_{k-i}\\
 &amp;end   \quad for\\
 &amp;r=H_k^{0}q \\
 &amp;for (i=m \ldots 1)   \quad do\\
    &amp;\quad \beta=\rho_{k-i}y_{k-i}^Tr \\
    &amp;\quad r=r+s_{k-i}(\alpha_i-\beta)\\
&amp;end  \quad for\\
 &amp;return   \quad r
\end{align*}
\]</span></p>
<p>该算法的正确性推导：</p>
<p>1、令: $ q_0=f(x_k)$ ，递归带入<span class="math inline">\(q\)</span>：</p>
<p><span class="math display">\[
\begin{align*}
q_i&amp;=q_{i-1}-\rho_{k-i}y_{k-i}s_{ki}^Tq_{i-1}\\                        &amp;=(I-\rho_{k-i}y_{k-i}s_{k-i}^T)q_{i-1} \\
          &amp;=V_{k-i}q_{i-1}\\
          &amp;=V_{k-i}V_{k-i+1}q_{i-2}\\
          &amp;=\ldots \\
          &amp; =V_{k-i}V_{k-i+1} \ldots V_{k-1} q_0\\
          &amp;=V_{k-i}V_{k-i+1} \ldots V_{k-1} \nabla f(x_k)
 \end{align*}
\]</span></p>
<p>相应的：</p>
<p><span class="math display">\[
\begin{align*}
\alpha_i&amp;=\rho_{k-i}s_{k-i}^Tq_{i-1}\\
&amp;=\rho_{k-i}s_{k-i}^T V_{k-i+1}V_{k-i+2} \ldots V_{k-1} \nabla f(x_k)
 \end{align*}
 \]</span></p>
<p>2、令：<span class="math inline">\(r_{m+1}=H_{k-m}q=H_{k-m}V_{k-i}V_{k-i+1} \ldots V_{k-1} \nabla f(x_k)\)</span></p>
<p><span class="math display">\[
\begin{align*}
r_i&amp;=r_{i+1}+s_{k-i}(\alpha_i-\beta)\\ &amp;=r_{i+1}+s_{k-i}(\alpha_i-\rho_{k-i}y_{k-i}^Tr_{i+1}) \\
&amp;=s_{k-i}\alpha_i+(I-s_{k-i}\rho_{k-i}y_{k-i}^T)r_{i+1}\\
&amp;=s_{k-i}\alpha_{i}+V_{k-i}^Tr_{i+1}
\end{align*}
\]</span></p>
<p>于是:</p>
<p><span class="math display">\[
\begin{align*}
r_1&amp;=s_{k-1}\alpha_1+V_{k-1}^Tr_2 =s_{k-1}\rho_{k-1}s_{k-1}^T \nabla f(x_k)+V_{k-1}^Tr_2\\
&amp;=s_{k-1}\rho_{k-1}s_{k-1}^T \nabla f(x_k)+V_{k-1}^T(s_{k-2}\alpha_2+V_{k-2}^Tr_3)\\
&amp;=s_{k-1}\rho_{k-1}s_{k-1}^T \nabla f(x_k)+V_{k-1}^Ts_{k-2}\rho_{k-2}s_{k-2}^TV_{k-1}\nabla f(x_k)+V_{k-1}^T V_{k-2}^T r_3\\
&amp;=\ldots \\
&amp;=s_{k-1}\rho_{k-1}s_{k-1}^T \nabla f(x_k)\\
&amp;+V_{k-1}^T s_{k-2}\rho_{k-2} s_{k-2}^TV_{k-1}  \nabla f(x_k)\\
&amp;+\ldots\\
&amp;+ (V_{k-1}^TV_{k-2}^T\ldots V_{k-m+2}^T) S_{k-m+1}\rho_{k-m+1}S_{k-m+1}^T (V_{k-m+1}\ldots V_{k-2}V_{k-1}) \nabla f(x_k)\\
&amp;+ (V_{k-1}^TV_{k-2}^T\ldots V_{k-m+1}^T) S_{k-m}\rho_{k-m}S_{k-m}^T (V_{k-m}\ldots V_{k-2}V_{k-1}) \nabla f(x_k)\\
&amp;+(V_{k-1}^TV_{k-2}^T\ldots V_{k-m}^T) H_{k-m}(V_{k-m}\ldots V_{k-2}V_{k-1}) \nabla f(x_k)
\end{align*}
\]</span></p>
<p>这个two-loop recursion算法的结果和**公式1*初始梯度**的形式完全一样，这么做的好处是：</p>
<p>1、只需要存储<span class="math inline">\(s_{k-i}、y_{k-i} （i=1~m）\)</span>；</p>
<p>2、计算可行方向的时间复杂度从<span class="math inline">\(O(n*n)\)</span>降低到了<span class="math inline">\(O(n*m)\)</span>，当<span class="math inline">\(m\)</span>远小于<span class="math inline">\(n\)</span>时为线性复杂度。</p>
<p>总结L-BFGS算法的步骤如下：</p>
<p><strong>Step1</strong>:选初始点<span class="math inline">\(x_0\)</span>，允许误差<span class="math inline">\(\epsilon &gt;0\)</span>，存储最近迭代次数<span class="math inline">\(m\)</span>（一般取6）；</p>
<p><strong>Step2</strong>:<span class="math inline">\(k=0, \quad \ H_0=I , \quad r=\nabla f(x_{0})\)</span>；</p>
<p><strong>Step3</strong>:如果 <span class="math inline">\(||\nabla f(x_{k+1})||\leq \epsilon\)</span> 则返回最优解<span class="math inline">\(x_{k+1}\)</span>，否则转<strong>Step4</strong>；</p>
<p><strong>Step4</strong>:计算本次迭代的可行方向：<span class="math inline">\(p_k=-r _k\)</span>；</p>
<p><strong>Step5</strong>: 计算步长<span class="math inline">\(\alpha_k&gt;0\)</span>，对下面式子进行一维搜索：</p>
<p><span class="math display">\[f(x_k+\alpha_kp_k)=\min\limits_{\alpha \geq 0} \quad   f(x_k+\alpha p_k)\]</span></p>
<p><strong>Step6</strong>:更新权重<span class="math inline">\(x\)</span>：</p>
<p><span class="math display">\[ x_{k+1}=x_k+\alpha_kp_k\]</span></p>
<p><strong>Step7</strong>: 如果 $ k &gt; m$ 只保留最近m次的向量对，需删除(<span class="math inline">\(s_{k-m},y_{k-m}\)</span>)；</p>
<p><strong>Step8</strong>:计算并保存： <span class="math display">\[
\begin{align*}
s_k&amp;=x_{k+1}-x_k\\
y_k&amp;=\nabla f(x_{k+1})-\nabla f(x_k)
\end{align*}
\]</span></p>
<p><strong>Step9</strong>:用two-loop recursion算法求得： <span class="math display">\[r_k=H_k\nabla f(x_k)\]</span></p>
<p><span class="math inline">\(k=k+1\)</span>，转<strong>Step3</strong>。</p>
<p>需要注意的地方，每次迭代都需要一个<span class="math inline">\(H_{k-m}\)</span> ，实践当中被证明比较有效的取法为：</p>
<p><span class="math display">\[
\begin{align*}
H_k^0&amp;=\gamma_k I\\
\gamma_k&amp;=\frac{s_{k-1}^Ty_{k-1}}{y_{k-1}^Ty_{k-1}}
\end{align*}
\]</span></p>
<h3 id="owl-qn算法原理">4.5.3 OWL-QN算法原理</h3>
<p><strong>1、问题描述</strong></p>
<p>对于类似于Logistic Regression这样的Log-Linear模型，一般可以归结为最小化下面这个问题：</p>
<p><span class="math display">\[
                          J(x)=l(x)+r(x)
                          \]</span> 其中，第一项为loss function，用来衡量当训练出现偏差时的损失，可以是任意可微凸函数（如果是非凸函数该算法只保证找到局部最优解），后者为regularization term，用来对模型空间进行限制，从而得到一个更“简单”的模型。 根据对模型参数所服从的概率分布的假设的不同，regularization term一般有：L2-norm（模型参数服从Gaussian分布）；L1-norm（模型参数服从Laplace分布）；以及其他分布或组合形式。</p>
<p>L2-norm的形式类似于：</p>
<p><span class="math display">\[
                         J(x)=l(x)+C\sum\limits_i{x_i^2}
\]</span> L1-norm的形式类似于：</p>
<p><span class="math display">\[
                         J(x)=l(x)+C\sum\limits_i{|x_i|}
\]</span></p>
<p>L1-norm和L2-norm之间的一个最大区别在于前者可以产生稀疏解，这使它同时具有了特征选择的能力，此外，稀疏的特征权重更具有解释意义。</p>
对于损失函数的选取就不在赘述，看两幅图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjdgn91r7v1p7a1o1c1o2f100b1t.png" width="400" /> 图1 - 红色为Laplace Prior，黑色为Gaussian Prior
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjf0o2mbd108vl2p1vhh1v5f2a.png" width="400" /> 图2 直观解释稀疏性的产生
</center>
<p>对LR模型来说损失函数选取凸函数，那么L2-norm的形式也是的凸函数，根据最优化理论，最优解满足KKT条件，即有：<span class="math inline">\(\nabla J(x^*)=0\)</span> ，但是L1-norm的regularization term显然不可微，怎么办呢？</p>
<p>2、Orthant-Wise Limited-memory Quasi-Newton</p>
OWL-QN主要是针对L1-norm不可微提出的，它是基于这样一个事实：任意给定一个维度象限，L1-norm 都是可微的，因为此时它是一个线性函数：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjijog11ju16bmmdk1rcg134d2n.png" width="300" /> 图3 任意给定一个象限后的L1-norm
</center>
<p>OWL-QN中使用了次梯度决定搜索方向，凸函数不一定是光滑而处处可导的，但是它又符合类似梯度下降的性质，在多元函数中把这种梯度叫做次梯度，见维基百科http://en.wikipedia.org/wiki/Subderivative</p>
举个例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjji7k12qhvta1gud16d21iv734.png" width="300" /> 图4 次导数
</center>
<p>对于定义域中的任何<span class="math inline">\(x_0\)</span>，我们总可以作出一条直线，它通过点<span class="math inline">\((x_0, f(x_0))\)</span>，并且要么接触f的图像，要么在它的下方。这条直线的斜率称为函数的次导数，推广到多元函数就叫做次梯度。</p>
<p>次导数及次微分： 凸函数<span class="math inline">\(f:I→R\)</span>在点<span class="math inline">\(x_0\)</span>的次导数，是实数c使得：</p>
<p><span class="math display">\[
                        f(x)-f(x_0)\ge c(x-x_0)
\]</span> 对于所有I内的x。可以证明，在点x0的次导数的集合是一个非空闭区间[a, b]，其中a和b是单侧极限</p>
<p><span class="math display">\[
              a=\lim_{x\to x_0^-}\frac{f(x)-f(x_0)}{x-x_0}\\
              b=\lim_{x\to x_0^+}\frac{f(x)-f(x_0)}{x-x_0}
\]</span></p>
<p>它们一定存在，且满足<span class="math inline">\(a ≤ b\)</span>。所有次导数的集合<span class="math inline">\([a, b]\)</span>称为函数<span class="math inline">\(f\)</span>在<span class="math inline">\(x_0\)</span>的次微分。</p>
<p><strong>OWL-QN和传统L-BFGS的不同之处在于：</strong></p>
<ul>
<li>利用次梯度的概念推广了梯度 定义了一个符合上述原则的虚梯度，求一维搜索的可行方向时用虚梯度来代替L-BFGS中的梯度： <span class="math display">\[
\begin{align*}
\Diamond_i f(x) &amp;=\left\{
           \begin{array}{**lr**}
           \partial_i^{-}f(x) &amp; if &amp;\partial_i^{-}f(x)&gt;0 \\
           \partial_i^{+}f(x)&amp; if &amp;\partial_i^{+}f(x)&lt;0\\
           0 &amp; &amp;otherwise
           \end{array}
\right.\\
\partial_i^{\pm}f(x)&amp;=\frac{\partial}{\partial x_i}l(x)+\left\{
           \begin{array}{**lr**}
           C\sigma (x_i) &amp;  if &amp;x_i\neq 0\\
           \pm C&amp; if &amp; x_i=0
           \end{array}
\right.\\
\partial_i^{-}f(x) &amp;\leq \partial_i^{+}f(x)
\end{align*}
\]</span> 怎么理解这个虚梯度呢？见下图： 对于非光滑凸函数，那么有这么几种情况：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjqkt419971tob174m1lmo1kih3h.png" width="300" /> 图5 <span class="math inline">\(\partial_i^-f(x)&gt;0\)</span>
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjr9sra7uhbh1hukbl01vtp3u.png" width="300" /> 图6 <span class="math inline">\(\partial_i^+f(x)&lt;0\)</span>
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjropb8ee7tf1hnck4doaf4b.png" width="400" /> 图7 otherwise
</center></li>
<li>一维搜索要求不跨越象限 要求更新前权重与更新后权重同方向：</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjjubf4103g1son9t5qe61q394r.png" width="300" /> 图8 OWL-QN的一次迭代
</center>
<p>总结OWL-QN的一次迭代过程：</p>
<ul>
<li><p>Find vector of steepest descent</p></li>
<li><p>Choose sectant</p></li>
<li><p>Find L-BFGS quadratic approximation</p></li>
<li><p>Jump to minimum</p></li>
<li><p>Project back onto sectant</p></li>
<li><p>Update Hessian approximation using gradient of loss alone</p></li>
</ul>
<p>最后OWL-QN算法框架如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_4/image_1fbjk825e1vldbo71as012u1gsi5o.png" width="400" />
</center>
<p>与L-BFGS相比，第一步用虚梯度代替梯度，第二、三步要求一维搜索不跨象限，也就是迭代前的点与迭代后的点处于同一象限，第四步要求估计Hessian矩阵时依然使用loss function的梯度（因为L1-norm的存在与否不影响Hessian矩阵的估计）。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>最优化</tag>
        <tag>第四章</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第七章 金融风控</title>
    <url>/article/fb9cd06d.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb2si3rln5ctqt223kn1bmt2t.png" width=266 /> 本章对于机器学习在金融风控领域的业务知识和相关应用做了较为详细的介绍。 <span id="more"></span></p>
<h1 id="金融风控应用">7. 金融风控应用</h1>
<h2 id="风控概述">7.1 风控概述</h2>
<h3 id="风控在行业上的区别">7.1.1 风控在行业上的区别</h3>
<p>不同行业的风控有不同的区别，大致区别如下图。其实大家也可以很直观的感觉到：比如，你去银行贷款，银行会让你提供各种材料，恨不得知道你祖宗八代的信息，而你去贷现金贷，恨不得提供个身份证号就给你放贷。不同业务场景下，面对的用户不同，风险不同，收益不同，在合适场景下做合适的事儿。 <!--more--></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb0arhlbdsbvghdlvnl1p70m.png" width="800" />
</center>
<h3 id="风控审批流程逻辑框架">7.1.2 风控审批流程逻辑框架</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb0e8jr1fd2joe1gij0dad1g.png" width="800" />
</center>
风控是整个金融业务的核心之一，而贷前、贷中、贷后是风控切入的三个场景。风控很大的工作量就是在判断用户的还款能力（比如，授信流程）和还款意愿（比如，反欺诈流程），技术角度，目前纯基于模型去做的公司我认为没有，大部分都是规则辅以模型的方式，但这里面数据是重中之重，一般会借助于自有数据、第三方数据等。一般系统架构上会是这样：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1cf4ccn4i13sja8vj6iucb15q936.png" width="450" />
</center>
<ul>
<li>业务对接系统 由于风控系统需要和所有业务系统对接，所以这个对接服务是必不可少的，一方面把接口变化控制在这里，另一方面可以做各种字段适配，以保证进入风控系统的业务数据是统一而纯粹的。</li>
<li>规则配置平台 业务方用于配置风控规则的界面，一个好的风控系统，是可以让业务人员脱离开发而独立配置各种规则和实验的。</li>
<li>冠军挑战者服务 这是AB test或者Bucket Test在金融行业的别名，由于风控涉及到风险控制指标（如逾期率）、第三方数据花费、订单通过率等诸多结果指标，现实往往是这三大类指标的tradeoff，所以需要有一个强大的效果测试服务，能让业务人员做实验。</li>
<li>工作流程服务 这个是风控引擎的调度服务，用于发起各种内部流程，如：取数据、解析规则、返回结果等，一般情况下不需要人工介入及交互，所以这里不需要很重的工作框架，例如Activiti。</li>
<li>规则引擎 用于解析和执行规则的核心服务，一般规则引擎都是基于RETE算法的产生式系统（大家如果学过离散数学会很熟悉这个概念），简单来说是如何高效定义和执行if-else，开源的框架最有名的是DRools，当然还有很多商用引擎。对于没有精力或者能力的团队可以直接用它，但有能力情况下建议还是自己做，毕竟像DRools这样的太通用、太重。</li>
<li>数据服务 这里包括第三方数据和自有数据，前者主要是采购的市面上第三方数据源，一般良心点的是查得收费的，这部分数据是风控的成本，要做好缓存和花费规划；后者是业务自身的数据，可以是业务数据、统计数据、挖掘数据等，两者在逻辑上是分开的，一般能用自有数据解决的就不用第三方数据，能用免费数据解决的不用收费数据。</li>
<li>反欺诈服务 这个是用来发现用户欺诈行为的，可以通过黑名单、类似广告中look alike用户发现、欺诈关系发现等方法和算法尽可能降低贷款风险，一般这类欺诈事件一旦发生，贷后催收就很被动了，资产会大概率减值。</li>
<li>前端报表服务 方便业务看数，可以是定制报表或自助报表的形式。</li>
<li>日志服务 日志在系统中是最核心的地位之一，决定了整个系统有多好用和合理，尤其冠军挑战者这样的服务和日志设计的好不好有及其紧密的关系。</li>
<li>数据采集服务 用来采集业务数据、行为数据等，属于常规服务。</li>
<li>模型服务 用于做模型inference，属于常规服务。</li>
<li>数据仓库与集市 离线部分服务，用于建立离线数据支持部分，帮助生成线上使用数据和模型，决定数据质量、数据丰富度等，是整个风控的重中之重。</li>
<li>离线挖掘服务 基于仓库或集市数据挖掘相关标签。</li>
<li>爬虫平台 抓取免费的第三方数据，属于常规服务。</li>
<li>机器学习平台 用于离线训练各种模型，属于常规服务。</li>
<li>大数据平台 包括hadoop平台、kafka服务、flume服务、streaming服务等大数据服务。</li>
</ul>
<h3 id="风控是需要动态闭环的">7.1.3 风控是需要动态闭环的</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb0had6rvj1qun11crkfakqd30.png" width="300" />
</center>
<p>风控是数据、模型/策略和监控的动态闭环，通过三要素不断迭代运转。</p>
<h3 id="数据是风控的核心">7.1.4 数据是风控的核心</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb0l9r33d01mg9s0aollj873m.png" width="800" />
</center>
<p>不同的数据刻画用户不同方面，好的数据事半功倍，差的数据事倍功半。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb0nke613ijn112e41osgs7s4g.png" width="350" />
</center>
<p>其中：DPD：Days past due，M：month，C：cycle，从这个月还款日到下个月还款日中间的30天。 逾期相关指标是风控中非常核心的部分，直接决定了公司资产减值情况，好的风控能很好的拿捏逾期与收益之间的平衡。</p>
<h3 id="融资租赁业务需要以风险为中心考虑收益和产品发展策略">7.1.5 融资租赁业务需要以风险为中心考虑收益和产品发展策略</h3>
Risk Adjusted Return on Capital：将未来可预计的风险损失量化为当期成本。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb2tj33bskjng1nl41nkt1kll3a.png" width="600" />
</center>
Economic Value Added：全面评价企业经营者有效使用资本和为股东创造价值的能力，是一种管理理念和企业文化。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb2si3rln5ctqt223kn1bmt2t.png" width="600" />
</center>
<p>这两个公式意味着我们需要在风险控制大框架下最大化压榨资本的剩余价值。</p>
<h3 id="风险政策是分层级联的">7.1.6 风险政策是分层级联的</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb2v2julls1ht2aro1d3r109s3n.png" width="500" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb309q0r43t0udlu16cm4c344.png" width="300" />
</center>
<p>风控政策（规则）是分场景分级级联的，不同场景下的策略打法不尽相同。政策制定会通过实验决定我们的投入产出比。</p>
<h3 id="风控是以若干假设为前提的">7.1.7 风控是以若干假设为前提的</h3>
<p>就像所有统计或机器学习的应用一样，规则和模型都是建立在一定的建设下才能成立的。</p>
<p>1、空间假设——度量意义，例如，“距离”这个定义是在欧式空间下的长度、角度还是在希尔伯特空间下的长度、角度。</p>
<p>2、样本量假设——统计意义，例如，达到什么样的样本量规模下，产生的实验结果才是有统计意义的。</p>
<p>3、样本标注假设——“坏”的意义，例如，我可以假设所有到期未还款的用户为坏样本，也可以假设所有被拖车的用户为坏样本，这与具体使用场景也有关系。</p>
<p>4、分布一致性假设——学习意义，例如，我们会假设近期历史数据的概率分布会和未来一段时间的数据分布一致。</p>
<p>5、概率分布假设——函数意义，例如，我们常常会假设，数据服从高斯分布。</p>
<p>6、极大似然假设——求解意义，例如，我们假设求得的参数能最大程度复现已有样本是我们想要的理想模型，那么使用极大似然即是合理方法。</p>
<h3 id="风控是个最优化问题">7.1.8 风控是个最优化问题</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb34ms5rcjtu0m8j168r12k96l.png" width="450" />
</center>
<p>毫无疑问，现实当中的大部分问题都可看做最优化问题，只是复杂度不同而已。风控可以看做是在权衡通过率、花费数据成本、产生的收益、逾期坏账、用户授信额度等等诸多要求的限制下的一个优化问题。</p>
<h3 id="风控是在不停的做实验">7.1.9 风控是在不停的做实验</h3>
在我看来风控是一门实验科学，金融行业里叫冠军者挑战赛，互联网行业叫AB Test、Bucket Test，一篇经典的论文如下：《Overlapping Experiment Infrastructure: More, Better, Faster Experimentation》，是源自Google的分层实验架构，它影响了整个互联网的AB Test工程架构。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb370rj1ams1up5valncu142v7s.png" width="800" />
</center>
<h3 id="保证风控实验的置信度在于正确分割流量">7.1.10 保证风控实验的置信度在于正确分割流量</h3>
实验要保证结果的置信度，是需要正确分割流量的，一旦不合理则实验结果无效甚至误导，比如著名的Simpson's Paradox，就是违反了分布一致性假设的典型例子，明明单独看商学院和法学院，男生录取率都远高于女生，但从整体看女生录取率却远高于男生：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb390dqu291jn91d3dnmadf93.png" width="500" />
</center>
也有一些基于统计的方法估计流量切分置信度，例如下面这种方法：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb3a10i126a32q42em79d889t.png" width="600" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb3aqn31jhok2mgdfrtp1rvuaq.png" width="500" />
</center>
<h3 id="评价指标在风控中是至关重要的">7.1.11 评价指标在风控中是至关重要的</h3>
<p>风控规则和模型会涉及各种变量，例如：</p>
<p>1、连续型变量——价格、时间等，值域在实数域，可进行加、减、乘、除、比较等算术运算；</p>
<p>2、二元离散型变量——只有两种状态，如：0/1、真/假、正/负、逾期/正常、点击/未点击等；</p>
<p>3、顺序离散型变量——逾期状态（M0、M1……）、年龄等，值域在整数域或自然数域，可进行比较运算；</p>
<p>4、无序离散型变量——性别、颜色等，值域在整数域或自然数域，可完全枚举，但不能进行比较运算。</p>
<p>但不管什么数据源、特征、策略、模型评价，都应该以业务需求为导向、能区分用户行为为目标。</p>
各种评价指标体系如下，实际当中合理使用即可。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb3cspl12vi129e1b241gnk1sl9c1.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb3e44g1n1j1t5q11nekco1h3fce.png" width="800" />
</center>
<h3 id="有效监控对风控业务保驾护航">7.1.12 有效监控对风控业务保驾护航</h3>
<p>毫无疑问，各种维度的数据监控是风控业务的保镖。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1ccb3fr2t1i1h1nr2hct57bkh0d8.png" width="800" />
</center>
<h2 id="风控平台架构">7.2 风控平台架构</h2>
<p>实践中，我们自研风控系统的目标是以平台方式提供给公司内外业务人员做配置化风险政策制定、风控模型构建和实验、风控效果监测、风控能力输出、风险客户画像等等。 一般来说，了解一个公司风控能力的强弱有这么几点：</p>
<p>1、对公司业务场景及一线业务的理解深度</p>
<p>2、数据质量及由业务规模决定的<strong>标注</strong>数据规模</p>
<p>3、风控系统针对业务人员的自助程度、配置快速性</p>
<p>4、风控模型构建、实验及应用能力</p>
<p>5、涉及人工审核的运营能力</p>
<p>6、数据化监测及分析能力</p>
从系统研发角度，市面上其实有很多做风控系统的公司，比如：大的有FECO，小的有各个创业公司，但坦白地讲，风控能力作为保证公司长治久安和业务稳步发展的核心能力之一，有一定业务量且有技术能力的公司一定会自研，这其实也是在国内做2B业务的一个难点，但凡有能力的公司，谁也不愿意核心被人卡着，此外国内企业对2B业务的付费意愿也不足，所以我真心佩服做2B业务还能做起来的公司。 ### 7.2.1 风控系统发展概述 一般公司的风控系统的发展可能会有这么几个阶段：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/%E5%8F%91%E5%B1%95%E6%AF%94%E8%BE%83.png" width="800" />
</center>
<p>1、采购现成系统显然是貌似最省事儿的，从短期来看，可以让公司业务快速展业，这个阶段抢占业务山头是最重要的，但长远来看，可能会遇到的问题不少，比如：和现有业务贴合度不够时，需要额外定制化开发，势必会产生一系列费用，此外数据使用、模型使用、系统咨询、系统培训等等都会产生费用，当业务量起来后，再想换系统那成本就很高了。</p>
<p>2、当公司具有开发能力时，基于采购的系统做定制化封装也不失为一条路，但是从可维护性、成本角度来看，未来的性价比依然很低。</p>
<p>3、开始就具有技术能力的公司，可能会选择基于开源框架做自研，好处是可控性和业务贴合度都比较好，但做技术的人都知道，当你基于一套开源框架想干好活儿时，你需要熟悉整个框架。举个例子，风控政策制定是业务强需求，那么系统必须支持规则配置和解析，于是很多公司会使用开源规则引擎，例如DRules，实际上你需要的可能只是它的一部分功能，但如果不对整个框架熟悉，未来出了线上问题你可能哭都没地儿去；更糟糕的是，不是每个团队成员都熟悉开源框架，当人员离职后可能带来系统上的风险。</p>
<p>所以只要有能力，我们会选择全套纯自研，进而迈向云端平台化，未来还可能成为一个技术盈利点，比如我们的很多线下合作渠道没有技术人员又想做自己的风控，乐观情况下，我们可以开个账号做个配置就能实现风控能力输出。</p>
<h3 id="风控系统架构">7.2.2 风控系统架构</h3>
其实万事万物都有其相通性，尤其在系统架构上，在我看来，广告投放系统、推荐系统与风控系统具有极高相通性，比如，系统需要有够好的稳定性、容错性（包括防雪崩）、扩展性、并发性（包括服务降级）、对算法的支持性、标准化日志、权限控制、实时数据采集、数据可视化、数据统计、指标监控、自动化运维等等，由于我们之前恰好都做过，整体架构类似云原生，比如大体可以有以下架构：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/arch.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/ts%281%29.png" width="800" />
</center>
<p>1、统一的日志格式及服务，这个是要放在首位设计的，这里的统一体现在几个方面：</p>
<ul>
<li><p>统一的日志格式规范，每一个字段、每一个嵌套关系、每一个扩展段等等都有严格的规范定义，技术选型方面采用ProtoBuf，这样将来对日志的解析可以采用一套方法，管理方便且不容易出错，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package pb_interface.fintech;</span><br><span class="line">import &quot;pb_interface/fintech/*/*.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/**/**.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/***/***.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/****/****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">import &quot;pb_interface/fintech/*****/*****.proto&quot;;</span><br><span class="line">message FinTechPbLog&#123;</span><br><span class="line">	required string pbLogId=1;		//log唯一标识</span><br><span class="line">	required string createTime=2;	//生成时间</span><br><span class="line">	required string serveName=3;	//服务名称</span><br><span class="line">	optional int32 errCode=4;		//返回码:0正常,非0异常</span><br><span class="line">	optional string errMsg=5;		//返回描述</span><br><span class="line">	optional pb_interface.fintech.*.* *=6; //主引擎服务日志</span><br><span class="line">	optional pb_interface.fintech.**.** **=7;//规则引擎服务日志</span><br><span class="line">	optional pb_interface.fintech.***.*** ***=8; //数据处理服务日志</span><br><span class="line">	optional pb_interface.fintech.****.**** ****=9;//配置更新服务日志</span><br><span class="line">	optional pb_interface.fintech.***.*** ***=10; //引擎回调服务日志</span><br><span class="line">	optional pb_interface.fintech.*.** ***=11; //数据源指标字段日志</span><br><span class="line">	optional pb_interface.fintech.**.** **=12;//指定名单服务日志</span><br><span class="line">	optional pb_interface.fintech.*.** **=13;//图像处理服务日志</span><br><span class="line">	optional pb_interface.fintech.**.** **=14;//明细服务日志</span><br><span class="line">	optional pb_interface.fintech.**.** **=15;//inference服务日志</span><br><span class="line">	optional pb_interface.fintech.***.** ***=16;//异步交互服务日志</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>统一的采集、解析、分析、展示方案，包括提供给算法团队的特征字段，这样在使用层面极大地方便了自己和降低出问题的概率。</p></li>
<li><p>统一的监控展示方案，对应用系统涉及的从前到后的一系列交互统一做监控，能够对每个请求的今生来世做到一通贯穿。</p></li>
<li><p>统一的数据安全方案，包括脱敏方案、提取流程、加密方案、反显方案等，做到分层分级安全可控。</p></li>
</ul>
<p>2、统一的版本及权限控制，包括以下几个方面：</p>
<ul>
<li><p>代码版本需要有一套管理流程，代码提交前必须做交叉Code Review</p></li>
<li><p>所有的风控模型也需要做类似的版本管理，任何一个模型的特征、权重、参数、分流情况等都需要控制到</p></li>
<li><p>对接入风控的业务系统做统一的接口认证和鉴权控制</p></li>
<li><p>对使用系统的用户做统一的分组权限控制</p></li>
</ul>
<p>3、风控对接系统 - 对接业务系统服务，采用标准化的RESTful接口对接所有业务系统，由于受限于数据源的获取速度，所以风控审批执行会同时支持同步模式和异步模式</p>
<ul>
<li>业务配置服务，除非新增数据源，否则所有风控政策制定都采用可视化配置方式实现，无需代码开发，且实时生效。对于风控模型使用也是类似的逻辑，只要基本的特征数据没有增加，都以配置方式实现模型应用。</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-02-15%20%E4%B8%8B%E5%8D%8812.09.38.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1e13i9skc33dal1mkp1jrn3js1e.png" width="800" />
</center>
<p>4、AB Test服务 - 大的方面支持订单粒度和用户粒度随机或有策略AB，细的方面支持用户的灵活分组，例如：年龄、地区等以及这些条件的交叉</p>
<ul>
<li><p>每个分组的实验量必须具有统计意义，测试时间要足够，并明确每个实验的从前端到后端的全路径</p></li>
<li><p>同一个用户在相同分流策略下可重入，不会出现一个用户一会儿审批通过一会儿审批拒绝，否则不仅用户体验差，还会招来用户投诉</p></li>
<li><p>由于汽车的客单价比较高，实验表现期很长，所以每次实验要做到尽量降低实验成本，尽可能的利用历史数据</p></li>
<li><p>所有实验都是可视化实时配置且有相应实验运营后台，展示每个实验的详细情况</p></li>
<li><p>离线日志回放，每做一个新模型，能够将历史样本批量回放，一定程度模拟真实场景效率和效果表现</p></li>
</ul>
<p>5、风控主服务 - 初始化全局环境、串流程，调度和组合各个微服务的功能</p>
<ul>
<li>针对同步或异步场景对业务系统返回结果或做异步回调</li>
</ul>
<p>6、规则解析服务</p>
<ul>
<li><p>平台在设计时，业务流程和业务规则是完全分开不耦合的，所以规则解析服务只负责解析、检查和执行规则。在风控领域，政策规则的特点是：有大量规则（甚至规则的模式间有一定重复性），但变化并不那么多。而开源的类似Drools的框架，虽然基本能满足需求但一方面随着业务的复杂性越来越高，管理起来越来越费劲，另一方面它实在太重了，学习、维护成本高还不能从架构层面锻炼队伍。 所以我们干脆以RETE算法（论文见：Charles Forgy的 《Rete: A Fast Algorithm for the Many Pattern/Many Object Pattern Match Problem》.）及编译原理的语法分析树解析算法为蓝本自研。</p></li>
<li><p>在操作符方面，针对风控业务，至少需要支持：</p>
<ul>
<li><p>&amp;&amp;</p></li>
<li><p>||</p></li>
<li><p>!</p></li>
<li><p>null判断</p></li>
<li><p>==/!=</p></li>
<li><p>in/not in</p></li>
<li><p>包含/不包含</p></li>
<li><p>前/后缀等</p></li>
</ul></li>
<li><p>在管理模式方面，至少需要支持：</p>
<ul>
<li><p>规则集合管理</p></li>
<li><p>规则优先级</p></li>
<li><p>规则互斥</p></li>
<li><p>规则依赖</p></li>
<li><p>规则循环</p></li>
<li><p>规则有效期</p></li>
<li><p>规则缓存等</p></li>
</ul></li>
<li><p>在取值管理上，至少要支持：</p>
<ul>
<li><p>常量</p></li>
<li><p>变量</p></li>
<li>自定义公式</li>
</ul></li>
<li><p>在服务部署和响应上，服务横向扩展、解析可以并行执行；单规则解析响应时间在整个规则执行耗时上要做到占比小于99.9%，实际当中，特征取数占执行时间的大头，规则解析时间忽略不计</p></li>
</ul>
<p>7、Inference服务 一系列微服务，实现y=f(x)的特征取数和计算。需要支持：</p>
<ul>
<li><p>XGBoost/LightGBM（ATM类模型）</p></li>
<li><p>Logistic Regression</p></li>
<li><p>MLP及DeepFM类前向传播</p></li>
<li><p>记录时点特征日志、inference日志和模型计算结果</p></li>
</ul>
<p>8、关联及反欺诈服务</p>
<p>在风控场景下，用户的申请能否通过，主要衡量两方面：</p>
<ul>
<li><p>用户的还款能力 还款能力与国家经济情况、用户个人经济情况、家庭突发情况等有关系，可以围绕着用户的属性数据和消费行为数据做刻画</p></li>
<li><p>用户的还款意愿 真正影响公司资产质量的是对用户还款意愿的预判及用户是否会发生欺诈。欺诈行为往往不是个体行为，对于像汽车这样的大宗消费品，如果发生团体欺诈，损失可想而知。</p></li>
<li><p>关联反欺诈，根儿上主要还是依赖能够拿到的数据，做法上大致有两大类方法：</p></li>
<li><p>想象每个用户是一个圆点，每个实体（如某4s店、某银行）是个方点，圆点和圆点或圆点和实体之间的边是关系或行为，利用图算法可以查找异常聚集、多度的多头借贷等</p></li>
<li><p>类似广告的look-alike，分析已有的欺诈种子用户，找到和他最类似的用户等</p></li>
</ul>
<p>9、在线数据服务</p>
<ul>
<li><p>特征数据及实时数据服务，主要负责几个方面：</p>
<ul>
<li><p>离线生成的特征数据在线使用，风控模型中有一类特征是通过离线挖掘生成后导入线上的，这类特征大部分是T+1特征及月、季度、年时间范围特征</p></li>
<li><p>反馈类特征数据在线使用，这类特征主要与用户行为有关，例如，某个渠道当天进件量，配合实时数据采集服务，这类特征需要伪实时或实时更新</p></li>
<li><p>模型权重数据在线使用，包括离线模型权重和online learning模型权重。在机器学习相关工程应用中，特征的online更新（用的更多）和模型的online更新都可以起到捕捉实时数据概率分布的作用 ，可单独使用也可结合使用，但特征或权重监控必须做到位</p></li>
<li><p>数据缓存服务，承担各类数据的缓存工作</p></li>
</ul></li>
<li><p>数据监控服务，主要监控以下几类：</p>
<ul>
<li><p>特征监控：监控特征分布是否有大波动、缺失特征是否有大波动等，例如，由于系统bug导致某个特征大量缺失，通过监控立刻报警并熔断</p></li>
<li>权重监控：监控模型权重分布是否有大波动、权重重要性排序是否有大波动等，例如，在online learning（如：FTRL）中，本就使用类似SGD方式更新权重，虽然有L2正则在一定程度上帮助稳定权重更新，但依然无法避免权重可能学飞掉，所以有效的监控很重要，一旦波动过大就做一次批量样本的模型修正</li>
<li>卡单监控：全流程描述一个单子从提报到生效的全链路，可视化的告诉运营和开发人员，单子到哪儿了，卡那儿了，由于全流程往往需要多个独立系统互相配合，所以开篇讲到的统一日志设计的重要性不言而喻</li>
<li>运维监控：对系统做接口粒度监控，流量如何、响应时间如何等</li>
<li><p>业务指标监控：监控核心业务指标，例如，实时自动审批率表现如何</p></li>
</ul></li>
</ul>
<p>10、实时数据采集服务 - 外部合规数据接入服务，由于一家公司的数据积累毕竟有限，所以风控业务开展往往需要采购第三方数据： - 采购时首要考虑数据是否为一手数据、数据是否合规合法、获取时用户是否知晓且主动授权等 - 其次考虑数据的覆盖率如何，例如，人群覆盖率 - 然后考虑数据在风控政策或风控模型上的贡献度 - 最后是商务谈判，这一步一定要有技术参与，尽可能保证数据接入标准化，方便接入服务，以上完成后，外部数据的接入从时间和质量上都会可控</p>
<ul>
<li><p>提报业务数据，采集销售或用户在提报时录入的信息</p></li>
<li><p>用户及渠道行为数据，采集用户或者渠道业务时点的行为，例如：某个用户在几个渠道下过单，某个渠道当前进件量是否异常等</p></li>
</ul>
<p>11、模型一键发布及数据导入服务，连接线上与线下的桥梁，导入效率要够高，对大数据量以mapreduce方式支持集群数据导入 - 模型一键发布服务，管理和发布离线训练好的模型，可将模型一键发布到测试、UAT、生产等环境</p>
<ul>
<li>数据导入服务，将离线特征数据及其他必要数据导入线上</li>
</ul>
<p>12、机器学习平台 - 广义来说，整个风控平台就是个机器学习平台，同时包括离线和在线服务</p>
<ul>
<li>狭义来说，包括离线日志处理、数据标注、特征分析与提取、模型Pipline离线训练、模型测试验证、日志回放模拟、模型剪枝和压缩等等。我们把以上步骤封装成各种机器学习组件，一定程度上，用户不需要写代码，而是采取可视化、拖拽方式建模。</li>
</ul>
<p>总的来说一套成熟的风控平台需要多年的技术打磨，以平台方式而不是软件方式打造，一方面要保证不被点状的需求带偏，另一方面重视业务通用性和使用体验、最后设计时要有一定高度，以适应未来未知的挑战。</p>
<h2 id="风控建模方法">7.3 风控建模方法</h2>
<p><strong>金融的本质是基于信用风险的生意</strong>，而金融天生又是厌恶风险的，不管是为有钱人理财还是为缺钱人融资。所以要做好这个生意，需要：</p>
<ul>
<li><p>尽量保证资产的安全，毫无疑问，这个是金融的基石但不是唯一目标</p></li>
<li><p>尽量保证资源的最优化配置，不同机构最优化的目标不一样，比如，可以是企业利益最大化，或者兼顾社会责任等</p></li>
</ul>
<p>虽然现在互联网金融一地鸡毛，但是从互联网行业（计算广告、智能推荐等）继承而来的建模方法和系统思维，私认为是远领先于传统金融机构的。</p>
<h3 id="建模概述">7.3.1 建模概述</h3>
<p>风控建模的目的主要有：</p>
<ul>
<li><p>通过完备的理论将风险数据化，减少主观性，把过去依靠“经验”的授信变成数据化的授信，把判断过程中的物料全部数据化落地存储，做到有根有据、可查可追</p></li>
<li><p>提高最优化资源配置能力，将风险考量放入到衡量公司每个项目的盈利能力中，风控一定不是一味地降低风险，而是tradeoff风险和收益</p></li>
<li><p>提高运营效率、降低运营成本，显而易见，全自动的审核速度是秒级甚至毫秒级的，而人工审核是几分钟级、十几分钟甚至小时、跨天的。当然，现阶段受限于能够获取的数据规模和质量，人工审核依然必不可少，但风控建模依然可以很好的去辅助人工审核。</p></li>
</ul>
一般来说建模有以下几个步骤：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/step.png" width="350" />
</center>
<h3 id="需求分析与目标定义">7.3.2 需求分析与目标定义</h3>
<ul>
<li>需求分析</li>
</ul>
<p>明确了业务需求并准确做出分析，项目就成功了一半，这个很考验产品、研发同学的分析能力。我们强调不要过分建模，不是所有看似建模的需求需求都需要通过建模来完成，很多情况下if-else能搞定的事儿就不要用模型，大家容易犯的错误是拿着锤子看什么都像钉子。</p>
<ul>
<li>目标定义</li>
</ul>
<p>目标定义是需求分析里的一个阶段，我单独拿出来强调。明确将来应用的场景进而确定建模目标是什么，这一步决定了将来应用的成败。 例如：风控里最常做的事儿是预测用户的逾期概率，你需要进一步明确： - 是M1逾期率还是首期逾期率 - 什么样的用户被定义为“坏”用户 - 是融资租赁场景还是售后回租场景 - 新车还是二手车 - 白户做不做（明确白户的定义是什么）</p>
<h3 id="数据准备">7.3.3 数据准备</h3>
规范化对数据分层、分主题管理，确定建模需要什么数据，这些数据从哪儿来放在哪儿了，字段含义是什么，缺失情况如何，是否能够直接使用，能回溯多久等等一系列数据需求，数据需要以统一模式存储和管理，体系化做数据积累，不要来一个项目做一个。 一般采用数据仓库+数据集市方式管理，架构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/tt.png" width="800" />
</center>
<p>其实这一步是贯穿公司数据管理整个过程的，建模只是受益方之一，机器学习领域成熟的模型足够多，但如果没有好的数据体系保证质量，往往事倍功半。 一般来说，风控数据来源主要有三部分：</p>
<ul>
<li><p>以订阅方式获取的业务数据，例如：用户进件时的用户信息、车辆信息、融资信息</p></li>
<li><p>以采集方式获取的行为数据，例如：某个渠道、某些地域的进件行为、用户群申请行为</p></li>
<li><p>以购买方式获取的合规数据，例如：中国人民银行征信数据</p></li>
</ul>
<p>1、Stage层，所有数据通过数据总线以既定的规范分主题接入，这一层是最原始的数据，原则上不对外提供服务。</p>
<p>2、ODS层，对Stage层数据做不带业务逻辑的加工和清洗，为将来抽象到上一层做准备，同样原则上不对外提供服务。</p>
<p>3、MDS层，原则上所有业务需求涉及的数据都应该能得到满足，这一层会分层、分主题的做数据加工，数据要尽可能复用。</p>
<p>4、公共主题，所有经过业务逻辑处理的、定义明确的、口径一致的可公共使用的数据会放在这一层，例如，用户的基本信息，年龄、性别、唯一标识等。</p>
<p>5、垂直集市，基于MDS数据，加工并抽象出来的某个垂直业务主题的数据，这层可认为是此业务主题下的标准数据，例如：名为dm_risk_secondhand_nobehavior_features_116_v1 的宽表为风控二手车业务场景下针对白户的v1.0含有116个特征的数据集合</p>
<h3 id="数据标注">7.3.4 数据标注</h3>
<p>数据标注是数据准备里的一部分，这里单独拿出来做强调，它是风控建模里的一个难点和重点。目前工业应用里最多的还是监督学习supervised learning，需要对数据做样本标注，对分类问题，标注样本的目标类别，对回归问题，标注样本的目标值。 一般来说，对于正常业务量的汽车金融公司，以36期为主要产品的话，早期模型应用会较少（从已经有大量数据积累的场景transfer过来的模型除外），因为数据量级和数据表现都不充足，公司展业三年后开启模型应用之旅。 先介绍几个风控常用的指标和数据标注方法，会影响到样本选取和数据标注，进而影响风控建模质量或基于IFRS9的预期损失准备金拨备：</p>
<ul>
<li><p><strong>账龄(Month on Book，MOB)</strong></p>
<p>指合同生效并放款后的月份，其最大值与金融产品期限有关。 以汽车金融主流的36期产品参照，MOB最大值为36，其中： MOB0 = 合同生效放款的日期到当月月底 MOB1 = 放款后第2个月（1号到月底的整月） ...... MOB36 = 放款后第36个月（1号到月底的整月） <strong>例如：</strong> 2020年2月17日合同生效并放款的订单： MOB0 = 2020年2月 MOB1 = 2020年3月 ...... MOB36 = 2023年2月</p></li>
<li><p><strong>逾期天数(Days Past Due，DPD)</strong></p>
<p>1、逾期天数 = 用户实际还款日 - 合同约定应还款日 <strong>例如：</strong> 假设合同约定每月还款日为6号，用户9号还款，那么逾期天数为3天</p>
<p>2、把上面的逾期天数按照某种规则划分区间后定义<strong>逾期期数(M)</strong> <strong>例如：</strong> M0 = 未逾期 M1 = 逾期1-30天，每家公司根据各自的催收策略不同，会细分该档，另外涉及到逾期征信上报的，各家容忍度也不一样，M1数据是目前风控建模用的最多的。 M2 = 逾期31-60天 M3 = 逾期61-90天 M4 = 逾期91-120天 M5 = 逾期121-150天 M6 = 逾期151-180天 M7 = 逾期超过180天，此时资产大概率回收无望，一般会采取核销。</p></li>
<li><p><strong>逾期率(Overdue Rate)</strong></p>
<p>1、订单粒度逾期率 = 逾期订单数 / 合同生效订单总数</p>
<p>2、金额粒度逾期率 = 逾期金额 / 合同生效订单总金额 它是一个时点指标且会和逾期期数相关，比如：2020.2.19日的M1逾期率</p></li>
<li><strong>账龄分析(Vintage Analysis)</strong> 通过看逾期率，可以知道某个时点的资产情况，但无法知道变化趋势，所以需要做账龄分析，一般方法是：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/vintage.png" width="800" />
</center>
<p><strong>例1：</strong></p>
假设针对新车消费贷场景的12期产品(数据为编造)
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1e1gu26h62uaq13l27sm19d39.png" width="800" />
</center>
<p>其中，Vintage曲线的横坐标为账龄(MOB)，纵坐标为资产质量(如：逾期率)，每条曲线代表一个放款周期(如：月)。 账龄分析可以帮助我们得到以下信息：</p></li>
<li><p><strong>确定资产质量好坏情况</strong> Vintage曲线平缓稳定后(随着MOB增加，切线斜率接近0)的逾期率最能代表当期资产质量，如果曲线不能收敛，需要要做进一步分析。 <strong>如例1：</strong></p>
<p>3月份生效的订单逾期率在1.3%左右稳定，可以认为此时这部分资产质量基本稳定。</p></li>
<li><p><strong>分析资产质量变化规律</strong></p>
<p>1、如果发现逾期率一直上升(随着MOB增加，切线斜率平稳增加或下降很小)，需要检查是不是逾期数据取数逻辑或质量有问题，如果确定系统没问题，那么需要尽快分析原因、做风控政策调整。</p>
<p>2、 如果逾期率超过某个阈值(比如：2%)有失控趋势，则需要调整风控尺度，收口业务规模。</p>
<p>3、 如果发现前期逾期率上升很快(随着MOB增加，切线斜率迅速增加)甚至具有一定特性（如：地域性），那么很大可能是发生团体欺诈了。</p>
<p>4、 如果逾期率上升后很快下降，则很可能是计算方法或数据质量有问题了。</p>
<p><strong>如例1：</strong></p>
<p>1月份控制的还行，最终逾期率1.5%左右，跑完了所有账期，在2月份出现逾期率明显上升，说明控制的不好或者是为了某种销售策略（如，想做做春节前冲量），在分析原因后修正了3月份的风控策略，使得逾期率下来并稳定在1.3%左右。</p>
<ul>
<li><strong>时点质量界定</strong></li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/dur.png" width="600" />
</center>
<p>风控建模或分析，选取基准时点很重要，时点选的太晚（如，所有账期走完），则之前的数据分布和未来数据分布很可能差异过大，导致出来的模型泛化性较差；时点选的太早，则风险暴露不充分，同样会导致泛化性较差，所以通过分析Vintage曲线看资产质量变化，可以帮助定义基准时点，提高未来模型的质量，ps：这点是与计算广告、推荐和搜索相比差别最大的难点，它们的数据标注不存在滞后性，比如：对广告的一次曝光，用户看到后想点就点了，不想就关了，从概率建模角度，这是典型的Bernoulli Distribution。此外这个滞后性也决定了风控做E&amp;E(Explore and Exploit)的成本远高于前三类，所以在数据标注和实验设计上都有很大不同。</p>
<p><strong>如例1：</strong> 对每个月生效合同观察发现经过6个MOB逾期率上升趋缓，说明可以以基准时点往前推半年为训练数据，基准之后的数据为测试数据且至少需要1年的数据。</p></li>
<li><p><strong>滚动率分析(Roll Rate Analysis)</strong></p>
<p>业务目标决定了哪些不是目标用户，例如，可以是欺诈用户，也可以是曾经发生M2+逾期的用户。目标也与大环境有关系，例如，因为贷后催收行业整顿，导致用户M1后大概率会迁移到M2，那就需要改变目标用户标注。</p>
<p>所以前面几个指标能帮我们确定逾期率变化趋势和基准时点前后怎么选取，但不能帮着定义什么样的用户是“坏”用户，因此我们需要借助滚动率分析工具。假设：</p>
<p>1、基准时点前推6个月为训练数据，后探12个月为测试数据；</p>
<p>2、定义训练数据的6个月期间：没有逾期的用户为好用户trG，最长曾经逾期期数为M3及以上的用户为trM3+，最长曾经逾期期数为M2的用户为trM2，最长曾经逾期期数为M1的用户为trM1；</p>
<p>3、定义测试数据的6个月期间：没有逾期的用户为好用户teG，最长曾经逾期期数为M3及以上的用户为teM3+，最长曾经逾期期数为M2的用户为teM2，最长曾经逾期期数为M1的用户为teM1；</p>
<p>4、基准时点采样5次，以消除随机点影响</p>
<p>5、保证两段时间的样本数要有统计意义</p>
分别统计这两段时间的用户表现，可以得到tr到te用户状态的笛卡尔积：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/dika%281%29.png" width="400" />
</center>
<p>例如(数据为编造)：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1e1ld3j0914gqou11iov8ph1f7g3e.png" width="450" />
</center>
<p>1、训练数据中的正常客户，在测试数据中98%会继续正常还款，1.5%会转化为M1，0.5%会转化为M2，没有客户转化到M3；</p>
<p>2、训练数据中M1的客户，在测试数据中2%会转化为正常还款，4%会保持M1，80%会转化为M2，14%会转化为M3及以上；</p>
<p>3、训练数据中M2的客户，在测试数据中0.5%会转化为正常还款，1%会转化为M1，10%会保持为M2，88.5%会转化为M3及以上；</p>
<p>4、训练数据中M3及上的客户，在测试数据中0.1%会转化为正常还款，1%会转化为M1，3%会转化为M2，95.9%会保持M3及以上。</p>
<p>基于以上分析，我们发现用户一旦发生M1逾期，有80%会转化为M2，而M2逾期有88.5%会转化为M3，最终M3逾期有95.9%会保持M3或更差，这意味着：用户一旦发生M1逾期，最终会以较大概率转化到M3逾期，进而就“坏”透了，所以，坏用户=某个时间内曾经出现过M1及以上逾期的用户，数据样本中除了有明确定义的坏样本外，有些样本由于表现期的问题会被排除，总的来说，坏用户定义是由业务目标决定的，滚动率分析是帮助定义坏用户的工具。</p></li>
<li><p>总结</p>
<p>综上所述，利用Vintage分析和滚动率分析，可以帮助确定：以某时点为基准的训练及测试数据范围和定义坏用户。</p></li>
</ul>
<h3 id="拒绝推断">7.3.5 拒绝推断</h3>
风控与广告、推荐搜索有一个类似的问题，即幸存者偏差（Survivorship Bias），以广告CTR预估为例：影响其预估准确性的因素是AUC(Ads、User、Context)，建模中能被使用的样本是由有机会曝光的广告产生的，显然数据必然会有偏；此外不同的广告位产生的样本也会有位置偏差，在顶通栏的广告一定比在底通栏的更有机会被用户看到，从而被点击。所以最无偏的情况是每个广告对每个用户在每个上下文环境(如：位置、时段)下都曝光一次，之后看用户反应，但从经济成本、可行性等方面看显然不现实，所以广告会采用E&amp;E的方式，边给曝光机会边探索，通过实时流采集投放效果(感知)并动态评价(决策)，总之是以一定成本尽可能让平台利益最大化(如：最大化eCPM)。 但<strong>对风控来说，最大的问题是用户逾期的滞后性及客单价</strong>。对现金贷场景可能还好些，可以先通过放款小额度贷款去试用户，但对汽车金融等大额消费贷场景就不行了，只能折中使用拒绝推断，尽可能的利用已有数据。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/jujuetuiduan.png" width="600" />
</center>
拒绝推断有很多种方法，不过实践当中我们认为最有效的还是Parceling，它有很多变体，举一个常用的方法：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/pac.png" width="600" />
</center>
例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/image_1e1m1rapkmeb12mg1p411ogb1a056j.png" width="600" />
</center>
<p>1、利用”通过样本“训练”模型1“</p>
<p>2、按照置信度对”通过样本“做9个分组，置信度越高逾期率越低；</p>
<p>2、对每个分组统计”实际逾期率“及相应样本总数</p>
<p>3、利用”模型1“对”拒绝样本“做inference，同样按照置信度从高到低分9组</p>
<p>4、对每个分组统计样本总数，根据该组的逾期率，抽样得到”推断坏样本“，剩余的为”推断好样本“</p>
<p>5、合并”通过样本“和”推断好、坏样本“</p>
<p>6、训练”模型2“</p>
<p>总的来说，使用拒绝推断方法一方面可以部分修正训练数据的数据分布，让模型表现的更加稳定，泛化性更强；另一方面充分利用了历史数据，节省未来线上实验的成本。</p>
<h3 id="风控建模">7.3.6 风控建模</h3>
<p><strong>1、基本框架</strong> 风控建模的方法和广告、推荐及搜索的建模方法没区别，只是整体会更加保守些，因为风控这个业务很注重可解释性，表现在以下两个方面：</p>
<ul>
<li><p>对风控业务可解释 找到影响风险水平的原因，可以有的放矢的调整业务走向，例如，发现地区+车型组合特征对逾期率模型贡献高，则可进一步看哪个地区哪个车型，然后做业务判断。</p></li>
<li><p>对销售业务可解释 例如，在前端业务发生拒单时，帮助销售向客户解释原因；销售利用可解释的模型变量，有的放矢的和用户面聊，帮助控风险。</p></li>
</ul>
一般的建模框架如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/ml.png" width="800" />
</center>
<p>与传统机器学习类似，数据及特征准备耗费80%以上建模时间(即使使用AutoML框架辅助特征发现)，而模型方面，由于对可解释性的强烈需求及实际建模效果，早期的baseline是Logistic Regression，现在的baseline是Additive Tree Models(如，各种版本GBDT模型、RF模型，详情可见《<a href="https://www.zybuluo.com/vivounicorn/note/798611#25-additive-tree-%E6%A8%A1%E5%9E%8B">建模方法回顾-Additive Tree Models</a>》)。</p>
<p>需要说明的是，深度学习模型，诸如：</p>
<ul>
<li><p><a href="http://ir.ia.ac.cn/bitstream/173211/12337/1/A%20Convolutional%20Click%20Prediction%20Model.pdf">Convolutional Click Prediction Model</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1601.02376.pdf">Factorization-supported Neural Network</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1611.00144.pdf">Product-based Neural Network</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1606.07792.pdf">Wide &amp; Deep</a></p></li>
<li><p><a href="http://www.ijcai.org/proceedings/2017/0239.pdf">DeepFM</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1704.05194.pdf">Piece-wise Linear Model</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1708.05123.pdf">Deep &amp; Cross Network</a></p></li>
<li><p><a href="https://www.ijcai.org/Proceedings/2017/0435.pdf">Attentional Factorization Machine</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1708.05027.pdf">Neural Factorization Machine</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1803.05170.pdf">xDeepFM</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1706.06978.pdf">Deep Interest Network</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1809.03672.pdf">Deep Interest Evolution Network</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1810.11921.pdf">AutoInt</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1902.09096.pdf">NFFM</a></p></li>
<li><p><a href="https://arxiv.org/pdf/1904.04447">FGCNN</a></p></li>
<li><p><a href="https://arxiv.org/abs/1905.06482">Deep Session Interest Network</a></p></li>
</ul>
<p>虽然在风控特征自动发现方面可以起到一定作用，但并不那么适合风控建模，一方面是金融领域并没有那么大的标注数据，而深度学习模型在数据量足够大时才有明显优势，另一方面就是可解释性太差了。</p>
<p><strong>2、效果评价指标</strong> 风控建模本质上也是个排序问题，是更智能的狗熊掰棒子，同样也容易出现正负样本分布很不平衡问题(尤其是欺诈问题)，类似广告、推荐和搜索。</p>
<ul>
<li><p>K-S值</p>
<p>风控行业大家喜欢使用K-S值来评价模型好坏，值越大代表正负样本分的越开，一个可用的模型K-S值至少0.5，但是，假设正样本都被预测成了负样本，负样本都被预测成了正样本，猜猜这个指标会如何？</p></li>
<li><p>AUC值</p>
<p>个人更喜欢用AUC指标，它是个概率值，AUC=0.5代表你的模型和随机分类一个效果，AUC=0.8左右模型就可用了，AUC超过0.9了，赶紧查是不过拟合了。其数学含义更直接，假设负样本是多数派，那么AUC值表示：当线上随机来一个正样本和一个负样本时，当前模型将这个正样本排在负样本前面的概率。</p></li>
</ul>
<p><strong>3、阈值选择</strong> 在风控审批场景中，大体会有三种处理方法：</p>
<ul>
<li><p>自动通过</p>
<p>模型或策略规则，输出很高的通过置信度时，则认为用户大概率不会逾期，此时一般会让进件直接通过，这样前端的时效性和用户体验会很好。</p></li>
<li><p>自动拒绝</p>
<p>当模型或策略规则，输出很高的拒绝置信度时，则认为用户大概率会逾期，此时进件一般会被直接拒绝，尤其是触碰红线的用户，则一票否决且不允许召回。</p></li>
<li><p>转人工审核</p>
<p>介于通过与否的置信度不那么高的用户，会依据人力情况被转到人工审核岗，之后通过电话、面聊等方式决定是否准予通过。</p></li>
</ul>
<p>但由于风控模型输出的置信度是个概率值或连续值，所以需要通过做阈值截取得到以上三种结果。 例如，我们做自动拒绝判定(自动通过的逻辑与下面方法类似，不再赘述)，除了考虑业务量、人力情况等因素外，还需要考虑经济收益，即：我们希望被自动拒绝的订单尽可能多的是”坏“客户，尽可能少的是”好“客户，每拒绝一个”坏“客户，会挽回一单经济损失，而每拒绝一个”好“客户，会丢失一单经济收益，所以确定自动拒绝置信度的阈值要通过算法方式合理设定。 假设：</p>
<ul>
<li><p>训练了一个某场景下预测M1逾期率的模型，每一个订单的NPV值(或IRR值)已知，需要确定阈值以尽可能拒绝”坏“用户，让整体收益最大化；</p></li>
<li><p>有一条曲线是描述拒绝”坏“客户后挽回的经济损失，另一条曲线是拒绝一个”好“客户后丢失的经济收益；</p></li>
<li><p>横坐标是拒绝用户占总用户的比例，纵坐标是累积的平均NPV(IRR)值</p></li>
</ul>
<p>那么：</p>
<ul>
<li>如果模型特别差，所有好样本置信分都低于坏样本置信分，意味着下图：</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/worst.png" width="800" />
</center>
<ul>
<li>如果模型特别好，所有好样本置信分都高于坏样本置信分，意味着下图，最优拒绝阈值是让两条曲线间距最大的点(有点类似KS值)：</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/best.png" width="800" />
</center>
<ul>
<li>正常应用的模型，例如AUC达到0.8以上，大部分好样本置信分都高于坏样本置信分，意味着下图，同样，最优拒绝阈值是让两条曲线间距最大的点(有点类似KS值)：</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_7/normal.png" width="800" />
</center>
<p>最终确定的拒绝阈值会根据业务量、风险敞口大小、人力情况等因素，在这个最优点附近调整。</p>
<h2 id="风控模型监控">7.4 风控模型监控</h2>
<p>模型监控大概包括几部分：监控模型训练和测试指标、监控模型在线应用时的指标、监控业务关心的指标。</p>
<h3 id="离线模型监控">7.4.1 离线模型监控</h3>
<p>监控多次训练和测试模型本身的指标，包括不限于：</p>
<ul>
<li><p>标注数据分布稳定性 正常情况下，每个建模周期（如，每天、每月）的正负样本标注数据应该是稳定的，例如，某个周期同样量级且表现充分的样本中突然多出大量负样本。</p></li>
<li><p>特征稳定性 包括每个特征的缺失率、样本覆盖率、权重PSI值、特征重要性排序等。</p></li>
<li><p>置信分稳定性 置信度分数变化趋势、每个置信度范围覆盖的人群和模型指标都应该是稳定的。</p></li>
<li><p>人群分布稳定性 每个决策区间（如，拒绝、通过、转人工）下的人群数应该是稳定的。</p></li>
<li><p>模型指标稳定性 模型训练及测试集中的：AUC、ACC、Recall、F1、Precision、决策点置信度分值等都应该是稳定的。</p></li>
</ul>
<h3 id="在线模型监控">7.4.2 在线模型监控</h3>
<ul>
<li><p>在线特征稳定性 监控模型线上用到的特征实时分布是否与离线没有大的差距。</p></li>
<li><p>在线评分稳定性 置信分输出趋势是否稳定，各个决策区间下的人群是否稳定等。</p></li>
</ul>
<h3 id="业务监控">7.4.3 业务监控</h3>
<ul>
<li><p>每个模型AB后的进件量、自动通过、拒绝、转人工量/率监控</p></li>
<li><p>Vintage及滚动率监控</p></li>
<li><p>各级逾期率监控</p></li>
<li><p>模型特征花费监控</p></li>
<li><p>业务达标率监控 ......</p></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第七章</tag>
        <tag>金融风控</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第九章 语义分割</title>
    <url>/article/b12a240.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7ig9dqebe1n3v1jmb1o2g1gdim.png" width=266 /> 本章对于机器学习在计算机视觉中的语义分割领域经典的FCN模型做了简要介绍，后几节待填坑。 <span id="more"></span></p>
<h1 id="语义分割">9. 语义分割</h1>
<h2 id="fcn">9.1 FCN</h2>
<p>FCN在《<a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Fully Convolutional Networks for Semantic Segmentation</a>》中第一次被提出，个人认为是实现图像end to end语义分割的开山之作，第一次做到了低成本的像素级分类预测（end-to-end, pixels-to-pixels），另外这个方法用在目标检测、识别上效果好于传统新方法(如：Faster R-CNN)。</p>
<p>所谓语义分割简单说就是不但要知道你属于哪一类，还要知道你在哪儿：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1blc5thhohau12itero1ige1v6dm.png" width="800"  />
</center>
<p>从左到右分别是：原图、ground truth图、训练2轮的模型预测图、训练5轮的模型预测图（ps：截止本文前，训练达到理想状态还差200多轮）。</p>
<h3 id="算法概述">9.1.1 算法概述</h3>
<p>CNN网络无疑是特征提取的利器，尤其在图像领域，回顾我们的做法：CNN做特征提取+全连接层做特征组合+分类/回归，为了能提高模型预测能力，需要通过多个全连接层（做笛卡尔积）做特征组合，这里是参数数量最多的地方，成为模型训练，尤其是inference时的最大瓶颈（所以模型压缩和剪枝算法会把第一把刀放在全连接层），而由于全连接层的存在，导致整个网络的输入必须是固定大小的：由于卷积和采样操作更本不关心输入大小如何，试想如果输入大小不一，不同图片到了全连接层时其输入节点数是不一样的，而网络的定义必须事先定义好，所以没法儿玩儿了，于是有了前面的SPP及RoI pooling来解决这个问题，FCN则是解决这个问题的另一个思路。</p>
<p>总结该算法要解决的问题如下：</p>
<p>1、取消网络对输入数据大小必须固定的限制；</p>
<p>2、提高模型效果且加快其训练和inference速度。</p>
相比于传统CNN，FCN把全连接层全部替换成卷积层，并在feature map(可以是其中任何一个)上<strong>做上采样</strong>，使其恢复到原始图片大小，这样不但保留了每个像素的空间信息，而且每个像素都会有一个分类预测。比如下图中pixelwise prediction那一层，小猫、小狗、电视、背景都会在像素级别做分类预测：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7ig9dqebe1n3v1jmb1o2g1gdim.png" width="500"  />
</center>
<h3 id="卷积回顾">9.1.2 1×1卷积回顾</h3>
<p>前面我们在介绍各种经典识别网络中介绍了1×1卷积核，回顾下它的作用，尤其对多通道而言：</p>
<p>1、每个1×1卷积核会有一个参数，利用它们可以做跨通道特征融合，即对多个通道的feature map做线性组合；</p>
<p>2、具有降维或升维作用，如：在GoogleNet中它可以跟在pooling层后面做降维，也可以直接通过减少通道数做降维，大大减少了参数量；</p>
<p>3、可以在不损失feature map信息的前提下利用后面的激活函数增加模型非线性表征能力，可以低成本的把网络变深。</p>
<h3 id="全卷积网络">9.1.3 全卷积网络</h3>
<p>使用传统CNN做像素级分类的问题：</p>
<p>1、为了考虑上下文信息，需要一个滑动窗口，利用滑动窗口内的feature map对每个像素做分类，分类效果及存储空间随滑动窗口的大小上升；</p>
<p>2、为了考虑上下文信息，导致相邻两个窗口之间有大量的像素重复，意味着大量计算重复；</p>
<p>3、原图的空间信息没有被很好的利用；</p>
<p>4、原图需要固定大小，图像的resize（本质就是图像的下采样）导致信息损失。</p>
FCN则很好的解决了上面几个问题。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7jj2q4i9n16l81fm1bf8nhb13.png" width="500"  />
</center>
上图是传统CNN工作流程，下图是FCN工作流程，它最终可以得到关于目标的热图，这种变换除了在语义分割、检测、识别上用到，也会在feature map可视化上用来帮助分析特征。 一张图说明：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7p4cjk1klm1kqc4oefh67ci1g.png" width="800"  />
</center>
<p>理解FCN最关键的一步是理解上采样（upsampling）。</p>
<h3 id="nyquistshannon采样定理">9.1.4 Nyquist–Shannon采样定理</h3>
<p>关于采样，这个话题可大可小，从定义上说，采样是这么一个过程：在尽可能减少信息损失的情况下，将信号从一种采样率下的形态转换为另外一种，对于图片，这个过程叫做图像缩放。详细定义参见<a href="http://avisynth.nl/index.php/Resampling">Resampling</a>。</p>
<p>对计算机而言无法处理连续信号（读者想想为什么？），必须通过采样做信号离散化，那就必须回答一个问题：理想情况下，以什么样的频率采样能完美重构连续信号的信息。</p>
<p>Nyquist–Shannon采样定理回答了上面的问题：当对信号均匀间隔离散采样且信号的带宽小于采样率的一半时，原始连续信号可以被其得到的采样样本完全重构，不满足该条件则会出现混叠(Aliasing)现象。</p>
<p>理论上连续信号可以通过以下公式重构（信息重构器）：</p>
<span class="math display">\[
\text{s(x) = sum_n s(n*T) * sinc((x-n*T)/T), with sinc(x) = sin(pi*x)/(pi*x) for x!=0, and = 1 for x=0}
\]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7skcf2l9opk4f19si01a0c1t.png" width="500"  />
</center>
<p>其中采样率为:1/T，s(n*T)是s(x)的采样样本，sinc(x)是采样核(resampling kernel)。</p>
<p>一般来说 信息重构器有以下性质：</p>
<p>1、<span class="math inline">\(s(m*T)\)</span>确实是信号<span class="math inline">\(s(x)\)</span>的样本；</p>
<p>2、$_n{sinc((x-n*T)/T)} = 1 $;</p>
<p>3、resampling kernel：<span class="math inline">\(sinc(x)=* \text{ for x!=0, and = 1 for x=0}\)</span>；</p>
<p>4、resampling kernel：<span class="math inline">\(sinc(x)\)</span>是对称的，<span class="math inline">\(sinc(x) = sinc(-x)\)</span>；</p>
<p>5、resampling kernel：<span class="math inline">\(sinc(x)\)</span>是处处可微的。</p>
<p>当然还有其他形式的resampling kernel，比如bilinear resampling kernel，满足上述性质2、3、4：</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
1 - |x|&amp; \text{|x|&lt;1}\\
0&amp; \text{other}
\end{cases}
\]</span></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bl7va3qf153pjto2n1ahrn52n.png" width="500"  />
</center>
<p>这个函数在FCN里广泛用到。</p>
<p>我利用scikit-image library给个简单的bilinear resampling示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> skimage.transform</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> ogrid, repeat, newaxis</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_with_skimage</span>(<span class="params">img, factor</span>):</span></span><br><span class="line">    <span class="comment"># order=1表示bilinear resampling，参见：http://scikit-image.org/docs/dev/api/skimage.transform.html。</span></span><br><span class="line">    <span class="comment"># order的含义：</span></span><br><span class="line">    <span class="comment"># 0: Nearest-neighbor</span></span><br><span class="line">    <span class="comment"># 1: Bi-linear (default)</span></span><br><span class="line">    <span class="comment"># 2: Bi-quadratic</span></span><br><span class="line">    <span class="comment"># 3: Bi-cubic</span></span><br><span class="line">    <span class="comment"># 4: Bi-quartic</span></span><br><span class="line">    <span class="comment"># 5: Bi-quintic</span></span><br><span class="line">    <span class="keyword">return</span> skimage.transform.rescale(img,</span><br><span class="line">                                     factor,</span><br><span class="line">                                     mode=<span class="string">&#x27;constant&#x27;</span>,</span><br><span class="line">                                     cval=<span class="number">0</span>,</span><br><span class="line">                                     order=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    target = upsample_with_skimage(img=io.imread(<span class="string">&quot;feature_map.jpg&quot;</span>), factor=<span class="number">5</span>)</span><br><span class="line">    io.imsave(<span class="string">&quot;upsampling.png&quot;</span>, target, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1blc6rav11cik1qkgmnf1b9qovg1g.png" width="700"  />
</center>
<h3 id="转置卷积transposed-convolution">9.1.5 转置卷积(Transposed Convolution)</h3>
<p>很多人把这个过程叫做“反卷积(deconvolution)”，但我认为这么叫是错误的，它的过程并不是对卷积的逆运算，它除了用在FCN中还会用在卷积可视化、对抗神经网络中。 原理如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_9/image_1bleq0o8judv1ma7bjegob1nbv9.png" width="500"  />
</center>
<p>假设，输入为4×4、输出为2×2、卷积核为3×3，则把输出、输入和卷积核按照从左到右、从上到下展开为向量，前向传播的卷积过程相当于输入与以下稀疏矩阵的乘积：</p>
<p><span class="math display">\[
\begin{equation}
W=\left(
\begin{array}{lll}
w_{0,0} &amp;0&amp;0&amp;0 \\
w_{0,1} &amp;w_{0,0}&amp;0&amp;0 \\
w_{0,2} &amp;w_{0,1}&amp;0&amp;0 \\
0 &amp;w_{0,2}&amp;0&amp;0 \\
w_{1,0} &amp;0&amp;w_{0,0}&amp;0 \\
w_{1,1} &amp;w_{1,0}&amp;w_{0,1}&amp;w_{0,0} \\
w_{1,2} &amp;w_{1,1}&amp;w_{0,2}&amp;w_{0,1} \\
0 &amp;w_{1,2}&amp;0&amp;w_{0,2} \\
w_{2,0} &amp;0&amp;w_{1,0}&amp;0 \\
w_{2,1} &amp;w_{2,0}&amp;w_{1,1}&amp;w_{1,0} \\
w_{2,2} &amp;w_{2,1}&amp;w_{1,2}&amp;w_{1,1} \\
0 &amp;w_{2,2}&amp;0&amp;w_{1,2} \\
0 &amp;0&amp;w_{2,0}&amp;0 \\
0 &amp;0&amp;w_{2,1}&amp;w_{2,0} \\
0 &amp;0&amp;w_{2,2}&amp;w_{2,1} \\
0 &amp;0&amp;0&amp;w_{2,2}
\end{array}
\right)^T\nonumber
\end{equation}
\]</span></p>
<p>前向传播过程就表述为：</p>
<p><span class="math display">\[
\begin{equation}
Y=W \cdot X =\left(
\begin{array}{lll}
w_{0,0} &amp;0&amp;0&amp;0 \\
w_{0,1} &amp;w_{0,0}&amp;0&amp;0 \\
w_{0,2} &amp;w_{0,1}&amp;0&amp;0 \\
0 &amp;w_{0,2}&amp;0&amp;0 \\
w_{1,0} &amp;0&amp;w_{0,0}&amp;0 \\
w_{1,1} &amp;w_{1,0}&amp;w_{0,1}&amp;w_{0,0} \\
w_{1,2} &amp;w_{1,1}&amp;w_{0,2}&amp;w_{0,1} \\
0 &amp;w_{1,2}&amp;0&amp;w_{0,2} \\
w_{2,0} &amp;0&amp;w_{1,0}&amp;0 \\
w_{2,1} &amp;w_{2,0}&amp;w_{1,1}&amp;w_{1,0} \\
w_{2,2} &amp;w_{2,1}&amp;w_{1,2}&amp;w_{1,1} \\
0 &amp;w_{2,2}&amp;0&amp;w_{1,2} \\
0 &amp;0&amp;w_{2,0}&amp;0 \\
0 &amp;0&amp;w_{2,1}&amp;w_{2,0} \\
0 &amp;0&amp;w_{2,2}&amp;w_{2,1} \\
0 &amp;0&amp;0&amp;w_{2,2}
\end{array}
\right)^T\nonumber
\cdot
\left(
\begin{array}{lll}
1\\
2\\
3\\
4 \\
5\\
6\\
7\\
8 \\
9\\
10\\
11\\
12\\
13\\
14\\
15\\
16
\end{array}
\right)\nonumber=
\left(
\begin{array}{lll}
1\\
2\\
3\\
4
\end{array}
\right)\nonumber
\end{equation}
\]</span></p>
<p>误差反向传播(如果记不清了可以回看5.1节)：</p>
<p><span class="math display">\[
\frac{\partial E}{\partial X}=W^T\frac{\partial E}{\partial Y}
\]</span></p>
<p>那么反过来，我们希望从4维向量映射回16维向量怎么做呢：把上面过程逆反一下(当然该做padding还得做)： 前向传播： <span class="math display">\[Y=W^T X
\]</span> 反向传播: <span class="math display">\[
\frac{\partial E}{\partial X}=(W^T)^T\frac{\partial E}{\partial Y}=W\frac{\partial E}{\partial Y}
\]</span></p>
<p>整个过程平滑柔顺，多种情况下的详细解释可以看：<a href="http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic">《Convolution arithmetic tutorial》</a></p>
<p>keras下做转置卷积，输入feature map及最终效果同8.7.4。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_kernel_size</span>(<span class="params">factor</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    给定上采样因子，返回核大小，上采样因子大小等于转置卷积步长。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * factor - factor % <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_filt</span>(<span class="params">size</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    返回上采样bilinear kernel矩阵。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    factor = (size + <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> size % <span class="number">2</span> == <span class="number">1</span>:</span><br><span class="line">        center = factor - <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        center = factor - <span class="number">0.5</span></span><br><span class="line">    og = np.ogrid[:size, :size]</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span> - <span class="built_in">abs</span>(og[<span class="number">0</span>] - center) / factor) * \</span><br><span class="line">           (<span class="number">1</span> - <span class="built_in">abs</span>(og[<span class="number">1</span>] - center) / factor)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bilinear_upsample_weights</span>(<span class="params">factor, channel</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用bilinear filter初始化转置卷积权重矩阵。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    filter_size = get_kernel_size(factor)</span><br><span class="line"></span><br><span class="line">    weights = np.zeros((filter_size,</span><br><span class="line">                        filter_size,</span><br><span class="line">                        channel,</span><br><span class="line">                        channel), dtype=np.float32)</span><br><span class="line"></span><br><span class="line">    upsample_kernel = upsample_filt(filter_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(channel):</span><br><span class="line"></span><br><span class="line">        weights[:, :, i, i] = upsample_kernel</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_keras</span>(<span class="params">factor, input_img</span>):</span></span><br><span class="line"></span><br><span class="line">    SCALE = <span class="number">256</span></span><br><span class="line">    channel = input_img.shape[<span class="number">2</span>]</span><br><span class="line">    scale_height = input_img.shape[<span class="number">0</span>] * factor</span><br><span class="line">    scale_width = input_img.shape[<span class="number">1</span>] * factor</span><br><span class="line">    expanded_img = np.expand_dims(input_img, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&quot;/gpu:1&quot;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line">        sess = tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                       log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                       gpu_options=gpu_options))</span><br><span class="line">        input_value = tf.placeholder(tf.float32)</span><br><span class="line">        trans_filter = tf.placeholder(tf.float32)</span><br><span class="line">        upsample_filter_np = bilinear_upsample_weights(factor, channel)</span><br><span class="line"></span><br><span class="line">        res = K.conv2d_transpose(input_value, trans_filter,</span><br><span class="line">                    output_shape=[<span class="number">1</span>, scale_height, scale_width, channel],</span><br><span class="line">                    padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                    strides=(factor, factor))</span><br><span class="line"></span><br><span class="line">        final_result = sess.run(res,</span><br><span class="line">                            feed_dict=&#123;trans_filter: upsample_filter_np,</span><br><span class="line">                                       input_value: expanded_img&#125;)</span><br><span class="line">    <span class="keyword">if</span> channel != <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> final_result.squeeze() / SCALE</span><br><span class="line">    <span class="keyword">return</span> final_result.squeeze()</span><br><span class="line"></span><br><span class="line">upsampled_img_keras = upsample_keras(factor=<span class="number">5</span>, input_img=skimage.io.imread(<span class="string">&quot;feature_map.jpg&quot;</span>))</span><br><span class="line">skimage.io.imsave(<span class="string">&quot;bilinear_feature_map.jpg&quot;</span>,upsampled_img_keras, interpolation=<span class="string">&#x27;none&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="代码实践">9.1.6 代码实践</h3>
<p>开源代码可参见：<a href="https://github.com/aurora95/Keras-FCN">Keras-FCN</a>，虽然缺点是训练有点慢，模型有点大，但对于理解如何实现很有帮助。</p>
<p>里面实现了五种模型，两种基于vgg-16，两种基于resnet-50，一种基于densenet。</p>
<p>上采样操作做为一个新的网络层意味着它需要能够前向传播、反向传播、更新权重，其实现在代码中为BilinearUpSampling.py。</p>
<p>inference.py的代码需要稍微变下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> preprocess_input</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">model_name, weight_file, image_size, image_list, data_dir, label_dir, return_results=<span class="literal">True</span>, save_dir=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              label_suffix=<span class="string">&#x27;.png&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">              data_suffix=<span class="string">&#x27;.jpg&#x27;</span></span>):</span></span><br><span class="line">    current_dir = os.path.dirname(os.path.realpath(__file__))</span><br><span class="line">    <span class="comment"># mean_value = np.array([104.00699, 116.66877, 122.67892])</span></span><br><span class="line">    batch_shape = (<span class="number">1</span>, ) + image_size + (<span class="number">3</span>, )</span><br><span class="line">    save_path = os.path.join(current_dir, <span class="string">&#x27;Models/&#x27;</span>+model_name)</span><br><span class="line">    model_path = os.path.join(save_path, <span class="string">&quot;model.json&quot;</span>)</span><br><span class="line">    checkpoint_path = os.path.join(save_path, weight_file)</span><br><span class="line">    <span class="comment"># model_path = os.path.join(current_dir, &#x27;model_weights/fcn_atrous/model_change.hdf5&#x27;)</span></span><br><span class="line">    <span class="comment"># model = FCN_Resnet50_32s((480,480,3))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))</span></span><br><span class="line">    <span class="comment">#session = tf.Session(config=config)</span></span><br><span class="line">    <span class="comment">#K.set_session(session)</span></span><br><span class="line"></span><br><span class="line">    model = <span class="built_in">globals</span>()[model_name](batch_shape=batch_shape, input_shape=(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>))</span><br><span class="line">    model.load_weights(checkpoint_path, by_name=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> img_num <span class="keyword">in</span> image_list:</span><br><span class="line">        img_num = img_num.strip(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        total += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;#%d: %s&#x27;</span> % (total,img_num))</span><br><span class="line">        image = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/%s%s&#x27;</span> % (data_dir, img_num, data_suffix))</span><br><span class="line">        image = img_to_array(image)  <span class="comment"># , data_format=&#x27;default&#x27;)</span></span><br><span class="line"></span><br><span class="line">        label = Image.<span class="built_in">open</span>(<span class="string">&#x27;%s/%s%s&#x27;</span> % (label_dir, img_num, label_suffix))</span><br><span class="line">        label_size = label.size</span><br><span class="line"></span><br><span class="line">        img_h, img_w = image.shape[<span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># long_side = max(img_h, img_w, image_size[0], image_size[1])</span></span><br><span class="line">        pad_w = <span class="built_in">max</span>(image_size[<span class="number">1</span>] - img_w, <span class="number">0</span>)</span><br><span class="line">        pad_h = <span class="built_in">max</span>(image_size[<span class="number">0</span>] - img_h, <span class="number">0</span>)</span><br><span class="line">        image = np.lib.pad(image, ((pad_h/<span class="number">2</span>, pad_h - pad_h/<span class="number">2</span>), (pad_w/<span class="number">2</span>, pad_w - pad_w/<span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>)), <span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">0.</span>)</span><br><span class="line">        <span class="comment"># image -= mean_value</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;img = array_to_img(image, &#x27;channels_last&#x27;, scale=False)</span></span><br><span class="line"><span class="string">        img.show()</span></span><br><span class="line"><span class="string">        exit()&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># image = cv2.resize(image, image_size)</span></span><br><span class="line"></span><br><span class="line">        image = np.expand_dims(image, axis=<span class="number">0</span>)</span><br><span class="line">        image = preprocess_input(image)</span><br><span class="line"></span><br><span class="line">        result = model.predict(image, batch_size=<span class="number">1</span>)</span><br><span class="line">        result = np.argmax(np.squeeze(result), axis=-<span class="number">1</span>).astype(np.uint8)</span><br><span class="line"></span><br><span class="line">        result_img = Image.fromarray(result, mode=<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line">        result_img.palette = label.palette</span><br><span class="line">        <span class="comment"># result_img = result_img.resize(label_size, resample=Image.BILINEAR)</span></span><br><span class="line">        result_img = result_img.crop((pad_w/<span class="number">2</span>, pad_h/<span class="number">2</span>, pad_w/<span class="number">2</span>+img_w, pad_h/<span class="number">2</span>+img_h))</span><br><span class="line">        <span class="comment"># result_img.show(title=&#x27;result&#x27;)</span></span><br><span class="line">        <span class="keyword">if</span> return_results:</span><br><span class="line">            results.append(result_img)</span><br><span class="line">        <span class="keyword">if</span> save_dir:</span><br><span class="line">            result_img.save(os.path.join(save_dir, img_num + <span class="string">&#x27;.png&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:1&#x27;</span>):</span><br><span class="line">	gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line">    	model_name = <span class="string">&#x27;AtrousFCN_Resnet50_16s&#x27;</span></span><br><span class="line">    	weight_file = <span class="string">&#x27;checkpoint_weights.hdf5&#x27;</span></span><br><span class="line">    	image_size = (<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">    	data_dir = os.path.expanduser(<span class="string">&#x27;~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/JPEGImages&#x27;</span>)</span><br><span class="line">    	label_dir = os.path.expanduser(<span class="string">&#x27;~/.keras/datasets/VOC2012/VOCdevkit/VOC2012/SegmentationClass&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    	image_list = sys.argv[<span class="number">1</span>:]<span class="comment">#&#x27;2007_000491&#x27;</span></span><br><span class="line">    	results = inference(model_name, weight_file, image_size, image_list, data_dir, label_dir, save_dir=<span class="string">&quot;result&quot;</span>)</span><br><span class="line">    	<span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        	result.show(title=<span class="string">&#x27;result&#x27;</span>, command=<span class="literal">None</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="fcn-crf">9.2 FCN-CRF</h2>
<h2 id="segnet">9.3 SegNet</h2>
<h2 id="ubernet">9.4 UberNet</h2>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第九章</tag>
        <tag>FCN</tag>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第五章 深度神经网络</title>
    <url>/article/783e74f9.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png" width=266 /> 本章对机器视觉方面的深度神经网络做了历史回顾及原理介绍，由于这方面技术发展很快，所以文章内容主要集中于几个极具代表性的框架。 <span id="more"></span></p>
<h1 id="深度神经网络">5. 深度神经网络</h1>
<p>深度学习是基于多层神经网络的一种对数据进行自动表征学习的框架，能使人逐步摆脱传统的人工特征提取过程，它的基础之一是distributed representation，读论文时注意以下概念区分：</p>
<ul>
<li><p>Distributional representation</p>
<p>Distributional representation是基于某种分布假设和上下文共现的一类表示方法，比如，对于词的表示来说：有相似意义的词具有相似的分布。</p>
<p>从技术上讲这类方法的缺点是：通常对存储敏感，在representation上也不高效，但是优点是：算法相对简单，甚至像LSA那样简单的线性分解就行。</p>
<p>几类常见的Distributional representation模型：</p>
<ul>
<li><p><a href="http://en.wikipedia.org/wiki/Latent_semantic_analysis">Latent semantic analysis</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet allocation</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Self-organizing_map">Self-organizing map</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Hyperspace_Analogue_to_Language">HAL</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Independent_component_analysis">Independent component analysis</a></p></li>
<li><p><a href="http://en.wikipedia.org/wiki/Random_indexing">Random indexing</a></p></li>
</ul></li>
<li><p>Distributed representation</p>
<p>Distributed representation是对实体（比如：词、车系编号、微博用户id等等）稠密、低维、实数的向量表示，也就是常说的embedding，它不需要做分布假设，向量的每个维度代表实体在某个空间下的隐含特征。</p>
<p>从技术上讲它的缺点是：计算代价较高，算法往往不简单直接，通常通过神经网络/深度神经网络实现，优点是：对原始信息的有效稠密压缩表示，不仅仅是考虑“共现”，还会考虑其他信息，比如：“时序”等。</p>
<p>几类常见的Distributed representation模型：</p>
<ul>
<li><p>Collobert and Weston embeddings</p></li>
<li><p>HLBL embeddings</p></li>
</ul></li>
</ul>
<p>关于Distributional representation和Distributed representation以及几个相关概念，看论文<a href="http://www.aclweb.org/anthology/P10-1040">Word representations: A simple and general method for semi-supervised learning</a>即可明了。</p>
<h2 id="反向传播">5.1 反向传播</h2>
反向传播是神经网络参数学习的必备工具，以经典的多层前向神经网络为例：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1asuka9jl1u479sd1k7l64l11s2m.png" width="350"  />
</center>
整个网络可以认为是以下结构的重复，其中n代表处于第几层：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1avm00h74gbiodp19bv1sbj19au1j.png" width="350"  />
</center>
<p>假设：</p>
<p>1、当<span class="math inline">\(n=o\)</span>为输出层时，整个网络的误差表示为：<span class="math inline">\(E^o(X^o,D)\)</span>，其中<span class="math inline">\(D\)</span>为期望输出；</p>
<p>2、任意层的激活函数表示为<span class="math inline">\(F(x)\)</span>；</p>
<p>3、第<span class="math inline">\(n\)</span>层输入为上一层输出<span class="math inline">\(X^{n-1}\)</span>，该层权重为<span class="math inline">\(W^n\)</span>，则:</p>
<p>该层中间输出为：<span class="math inline">\(Y^n=W^nX^{n-1}\)</span> 该层输出为：<span class="math inline">\(X^n=F(Y^n)\)</span>。</p>
<p>那么误差反向传播原理为：</p>
<p><span class="math display">\[
\begin{array}{l}
\frac{\partial E^o}{\partial Y^n}=F&#39;(Y^n)\frac{\partial E^o}{\partial X^n}\\
\frac{\partial E^o}{\partial W^n}=X^{n-1}\frac{\partial E^o}{\partial Y^n}\\
\frac{\partial E^o}{\partial X^{n-1}}=(W^n)^T\frac{\partial E^o}{\partial Y^n}\\
\end{array}
\]</span> 其中，定义<span class="math inline">\(\delta^n=\frac{\partial E^o}{\partial Y^n}\)</span>为误差反向传播时第<span class="math inline">\(n\)</span>层某个节点的“误差敏感度”。</p>
<p>参数学习过程为：<span class="math inline">\(W_t=W_{t-1}-\eta \frac{\partial E}{\partial W_{t-1}}\)</span>，其中<span class="math inline">\(\eta\)</span>的讨论前文已经做过不在赘述，应用导数的链式传导原理，所有层的权重都将得到更新。</p>
<h2 id="卷积网络结构演化史">5.2 卷积网络结构演化史</h2>
网络结构的发展历程更像是一个<strong>实验科学</strong>的过程，人们通过不断地尝试和实验来得到与验证各种网络结构。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bam7ahp49p41r9s1a7pe5g1ags9.png" width="800"  />
</center>
<h2 id="cnn基本原理">5.3 CNN基本原理</h2>
<strong>卷积</strong>神经网络是我认为非常好用的一类神经网络结构，当数据具有局部相关性时是一种比较好选择，在图像、自然语言处理、棋类竞技、新药配方研制等方面有广泛应用。比如，经典的LeNet-5网络结构：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1atkth39kk2v1hk41ga1j7pnh9m.png" width="800"  />
</center>
<h3 id="sigmoid激活函数">5.3.1 Sigmoid激活函数</h3>
激活函数是神经网络必备工具，而Sigmoid激活函数是早期神经网络最普遍的选择。Sigmoid函数是类神奇的函数，广义上所有形为“S”的函数都可叫做Sigmoid函数，从早期的感知机模型中Sigmoid函数就被用来模拟生物细胞的激活反应，所以又被叫做激活函数，从数学角度看，Sigmoid函数对中间信号增益较大而对两侧信号增益小，所以在信号的特征空间映射上效果好。 从生物角度看，中间部分类似神经元的兴奋状态而两侧类似神经元的抑制状态，所以神经网络在学习时，区分度大的重要特征被推向中间而次要特征被推向两侧。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a0q0pg13mp31k17d41ni0sabi.png" width="350"  />
</center>
<p><span class="math display">\[
logistic(x)=\frac{1}{1+e^{-x}}\\
tanh(x)=2logistic(2x)-1
\]</span></p>
<p>Logistic函数最早是<a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre François Verhulst</a>在研究人口增长问题时提出的，由于其强悍的普适性（从概率角度的理解见前面对Logistic Regression的讲解）而被广泛应用（在传统机器学习中派生出Logistic Regression），但是实践中，它作为激活函数有两个重要缺点：</p>
<ul>
<li><p>梯度消失问题（Vanishing Gradient Problem）</p>
<p>从前面BP的推导过程可以看出：误差从输出层反向传播时，在各层都要乘以当前层的误差敏感度，而误差敏感度又与<span class="math inline">\(Sigmoid&#39;(x)\)</span>有关系，由于<span class="math inline">\(Sigmoid&#39;(x)\in(0,1)\)</span> 且<span class="math inline">\(x\in(0,1) \text{ or }x\in(-1,1)\)</span>，可见误差会从输出层开始呈指数衰减，这样即使是一个4层神经网络可能在靠近输入层的部分都已经无法学习了，更别说“更深”的网络结构了，Hinton提出的逐层贪心预训练方法在一定程度缓解了这个问题但没有真正解决。</p></li>
<li><p>激活输出非0均值问题</p>
<p>假设一个样本一个样本的学习，当前层输出非0均值信号给下一层神经元时：如果输入值大于0，则后续通过权重计算出的梯度也大于0，反之亦然，这会导致整个网络训练速度变慢，虽然采用batch的方式训练会缓解这个问题，但毕竟在训练中是拖后腿的，所以Yann LeCun在《Efficient BackPro》一文中也提到了解决的trick。</p></li>
</ul>
<p>Tanh函数是另外一种Sigmoid函数，它的输出是0均值的，Yann LeCun给出的一种经验激活函数形式为：<span class="math display">\[f(x)=1.7159 \cdot tanh(\frac{2}{3}x)\]</span>但这个函数依然解决不了梯度消失问题，后续介绍其他网络结构时会看到在激活函数层面上的演化。</p>
<p>CNN的典型特点是：局部相关性（稀疏连接）、权重与偏置共享及采样，一套典型的结构由输入层、卷积层、采样层、全连接层、输出层组成。</p>
<h3 id="输入层">5.3.2 输入层</h3>
CNN的输入层一般为一个n维矩阵，可以是图像、向量化后的文本等等。比如一幅彩色图像：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s7tchpjd91hq3j4l1n6n2f11g.png" width="400"  />
</center>
<h3 id="卷积层">5.3.3 卷积层</h3>
卷积操作在数学上的定义如下： <span class="math display">\[f*g = \int^{\infty}_{-\infty}(\sum^{\infty}_{-\infty}) f(\tau)g(x-\tau)d\tau  \tag{1}\]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0s71detai81p86nl3uobg9h13.png" width="800"  />
</center>
<p>但对于我们正在讲的CNN中的卷积<strong>并不是严格意义的卷积(<a href="http://mathworld.wolfram.com/Convolution.html">Convolution</a>)</strong>操作，而是变体<a href="http://mathworld.wolfram.com/Cross-Correlation.html"><strong>Cross-Correlation</strong></a>: <span class="math display">\[f★ g = \int^{\infty}_{-\infty}(\sum^{\infty}_{-\infty}) \bar{f}(\tau)g(x+\tau)d\tau  \tag{1}\]</span> 其中<span class="math inline">\(\bar{f}\)</span>为<span class="math inline">\(f\)</span>的<a href="http://mathworld.wolfram.com/ComplexConjugate.html">Complex Conjugate</a>。</p>
<p>卷积层的作用：</p>
<p>当数据及其周边有局部关联性时可以起到滤波、去噪、找特征的作用；</p>
<p>每一个卷积核做特征提取得到结果称为feature map，利用不同卷积核做卷积会得到一系列feature map，这些feature map大小为长×宽×深度(卷积核的个数)并作为下一层的输入。</p>
<p>以图像处理为例，卷积可以有至少3种理解：</p>
<ul>
<li><p>平滑</p>
当设置一个平滑窗口后（如3×3），除了边缘外，图像中每个像素点都是以某个点为中心的窗口中各个像素点的加权平均值，这样由于每个点都考虑了周围若干点的特征，所以本质上它是对像素点的平滑。</li>
<li><p>滤波</p>
<p>将信号中特定波段频率过滤的操作，是防干扰的一类方法，如果滤波模板(卷积核)是均匀分布，那么滤波就是等权滑动平均，如果模板是高斯分布，那么滤波就是权重分布为钟形的加权滑动平均，不同的模板能得到图像的不同滤波后特征。</p></li>
<li><p>投影</p>
<p>卷积是个内积操作，如果把模板(卷积核)拉直后看做一个基向量，那么滑动窗口每滑动一次就会产生一个向量，把这个向量往基向量上做投影就得到feature map，如果模板有多个，则组成一组基，投影后得到一组feature map。</p></li>
</ul>
<p>卷积和权重共享可以在保证效果的基础上大大降低模型复杂度，说明如下：</p>
输入层为5×5矩阵，卷积核为3×3矩阵，隐藏层为：3×3矩阵：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbehg11su3pj3ksq92mvj12n.png" width="400"  />
</center>
<ul>
<li><p>采用全连接神经网络</p>
<p>参数个数为：5×5×9=225</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sbvo0ourbp1nesm1eg518no3h.png" width="250"  />
</center></li>
<li><p>采用局部连接神经网络</p>
隐藏层只与3×3大小的局部像素相连，参数个数为：3×3×9=81
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc08fspt4vju1ql6184d4ci3u.png" width="250"  />
</center></li>
<li><p>采用局部连接权重共享神经网络</p>
所有隐藏层共享权值，且权值为卷积核，参数个数为：3×3×1=9，共享权重的本质含义是对图片某种统计模式的描述，这种模式与图像位置无关。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sc818png019o31tckas91d6r4o.png" width="250"  />
</center></li>
</ul>
<h3 id="zero-padding">5.3.4 Zero-Padding</h3>
Zero-Padding是一种影响输出层构建的方法，思路比较简单：把输入层边界外围用0填充，当我们希望输出空间维度和输入空间维度大小一样时可以用此方法，例如下图：当输入为4×4，卷积核为3×3时，利用Zero-Padding可以让输出矩阵也是4×4。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0scomd1143ebfh1iq918jencv5i.png" width="250"  />
</center>
<p>Zero-Padding一方面让你的网络结构设计更灵活，一方面还可以保留边界信息，不至于随着卷积的过程信息衰减的太快。 大家如果使用Tenserflow会知道它的padding参数有两个值：SAME，代表做类似上图的Zero padding，使得输入的feature map和输出的feature map有相同的大小；VALID，代表不做padding操作。</p>
<h3 id="采样层pooling">5.3.5 采样层(pooling)</h3>
通过卷积后。模型的参数规模大幅下降，但对于复杂网络参数个数依然很多，且容易造成过拟合，所以一种自然的方式就是做下采样，采样依然采用滑动窗口方式，常用采样有Max-Pooling（将Pooling窗口中的最大值作为采样值）和Mean-Pooling（将Pooling窗口中的所有值相加取平均，用平均值作为采样值），一个例子如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdf86mtg1i5110kv1kc3gl776.png" width="300"  />
</center>
实际上也有人尝试抛弃Pooling层而采用Stride大于1的卷积层，例如，以下例子中Stride=2，效果类似：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sdotesps7177gsg9188bl0p7j.png" width="300"  />
</center>
<p>另外，如果卷积层的下一层是pooling层，那么每个feature map都会做pooling，与人类行为相比，pooling可以看做是观察图像某个特征区域是否有某种特性，对这个区域而言不关心这个特性具体表现在哪个位置（比如：看一个人脸上某个局部区域是否有个痘痘）。</p>
<h3 id="全连接样层">5.3.6 全连接样层</h3>
<p>全连接层一般是CNN的最后一层，它是输出层和前面若干层的过渡层，用来组织生成特定节点数的输出层。</p>
<h3 id="参数求解">5.3.7 参数求解</h3>
<p>对于多分类任务，假设损失函数采用平方误差： <span class="math display">\[E(x)=\sum_{i=0}^N\sum_{k=0}^C(t^k_i-y^k_i)^2\]</span>，<span class="math inline">\(C\)</span>为分类个数，<span class="math inline">\(N\)</span>为样本数。 下面以一个样本为例推导CNN的原理： <span class="math display">\[E(x)=\sum_{k=0}^C(t^k-y^k)^2\]</span></p>
<ul>
<li><p>全连接层</p>
<p>为方便，假设偏置项<span class="math inline">\(b\)</span>都被放入权重项<span class="math inline">\(W\)</span>中，则对全连接层来说第<span class="math inline">\(n\)</span>层与第<span class="math inline">\(n-1\)</span>层的关系为： <span class="math display">\[
  \begin{array}{l}
  X^n=F(Y^n)\\
  Y^n=W^nX^{n-1}
  \end{array}
  \]</span> 反向传播定义为：</p>
<p><span class="math inline">\(\because\)</span> <span class="math display">\[
  \begin{array}{l}
  \delta^n=\frac{\partial E}{\partial Y^n}=F&#39;(Y^n)\frac{\partial E}{\partial X^n}\\
  \frac{\partial E}{\partial W^n}=X^{n-1}(\delta^n)^T\\
  \frac{\partial E}{\partial X^{n-1}}=(W^n)^T\frac{\partial E^o}{\partial Y^n}\\
  \end{array}
  \]</span> <span class="math inline">\(\therefore\)</span> <span class="math display">\[
  \left\{
  \begin{aligned}
  \delta^n  = &amp; F&#39;(Y^n)(W^{n+1})^T\delta^{n+1} \\
  \delta^L  = &amp; F&#39;(Y^L)(t^{n}-y^n) \quad\text{L表示最后一层}\\
  \frac{\partial E}{\partial W^n}  = &amp; X^{n-1}(\delta^n)^T
  \end{aligned}
  \right.
  \]</span> <span class="math display">\[
  \begin{array}{l}
  \Delta W^n=-\eta \frac{\partial E}{\partial W^n}\\
  W^n=W^{n-1}+\Delta W^n
  \end{array}
\]</span></p></li>
<li><p>卷积层 由于卷积操作、共享权重的存在，这一中间层的输出会被定义为： <span class="math display">\[
  \begin{array}{l}
  X_j^n=F(Y_j^n)\\
  Y_j^n=\sum_{i\in M_j}X_i^{n-1}k_{ij}^n+b_j^n
  \end{array}
  \]</span> 其中：<span class="math inline">\(n\)</span>为当前卷积层，<span class="math inline">\(j\)</span>为卷积层某个特征，<span class="math inline">\(k\)</span>为卷积核，<span class="math inline">\(b\)</span>为偏置。</p>
<p><strong>1、当前层为卷积层且下一层为下采样层(pooling)时</strong>，反向传播的原理为：</p>
<p><span class="math inline">\(\delta^n_j = \beta_j^{n+1}(F&#39;(Y^n)upsampled(\delta^{n+1}_j))\)</span></p>
<p>下面解释<span class="math inline">\(upsampled\)</span>和<span class="math inline">\(\beta\)</span>操作：</p>
卷积层在卷积窗口内的像素与下采样层的像素是多对一的关系，即下采样层的一个神经元节点对应的误差灵敏度对应于上一层卷积层的采样窗口大小的一块像素，下采样层每个节点的误差敏感值由上一层卷积层中采样窗口中节点的误差敏感值联合生成，因此，为了使下采样层的误差敏感度窗口大小和卷积层窗口(卷积核)大小一致，就需要对下采样层的误差敏感度做上采样<span class="math inline">\(upsampled\)</span>操作，相当于是某种逆映射操作，对于max-pooling、mean-polling或者各自的加权版本来说处理方法类似：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6io9a0j12rlem41vklu4tjfe13.png" width="400"  />
</center>
<p><span class="math display">\[
  \begin{array}{l}
  \delta^n_j=F&#39;(Y^n_j)\frac{\partial E}{\partial X^n_j}\\
  \frac{\partial E}{\partial X^{n}_j}=(W^{n+1}_j)^T\frac{\partial E^o}{\partial Y^{n+1}_j}\\
  \delta^n_j = \beta_j^{n+1}(F&#39;(Y^n_j)upsampled(\delta^{n+1}_j))
  \end{array}
  \]</span> 第<span class="math inline">\(n\)</span>层为卷积层和第<span class="math inline">\(n+1\)</span>层为下采样层，由于二者维度上的不一致，需要做以下操作来分配误差敏感项，以mean-pooling为例，假设卷积层的核为4×4，pooling的窗口大小为2×2，为简单起见，pooling过程采用每次移动一个窗口大小的方式，显然pooling后的矩形大小为2×2，如果此时pooling后的矩形误差敏感值如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6isstg3thaur990dsvn1bjq1g.png" width="100"  />
</center>
<span class="math inline">\(upsampled\)</span>操作，按照顺序对每个误差敏感项在水平和垂直方向各复制出口大小次：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6it7aknd6aabt41sr9i16vj1t.png" width="200"  />
</center>
做误差敏感项归一化，即上面公式里的<span class="math inline">\(\beta\)</span>取值，需要注意，如果采用的是加权平均的话，则窗口内误差敏感项权重是不一样的（不像现在这样是等权的）。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ito67157a3lji5b1vs4f932a.png" width="200"  />
</center>
<p><strong>2、当前层为卷积层，与其相连的上一层相关核权重及偏置</strong>计算如下：</p>
<p>假设通过<span class="math inline">\((p,q)\)</span>来标识卷积层任意位置，则：</p>
<span class="math display">\[
  \begin{array}{l}
  \frac{\partial E}{\partial k_{ij}^n} =\sum_{p,q}(\delta_j^{n})_{pq}(X_{i}^{n-1})_{pq}\\
  \frac{\partial E}{\partial b_j}=\sum_{p,q}(\delta_j^{n})_{pq}
  \end{array}
  \]</span> 假设第<span class="math inline">\(n-1\)</span>层输入矩阵大小为5×5：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9e6ve110a1bs81ph1bao1l1n2n.png" width="200"  />
</center>
第<span class="math inline">\(n\)</span>层误差敏感项矩阵大小为4×4：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6j9fhp91quu11461ljn70418p734.png" width="200"  />
</center>
则核<span class="math inline">\(k_{ij}^n\)</span>的偏导为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b6ja5d7k7pr1ee017s57201jr33h.png" width="600"  />
</center>
<p><span class="math display">\[
  \begin{aligned}
  75.75=&amp;1*1.25+3*1.25+5*2+7*2+\\
        &amp;2*1.25+4*1.25+5*2+6*2+\\
        &amp;5*0.75+7*0.75+1*0.5+3*0.5+\\
        &amp;1*0.75+2*0.75+3*0.5+5*0.5
  \end{aligned}
  \]</span></p>
<p>偏置<span class="math inline">\(b_j\)</span>的偏导为误差敏感项矩阵元素之和： <span class="math display">\[
  \begin{aligned}
  18=1.25*4+0.75*4+2*4+0.5*4
  \end{aligned}
  \]</span></p>
<p><strong>3、当前层为下采样(pooling)层且下一层为卷积层时</strong>反向传播的原理如下： <span class="math display">\[
  \begin{array}{l}
  \delta^n_j=F&#39;(Y_j^n)\sum_{p,q}(\delta_j^{n+1})_{pq}*(k_{j}^{n+1})_{pq}\\
  \end{array}
  \]</span></p>
其中运算符号<span class="math inline">\(*\)</span>为卷积操作。一个简单的例子如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77kp1qgjns27t83h1m86cvem.png" width="400"  />
</center>
<p>假设下采样(pooling)层处于第<span class="math inline">\(n\)</span>层且feature map大小为3×3，其下一层为卷积层处于第<span class="math inline">\(n+1\)</span>层且通过两个2×2卷积核得到了两个feature map(蓝色虚框框住的网络结构)。</p>
2个卷积核为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77m4h5p1kes1nmt1c9068flcr13.png" width="300"  />
</center>
假设第<span class="math inline">\(n+1\)</span>层对两个卷积核的误差敏感项已经计算好：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77mrpk7iql1vcd1mtsnnn154l1p.png" width="300"  />
</center>
则对第<span class="math inline">\(n+1\)</span>层的误差敏感项做zero-padding并利用卷积操作（注意：会对卷积核做180度旋转）可以得到第<span class="math inline">\(n\)</span>层的误差敏感项，过程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77rq7l71v78t1f2u6kob1cvm26.png" width="500"  />
</center>
假设<span class="math inline">\(F&#39;(Y_j^n)=1\)</span>，则第<span class="math inline">\(n\)</span>层的误差敏感项为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77s7vp8hta1ikg1h041juv1i1c2j.png" width="500"  />
</center></li>
</ul>
<h3 id="cnn在nlp领域应用实例">5.3.8 CNN在NLP领域应用实例</h3>
<p>在NLP领域，文本分类是一类常用应用，传统方法是人工提取类似n-gram的各种特征以及各种交叉组合。文本类似图像天然有一种局部相关性，想到利用CNN做一种End to End的分类器，把提特征的工作交给模型。</p>
<p>对于一个句子，它是一维的，无法像图像一样直接处理，因此需要通过distributed representation learning得到词向量，或者在模型第一层增加一个embedding层起到类似作用，这样一个句子就变成二维的了：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0sfnrui1mvnnnd1l2p1t68nm880.png" width="300"  />
</center>
<p>我们用Tensorflow为后端的Keras搭建这个模型：</p>
<p>前面说到可以使用两种方法得到词向量：</p>
<p>1、预先训练好的结果，例如使用已经训练好的word2vec模型，相关资料：<a href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html">Using pre-trained word embeddings in a Keras model</a>；</p>
<p>2、模型第一层增加embedding层，我们使用这种方式。</p>
<p>网络结构如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_embedding_cnn</span>(<span class="params">max_caption_len, vocab_size</span>):</span></span><br><span class="line">    <span class="comment"># 二分类问题</span></span><br><span class="line">    nb_classes = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 词向量维度</span></span><br><span class="line">    word_dim = <span class="number">256</span></span><br><span class="line">    <span class="comment"># 卷积核个数</span></span><br><span class="line">    nb_filters = <span class="number">64</span></span><br><span class="line">    <span class="comment"># 使用max pooling的窗口大小</span></span><br><span class="line">    nb_pool = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 卷积核大小</span></span><br><span class="line">    kernel_size = <span class="number">5</span></span><br><span class="line">    <span class="comment"># 模型结构定义</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    <span class="comment"># 第一层是embedding层</span></span><br><span class="line">    model.add(Embedding(output_dim=word_dim, input_dim=vocab_size, input_length=max_caption_len, name=<span class="string">&#x27;main_input&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment"># 第二层是激活函数为Relu的卷积层</span></span><br><span class="line">    model.add(Convolution1D(nb_filters, kernel_size))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment"># 第三层是max pooling层</span></span><br><span class="line">    model.add(MaxPooling1D(nb_pool))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    <span class="comment"># 第四层是全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">256</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.3</span>))</span><br><span class="line">    <span class="comment"># 第五层是输出层</span></span><br><span class="line">    model.add(Dense(nb_classes))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="comment"># 损失函数采用交叉熵，优化算法采用adadelta</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                  optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
max_caption_len=100时的网络结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b72kbakimjb19plrt512qj1t6e16.png" width="300"  />
</center>
运行效果：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b0shaditah31jeuur91te010718d.png" width="800"  />
</center>
<p>详细代码可以参见GitHub：<a href="https://github.com/vivounicorn/cnn-tc-keras"><strong>Cnn-tc-Keras</strong></a>。</p>
<h2 id="lenet-5">5.4 LeNet-5</h2>
最初的网络结构来源于论文：《<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Gradient-based learning applied to document recognition</a>》(论文里使用原始未做规范化的数据时，INPUT是32×32的)，我用以下结构做说明:
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b8b8u29j17gqo4713s12fsme39.png" width="800"  />
</center>
<p>LeNet-5一共有8层：1个输入层+3个卷积层(C1、C3、C5)+2个下采样层(S2、S4)+1个全连接层(F6)+1个输出层，每层有多个feature map(自动提取的多组特征)。</p>
<h3 id="输入层-1">5.4.1 输入层</h3>
<p>采用keras自带的MNIST数据集，输入像素矩阵为28×28的单通道图像数据。</p>
<h3 id="c1卷积层">5.4.2 C1卷积层</h3>
<p>由6个feature map组成，每个feature map由5×5卷积核生成(feature map中每个神经元与输入层的5×5区域像素相连)，考虑每个卷积核的bias，该层需要学习的参数个数为：(5×5+1)×6=<strong>156</strong>个，神经元连接数为：156×24×24=<strong>89856</strong>个。</p>
<h3 id="s2下采样层">5.4.3 S2下采样层</h3>
<p>该层每个feature map一一对应上一层的feature map，由于每个单元的2×2感受野采用不重叠方式移动，所以会产生6个大小为12×12的下采样feature map，如果采用Max Pooling/Mean Pooling，则该层需要学习的参数个数为<strong>0</strong>个(如果采用非等权下采样——即采样核有权重，则该层需要学习的参数个数为：(2×2+1)×6=30个)，神经元连接数为：30×12×12=<strong>4320</strong>个。</p>
<h3 id="c3卷积层">5.4.4 C3卷积层</h3>
<p>这层略微复杂，S2神经元与C3是多对多的关系，比如最简单方式：用S2的所有feature map与C3的所有feature map做全连接(也可以对S2抽样几个feature map出来与C3某个feature map连接)，这种全连接方式下：6个S2的feature map使用6个独立的5×5卷积核得到C3中1个feature map(生成每个feature map时对应一个bias)，C3中共有16个feature map，所以该层需要学习的参数个数为：(5×5×6+1)×16=<strong>2416</strong>个，神经元连接数为：2416×8×8=<strong>154624</strong>个。</p>
<h3 id="s4下采样层">5.4.5 S4下采样层</h3>
<p>同S2，如果采用Max Pooling/Mean Pooling，则该层需要学习的参数个数为<strong>0</strong>个，神经元连接数为：(2×2+1)×16×4×4=<strong>1280</strong>个。</p>
<h3 id="c5卷积层">5.4.6 C5卷积层</h3>
<p>类似C3，用S4的所有feature map与C5的所有feature map做全连接，这种全连接方式下：16个S4的feature map使用16个独立的1×1卷积核得到C5中1个feature map(生成每个feature map时对应一个bias)，C5中共有120个feature map，所以该层需要学习的参数个数为：(1×1×16+1)×120=<strong>2040</strong>个，神经元连接数为：<strong>2040</strong>个。</p>
<h3 id="f6全连接层">5.4.7 F6全连接层</h3>
<p>将C5层展开得到4×4×120=<strong>1920</strong>个节点，并接一个全连接层，考虑bias，该层需要学习的参数和连接个数为：(1920+1)*84=<strong>161364</strong>个。</p>
<h3 id="输出层">5.4.8 输出层</h3>
<p>该问题是个10分类问题，所以有10个输出单元，通过softmax做概率归一化，每个分类的输出单元对应84个输入。</p>
Minist(Modified NIST)数据集下使用LeNet-5的训练<a href="http://shixialiu.com/publications/cnnvis/demo/">可视化</a>：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b77tbfq8ml168019l1p6t36i9.png" width="800"  />
</center>
<p>可以看到其实全连接层之前的各层做的就是特征提取的事儿，且比较通用，对于标准化实物（人、车、花等等）可以复用，后面会单独介绍模型的fine-tuning。</p>
<h3 id="lenet-5代码实践">5.4.9 LeNet-5代码实践</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist, cifar10</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_LeNet5</span>():</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Convolution2D(<span class="number">6</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>, input_shape = (<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), dim_ordering=<span class="string">&#x27;tf&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(Convolution2D(<span class="number">16</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(Convolution2D(<span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">84</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;sigmoid&quot;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    model = build_LeNet5()</span><br><span class="line">    model.summary()</span><br><span class="line">    plot(model, to_file=<span class="string">&quot;LeNet-5.png&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">    (X_train, y_train), (X_test, y_test) = mnist.load_data()</span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    Y_train = np_utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">    Y_test = np_utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    nb_epoch = <span class="number">1</span></span><br><span class="line">    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">              verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">    score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br><span class="line">    y_hat = model.predict_classes(X_test)</span><br><span class="line">    test_wrong = [im <span class="keyword">for</span> im <span class="keyword">in</span> <span class="built_in">zip</span>(X_test,y_hat,y_test) <span class="keyword">if</span> im[<span class="number">1</span>] != im[<span class="number">2</span>]]</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> ind, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_wrong[:<span class="number">100</span>]):</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">        plt.subplot(<span class="number">10</span>, <span class="number">10</span>, ind + <span class="number">1</span>)</span><br><span class="line">        im = <span class="number">1</span> - val[<span class="number">0</span>].reshape((<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        plt.text(<span class="number">0</span>, <span class="number">0</span>, val[<span class="number">2</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">        plt.text(<span class="number">8</span>, <span class="number">0</span>, val[<span class="number">1</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        plt.imshow(im, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    savefig(<span class="string">&#x27;error.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>网络结构
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aab1kq13lbvgbkfq1e0o1qb1c.png" width="300"  />
</center></li>
<li>错误分类可视化
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7aac0i71ibcppe89e1sh61fv11p.png" width="500"  />
</center></li>
</ul>
<h2 id="alexnet">5.5 AlexNet</h2>
<p>AlexNet在ILSVRC-2012的比赛中获得top5错误率15.3%的突破（第二名为26.2%），其原理来源于2012年Alex的论文《<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>》，这篇论文是深度学习火爆发展的一个里程碑和分水岭，加上硬件技术的发展，深度学习还会继续火下去。</p>
<h3 id="网络结构分析">5.5.1 网络结构分析</h3>
由于受限于当时的硬件设备，AlexNet在GPU粒度都做了设计，当时的GTX 580只有3G显存，为了能让模型在大量数据上跑起来，作者使用了两个GPU并行，并对网络结构做了切分，如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1baou2biq9uhumh1tm1d95du99.png" width="600"  />
</center>
<p>上下两层分别并行的跑在两个GPU上，虚线代表依赖，交叉的虚线代表两个GPU之间需要通信后交换数据。</p>
<ul>
<li><p>输入层</p>
<p>输入为224×224×3的三通道RGB图像，为方便后续计算，实际操作中通过padding做预处理，把图像变成227×227×3。</p></li>
<li><p>C1卷积层</p>
<p>该层由：卷积操作 + Max Pooling + LRN（后面详细介绍它）组成。</p>
<p>(1)、卷积层：由<strong>96</strong>个feature map组成，每个feature map由<strong>11×11</strong>卷积核在<strong>stride=4</strong>下生成，输出feature map为<strong>55×55×48×2</strong>，其中55=(227-11)/4+1，48为分在每 个GPU上的feature map数，2为GPU个数；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>（文中实验表明采用2×2的非重叠模式的Max Pooling相对更容易过拟合，在top 1和top 5下的错误率分别高0.4%和0.3%），输出feature map为<strong>27×27×48×2</strong>，其中27=(55-3)/2+1，48为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(4)、LRN：邻居数设置为5做归一化。 最终输出数据为归一化后的：<strong>27×27×48×2</strong>。</p></li>
<li><p>C2卷积层</p>
<p>该层由：卷积操作 + Max Pooling + LRN组成</p>
<p>(1)、卷积层：由<strong>256</strong>个feature map组成，每个feature map由<strong>5×5</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为2的padding，输出feature map为<strong>27×27×128×2</strong>，其中27=(27-5+2×2)/1+1，128为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>，输出feature map为<strong>13×13×128×2</strong>，其中13=(27-3)/2+1，128为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(4)、LRN：邻居数设置为5做归一化。</p>
<p>最终输出数据为归一化后的：<strong>13×13×128×2</strong>。</p></li>
<li><p>C3卷积层 该层由：卷积操作 + LRN组成（注意，没有Pooling层）</p>
<p>(0)、输入为<strong>13×13×256</strong>，因为这一层两个GPU会做通信（途中虚线交叉部分）</p>
<p>(1)、卷积层：之后由<strong>384</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×192×2</strong>，其中13=(13-3+2×1)/1+1，192为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>最终输出数据为归一化后的：<strong>13×13×192×2</strong>。</p></li>
<li><p>C4卷积层 该层由：卷积操作 + LRN组成（注意，没有Pooling层）</p>
<p>(1)、卷积层：由<strong>384</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×192×2</strong>，其中13=(13-3+2×1)/1+1，192为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(2)、激活函数：采用ReLU； 最终输出数据为归一化后的：<strong>13×13×192×2</strong>。</p></li>
<li><p>C5卷积层 该层由：卷积操作 + Max Pooling组成</p>
<p>(1)、卷积层：由<strong>256</strong>个feature map组成，每个feature map由<strong>3×3</strong>卷积核在<strong>stride=1</strong>下生成，为使输入和卷积输出大小一致，需要做参数为1的padding，输出feature map为<strong>13×13×128×2</strong>，其中13=(13-3+2×1)/1+1，128为分在每个GPU上的feature map数，2为GPU个数；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>(3)、Max Pooling：采用<strong>stride=2</strong>且核大小为<strong>3×3</strong>，输出feature map为<strong>6×6×128×2</strong>，其中6=(13-3)/2+1，128为分在每个GPU上的feature map数，2为GPU个数. 最终输出数据为归一化后的：<strong>6×6×128×2</strong>。</p></li>
<li><p>F6全连接层 该层为全连接层 + Dropout</p>
<p>(1)、使用4096个节点；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>(3)、采用参数为0.5的Dropout操作</p>
<p>最终输出数据为4096个神经元节点。</p></li>
<li><p>F7全连接层 该层为全连接层 + Dropout</p>
<p>(1)、使用4096个节点；</p>
<p>(2)、激活函数：采用ReLU；</p>
<p>(3)、采用参数为0.5的Dropout操作</p>
<p>最终输出为4096个神经元节点。</p></li>
<li><p>F8输出层 该层为全连接层 + Softmax</p>
<p>(1)、使用1000个输出的Softmax</p>
<p>最终输出为1000个分类。</p></li>
</ul>
<p>AlexNet的亮点如下：</p>
<h3 id="relu激活函数">5.5.2 ReLu激活函数</h3>
AlexNet引入了ReLU激活函数，这个函数是神经科学家Dayan、Abott在《<a href="http://cns-classes.bu.edu/cn510/Papers/Theoretical%20Neuroscience%20Computational%20and%20Mathematical%20Modeling%20of%20Neural%20Systems%20-%20%20Peter%20Dayan,%20L.%20F.%20Abbott.pdf">Theoretical Neuroscience</a>》一书中提出的更精确的激活模型：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1b7a4mkcb1m76g9ue2g92jn97v.png" width="600"  />
</center>
<p>其中： <span class="math display">\[
\begin{array}{l}
\text{Eq.2.9:        }F(L)=G[L-L_0]_+\\
\text{Eq.2.10:     }F(L)=\frac{r_{max}}{1+exp(g_1(L_{1/2}-L))}\\
\text{Eq.2.11:      }F(L)=r_{max}[tanh (g_2(L-L_0))]_+
\end{array}
\]</span></p>
<p>详情请阅读书中2.2 Estimating Firing Rates这一节。新激活模型的特点是：</p>
<ul>
<li><p>激活稀疏性（<span class="math inline">\(L\)</span>小于1时<span class="math inline">\(r\)</span>为0）</p></li>
<li><p>单边抑制（不像Sigmoid是双边的）</p></li>
<li><p>宽兴奋边界，非饱和性（ReLU导数始终为1），很大程度缓解了梯度消失问题</p></li>
</ul>
<p>1、 原始ReLu</p>
<p>在这些前人研究的基础上（可参见 Hinton论文：《<a href="https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf">Rectified Linear Units Improve Restricted Boltzmann Machines</a>》），类似Eq.2.9的新激活函数被引入： <span class="math display">\[f(x)=max(0,x)\]</span> 这个激活函数把负激活全部清零（模拟上面提到的稀疏性），这种做法在实践中即保留了神经网络的非线性能力，又加快了训练速度。 但是这个函数也有缺点：</p>
<ul>
<li><p>在原点不可微</p>
<p>反向传播的梯度计算中会带来麻烦，所以Charles Dugas等人又提出Softplus来模拟上述ReLu函数（可视作其平滑版）： <span class="math display">\[f(x)=log(1+e^x)\]</span></p>
实际上它的导数就是一个logistic-sigmoid函数： <span class="math display">\[f’(x)=\frac{1}{1+e^{-x}}\]</span></li>
<li><p>过稀疏性 当学习率设置不合理时，即使是一个很大的梯度，在经过ReLu单元并更新参数后该神经元可能永不被激活。</p></li>
</ul>
<p>2、 Leaky ReLu</p>
<p>为了解决上述过稀疏性导致的大量神经元不被激活的问题，<strong>Leaky ReLu</strong>被提了出来： <span class="math display">\[
f(x)=\left\{
\begin{aligned}
 \alpha x &amp;(x&lt;0) \\
x &amp;(x&gt;=0)
\end{aligned}
\right.
\]</span> 其中<span class="math inline">\(\alpha\)</span>是人工指定的较小值(如：0.1)，它一定程度保留了负激活信息。</p>
<p>3、Parametric ReLu 上述<span class="math inline">\(\alpha\)</span>值是可以不通过人为指定而学习出的，于是<strong>Parametric ReLu</strong>被提了出来: 利用误差反向传播原理： <span class="math display">\[
\begin{array}{l}
\frac{\partial{E}}{\partial{\alpha}}=\sum\frac{\partial{E}}{\partial{f(x)}}\frac{\partial{f(x)}}{\partial{\alpha}}
\end{array}
\]</span> <span class="math display">\[
\frac{\partial{f(x)}}{\partial{\alpha}}=\left\{
\begin{aligned}
x &amp;(x&lt;0) \\
0 &amp;(x&gt;=0)
\end{aligned}
\right.
\]</span> 当采用动量法更新<span class="math inline">\(\alpha\)</span>权重： <span class="math display">\[
\Delta\alpha=\mu\Delta\alpha+\epsilon\frac{\partial{E}}{\partial{\alpha}}
\]</span> 详情请阅读Kaiming He等人的《<a href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》</a>论文。</p>
<p>4、Randomized ReLu Randomized ReLu 可以看做是leaky ReLu的随机版本，原理是：假设<span class="math display">\[\alpha\text{~}Normal(\mu,\delta)\]</span>然后再做权重调整。 <span class="math display">\[
f(x)=\left\{
\begin{aligned}
 \alpha x &amp;(x&lt;0) \\
x &amp;(x&gt;=0)
\end{aligned}
\right.
\]</span> 其中：<span class="math display">\[
\alpha\text{~}Normal(\mu,\delta)\text{ and }\mu&lt;\delta\text{ and }\mu,\delta\in[0,1)\]</span></p>
<h3 id="local-response-normalization">5.5.3 Local Response Normalization</h3>
<p>LRN利用相邻feature map做特征显著化，文中实验表明可以降低错误率，公式如下： <span class="math display">\[
\begin{array}{l}
b_{x,y}^i=a_{x,y}^i/(k+\alpha \sum_{j=max(0,i-n/2)}^{min(N-1,i+n/2)}(a^i_{x,y})^2)^\beta
\end{array}
\]</span></p>
公式的直观解释如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb836lcgb616edc351dnct96m.png" width="800"  />
</center>
由于<span class="math inline">\(a\)</span>都是经过了ReLU的输出，所以一定是大于0的，函数：<span class="math inline">\(\frac{1}{(k+\alpha \sum x^2)^\beta}\)</span>取文中参数的图形如下（横坐标为<span class="math inline">\(\sum x^2\)</span>）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bb83e7v01up1olv1r98e68lpf1g.png" width="400"  />
</center>
<p>当<span class="math inline">\(\sum x^2\)</span>值较小时，即当前节点和其邻居节点输出值差距不明显且大家的输出值都不太大，可以认为此时特征间竞争激烈，该函数可以使原本差距不大的输出产生显著性差异且此时函数输出不饱和；当<span class="math inline">\(\sum x^2\)</span>值较大时，说明特征本身有显著性差别但输出值太大容易过拟合，该函数可以令最终输出接近0从而缓解过拟合提高了模型泛化性。</p>
<h3 id="overlapping-pooling">5.5.4 Overlapping Pooling</h3>
<p>如其名，实验表明有重叠的抽样可以提高泛化性。</p>
<h3 id="dropout">5.5.5 Dropout</h3>
<p>Dropout是文章亮点之一，属于提高模型泛化性的方法，操作比较简单，以一定概率随机让某些神经元输出设置为0，既不参与前向传播也不参与反向传播，也可以从正则化角度去看待它。</p>
<ul>
<li>从模型集成的角度看
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbdegnoi6i44cpr7n19r7dhs9.png" width="600"  />
</center></li>
</ul>
<p>无Dropout网络： <span class="math display">\[
\begin{array}{l}
Y^n=W^nX^{n-1}\\
X^n=F(Y^n)\\
\end{array}
\]</span></p>
<p>有Dropout网络： <span class="math display">\[
\begin{array}{l}
Y^n=W^nX^{n-1}\\
d^{n-1}\sim Bernoulli (p)\\
X^n=d^{n-1} \odot F(Y^n)
\end{array}
\]</span> 其中<span class="math inline">\(p\)</span>为Dropout的概率，<span class="math inline">\(n\)</span>为所在层。</p>
<p>它是极端情况下的Bagging，由于在每步训练中，神经元会以某种概率随机被置为无效，相当于是参数共享的新网络结构，每个模型为了使损失降低会尽可能学最“本质”的特征，“本质”可以理解为由更加独立的、和其他神经元相关性弱的、泛化能力强的神经元提取出来的特征；而如果采用类似SGD的方式训练，每步迭代都会选取不同的数据集，这样整个网络相当于是用不同数据集学习的多个模型的集成组合。</p>
<p>从数据扩充(Data Augmentation)的角度看：</p>
<p>机器学习学的就是原始数据的数据分布，而泛化能力强的模型自然不能只针对训练集上的数据正确映射输出，但要想学到好的映射又需要数据越多越好，很多论文已经证明，带领域知识的数据扩充能够提高训练数据对原始真实分布的覆盖度，从而能够提高模型泛化效果。 《<a href="https://arxiv.org/pdf/1506.08700.pdf">Dropout as Data Augmentation</a>》将Dropout看做数据扩充的方法，文中证明了：总能找到一个样本，使得原始神经网络的输出与Dropout神经网络的输出一致(projecting noise back into the input space)。 用论文中符号说明如下： <span class="math display">\[
\begin{array}{l}
h(x)=xW+b\\
a(h)=rect(h)\\
\widetilde{a}(h)=M \odot rect(h)
\end{array}
\]</span> 其中：<span class="math inline">\(x\)</span>为<span class="math inline">\(d_i\)</span>维空间的输入，<span class="math inline">\(h(x)\)</span>为从<span class="math inline">\(d_i\)</span>维空间到<span class="math inline">\(d_h\)</span>维空间的仿射映射，<span class="math inline">\(a(h)\)</span>为激活函数，<span class="math inline">\(\widetilde{a}(h)\)</span>为Dropout版激活函数，<span class="math inline">\(M\sim Bernoulli(p_h)\)</span>，<span class="math inline">\(rect(h)\)</span>为rectifier函数(比如：ReLU): 对任何一个隐层，假设都存在一个输入<span class="math inline">\(x^*\)</span>，满足： <span class="math display">\[
(a\circ h)(x^*)=rect(h(x^*))\approx \vec{m}\odot rect(h(x))=(\widetilde{a} \circ h)(x)
\]</span> 注：式子左边为原始神经网络某层，右边为Dropout神经网络某层。 采用SGD优化下面目标函数，总能找到一个输入<span class="math inline">\(x^*\)</span>： <span class="math display">\[min~L(x,x^*)=min~|(a\circ h)(x^*)-(\widetilde{a} \circ h)(x)|^2\]</span></p>
<p>对于一个<span class="math inline">\(n\)</span>层的神经网络： 原始神经网络表示为： <span class="math display">\[
{f}^{(i)}(x^*)=({a}^{(i)}\circ h^{(i)}\circ ...\circ{a}^{(1)}\circ h^{(1)})(x^*)
\]</span></p>
<p>Dropout神经网络表示为： <span class="math display">\[
\widetilde{f}^{(i)}(x)=(\widetilde{a}^{(i)}\circ h^{(i)}\circ ...\circ\widetilde{a}^{(1)}\circ h^{(1)})(x)
\]</span></p>
<p>采用SGD优化下面目标函数，总能找到一系列输入<span class="math inline">\((x^{(1)*},...,x^{(n)*})\)</span>： <span class="math display">\[
min~L(x,x^{(1)*},...,x^{(n)*})=min~\sum_{i=1}^{n}\lambda_i|{f}^{(i)}(x^{(i)*})-\widetilde{f}^{(i)}(x)|^2
\]</span></p>
<p>文中附录部分证明不可能找到唯一序列使得：<span class="math inline">\(x^*=x^{(1)*}=...=x^{(n)*}\)</span></p>
<p>所以每次Dropout都是在生成新的样本。</p>
<h3 id="数据扩充">5.5.6 数据扩充</h3>
<p>基本方法 正如前面所说，数据扩充本质是减少过拟合的方法，AlexNet使用的方法计算量较小，所以也不用存储在磁盘，代码实现时，当GPU在训练前一轮图像时，后一轮的图像扩充在CPU上完成，扩充使用了两种方法：</p>
<p>1、图像平移和图像反射(关于某坐标轴对称)；</p>
<p>2、通过ImageNet训练集做PCA，用PCA产生的特征值和特征向量及期望为0标准差为0.1的高斯分布改变原图RGB三个通道的强度，该方法使得top-1错误率降低1%。</p>
<h3 id="多gpu训练">5.5.7 多GPU训练</h3>
<p>作者使用GTX 580来加速训练，但受限于当时硬件设备的发展，作者需要对网络结构做精细化设计，甚至需要考虑两块GPU之间如何及何时通信，现在的我们比较幸福，基本不用考虑这些。</p>
<h3 id="alexnet代码实践">5.5.8 AlexNet代码实践</h3>
<p>使用<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>标准数据集，由6w张32×32像素图片组成，一共10个分类。像这样：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvdmto1d13f3mj8csu94fu1t.png" width="500"  />
</center>
<p>代码实现： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10,mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num*num):</span><br><span class="line">        axes=plt.subplot(num,num,i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#以下结构统一忽略LRN层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_AlexNet</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#第一层，卷积层 + max pooling</span></span><br><span class="line">    model.add(Convolution2D(<span class="number">96</span>, <span class="number">11</span>, <span class="number">11</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, input_shape = s))</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment">#第二层，卷积层 + max pooling</span></span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, <span class="number">5</span>, <span class="number">5</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment">#第三层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment">#第四层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">1024</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    <span class="comment">#第五层，卷积层</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">1024</span>, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    <span class="comment">#第六层，全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">3072</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment">#第七层，全连接层</span></span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    <span class="comment">#第八层， 输出层</span></span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    //使用第三个GPU卡</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>,                                                                                    allow_growth=<span class="literal">True</span>)</span><br><span class="line">        //只有卡<span class="number">3</span>可见防止tensorflow占用所有卡</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>]=<span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        model = build_AlexNet(s)</span><br><span class="line">        model.summary()</span><br><span class="line"></span><br><span class="line">        plot(model, to_file=<span class="string">&quot;AlexNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#预处理与数据扩充</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">25</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">False</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">                  verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br><span class="line">        y_hat = model.predict_classes(X_test)</span><br><span class="line">        test_wrong = [im <span class="keyword">for</span> im <span class="keyword">in</span> <span class="built_in">zip</span>(X_test,y_hat,y_test) <span class="keyword">if</span> im[<span class="number">1</span>] != im[<span class="number">2</span>]]</span><br><span class="line"></span><br><span class="line">        plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">        <span class="keyword">for</span> ind, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_wrong[:<span class="number">100</span>]):</span><br><span class="line">            plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">            plt.subplot(<span class="number">10</span>, <span class="number">10</span>, ind + <span class="number">1</span>)</span><br><span class="line">            plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">            plt.text(<span class="number">0</span>, <span class="number">0</span>, val[<span class="number">2</span>][<span class="number">0</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">            plt.text(<span class="number">8</span>, <span class="number">0</span>, val[<span class="number">1</span>], fontsize=<span class="number">14</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">            plt.imshow(toimage(val[<span class="number">0</span>]))</span><br><span class="line">        savefig(<span class="string">&#x27;Wrong.jpg&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<ul>
<li>训练数据可视化</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv7v5le1fkv1id5fe5180v17lt9.png" width="400"  />
</center>
<ul>
<li>网络结构
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbv8dth1kq99h1vvn1j72ofl13.png" width="300"  />
</center></li>
</ul>
<p>可以看到实践中，AlexNet的参数规模巨大（将近2亿个参数），所以即使在GPU上训练也很慢。</p>
<ul>
<li><p>错误分类可视化</p>
<p>蓝色为实际分类，红色为预测分类。</p></li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvjlvf9g4gl591a301tnn7722a.png" width="500"  />
</center>
<h2 id="vgg">5.6 VGG</h2>
<p>在论文《<a href="https://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a>》中提出，通过缩小卷积核大小来构建更深的网络。</p>
<h3 id="网络结构">5.6.1 网络结构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbj7cd733bns621ibu9p9g8d9.png" width="600"  />
</center>
<p>图中D和E分别为VGG-16和VGG-19，是文中两个效果最好的网络结构，VGG网络结构可以看做是AlexNet的加深版，VGG在图像检测中效果很好（如：Faster-RCNN），这种传统结构相对较好的保存了图片的局部位置信息（不像GoogLeNet中引入Inception可能导致位置信息的错乱）。 与AlexNet相比：</p>
<ul>
<li><p>相同点</p>
<ul>
<li><p>整体结构分五层；</p></li>
<li><p>除softmax层外，最后几层为全连接层；</p></li>
<li><p>五层之间通过max pooling连接。</p></li>
</ul></li>
<li><p>不同点</p>
<ul>
<li><p>使用3×3的小卷积核代替7×7大卷积核，网络构建的比较深；</p></li>
<li><p>由于LRN太耗费计算资源，性价比不高，所以被去掉；</p></li>
<li><p>采用了更多的feature map，能够提取更多的特征，从而能够做更多特征的组合。</p></li>
</ul></li>
</ul>
<h3 id="vgg代码实践">5.6.2 VGG代码实践</h3>
<p>VGG-16/VGG-19</p>
<p>使用<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a>数据集，ps复杂网络在这种数据集上表现不好。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar100,mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential, Graph</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num*num):</span><br><span class="line">        axes=plt.subplot(num,num,i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_VGG_16</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    fm = <span class="number">3</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>),input_shape=s))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">100</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_VGG_19</span>(<span class="params">s</span>):</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    fm = <span class="number">3</span></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>),input_shape=s))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">64</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">128</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">256</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(ZeroPadding2D((<span class="number">1</span>,<span class="number">1</span>)))</span><br><span class="line">    model.add(Convolution2D(<span class="number">512</span>, fm, fm, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(MaxPooling2D((<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">    model.add(Dense(<span class="number">100</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.visualize_util <span class="keyword">import</span> plot</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:2&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>,                                                                                    allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>]=<span class="string">&quot;2&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar100.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> (s)</span><br><span class="line">        model = build_VGG_16(s) <span class="comment">#build_VGG_19(s)</span></span><br><span class="line">        model.summary()</span><br><span class="line"></span><br><span class="line">        plot(model, to_file=<span class="string">&quot;VGG.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">100</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">False</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line">        <span class="comment"># training</span></span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line">        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<h2 id="msranet">5.7 MSRANet</h2>
<p>该网络的亮点有两个：提出PReLU和一种鲁棒性强的参数初始化方法</p>
<h3 id="prelu">5.7.1 PReLU</h3>
前面已经介绍过传统ReLU的一些缺点，PReLU是其中一种解决方案：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bbvq8lr81905f8m1do2fta2b59.png" width="500"  />
</center>
<p>如何合理保留负向信息，一种方式是上图中<span class="math inline">\(\alpha\)</span>值是可以不通过人为指定而自动学出来：</p>
<p>定义Parametric Rectifiers如下： <span class="math display">\[ f(y_i)=\left\{
\begin{aligned}
y_i, &amp; \text{if } y_i&gt;0 \\
\alpha_i y_i, &amp; else.
\end{aligned}
\right.
\]</span> 利用误差反向传播原理： <span class="math display">\[
\begin{array}{l}
\frac{\partial{E}}{\partial{\alpha_i}}=\sum_{y_i}\frac{\partial{E}}{\partial{f(y_i)}}\frac{\partial{f(y_i)}}{\partial{\alpha_i}}
\end{array}
\]</span> <span class="math display">\[
\frac{\partial{f(y_i)}}{\partial{\alpha_i}}=\left\{
\begin{aligned}
y_i, &amp;(y_i\leq 0) \\
0, &amp;(y_i&gt;0)
\end{aligned}
\right.
\]</span> 当采用动量法更新<span class="math inline">\(\alpha\)</span>权重： <span class="math display">\[
\Delta\alpha_i=\mu\Delta\alpha_i+\epsilon\frac{\partial{E}}{\partial{\alpha_i}}
\]</span> 详情请阅读Kaiming He等人的《<a href="https://arxiv.org/pdf/1502.01852.pdf">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification》</a>论文。</p>
<h2 id="highway-networks">5.8 Highway Networks</h2>
Highway Networks在我看来是一种承上启下的结构，来源于论文《<a href="https://arxiv.org/abs/1505.00387">Highway Networks</a>》借鉴了类似LSTM(后面会介绍)中门(gate)的思想，结构很通用(太通用的结构不一定是件好事儿)，给出了一种建立更深网络的思路：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bccghn95ouk13mihb18dk1htum.png" width="600"  />
</center>
<p><span class="math display">\[
\begin{array}{l}
y=H(x,W_h)\cdot T(x,W_t)+x \cdot C(x,W_c)
\end{array}
\]</span> 任何一层或几层都可以通过上述方式构建Block，公式中<span class="math inline">\(T\)</span>叫做transform gate，<span class="math inline">\(C\)</span>叫做carry gate，一般简单起见可以让<span class="math inline">\(C=1-T\)</span>，显然公式中<span class="math inline">\(x\)</span>，<span class="math inline">\(y\)</span>，<span class="math inline">\(H(x,W_h)\)</span>，<span class="math inline">\(T(x,W_t)\)</span>需要有相同的维度（比如，可以通过zero-padding或者做映射），通过这种结构可以把网络做到很深(比如100层以上)，并且优化没有那么困难，看着似乎提供了解决“深”网络学习问题的方案(下一节会解释“似乎”这个词)。</p>
<h2 id="residual-networks">5.9 Residual Networks</h2>
<p>残差网络在《<a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>》中被第一次提出，作者利用它在ILSVRC 2015的ImageNet 分类、检测、定位任务以及COCO 2015的检测、图像分割任务上均拿到第一名，也证明ResNet是比较通用的框架。</p>
<h3 id="resnet产生的动机">5.9.1 ResNet产生的动机</h3>
我一直说深度学习的研究很大程度是实验科学，ResNet的研究上也比较能体现这点。一个问题：是否能够通过简单的增加网络层数就能学到更好的模型呢？通过实验发现答案是否定的，并且随着层数的增加预测精度会趋于饱和，然后迅速下降，这个现象叫degradation。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcgu3avu1dc10dc1gbm1jmdpdt9.png" width="500"  />
</center>
图中可以看到在CIFAR-10数据集上，20层网络在训练集和测试集上的表现都明显好于56层网络，这显然不是过拟合导致的，这个现象也不符合我们的直观映像：按理说多增加一层的模型效果应该好于未增加时的模型，最起码不应该变差（比如直接做<span class="math inline">\(f(x)=x\)</span>恒等映射），于是作者提出原始的残差学习框架（也可以看成是Highway Networks在T=0.5时的特例）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch1m72996df6b1aqpjb43ka1g.png" width="400"  />
</center>
<p><span class="math display">\[
\begin{array}{l}
y_l=h(x_l)+F(x_l,\{W_l\})\\
x_{l+1}=f(y_l)
\end{array}
\]</span> 其中<span class="math inline">\(h(x_l)=x_l\)</span>为恒等映射，<span class="math inline">\(f\)</span>为<span class="math inline">\(ReLU\)</span>激活函数，输入和输出的维度是一样的（即使不一样也可以通过zero-padding或再做一次映射变成一样），图中恒等映射是在两层神经网络后，也可以在任意层后。 这个框架的假设是：多层非线性激活的神经网络学习恒等映射的能力比较弱，直接将恒等映射加入可以跳过这个问题。 与Highway Networks相比： - HN的transform gate和carry</p>
<h3 id="恒等映射">5.9.2 恒等映射</h3>
恒等映射在深度残差网络中究竟扮演什么角色呢？在《<a href="https://arxiv.org/abs/1603.05027">Identity Mappings in Deep Residual Networks</a>》中作者做了分析，并提出新的残差block结构，将<span class="math inline">\(h(x_l)=x_l\)</span>和<span class="math inline">\(f(y_l)=y_l\)</span>都改为恒等映射，通过这个变化使得信号在前向和反向传播中都有“干净”的路径（图中灰色部分），a为原始block结构，b为新的结构。。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch28tob175blpk1mri13no1gas2a.png" width="300"  />
</center>
<p>原始结构： <span class="math display">\[
\begin{array}{l}
x_{l+1}=relu(B(W_{i2}^T\cdot relu (B(W_{i1}^T\cdot x_l)))+x_l)
\end{array}
\]</span></p>
<p>新结构： <span class="math display">\[
\begin{array}{l}
x_{l+1}=W_{i2}^T\cdot relu(B(W_{i1}^T\cdot relu(B(x_l))))+x_l
\end{array}
\]</span></p>
<p>其中<span class="math inline">\(B\)</span>为Batch Normalization。</p>
在CIFAR-10上用1001层残差网络做测试，效果如下:
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bch6qshn1uu8evo1mek1q04j0j2n.png" width="400"  />
</center>
<p>新的proposed结构比原始结构效果明显： 双恒等映射下，任何一个残差block如下： <span class="math display">\[
\begin{array}{l}
x_{l+1}=x_l+F(x_l,\{W_l\})
\end{array}
\]</span> 对上述结构做递归展开，任何一个深层block和其所有浅层block的关系为： <span class="math display">\[
\begin{array}{l}
x_L=x_l+\sum_{i=l}^{L-1}F(x_i,\{W_i\})\\
x_L=x_0+\sum_{i=0}^{L-1}F(x_i,\{W_i\})
\end{array}
\]</span> 这个形式会有很好的计算性质，回想GBDT，是否觉得有点像？在反向传播时同样也有良好的性质： <span class="math display">\[
\begin{array}{l}
\frac{\partial E}{\partial x_l}=\frac{\partial E}{\partial x_L}\frac{\partial x_L}{\partial x_l}=\frac{\partial E}{\partial x_L}(1+\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}F(x_i,\{W_i\}))
\end{array}
\]</span> 前半部分<span class="math inline">\(\frac{\partial E}{\partial x_L}\)</span>传播时完全不用考虑权重层，可以很直接的把误差的梯度信息反向传播给任何一个浅层block，而<span class="math inline">\(\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}F(x_i,\{W_i\})\)</span>在mini-batch时又不太可能总为-1，所以即使权重很小也很难出现梯度消失的问题。假如不采用恒等映射，例如：<span class="math inline">\(h(x_l)=\lambda_lx_l\)</span>，则： <span class="math display">\[
\begin{array}{l}
x_{l+1}=\lambda_lx_l+F(x_l,\{W_l\})\\
x_L=(\prod_{i=1}^{L-1}\lambda_i)x_l+\sum_{i=l}^{L-1}(\prod_{j=i+1}^{L-1}\lambda_j)F(x_i,\{W_i\})\\
\frac{\partial E}{\partial x_l}=\frac{\partial E}{\partial x_L}(\prod_{i=1}^{L-1}\lambda_i+\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}(\prod_{j=i+1}^{L-1}\lambda_j)F(x_i,\{W_i\}))
\end{array}
\]</span> 如果网络比较深，对于参数<span class="math inline">\(\prod_{i=1}^{L-1}\lambda_i\)</span>，当<span class="math inline">\(\lambda_i&gt;1\)</span>时它会很大；当<span class="math inline">\(\lambda_i&lt;1\)</span>时，它会很小甚至消失，此时反向信号会被强制流到block的各个权重层，显然恒等映射的优点完全没有了。</p>
<h3 id="模型集成角度看残差网络">5.9.3 模型集成角度看残差网络</h3>
《<a href="https://arxiv.org/abs/1605.06431">Residual Networks Behave Like Ensembles of Relatively Shallow Networks</a>》中把残差网络做展开，其实会发现以下关系：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjstr2317mfjvu1vmk1ks650tp.png" width="600"  />
</center>
如果有<span class="math inline">\(n\)</span>个残差block，展开后会得到<span class="math inline">\(2^n\)</span>个路径，于是残差网络就可以看成这么多模型的集成。那么这些路径之间是否有互相依赖关系呢：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjtdpgvo9d4mu1qgvnnf1as816.png" width="600"  />
</center>
可以看到删除VGG任何一层，不管在CIFAR-10还是ImageNet数据集上，准确率立马变得惨不忍睹，而删除残差网络的任何一个block几乎不会影响效果，但删除采样层会对效果影响较大(采样层不存在展开多路径特点)，上面实验表明对残差网络，虽然多路径是联合训练的，但路径间相互没有强依赖性，直观的解释如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcju6o25j461qs419hj175kbv23.png" width="500"  />
</center>
即使删掉<span class="math inline">\(f_2\)</span>这个节点，还有其它路径存在，而非残差结构的路径则会断掉。 残差网络看做集成模型可以通过下面实验结果得到印证：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcjunpd21l3d15gltbnb3c1flo2g.png" width="600"  />
</center>
<p>模型在运行时的效果与有效路径的个数成正比且关系平滑，左图说明残差网络的效果类似集成模型，右图说明实践中残差网络可以在运行时做网络结构修改。</p>
<h3 id="残差网络中的短路径">5.9.4 残差网络中的短路径</h3>
通过残差block的结构可知展开后的<span class="math inline">\(n\)</span>个路径的长度服从二项分布<span class="math inline">\(X\sim B(n,1/2)\)</span>，(每次选择是否跳过权重层的概率是0.5)，所以其期望为：<span class="math inline">\(n/2\)</span>，下面三幅图是在有54个残差block下的实验，第一幅图为路径分布图，可以看到95%的路径长度都在19~35之间：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck0vn7b165t11ic1r8qq4btb32t.png" width="300"  />
</center>
由于路径长短不同，在反向传播时携带的梯度信息量也不同，路径长度与携带梯度信息量成反比，实验结果如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck114mu1q796bt1a1n17oi1ejg47.png" width="300"  />
</center>
残差网络中真正有效的路径几乎都是浅层路径，实验中有效路径长度在5~17之间，所以实践中做模型压缩可以先从长路径入手。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bck10n9n1oriqt7k915eb1psv3q.png" width="300"  />
</center>
<p>虽然残差网络没有解决梯度消失问题，只是把它给绕过了，并没有解决深层神经网络的本质问题，但我们应用时更多的看实践效果。</p>
<h3 id="代码实践">5.9.5 代码实践</h3>
下面我们实现在《<a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>》中提到的ResNet-34，并演示在CIFAR-10下的训练效果。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bckd30m886a135elhmf2m125c5u.png" width="400"  />
</center>
<ul>
<li><p>resnet.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> add</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Activation, Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Conv2D, MaxPooling2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;残差网络基本模块定义&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">&#x27;resnet&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        self.name = n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN与ReLU子结构，针对tensorflow&#x27;&#x27;&#x27;</span></span><br><span class="line">        normalize = BatchNormalization(axis=<span class="number">3</span>)(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(normalize)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bn_relu_weight</span>(<span class="params">self, filters, kernel_size, strides</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN-&gt;ReLu-&gt;Weight的子结构&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            act = self.bn_relu(<span class="built_in">input</span>)</span><br><span class="line">            conv = Conv2D(filters=filters,</span><br><span class="line">                          kernel_size=kernel_size,</span><br><span class="line">                          strides=strides,</span><br><span class="line">                          padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                          kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                          kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(act)</span><br><span class="line">            <span class="keyword">return</span> conv</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_bn_relu</span>(<span class="params">self, filters, kernel_size, strides</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中BN-&gt;ReLu-&gt;Weight的子结构&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="keyword">return</span> self.bn_relu(Conv2D(filters=filters,</span><br><span class="line">                                       kernel_size=kernel_size,</span><br><span class="line">                                       strides=strides,</span><br><span class="line">                                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shortcut</span>(<span class="params">self, left, right</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建propoesd残差block中恒等映射的子结构，分两种情况，输入、输出维度一致&amp;维度不一致&#x27;&#x27;&#x27;</span></span><br><span class="line">        left_shape = K.int_shape(left)</span><br><span class="line">        right_shape = K.int_shape(right)</span><br><span class="line">        stride_width = <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">1</span>] / right_shape[<span class="number">1</span>]))</span><br><span class="line">        stride_height = <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">2</span>] / right_shape[<span class="number">2</span>]))</span><br><span class="line">        equal_channels = left_shape[<span class="number">3</span>] == right_shape[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        x_l = left</span><br><span class="line">        <span class="comment"># 如果输入输出维度不一致需要通过映射变一致，否则一致则返回单位矩阵，这个映射发生在两个不同维度block之间(论文中虚线部分)</span></span><br><span class="line">        <span class="keyword">if</span> left_shape != right_shape:</span><br><span class="line">            x_l = Conv2D(filters=right_shape[<span class="number">3</span>],</span><br><span class="line">                         kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                         strides=(<span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">1</span>] / right_shape[<span class="number">1</span>])),</span><br><span class="line">                                  <span class="built_in">int</span>(<span class="built_in">round</span>(left_shape[<span class="number">2</span>] / right_shape[<span class="number">2</span>]))),</span><br><span class="line">                         padding=<span class="string">&quot;valid&quot;</span>,</span><br><span class="line">                         kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                         kernel_regularizer=l1_l2(<span class="number">0.01</span>, <span class="number">0.0001</span>))(left)</span><br><span class="line"></span><br><span class="line">        x_l_1 = add([x_l, right])</span><br><span class="line">        <span class="keyword">return</span> x_l_1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">basic_block</span>(<span class="params">self, filters, strides=(<span class="params"><span class="number">1</span>, <span class="number">1</span></span>), is_first_block=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;34层以内的残差网络使用的block，2层一跨&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="comment"># 恒等映射</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> is_first_block:</span><br><span class="line">                conv1 = self.bn_relu_weight(filters=filters,</span><br><span class="line">                                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                            strides=strides)(<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                conv1 = Conv2D(filters=filters, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                               strides=strides,</span><br><span class="line">                               padding=<span class="string">&quot;same&quot;</span>,</span><br><span class="line">                               kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                               kernel_regularizer=l1_l2(<span class="number">0.01</span>, <span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line">            <span class="comment"># 残差网络</span></span><br><span class="line">            residual = self.bn_relu_weight(filters=filters,</span><br><span class="line">                                           kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(conv1)</span><br><span class="line">            <span class="comment"># 构建一个两层的残差block</span></span><br><span class="line">            <span class="keyword">return</span> self.shortcut(<span class="built_in">input</span>, residual)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">residual_block</span>(<span class="params">self, block_func, filters, repeat_times, is_first_block</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;构建多层残差block&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">inner_func</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(repeat_times):</span><br><span class="line">                <span class="comment"># 第一个block的第一层，其输入为pooling层</span></span><br><span class="line">                <span class="keyword">if</span> is_first_block:</span><br><span class="line">                    strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">0</span>:  <span class="comment"># 每个残差block的第一层</span></span><br><span class="line">                        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">else</span>:  <span class="comment"># 每个残差block的非第一层</span></span><br><span class="line">                        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">                flag = i == <span class="number">0</span> <span class="keyword">and</span> is_first_block</span><br><span class="line">                <span class="built_in">input</span> = block_func(filters=filters,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   is_first_block=flag)(<span class="built_in">input</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> inner_func</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">residual_builder</span>(<span class="params">self, input_shape, softmax_num, func_type, repeat_times</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;指定输入、输出、残差block的类型、网络深度并构建残差网络&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">input</span> = Input(shape=input_shape)</span><br><span class="line">        <span class="comment"># 第一层为卷积层</span></span><br><span class="line">        conv1 = self.weight_bn_relu(filters=<span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))(<span class="built_in">input</span>)</span><br><span class="line">        <span class="comment"># 第二层为max pooling层</span></span><br><span class="line">        pool1 = MaxPooling2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&quot;same&quot;</span>)(conv1)</span><br><span class="line">        residual_block = pool1</span><br><span class="line">        filters = <span class="number">64</span></span><br><span class="line">        <span class="comment"># 接着16个残差block</span></span><br><span class="line">        <span class="keyword">for</span> i, r <span class="keyword">in</span> <span class="built_in">enumerate</span>(repeat_times):</span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                residual_block = self.residual_block(func_type,</span><br><span class="line">                                                     filters=filters,</span><br><span class="line">                                                     repeat_times=r,</span><br><span class="line">                                                     is_first_block=<span class="literal">True</span>)(residual_block)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                residual_block = self.residual_block(func_type,</span><br><span class="line">                                                     filters=filters,</span><br><span class="line">                                                     repeat_times=r,</span><br><span class="line">                                                     is_first_block=<span class="literal">False</span>)(residual_block)</span><br><span class="line">            filters *= <span class="number">2</span></span><br><span class="line"></span><br><span class="line">        residual_block = self.bn_relu(residual_block)</span><br><span class="line">        shape = K.int_shape(residual_block)</span><br><span class="line">        <span class="comment"># average pooling层</span></span><br><span class="line">        pool2 = AveragePooling2D(pool_size=(shape[<span class="number">1</span>], shape[<span class="number">2</span>]),</span><br><span class="line">                                 strides=(<span class="number">1</span>, <span class="number">1</span>))(residual_block)</span><br><span class="line">        flatten1 = Flatten()(pool2)</span><br><span class="line">        <span class="comment"># 全连接层</span></span><br><span class="line">        dense1 = Dense(units=softmax_num,</span><br><span class="line">                       kernel_initializer=<span class="string">&quot;he_normal&quot;</span>,</span><br><span class="line">                       activation=<span class="string">&quot;softmax&quot;</span>)(flatten1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Model(inputs=<span class="built_in">input</span>, outputs=dense1)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li>
<li><p>resnet-cifar-10.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> resnet</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau, CSVLogger, EarlyStopping</span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_visualize</span>(<span class="params">x, y, num</span>):</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num * num):</span><br><span class="line">        axes = plt.subplot(num, num, i + <span class="number">1</span>)</span><br><span class="line">        axes.set_title(<span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(y[i]))</span><br><span class="line">        axes.set_xticks([<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])</span><br><span class="line">        axes.set_yticks([<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])</span><br><span class="line">        plt.imshow(toimage(x[i]))</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line">        data_visualize(X_train, y_train, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line"></span><br><span class="line">        builder = resnet.ResNet(<span class="string">&quot;ResNet-test&quot;</span>)</span><br><span class="line">        resnet_34 = builder.residual_builder(s, class_num, builder.basic_block, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>])</span><br><span class="line">        model = resnet_34</span><br><span class="line">        model.summary()</span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;ResNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">100</span></span><br><span class="line">        <span class="comment"># import pdb</span></span><br><span class="line">        <span class="comment"># pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>,</span><br><span class="line">                        save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),</span><br><span class="line">                            steps_per_epoch=X_train.shape[<span class="number">0</span>],</span><br><span class="line">                            validation_data=(X_test, Y_test),</span><br><span class="line">                            epochs=nb_epoch,</span><br><span class="line">                            verbose=<span class="number">1</span>,</span><br><span class="line">                            max_q_size=<span class="number">100</span>,</span><br><span class="line">                            callbacks=[lr_reducer, early_stopper, csv_logger])</span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure> ps：注意使用keras的plot_model函数需要安装graphviz与pydot_ng，且安装顺序为先graphviz后pydot_ng。</p></li>
<li><p>graphviz安装 yum list available 'graphviz<em>' yum install 'graphviz</em>'</p></li>
<li><p>pydot_ng安装 pip install pydot_ng</p></li>
<li>网络结构
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bcuf44v814n11e17eco10fqha4i.png" width="300"  />
</center></li>
</ul>
<p>可以看到网络结构很复杂但需要训练的参数个数只有21296522个，远小于AlexNet参数个数。</p>
<ul>
<li>CIFAR-10训练情况
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdfrbd74dti1kpn8b2nho1l9u9.png" width="600"  />
</center></li>
</ul>
<p>迭代100次后，训练集上Acc为：0.8367，测试集上Acc为0.8346。</p>
<h2 id="maxout-networks">5.10 Maxout Networks</h2>
<p>Goodfellow等人在《<a href="http://www.jmlr.org/proceedings/papers/v28/goodfellow13.pdf">Maxout Networks</a>》一文中提出，这篇论文值得一看。 ### 5.10.1 Maxout激活函数 对于神经网络任意一层可以添加Maxout结构，公式如下： <span class="math display">\[
\begin{array}{l}
h_i(x)=max_{j\in [1,k]}z_{ij}\\
z_{ij}=x^TW_{...ij}+b_{ij}
\end{array}
\]</span> 上面的<span class="math inline">\(W\)</span>和<span class="math inline">\(b\)</span>是要学习的参数，这些参数可以通过反向传播计算，<span class="math inline">\(k\)</span>是事先指定的参数，<span class="math inline">\(x\)</span>是输入节点，假定有以下3层网络结构：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahcfttqvb61mgjjom10f0qjg9.png" width="300"  />
</center>
<p>Maxout激活可以认为是在输入节点<span class="math inline">\(x\)</span>和输出节点<span class="math inline">\(h\)</span>中间加了<span class="math inline">\(k\)</span>个隐含节点，以上图节点<span class="math inline">\(i\)</span>为例，<strong>上图红色部分</strong>在Maxout结构中被扩展为以下结构：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahdkbr71mq0bnoen29g715t3m.png" width="350"  />
</center>
实际上图所示的单个Maxout 单元本质是一个分段线性函数，而任意凸函数都可以通过分段线性函数来拟合，这个可以很直观的理解，以抛物线为例：每个<span class="math inline">\(z\)</span>节点都是一个线性函数，上图<span class="math inline">\(z_1\)</span>-<span class="math inline">\(z_4\)</span>节点输出对应下图<span class="math inline">\(k_1\)</span>-<span class="math inline">\(k_4\)</span>线段：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bahgd34419nmh3l15hk6srpvc1g.png" width="300"  />
</center>
<p>从全局上看，ReLU可以看做Maxout的一种特例，Maxout通过网络自动学习激活函数(从这个角度看Maxout也可以看做某种Network-In-Network结构)，不对<span class="math inline">\(k\)</span>做限制，只要两个Maxout 单元就能拟合任意连续函数，关于这部分论文中有更详细的证明，这里不再赘述，实际上它与Dropout配合效果更好，这里可以回想下核方法(Kernel Method)，核方法采用非线性核（如高斯核）也会有类似通过局部线性拟合来模拟非线性行为，但传统核方法会事先指定核函数（如高斯函数），而不是数据驱动的方式算出来，当然也有kernel组合方面的研究，但在我看来最终和神经网络殊途同归，其实都可以在神经网络的大框架下去思考（回想前面的SVM与神经网络的关系）。 凡事都有两面性，Maxout的缺点也是明显的：多了一倍参数、需要人为指定<span class="math inline">\(k\)</span>值、先验假设被学习的激活函数是凸的。</p>
<h2 id="network-in-network">5.11 Network in Network</h2>
<p>NIN的思想来源于《<a href="https://arxiv.org/abs/1312.4400">Network In Network</a>》,其亮点有2个方面：将传统卷积层替换为非线性卷积层以提升特征抽象能力；使用新的pooling层代替传统全连接层，后续出现的各个版本GoogLeNet也很大程度借鉴了这个思想。</p>
<h3 id="nin卷积层mlp-convolution">5.11.1 NIN卷积层(MLP Convolution)</h3>
<p>传统卷积操作，例如：<span class="math inline">\(f_{i,j,k}=max(W_k^T \cdot x_{i,j},0)\)</span>，本质是广义线性模型，意味着当数据接近线性可分时模型效果会比较好，反之亦然。Maxout网络在一定程度上解决了这个问题，但它有凸函数的假设，实际当中可能很多情况是非凸的，所以论文提出使用多层感知机(MLP)来拟合，不做任何先验假设。 选择MLP的原因是：</p>
<ul>
<li><p>MLP能拟合任意函数，不需要做先验假设(如：线性可分、凸集)；</p></li>
<li><p>MLP与卷积神经网络结构天然兼容，可以通过BP方便的做训练；</p></li>
<li><p>MLP本身也能做的较深，且特征能够得到复用；</p></li>
<li>通过MLP做卷积可以起到feature map级联交叉加权组合的作用，能提升特征抽象能力： <span class="math display">\[
  \begin{array}{l}
  f^1_{i,j,k_1}=max({w^1_{k_1}}^Tx_{i,j}+b_{k_1},0)\\
  \quad\quad \quad .\\
  \quad\quad \quad .\\
  \quad\quad \quad .\\
  f^1_{i,j,k_n}=max({w^n_{k_n}}^Tf_{i,j}^{n-1}+b_{k_n},0).
  \end{array}
  \]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15as53vqk1k4b1g601kic180s9.png" width="500"  />
</center></li>
</ul>
显然这个结构也等价于传统卷积层接着一个1×1卷积层，简单起见，下面示意图中激活函数使用线性激活（使用ReLU无非是让某些输出可能为0，不影响问题说明）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd5oqug8c827q01unr1i701lab9.png" width="500"  />
</center>
<p><span class="math display">\[
\begin{array}{l}
O_1=\sum_{i=1}^2\sum_{j=1}^2x_{ij} \cdot W_{ij} \cdot (C_1 \cdot W_{1ij}+ C_2 \cdot W_{ij,2})\\
C1=W_{m11}W_{o31}+W_{m12}W_{o32}\\
C2=W_{m21}W_{o31}+W_{m22}W_{o32}
\end{array}
\]</span> <span class="math inline">\(O_1\)</span>的前半部分是传统卷积层，后半部分可以看做1×1卷积层。 ### 5.11.2 NIN抽样层(Global Average Pooling) 把传统卷积网络分两部分看待：除全连接层外的各个卷积层看做特征提取器，全连接层看成特征组合器。由于全连接的存在破坏了数据的可解释性并大大增加了可训练参数的个数，NIN通过GAP来避免这两个问题，具体做法是：</p>
<ul>
<li>最后一层卷积feature map的个数与分类类别数一致，这种一致性可以产生相对较少的feature map，比如有10个分类和10个n×n的feature map；</li>
<li>每个feature map对应一个分类，并对整个feature map求平均值，这种方法能提高空间变换的稳定性，但损失了位置信息（例如在目标检测中位置信息很重要），比如10个n×n的feature map会得到10个实数值组成的一维向量；</li>
<li>用softmax做归一化，注意这里要区分传统CNN下的softmax激活和softmax归一，这一层没有需要优化的参数。 传统CNN与Mlpconv的区别如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd16cnk617e3160k1uvuar8n032q.png" width="600"  />
</center></li>
</ul>
最后整个NIN的网络结构如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd15r350126392fmchslo1uh120.png" width="500"  />
</center>
<h2 id="googlenet-inception-v1">5.12 GoogLeNet Inception V1</h2>
<p>GoogLeNet是由google的Christian Szegedy等人在2014年的论文《<a href="https://arxiv.org/abs/1409.4842">Going Deeper with Convolutions</a>》提出，其最大的亮点是提出一种叫Inception的结构，以此为基础构建GoogLeNet，并在当年的ImageNet分类和检测任务中获得第一，ps：GoogLeNet的取名是为了向YannLeCun的LeNet系列致敬。</p>
<h3 id="一些思考">5.12.1 一些思考</h3>
<p>为了提高深度神经网络的性能，最简单粗暴有效的方法是增加网络深度与宽度，但这个方法有两个明显的缺点：</p>
<ul>
<li>更深更宽的网络意味着更多的参数，从而大大增加过拟合的风险，尤其在训练数据不是那么多或者某个label训练数据不足的情况下更容易发生；</li>
<li>增加计算资源的消耗，实际情况下，不管是因为数据稀疏还是扩充的网络结构利用不充分（比如很多权重接近0），都会导致大量计算的浪费。</li>
</ul>
<p>解决以上两个问题的基本方法是将全连接或卷积连接改为稀疏连接。不管从生物的角度还是机器学习的角度，稀疏性都有良好的表现，回想Dropout网络以及ReLU激活函数，其本质就是利用稀疏性提高模型泛化性（但需要计算的参数没变少）。 简单解释下稀疏性，当整个特征空间是非线性甚至不连续时：</p>
<ul>
<li>学好局部空间的特征集更能提升性能，类似于Maxout网络中使用多个局部线性函数的组合来拟合非线性函数的思想；</li>
<li>假设整个特征空间由N个不连续局部特征空间集合组成，任意一个样本会被映射到这N个空间中并激活/不激活相应特征维度，如果用C1表示某类样本被激活的特征维度集合，用C2表示另一类样本的特征维度集合，当数据量不够大时，要想增加特征区分度并很好的区分两类样本，就要降低C1和C2的重合度（比如可用Jaccard距离衡量），即缩小C1和C2的大小，意味着相应的特征维度集会变稀疏。</li>
</ul>
尴尬的是，现在的计算机体系结构更善于稠密数据的计算，而在非均匀分布的稀疏数据上的计算效率极差，比如稀疏性会导致的缓存miss率极高，于是需要一种方法既能发挥稀疏网络的优势又能保证计算效率。好在前人做了大量实验（如《<a href="http://www.bmi.osu.edu/~umit/papers/Catalyurek10-SISC.pdf">On Two-Dimensional Sparse Matrix Partitioning: Models, Methods, and a Recipe</a>》），发现对稀疏矩阵做聚类得到相对稠密的子矩阵可以大幅提高稀疏矩阵乘法性能，借鉴这个思想，作者提出Inception的结构。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd8rs6me1krhgtl1jvh164rt1s9.png" width="500"  />
</center>
<ul>
<li>把不同大小卷积核抽象得到的特征空间看做子特征空间，每个子特征空间都是稀疏的，把这些不同尺度特征做融合，相当于得到一个相对稠密的空间；</li>
<li>采用1×1、3×3、5×5卷积核(不是必须的，也可以是其他大小)，stride取1，利用padding可以方便的做输出特征维度对齐；</li>
<li>大量事实表明pooling层能有效提高卷积网络的效果，所以加了一条max pooling路径；</li>
<li>这个结构符合直观理解，视觉信息通过不同尺度的变换被聚合起来作为下一阶段的特征，比如：人的高矮、胖瘦、青老信息被聚合后做下一步判断。</li>
</ul>
<p>这个网络的最大问题是5×5卷积带来了巨大计算负担，例如，假设上层输入为：28×28×192：</p>
<ul>
<li>直接经过96个5×5卷积层(stride=1，padding=2)后，输出为：28×28×96，卷积层参数量为：192×5×5×96=460800；</li>
<li>借鉴NIN网络，在5×5卷积前使用32个1×1卷积核做维度缩减，变成28×28×32，之后经过96个5×5卷积层(stride=1，padding=2)后，输出为：28×28×96，但所有卷积层的参数量为：192×1×1×32+32×5×5×96=82944，可见整个参数量是原来的1/5.5，且效果上没有多少损失。 新网络结构为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd91d78tsrb1qjl8jk1hio16dnm.png" width="500"  />
</center></li>
</ul>
<h3 id="googlenet结构">5.12.2 GoogLeNet结构</h3>
利用上述Inception模块构建GoogLeNet，实验表明Inception模块出现在高层特征抽象时会更加有效（我理解由于其结构特点，更适合提取高阶特征，让它提取低阶特征会导致特征信息丢失），所以在低层依然使用传统卷积层。整个网路结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd92vlme2jdpg82ie1nclfa913.png" width="600"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bd99affn1qkv1c1roijq4j10l526.png" width="600"  />
</center>
<p>网络说明：</p>
<ul>
<li><strong>所有卷积层</strong>均使用ReLU激活函数，包括做了1×1卷积降维后的激活；</li>
<li>移除全连接层，像NIN一样使用Global Average Pooling，使得Top 1准确率提高0.6%，但由于GAP与类别数目有关系，为了方便大家做模型fine-tuning，最后加了一个全连接层；</li>
<li>与前面的ResNet类似，实验观察到，相对浅层的神经网络层对模型效果有较大的贡献，训练阶段通过对Inception(4a、4d)增加两个额外的分类器来增强反向传播时的梯度信号，但最重要的还是<strong>正则化作用</strong>，这一点在GoogLeNet v3中得到实验证实，并间接证实了GoogLeNet V2中BN的正则化作用，这两个分类器的loss会以0.3的权重加在整体loss上，在模型inference阶段，这两个分类器会被去掉；</li>
<li>用于降维的1×1卷积核个数为128个；</li>
<li>全连接层使用1024个神经元；</li>
<li>使用丢弃概率为0.7的Dropout层；</li>
</ul>
<p>网络结构说明：</p>
<p>输入数据为224×224×3的RGB图像，图中"S"代表做same-padding，"V"代表不做。</p>
<ul>
<li>C1卷积层：64个7×7卷积核(stride=2，padding=3)，输出为：112×112×64；</li>
<li>P1抽样层：64个3×3卷积核(stride=2)，输出为56×56×64，其中：56=(112-3+1)/2+1</li>
<li>C2卷积层：192个3×3卷积核(stride=1，padding=1)，输出为：56×56×192；</li>
<li>P2抽样层：192个3×3卷积核(stride=2)，输出为28×28×192，其中：28=(56-3+1)/2+1，接着数据被分出4个分支，进入Inception (3a)</li>
<li>Inception (3a)：由4部分组成
<ul>
<li>64个1×1的卷积核，输出为28×28×64;</li>
<li>96个1×1的卷积核做降维，输出为28×28×96，之后128个3×3卷积核(stride=1，padding=1)，输出为：28×28×128</li>
<li>16个1×1的卷积核做降维，输出为28×28×16，之后32个5×5卷积核(stride=1，padding=2)，输出为：28×28×32</li>
<li>192个3×3卷积核(stride=1，padding=1)，输出为28×28×192，进行32个1×1卷积核，输出为：28×28×32 最后对4个分支的输出做“深度”方向组合，得到输出28×28×256，接着数据被分出4个分支，进入Inception (3b)；</li>
</ul></li>
<li>Inception (3b)：由4部分组成
<ul>
<li>128个1×1的卷积核，输出为28×28×128;</li>
<li>128个1×1的卷积核做降维，输出为28×28×128，进行192个3×3卷积核(stride=1，padding=1)，输出为：28×28×192</li>
<li>32个1×1的卷积核做降维，输出为28×28×32，进行96个5×5卷积核(stride=1，padding=2)，输出为：28×28×96</li>
<li>256个3×3卷积核(stride=1，padding=1)，输出为28×28×256，进行64个1×1卷积核，输出为：28×28×64 最后对4个分支的输出做“深度”方向组合，得到输出28×28×480； 后面结构以此类推。</li>
</ul></li>
</ul>
<h3 id="代码实践-1">5.12.3 代码实践</h3>
<ul>
<li><p>googlenet_inception_v1.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, Conv2D, Dense, MaxPooling2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout, Flatten, merge, ZeroPadding2D, Reshape, Activation</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> googlenet_custom_layers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_module</span>(<span class="params">name,</span></span></span><br><span class="line"><span class="params"><span class="function">                     input_layer,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_3x3_reduce,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_3x3,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_5x5_reduce,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_p_5x5,</span></span></span><br><span class="line"><span class="params"><span class="function">                     num_c_1x1_reduce</span>):</span></span><br><span class="line">    inception_1x1 = Conv2D(name=name+<span class="string">&quot;/inception_1x1&quot;</span>,</span><br><span class="line">                           filters=num_c_1x1,</span><br><span class="line">                           kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_3x3_reduce = Conv2D(name=name+<span class="string">&quot;/inception_3x3_reduce&quot;</span>,</span><br><span class="line">                                  filters=num_c_1x1_3x3_reduce,</span><br><span class="line">                                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                  kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                  activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                  kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_3x3 = Conv2D(name=name+<span class="string">&quot;/inception_3x3&quot;</span>,</span><br><span class="line">                           filters=num_c_3x3,</span><br><span class="line">                           kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_3x3_reduce)</span><br><span class="line"></span><br><span class="line">    inception_5x5_reduce = Conv2D(name=name+<span class="string">&quot;/inception_5x5_reduce&quot;</span>,</span><br><span class="line">                                  filters=num_c_1x1_5x5_reduce,</span><br><span class="line">                                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                  kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                  activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                  kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_5x5 = Conv2D(name=name+<span class="string">&quot;/inception_5x5&quot;</span>,</span><br><span class="line">                           filters=num_p_5x5,</span><br><span class="line">                           kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                           strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                           padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                           kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                           activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                           kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_5x5_reduce)</span><br><span class="line"></span><br><span class="line">    inception_max_pool = MaxPooling2D(name=name+<span class="string">&quot;/inception_max_pool&quot;</span>,</span><br><span class="line">                                      pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                      strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                      padding=<span class="string">&quot;same&quot;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_max_pool_proj = Conv2D(name=name+<span class="string">&quot;/inception_max_pool_project&quot;</span>,</span><br><span class="line">                                     filters=num_c_1x1_reduce,</span><br><span class="line">                                     kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                     strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                     padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                     kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_max_pool)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> (inception_1x1.get_shape(), inception_3x3.get_shape(), inception_5x5.get_shape(), inception_max_pool_proj.get_shape())</span><br><span class="line"></span><br><span class="line"><span class="comment">#    inception_output = tf.concat(3, [inception_1x1, inception_3x3, inception_5x5, inception_max_pool_proj])</span></span><br><span class="line">    <span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate</span><br><span class="line">    <span class="comment">#注意，由于变态的tensorflow更改了concat函数的参数顺序，需要注意自己的tf和keras版本</span></span><br><span class="line">    <span class="comment">#适时的将/usr/lib/python×××/site-packages/keras/backend/tensorflow_backend.py的1554行的代码由</span></span><br><span class="line">    <span class="comment">#return tf.concat([to_dense(x) for x in tensors], axis) 改为：</span></span><br><span class="line">    <span class="comment">#return tf.concat(axis, [to_dense(x) for x in tensors])</span></span><br><span class="line">    inception_output = concatenate([inception_1x1, inception_3x3, inception_5x5, inception_max_pool_proj])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> inception_output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">googLeNet_inception_v1_building</span>(<span class="params">input_shape, output_num, fine_tune=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    input_layer = Input(shape=input_shape)</span><br><span class="line">    <span class="comment"># 第一层，卷积层</span></span><br><span class="line">    conv1_7x7 = Conv2D(name=<span class="string">&quot;conv1_7x7/2&quot;</span>,</span><br><span class="line">                       filters=<span class="number">64</span>,</span><br><span class="line">                       kernel_size=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">                       strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                       activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    conv1_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(conv1_7x7)</span><br><span class="line">    <span class="comment"># 第二层，max pooling层</span></span><br><span class="line">    pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool1_3x3/2&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(conv1_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二层，LRN规范化</span></span><br><span class="line">    <span class="comment">#pool1_norm1 = tf.nn.lrn(pool1_3x3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#x27;ax_pool1_3x3/norm1&#x27;)</span></span><br><span class="line">    pool1_norm1 = googlenet_custom_layers.LRN2D(name=<span class="string">&#x27;max_pool1_3x3/norm1&#x27;</span>)(pool1_3x3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第四层，卷积层降维</span></span><br><span class="line">    conv2_3x3_reduce = Conv2D(name=<span class="string">&quot;conv2_3x3_reduce/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">64</span>,</span><br><span class="line">                              kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(pool1_norm1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第五层，卷积层</span></span><br><span class="line">    conv2_3x3 = Conv2D(name=<span class="string">&quot;conv2_3x3/1&quot;</span>,</span><br><span class="line">                       filters=<span class="number">192</span>,</span><br><span class="line">                       kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                       padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                       kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                       activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                       kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(conv2_3x3_reduce)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第六层，LRN规范化</span></span><br><span class="line">    <span class="comment">#conv2_norm2 = tf.nn.lrn(conv2_3x3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#x27;conv2_3x3/norm2&#x27;)</span></span><br><span class="line">    conv2_norm2 = googlenet_custom_layers.LRN2D(name=<span class="string">&#x27;conv2_3x3/norm2&#x27;</span>)(conv2_3x3)</span><br><span class="line"></span><br><span class="line">    conv2_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(conv2_norm2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第七层，max pooling层</span></span><br><span class="line">    pool2_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool2_3x3&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(conv2_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第八层，inception 3a</span></span><br><span class="line">    inception_3a = inception_module(<span class="string">&quot;inception_3a&quot;</span>,pool2_3x3, <span class="number">64</span>, <span class="number">96</span>, <span class="number">128</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    <span class="comment"># 第九层，inception 3b</span></span><br><span class="line">    inception_3b = inception_module(<span class="string">&quot;inception_3b&quot;</span>,inception_3a, <span class="number">128</span>, <span class="number">128</span>, <span class="number">192</span>, <span class="number">32</span>, <span class="number">96</span>, <span class="number">64</span>)</span><br><span class="line">    inception_3b_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(inception_3b)</span><br><span class="line">    <span class="comment"># 第十层，max pooling层</span></span><br><span class="line">    pool3_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool3_3x3/2&quot;</span>,</span><br><span class="line">                                pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                                padding=<span class="string">&#x27;valid&#x27;</span>)(inception_3b_zero_pad)</span><br><span class="line">    <span class="comment"># 第十一层，inception 4a</span></span><br><span class="line">    inception_4a = inception_module(<span class="string">&quot;inception_4a&quot;</span>,pool3_3x3, <span class="number">192</span>, <span class="number">96</span>, <span class="number">208</span>, <span class="number">16</span>, <span class="number">48</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十二层，分支loss1</span></span><br><span class="line">    loss1_ave_pool = AveragePooling2D(name=<span class="string">&quot;loss1/ave_pool&quot;</span>,</span><br><span class="line">                                      pool_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                                      strides=(<span class="number">3</span>, <span class="number">3</span>))(inception_4a)</span><br><span class="line"></span><br><span class="line">    loss1_conv = Conv2D(name=<span class="string">&quot;loss1/conv&quot;</span>,</span><br><span class="line">                        filters=<span class="number">128</span>,</span><br><span class="line">                        kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                        padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                        kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                        kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_ave_pool)</span><br><span class="line"></span><br><span class="line">    loss1_flat = Flatten()(loss1_conv)</span><br><span class="line"></span><br><span class="line">    loss1_fc = Dense(<span class="number">1024</span>,</span><br><span class="line">                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     name=<span class="string">&quot;loss1/fc&quot;</span>,</span><br><span class="line">                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_flat)</span><br><span class="line"></span><br><span class="line">    loss1_drop_fc = Dropout(<span class="number">0.7</span>)(loss1_fc)</span><br><span class="line"></span><br><span class="line">    loss1_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss1/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss1_drop_fc)</span><br><span class="line"></span><br><span class="line">    loss1_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss1_classifier)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十二层，inception_4b</span></span><br><span class="line">    inception_4b = inception_module(<span class="string">&quot;inception_4b&quot;</span>,inception_4a, <span class="number">160</span>, <span class="number">112</span>, <span class="number">224</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    <span class="comment"># 第十三层，inception_4c</span></span><br><span class="line">    inception_4c = inception_module(<span class="string">&quot;inception_4c&quot;</span>,inception_4b, <span class="number">128</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">24</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">    <span class="comment"># 第十四层，inception_4c</span></span><br><span class="line">    inception_4d = inception_module(<span class="string">&quot;inception_4d&quot;</span>,inception_4c, <span class="number">112</span>, <span class="number">144</span>, <span class="number">288</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十五层，分支loss2</span></span><br><span class="line">    loss2_ave_pool = AveragePooling2D(pool_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                                      strides=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                      name=<span class="string">&#x27;loss2/ave_pool&#x27;</span>)(inception_4d)</span><br><span class="line"></span><br><span class="line">    loss2_conv = Conv2D(name=<span class="string">&quot;loss2/conv&quot;</span>,</span><br><span class="line">                        filters=<span class="number">128</span>,</span><br><span class="line">                        kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                        padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                        kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                        kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_ave_pool)</span><br><span class="line"></span><br><span class="line">    loss2_flat = Flatten()(loss2_conv)</span><br><span class="line"></span><br><span class="line">    loss2_fc = Dense(<span class="number">1024</span>,</span><br><span class="line">                     activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                     name=<span class="string">&quot;loss2/fc&quot;</span>,</span><br><span class="line">                     kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_flat)</span><br><span class="line"></span><br><span class="line">    loss2_drop_fc = Dropout(<span class="number">0.7</span>)(loss2_fc)</span><br><span class="line"></span><br><span class="line">    loss2_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss2/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(loss2_drop_fc)</span><br><span class="line"></span><br><span class="line">    loss2_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss2_classifier)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十五层，inception_4e</span></span><br><span class="line">    inception_4e = inception_module(<span class="string">&quot;inception_4e&quot;</span>,inception_4d, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">    inception_4e_zero_pad = ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))(inception_4e)</span><br><span class="line">    <span class="comment"># 第十六层，max pooling层</span></span><br><span class="line">    pool4_3x3 = MaxPooling2D(name=<span class="string">&quot;max_pool4_3x3&quot;</span>,</span><br><span class="line">                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>)(inception_4e_zero_pad)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十七层，inception_5a</span></span><br><span class="line">    inception_5a = inception_module(<span class="string">&quot;inception_5a&quot;</span>,pool4_3x3, <span class="number">256</span>, <span class="number">160</span>, <span class="number">320</span>, <span class="number">32</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十八层，inception_5b</span></span><br><span class="line">    inception_5b = inception_module(<span class="string">&quot;inception_5b&quot;</span>,inception_5a, <span class="number">384</span>, <span class="number">192</span>, <span class="number">384</span>, <span class="number">48</span>, <span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第十九层，average pooling层</span></span><br><span class="line">    pool5_7x7 = AveragePooling2D(name=<span class="string">&quot;ave_pool5_7x7&quot;</span>,</span><br><span class="line">                                 pool_size=(<span class="number">7</span>, <span class="number">7</span>),</span><br><span class="line">                                 strides=(<span class="number">1</span>, <span class="number">1</span>))(inception_5b)</span><br><span class="line"></span><br><span class="line">    loss3_flat = Flatten()(pool5_7x7)</span><br><span class="line"></span><br><span class="line">    pool5_drop_7x7 = Dropout(<span class="number">0.4</span>)(loss3_flat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二十层，全连接层</span></span><br><span class="line">    loss3_classifier = Dense(output_num,</span><br><span class="line">                             name=<span class="string">&quot;loss3/classifier&quot;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(pool5_drop_7x7)</span><br><span class="line"></span><br><span class="line">    loss3_classifier_act = Activation(<span class="string">&#x27;softmax&#x27;</span>)(loss3_classifier)</span><br><span class="line"></span><br><span class="line">    googlenet_inception_v1 = Model(name=<span class="string">&quot;googlenet_inception_v1&quot;</span>,</span><br><span class="line">                                   <span class="built_in">input</span>=input_layer,</span><br><span class="line">                                   output=[loss1_classifier_act, loss2_classifier_act, loss3_classifier_act])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> fine_tune:</span><br><span class="line">        googlenet_inception_v1.load_weights(fine_tune)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> googlenet_inception_v1</span><br></pre></td></tr></table></figure></p></li>
<li>googlenet_custom_layers.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Layer</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRN2D</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   This code is adapted from pylearn2.</span></span><br><span class="line"><span class="string">    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha=<span class="number">1e-4</span>, k=<span class="number">2</span>, beta=<span class="number">0.75</span>, n=<span class="number">5</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">if</span> n % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;LRN2D only works with odd n. n provided: &quot;</span> + <span class="built_in">str</span>(n))</span><br><span class="line">        <span class="built_in">super</span>(LRN2D, self).__init__(**kwargs)</span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.k = k</span><br><span class="line">        self.beta = beta</span><br><span class="line">        self.n = n</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_output</span>(<span class="params">self, train</span>):</span></span><br><span class="line">        X = self.get_input(train)</span><br><span class="line">        b, ch, r, c = K.shape(X)</span><br><span class="line">        half_n = self.n // <span class="number">2</span></span><br><span class="line">        input_sqr = K.square(X)</span><br><span class="line">        extra_channels = K.zeros((b, ch + <span class="number">2</span> * half_n, r, c))</span><br><span class="line">        input_sqr = K.concatenate([extra_channels[:, :half_n, :, :],</span><br><span class="line">                                   input_sqr,</span><br><span class="line">                                   extra_channels[:, half_n + ch:, :, :]],</span><br><span class="line">                                  axis=<span class="number">1</span>)</span><br><span class="line">        scale = self.k</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n):</span><br><span class="line">            scale += self.alpha * input_sqr[:, i:i + ch, :, :]</span><br><span class="line">        scale = scale ** self.beta</span><br><span class="line">        <span class="keyword">return</span> X / scale</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">        config = &#123;<span class="string">&quot;name&quot;</span>: self.__class__.__name__,</span><br><span class="line">                  <span class="string">&quot;alpha&quot;</span>: self.alpha,</span><br><span class="line">                  <span class="string">&quot;k&quot;</span>: self.k,</span><br><span class="line">                  <span class="string">&quot;beta&quot;</span>: self.beta,</span><br><span class="line">                  <span class="string">&quot;n&quot;</span>: self.n&#125;</span><br><span class="line">        base_config = <span class="built_in">super</span>(LRN2D, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">list</span>(base_config.items()) + <span class="built_in">list</span>(config.items()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PoolHelper</span>(<span class="params">Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PoolHelper, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> x[:, :, <span class="number">1</span>:, <span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">        config = &#123;&#125;</span><br><span class="line">        base_config = <span class="built_in">super</span>(PoolHelper, self).get_config()</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">list</span>(base_config.items()) + <span class="built_in">list</span>(config.items()))</span><br></pre></td></tr></table></figure></li>
<li><p>googlenet_inception_v1-cifar10.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ReduceLROnPlateau, CSVLogger, EarlyStopping</span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> googlenet_inception_v1</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:4&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;4&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line"></span><br><span class="line">        (X_train, y_train), (X_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输入数据并做归一化</span></span><br><span class="line">        dim = <span class="number">32</span></span><br><span class="line">        channel = <span class="number">3</span></span><br><span class="line">        class_num = <span class="number">10</span></span><br><span class="line">        X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], dim, dim, channel).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">        Y_train = np_utils.to_categorical(y_train, class_num)</span><br><span class="line">        Y_test = np_utils.to_categorical(y_test, class_num)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">        datagen = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">            samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">            zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">            rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">            width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">            height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">            vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">        datagen.fit(X_train)</span><br><span class="line"></span><br><span class="line">        s = X_train.shape[<span class="number">1</span>:]</span><br><span class="line">        <span class="built_in">print</span>(s)</span><br><span class="line">        model = googlenet_inception_v1.googLeNet_inception_v1_building(s,class_num)</span><br><span class="line">        model.summary()</span><br><span class="line">        <span class="comment">#import pdb</span></span><br><span class="line">        <span class="comment">#pdb.set_trace()</span></span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-V1.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line">        model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">        batch_size = <span class="number">32</span></span><br><span class="line">        nb_epoch = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># import pdb</span></span><br><span class="line">        <span class="comment"># pdb.set_trace()</span></span><br><span class="line">        ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>,</span><br><span class="line">                        save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> <span class="built_in">range</span>(nb_epoch):</span><br><span class="line">            batches = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> X_batch, Y_batch <span class="keyword">in</span> datagen.flow(X_train, Y_train, batch_size=<span class="number">64</span>):</span><br><span class="line">                loss = model.train_on_batch(X_batch, [Y_batch,Y_batch,Y_batch]) <span class="comment"># note the three outputs</span></span><br><span class="line">                <span class="built_in">print</span> loss</span><br><span class="line">                <span class="comment">#print &#x27;\r\n&#x27;</span></span><br><span class="line">                <span class="comment">#loss_and_metrics = model.evaluate(X_test, [Y_test,Y_test,Y_test], batch_size=128)</span></span><br><span class="line">                <span class="comment">#model.fit(X_test, [Y_test,Y_test,Y_test], batch_size=64)</span></span><br><span class="line">                batches += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> batches &gt;= <span class="built_in">len</span>(X_train) / <span class="number">64</span>:</span><br><span class="line">                <span class="comment"># we need to break the loop by hand because</span></span><br><span class="line">                <span class="comment"># the generator loops indefinitely</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p></li>
</ul>
整个网络结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bddsvlg8mt7ejo267fso1pdp1g.png" width="600"  />
</center>
<p>需要训练的总参数量为10,334,030个。</p>
<h2 id="googlenet-inception-v2">5.13 GoogLeNet Inception V2</h2>
<p>GoogLeNet Inception V2在《<a href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>》出现，最大亮点是提出了Batch Normalization方法，它起到以下作用：</p>
<ul>
<li>使用较大的学习率而不用特别关心诸如梯度爆炸或消失等优化问题；</li>
<li>降低了模型效果对初始权重的依赖；</li>
<li>可以加速收敛，一定程度上可以不使用Dropout这种降低收敛速度的方法，但却起到了正则化作用提高了模型泛化性；</li>
<li>即使不使用ReLU也能缓解激活函数饱和问题；</li>
<li>能够学习到从当前层到下一层的分布缩放( scaling (方差)，shift (期望))系数。</li>
</ul>
<h3 id="一些思考-1">5.13.1 一些思考</h3>
<p>在机器学习中，我们通常会做一种假设：训练样本独立同分布(iid)且训练样本与测试样本分布一致，如果真实数据符合这个假设则模型效果可能会不错，反之亦然，这个在学术上叫Covariate Shift，所以从样本（外部）的角度说，对于神经网络也是一样的道理。从结构（内部）的角度说，由于神经网络由多层组成，样本在层与层之间边提特征边往前传播，如果每层的输入分布不一致，那么势必造成要么模型效果不好，要么学习速度较慢，学术上这个叫<strong>Internal</strong> Covariate Shift。</p>
<p>假设：<span class="math inline">\(y\)</span>为样本标注，<span class="math inline">\(X=\{x_1,x_2,x_3,......\}\)</span>为样本<span class="math inline">\(x\)</span>通过神经网络若干层后每层的输入；</p>
<p>理论上：<span class="math inline">\(p(x,y)\)</span>的联合概率分布应该与集合<span class="math inline">\(X\)</span>中任意一层输入的联合概率分布一致，如：<span class="math inline">\(p(x,y)=p(x_1,y)\)</span>； 但是：<span class="math inline">\(p(x,y)=p(y|x) \cdot p(x)\)</span>，其中条件概率<span class="math inline">\(p(y|x)\)</span>是一致的，即<span class="math inline">\(p(y|x)=p(y|x_1)=p(y|x_2)=......\)</span>，但由于神经网络每一层对输入分布的改变，导致边缘概率是不一致的，即<span class="math inline">\(p(x)\neq p(x_1)\neq p(x_2)......\)</span>，甚至随着网络深度的加深，前面层微小的变化会导致后面层巨大的变化。</p>
<h3 id="bn原理">5.13.2 BN原理</h3>
<p>BN整个算法过程如下：</p>
<p><span class="math display">\[
\begin{align*}
  &amp; \text{Input: Values of $x$ over a mini-batch: $B=\{x_1...m\}$} \\
  &amp; \text{ $\qquad \quad$ Paramters to be learned:$\gamma$,$\beta$} \\
  &amp; \text{Output:} \{y_i = BN_{\gamma,\beta}(x_i)\} \\
  &amp; \quad \mu_{B} \gets \frac{1}{m} \sum_{i=1}^{m}{x_i} \qquad &amp;&amp;\text{//mini-batch mean}\\
  &amp; \quad \sigma^2_B \gets \frac{1}{m} \sum_{i=1}^{m}{(x_i-\mu_B)^2} \qquad &amp;&amp;\text{//mini-batch variance}\\
  &amp; \quad \hat{x}_i \gets \frac{x_i-\mu_B}{\sqrt{\sigma_B^2 +\epsilon}} \qquad &amp;&amp;\text{//normalize}\\
  &amp; \quad y_i \gets \gamma\hat{x}_i+\beta \equiv BN_{\gamma,\beta}(x_i) \qquad &amp;&amp;\text{//scale and shift}\\
\end{align*}
\]</span></p>
<ul>
<li>以batch的方式做训练，对m个样本求期望和方差后对训练数据做白化，通过白化操作可以去除特征相关性并把数据缩放在一个球体上，这么做的好处既可以加快优化算法的优化速度也可能提高优化精度，一个直观的解释：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtd6v182o9m1ua0r1df01dtl1g.png" width="400"  />
</center>
左边是未做白化的原始可行域，右边是做了白化的可行域；</li>
<li>当原始输入对模型学习更有利时能够恢复原始输入（和残差网络有点神似）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtavq8vm617es57jul11f7hm.png" width="400"  />
</center></li>
</ul>
<p>这里的参数<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\sigma\)</span>是需要学习的。</p>
<p>参数学习依然是利用反向传播原理：</p>
<p><span class="math display">\[
\begin{align*}
  &amp; \frac{\partial l}{\partial \hat{x}_i}=\frac{\partial l}{\partial \hat{y}_i} \cdot \gamma \\
  &amp; \frac{\partial l}{\partial \sigma_B^2}=\sum_{i=1}^{m}\frac{\partial l}{\partial \hat{x}_i} \cdot (x_i-\mu_B) \cdot \frac{-1}{2}(\sigma_B^2+\epsilon)^{-3/2}\\
  &amp; \frac{\partial l}{\partial \mu_B}=(\sum_{i=1}^{m}\frac{\partial l}{\partial \hat{x}_i} \cdot \frac{-1}{\sqrt{\sigma_B^2+\epsilon}})+\frac{\partial l}{\partial \sigma_B^2} \cdot \frac{\sum_{i=1}^m -2(x_i-\mu_B)}{m} \\
  &amp; \frac{\partial l}{\partial x_i}= \frac{\partial l}{\partial \hat{x}_i} \cdot \frac{1}{\sqrt{\sigma_B^2+\epsilon}} + \frac{\partial l}{\partial \sigma_B^2} \cdot \frac{2(x_i-\mu_B)}{m} + \frac{\partial l}{\partial \mu_B} \cdot \frac{1}{m} \\
  &amp; \frac{\partial l}{\partial \gamma}=\sum_{i=1}^m \frac{\partial l}{\partial \hat{y}_i} \cdot \hat{x}_i\\
  &amp; \frac{\partial l}{\partial \beta}=\sum_{i=1}^m \frac{\partial l}{\partial \hat{y}_i} \\
\end{align*}
\]</span></p>
<p>对卷积神经网络而言，BN被加在激活函数的非线性变换前，即： <span class="math display">\[y=f(BN(W^Tx +b))\]</span> 由于BN参数<span class="math inline">\(\gamma\)</span>的存在，这里的偏置<span class="math inline">\(b\)</span>可以被去掉，即： <span class="math display">\[y=f(BN(W^Tx))\]</span> 所以在看相关代码实现时大家会发现没有偏置这个参数。</p>
<p>另外当采用较大的学习率时，传统方法会由于激活函数饱和区的存在导致反向传播时梯度出现爆炸或消失，但采用BN后，参数的尺度变化不影响梯度的反向传播，可以证明： <span class="math display">\[
\begin{array}{l}
BN(Wu)=BN((\alpha W)u)\\
\frac{\partial BN((\alpha W)u)}{\partial u}=\frac{\partial BN(Wu)}{\partial u}\\
\frac{\partial BN((\alpha W)u)}{\partial (\alpha W)}=\frac{1}{\alpha}\cdot \frac{\partial BN(Wu)}{\partial W}
\end{array}
\]</span></p>
<p>在模型Inference阶段，BN层需要的期望和方差是固定值，由于所有训练集batch的期望和方差已知，可以用这些值对整体训练集的期望和方差做无偏估计修正，修正方法为： <span class="math display">\[
\begin{array}{l}
E(x)=E_B(\mu_B)\\
Var(x)=\frac{m}{m-1}E_B(\sigma_B^2)\\
\text{其中B为训练集所有batch（大小都为m）的集合集合.}\\
\end{array}
\]</span></p>
<p>Inference时的公式变为： <span class="math display">\[
\begin{array}{l}
y=\frac{\gamma}{\sqrt{Var(x)+\epsilon}}\cdot x+(\beta-\frac{\gamma E(x)}{\sqrt{Var(x)+\epsilon}})
\end{array}
\]</span></p>
<h3 id="卷积神经网络中的bn">5.13.3 卷积神经网络中的BN</h3>
卷积网络中采用权重共享策略，每个feature map只有一对<span class="math inline">\(\gamma\)</span>，<span class="math inline">\(\sigma\)</span>需要学习。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtjnc2l13p71a88fpv1n001nuj2a.png" width="800"  />
</center>
<h3 id="代码实践-2">5.13.4 代码实践</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> plot,savefig</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist, cifar10</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Dropout, Activation, Flatten, Reshape</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD, RMSprop</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_LeNet5</span>():</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    model.add(Convolution2D(<span class="number">96</span>, <span class="number">11</span>, <span class="number">11</span>, border_mode=<span class="string">&#x27;same&#x27;</span>, input_shape = (<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>), dim_ordering=<span class="string">&#x27;tf&#x27;</span>))</span><br><span class="line"><span class="comment">#注释1    model.add(BatchNormalization())</span></span><br><span class="line">    model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="comment">#注释2    model.add(BatchNormalization())</span></span><br><span class="line">    model.add(Activation(<span class="string">&quot;tanh&quot;</span>))</span><br><span class="line"></span><br><span class="line">    model.add(Convolution2D(<span class="number">120</span>, <span class="number">1</span>, <span class="number">1</span>, border_mode=<span class="string">&#x27;valid&#x27;</span>))</span><br><span class="line"><span class="comment">#注释3    model.add(BatchNormalization())</span></span><br><span class="line"></span><br><span class="line">    model.add(Flatten())</span><br><span class="line">    model.add(Dense(<span class="number">10</span>))</span><br><span class="line">    model.add(BatchNormalization())</span><br><span class="line">    model.add(Activation(<span class="string">&quot;relu&quot;</span>))</span><br><span class="line"><span class="comment">#注释4    model.add(Dense(10))</span></span><br><span class="line">    model.add(Activation(<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line">    model = build_LeNet5()</span><br><span class="line">    model.summary()</span><br><span class="line"></span><br><span class="line">    plot_model(model, to_file=<span class="string">&quot;LeNet-5.png&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    (X_train, y_train), (X_test, y_test) = cifar10.load_data()<span class="comment">#mnist.load_data()</span></span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>).astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255</span></span><br><span class="line">    Y_train = np_utils.to_categorical(y_train, <span class="number">10</span>)</span><br><span class="line">    Y_test = np_utils.to_categorical(y_test, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># this will do preprocessing and realtime data augmentation</span></span><br><span class="line">    datagen = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">False</span>,  <span class="comment"># set input mean to 0 over the dataset</span></span><br><span class="line">        samplewise_center=<span class="literal">False</span>,  <span class="comment"># set each sample mean to 0</span></span><br><span class="line">        featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide inputs by std of the dataset</span></span><br><span class="line">        samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># divide each input by its std</span></span><br><span class="line">        zca_whitening=<span class="literal">False</span>,  <span class="comment"># apply ZCA whitening</span></span><br><span class="line">        rotation_range=<span class="number">25</span>,  <span class="comment"># randomly rotate images in the range (degrees, 0 to 180)</span></span><br><span class="line">        width_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images horizontally (fraction of total width)</span></span><br><span class="line">        height_shift_range=<span class="number">0.1</span>,  <span class="comment"># randomly shift images vertically (fraction of total height)</span></span><br><span class="line">        horizontal_flip=<span class="literal">False</span>,  <span class="comment"># randomly flip images</span></span><br><span class="line">        vertical_flip=<span class="literal">False</span>)  <span class="comment"># randomly flip images</span></span><br><span class="line"></span><br><span class="line">    datagen.fit(X_train)</span><br><span class="line">    <span class="comment"># training</span></span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">    batch_size = <span class="number">32</span></span><br><span class="line">    nb_epoch = <span class="number">8</span></span><br><span class="line">    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,</span><br><span class="line">              verbose=<span class="number">1</span>, validation_data=(X_test, Y_test))</span><br><span class="line">    score = model.evaluate(X_test, Y_test, verbose=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test score:&#x27;</span>, score[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Test accuracy:&#x27;</span>, score[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<p>三组实验对比：</p>
<ul>
<li>第一组：放开所有注释</li>
<li>第二组：放开注释4</li>
<li>第三组：注释掉所有BN
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bdtueg4i30e4p1gbu1oukdc9m.png" width="500"  />
</center></li>
</ul>
<h2 id="googlenet-inception-v3">5.14 GoogLeNet Inception V3</h2>
<p>GoogLeNet Inception V3在《Rethinking the Inception Architecture for Computer Vision》中提出（注意，在这篇论文中作者把该网络结构叫做v2版，我们以最终的v4版论文的划分为标准），该论文的亮点在于：</p>
<ul>
<li>提出通用的网络结构设计准则</li>
<li>引入卷积分解提高效率</li>
<li>引入高效的feature map降维</li>
</ul>
<h3 id="网络结构设计的准则">5.14.1 网络结构设计的准则</h3>
<p>前面也说过，深度学习网络的探索更多是个实验科学，在实验中人们总结出一些结构设计准则，但说实话我觉得不一定都有实操性：</p>
<ul>
<li>避免特征表示上的瓶颈，尤其在神经网络的前若干层 神经网络包含一个自动提取特征的过程，例如多层卷积，直观并符合常识的理解：如果在网络初期特征提取的太粗，细节已经丢了，后续即使结构再精细也没法做有效表示了；举个极端的例子：在宇宙中辨别一个星球，正常来说是通过由近及远，从房屋、树木到海洋、大陆板块再到整个星球之后进入整个宇宙，如果我们一开始就直接拉远到宇宙，你会发现所有星球都是球体，没法区分哪个是地球哪个是水星。所以feature map的大小应该是随着层数的加深逐步变小，但为了保证特征能得到有效表示和组合其通道数量会逐渐增加。 下图违反了这个原则，刚开就始直接从35×35×320被抽样降维到了17×17×320，特征细节被大量丢失，即使后面有Inception去做各种特征提取和组合也没用。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be4l9h9t1sjrd4b1m3f1bkj1dp29.png" width="200"  />
</center></li>
<li>对于神经网络的某一层，通过更多的激活输出分支可以产生互相解耦的特征表示，从而产生高阶稀疏特征，从而加速收敛，注意下图的1×3和3×1激活输出：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be7flg7p1aeu7gi1jo17ulctr9.png" width="400"  />
</center></li>
<li>合理使用维度缩减不会破坏网络特征表示能力反而能加快收敛速度，典型的例如通过两个3×3代替一个5×5的降维策略，不考虑padding，用两个3×3代替一个5×5能节省1-（3×3+3×3）/(5×5)=28%的计算消耗。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9mjahe8hj1ceus9q1curia09.png" width="600"  />
</center>
以及一个n×n卷积核通过顺序相连的两个1×n和n×1做降维（有点像矩阵分解），如果n=3，计算性能可以提升1-(3+3)/9=33%，但如果考虑高性能计算性能，这种分解可能会造成L1 cache miss率上升。</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9nrvv21ior1jdamaqea0u4213.png" width="600"  />
</center>
<ul>
<li>通过合理平衡网络的宽度和深度优化网络计算消耗（这句话尤其不具有实操性）。</li>
<li>抽样降维，传统抽样方法为pooling+卷积操作，为了防止出现特征表示的瓶颈，往往需要更多的卷积核，例如输入为n个d×d的feature map，共有k个卷积核，pooling时stride=2，为不出现特征表示瓶颈，往往k的取值为2n，通过引入inception module结构，即降低计算复杂度，又不会出现特征表示瓶颈，实现上有如下两种方式：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9opsk11bmu1vj5ovf145e85g1g.png" width="600"  />
</center></li>
</ul>
<h3 id="平滑样本标注">5.14.2 平滑样本标注</h3>
<p>对于多分类的样本标注一般是one-hot的，例如[0,0,0,1]，使用类似交叉熵的损失函数会使得模型学习中对ground truth标签分配过于置信的概率，并且由于ground truth标签的logit值与其他标签差距过大导致，出现过拟合，导致降低泛化性。一种解决方法是加正则项，即对样本标签给个概率分布做调节，使得样本标注变成“soft”的，例如[0.1,0.2,0.1,0.6]，这种方式在实验中降低了top-1和top-5的错误率0.2%。</p>
<h3 id="网络结构-1">5.14.3 网络结构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9q5nr61700p257kh1ov3j2v1t.png" width="400"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1be9qg7hf1ssd1e7vukj40f8hb2a.png" width="600"  />
</center>
<h3 id="代码实践-3">5.14.4 代码实践</h3>
<p>为了能在单机跑起来，对feature map做了缩减，为适应cifar10的输入大小，对输入的stride做了调整，代码如下。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Dropout, Dense, Lambda, Flatten, Activation, merge</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D, Conv2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate, add</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> CSVLogger, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping</span><br><span class="line"></span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">filter_control = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Helper to build a BN -&gt; relu block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    norm = BatchNormalization()(<span class="built_in">input</span>)</span><br><span class="line">    <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(norm)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">before_inception</span>(<span class="params">input_shape, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line">    <span class="keyword">if</span> small_mode:</span><br><span class="line">        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    before_conv1_3x3 = Conv2D(name=<span class="string">&quot;before_conv1_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    before_conv2_3x3 = Conv2D(name=<span class="string">&quot;before_conv2_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv1_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv3_3x3 = Conv2D(name=<span class="string">&quot;before_conv3_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    before_pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;before_pool1_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(before_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv4_3x3 = Conv2D(name=<span class="string">&quot;before_conv4_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">80</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv5_3x3 = Conv2D(name=<span class="string">&quot;before_conv3_3x3/2&quot;</span>,</span><br><span class="line">                              filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=strides,</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv4_3x3)</span><br><span class="line"></span><br><span class="line">    before_conv6_3x3 = Conv2D(name=<span class="string">&quot;before_conv6_3x3/1&quot;</span>,</span><br><span class="line">                              filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                              kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                              strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                              kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                              activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                              padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                              kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(before_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> before_conv6_3x3</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_A</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line">    <span class="comment"># (20,20,288)</span></span><br><span class="line"></span><br><span class="line">    inception_A_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv2_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv3_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_A_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">48</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv5_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv5_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_conv4_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_A_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                    pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                    padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_conv6_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv6_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_A_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_A_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_A_merge1 = concatenate([inception_A_conv3_3x3, inception_A_conv5_3x3, inception_A_conv6_1x1, inception_A_conv7_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_A_merge1)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_B</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    inception_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv2_1x7 = Conv2D(name=<span class="string">&quot;inception_A_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv3_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv3_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv2_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_conv4_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv4_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv3_7x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv5_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv5_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv4_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_conv6_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv6_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv7_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv7_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv6_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv8_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv8_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_conv7_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_B_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                             padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_conv9_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv9_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_B_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_B_conv10_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv10_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_B_merge1 = concatenate(</span><br><span class="line">        [inception_B_conv5_7x1, inception_B_conv8_7x1, inception_B_conv9_1x1, inception_B_conv10_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_B_merge1)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_C</span>(<span class="params">i, input_shape</span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    inception_C_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">448</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv2_3x3 = Conv2D(name=<span class="string">&quot;inception_C_conv2_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv3_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_conv4_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv4_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_merge1 = concatenate([inception_C_conv3_1x3, inception_C_conv4_3x1])</span><br><span class="line"></span><br><span class="line">    inception_C_conv5_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv5_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv6_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv6_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv7_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv7_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_merge2 = concatenate([inception_C_conv6_1x3, inception_C_conv7_3x1])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    inception_C_pool1_3x3 = AveragePooling2D(name=<span class="string">&quot;inception_C_pool1_3x3/1&quot;</span> + i,</span><br><span class="line">                                             pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                             padding=<span class="string">&#x27;same&#x27;</span>)(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_conv8_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv8_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(inception_C_pool1_3x3)</span><br><span class="line"></span><br><span class="line">    inception_C_conv9_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv9_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">320</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.00001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    inception_C_merge3 = concatenate(</span><br><span class="line">        [inception_C_merge1, inception_C_merge2, inception_C_conv8_1x1, inception_C_conv9_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(inception_C_merge3)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inception_v3</span>(<span class="params">input_shape, nb_classes=<span class="number">10</span>, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    x = before_inception(input_layer, small_mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3 x Inception A</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        x = inception_A(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5 x Inception B</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        x = inception_B(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2 x Inception C</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        x = inception_C(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    x = AveragePooling2D((<span class="number">8</span>, <span class="number">8</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dropout</span></span><br><span class="line">    x = Dropout(<span class="number">0.8</span>)(x)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output</span></span><br><span class="line">    out = Dense(output_dim=nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    model = Model(input_layer, output=out, name=<span class="string">&#x27;Inception-v3&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line">        (x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reorder dimensions for tensorflow</span></span><br><span class="line">        x_train = np.transpose(x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        x_test = np.transpose(x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line">        <span class="built_in">print</span>(x_train.shape[<span class="number">0</span>], <span class="string">&#x27;train samples&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(x_test.shape[<span class="number">0</span>], <span class="string">&#x27;test samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">        y_train = np_utils.to_categorical(y_train)</span><br><span class="line">        y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">        s = x_train.shape[<span class="number">1</span>:]</span><br><span class="line">        batch_size = <span class="number">128</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        nb_classes = <span class="number">10</span></span><br><span class="line">        model = create_inception_v3(s, nb_classes)</span><br><span class="line">        model.summary()</span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-V3.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        model.fit(x_train, y_train,</span><br><span class="line">                  batch_size=batch_size, nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                  validation_data=(x_test, y_test), shuffle=<span class="literal">True</span>,</span><br><span class="line">                  callbacks=[])</span><br><span class="line">        <span class="comment"># Model saving callback</span></span><br><span class="line">        checkpointer = ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                       verbose=<span class="number">0</span>,</span><br><span class="line">                                       save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Using real-time data augmentation.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        datagen_train = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">0</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line">        datagen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">        history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=<span class="literal">True</span>),</span><br><span class="line">                                      samples_per_epoch=x_train.shape[<span class="number">0</span>],</span><br><span class="line">                                      nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                                      validation_data=(x_test, y_test),</span><br><span class="line">                                      callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer])</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h2 id="googlenet-inception-v4resnet-v1v2">5.15 GoogLeNet Inception V4/ResNet V1/V2</h2>
<p>这三种结构在《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》一文中提出，论文的亮点是：提出了效果更好的GoogLeNet Inception v4网络结构；与残差网络融合，提出效果不逊于v4但训练速度更快的结构。</p>
<h3 id="googlenet-inception-v4网络结构">5.15.1 GoogLeNet Inception V4网络结构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea0k93g3969st1toj1bbs1vde9.png" width="600"  />
</center>
<h3 id="googlenet-inception-resnet网络结构">5.15.2 GoogLeNet Inception ResNet网络结构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea31r2e1oid1cu8t4v3hm1vq99.png" width="600"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bea36i8k1oru10st3q1d511qdsm.png" width="400"  />
</center>
<h3 id="代码实践-4">5.15.3 代码实践</h3>
<p>GoogLeNet Inception ResNet V2 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Dropout, Dense, Lambda, Flatten, Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> MaxPooling2D, Conv2D, AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers.merge <span class="keyword">import</span> concatenate, add</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l1_l2</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> CSVLogger, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping</span><br><span class="line"></span><br><span class="line">lr_reducer = ReduceLROnPlateau(monitor=<span class="string">&#x27;val_loss&#x27;</span>, factor=np.sqrt(<span class="number">0.5</span>), cooldown=<span class="number">0</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>)</span><br><span class="line">early_stopper = EarlyStopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, min_delta=<span class="number">0.0005</span>, patience=<span class="number">15</span>)</span><br><span class="line">csv_logger = CSVLogger(<span class="string">&#x27;resnet34_cifar10.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">tf.python.control_flow_ops = tf</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line">filter_control = <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bn_relu</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Helper to build a BN -&gt; relu block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    norm = BatchNormalization()(<span class="built_in">input</span>)</span><br><span class="line">    <span class="keyword">return</span> Activation(<span class="string">&quot;relu&quot;</span>)(norm)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_stem</span>(<span class="params">input_shape, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = input_shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> small_mode:</span><br><span class="line">        strides = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    stem_conv1_3x3 = Conv2D(name=<span class="string">&quot;stem_conv1_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(input_layer)</span><br><span class="line"></span><br><span class="line">    stem_conv2_3x3 = Conv2D(name=<span class="string">&quot;stem_conv2_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv1_3x3)</span><br><span class="line"></span><br><span class="line">    stem_conv3_3x3 = Conv2D(name=<span class="string">&quot;stem_conv3_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    stem_pool1_3x3 = MaxPooling2D(name=<span class="string">&quot;stem_pool1_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(stem_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    stem_conv4_3x3 = Conv2D(name=<span class="string">&quot;stem_conv4_3x3/2&quot;</span>,</span><br><span class="line">                            filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=strides,</span><br><span class="line">                            padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv3_3x3)</span><br><span class="line"></span><br><span class="line">    stem_merge1 = concatenate([stem_pool1_3x3, stem_conv4_3x3])</span><br><span class="line"></span><br><span class="line">    stem_conv5_1x1 = Conv2D(name=<span class="string">&quot;stem_conv5_1x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge1)</span><br><span class="line"></span><br><span class="line">    stem_conv6_3x3 = Conv2D(name=<span class="string">&quot;stem_conv6_3x3/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    stem_conv7_1x1 = Conv2D(name=<span class="string">&quot;stem_conv7_1x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge1)</span><br><span class="line"></span><br><span class="line">    stem_conv8_7x1 = Conv2D(name=<span class="string">&quot;stem_conv8_7x1/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv7_1x1)</span><br><span class="line"></span><br><span class="line">    stem_conv9_1x7 = Conv2D(name=<span class="string">&quot;stem_conv8_1x7/1&quot;</span>,</span><br><span class="line">                            filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                            kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                            strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                            padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                            kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                            activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                            kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv8_7x1)</span><br><span class="line"></span><br><span class="line">    stem_conv10_3x3 = Conv2D(name=<span class="string">&quot;stem_conv10_3x3/1&quot;</span>,</span><br><span class="line">                             filters=<span class="number">96</span> // filter_control,</span><br><span class="line">                             kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                             kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                             activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_conv9_1x7)</span><br><span class="line"></span><br><span class="line">    stem_merge2 = concatenate([stem_conv6_3x3, stem_conv10_3x3])</span><br><span class="line"></span><br><span class="line">    stem_pool2_3x3 = MaxPooling2D(name=<span class="string">&quot;stem_pool2_3x3/2&quot;</span>,</span><br><span class="line">                                  pool_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                  strides=strides,</span><br><span class="line">                                  padding=<span class="string">&#x27;valid&#x27;</span>)(stem_merge2)</span><br><span class="line"></span><br><span class="line">    stem_conv11_3x3 = Conv2D(name=<span class="string">&quot;stem_conv11_3x3/2&quot;</span>,</span><br><span class="line">                             filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                             kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                             strides=strides,</span><br><span class="line">                             padding=<span class="string">&#x27;valid&#x27;</span>,</span><br><span class="line">                             kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                             activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                             kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(stem_merge2)</span><br><span class="line"></span><br><span class="line">    stem_merge3 = concatenate([stem_pool2_3x3, stem_conv11_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(stem_merge3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_A</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    init = <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">    inception_A_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_A_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line">    inception_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv3_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">32</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_A_conv5_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv5_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">48</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv4_1x1)</span><br><span class="line"></span><br><span class="line">    inception_A_conv6_3x3 = Conv2D(name=<span class="string">&quot;inception_A_conv6_3x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">64</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   kernel_initializer=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                                   kernel_regularizer=l1_l2(<span class="number">0.0001</span>))(inception_A_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    inception_merge1 = concatenate([inception_A_conv1_1x1, inception_A_conv3_3x3, inception_A_conv6_3x3])</span><br><span class="line"></span><br><span class="line">    inception_A_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_A_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">384</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(inception_merge1)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_A_conv7_1x1])</span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_B</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    init = <span class="built_in">input</span></span><br><span class="line"></span><br><span class="line">    inception_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_B_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">128</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_B_conv3_1x7 = Conv2D(name=<span class="string">&quot;inception_B_conv3_1x7/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">160</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">7</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_B_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_B_conv4_7x1 = Conv2D(name=<span class="string">&quot;inception_B_conv4_7x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">7</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_B_conv3_1x7)</span><br><span class="line"></span><br><span class="line">    inception_B_merge = concatenate([inception_B_conv1_1x1, inception_B_conv4_7x1])</span><br><span class="line"></span><br><span class="line">    inception_B_conv7_1x1 = Conv2D(name=<span class="string">&quot;inception_B_conv7_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">1154</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(inception_B_merge)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_B_conv7_1x1])</span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inception_resnet_v2_C</span>(<span class="params">i, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="comment"># 输入是一个ReLU激活</span></span><br><span class="line">    inception_C_conv1_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv1_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_C_conv2_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv2_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">192</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_1x3 = Conv2D(name=<span class="string">&quot;inception_C_conv3_1x3/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">224</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_C_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    inception_C_conv3_3x1 = Conv2D(name=<span class="string">&quot;inception_C_conv3_3x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(inception_C_conv3_1x3)</span><br><span class="line"></span><br><span class="line">    ir_merge = concatenate([inception_C_conv1_1x1, inception_C_conv3_3x1])</span><br><span class="line"></span><br><span class="line">    inception_C_conv4_1x1 = Conv2D(name=<span class="string">&quot;inception_C_conv4_1x1/1&quot;</span> + i,</span><br><span class="line">                                   filters=<span class="number">2048</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;linear&#x27;</span>)(ir_merge)</span><br><span class="line"></span><br><span class="line">    out = add([<span class="built_in">input</span>, inception_C_conv4_1x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> bn_relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduction_A</span>(<span class="params"><span class="built_in">input</span>, k=<span class="number">192</span>, l=<span class="number">224</span>, m=<span class="number">256</span>, n=<span class="number">384</span></span>):</span></span><br><span class="line">    pool_size = (<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    reduction_A_pool1 = MaxPooling2D(name=<span class="string">&quot;reduction_A_pool1/2&quot;</span>,</span><br><span class="line">                                     pool_size=pool_size,</span><br><span class="line">                                     strides=strides,</span><br><span class="line">                                     padding=<span class="string">&#x27;valid&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv1_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv1_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=n // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv2_1x1 = Conv2D(name=<span class="string">&quot;reduction_A_conv2_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=k // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv2_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv2_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=l // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_A_conv2_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_A_conv3_3x3 = Conv2D(name=<span class="string">&quot;reduction_A_conv3_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=m // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_A_conv2_3x3)</span><br><span class="line"></span><br><span class="line">    reduction_A_merge = concatenate([reduction_A_pool1, reduction_A_conv1_3x3, reduction_A_conv3_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reduction_A_merge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduction_B</span>(<span class="params"><span class="built_in">input</span></span>):</span></span><br><span class="line">    pool_size = (<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    strides = (<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    reduction_B_pool1 = MaxPooling2D(name=<span class="string">&quot;reduction_B_pool1/2&quot;</span>,</span><br><span class="line">                                     pool_size=pool_size,</span><br><span class="line">                                     strides=strides,</span><br><span class="line">                                     padding=<span class="string">&#x27;valid&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv1_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv3_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv2_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv2_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv1_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv3_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv3_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv4_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv4_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv3_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv5_1x1 = Conv2D(name=<span class="string">&quot;reduction_B_conv5_1x1/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">256</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv5_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv5_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">288</span> // filter_control,</span><br><span class="line">                                   kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                                   strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                   padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv5_1x1)</span><br><span class="line"></span><br><span class="line">    reduction_B_conv6_3x3 = Conv2D(name=<span class="string">&quot;reduction_B_conv6_3x3/1&quot;</span>,</span><br><span class="line">                                   filters=<span class="number">320</span> // filter_control,</span><br><span class="line">                                   kernel_size=pool_size,</span><br><span class="line">                                   strides=strides,</span><br><span class="line">                                   activation=<span class="string">&#x27;relu&#x27;</span>)(reduction_B_conv5_3x3)</span><br><span class="line"></span><br><span class="line">    reduction_B_merge = concatenate(</span><br><span class="line">        [reduction_B_pool1, reduction_B_conv2_3x3, reduction_B_conv4_3x3, reduction_B_conv6_3x3])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> reduction_B_merge</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_inception_resnet_v2</span>(<span class="params">input_shape, nb_classes=<span class="number">10</span>, small_mode=<span class="literal">False</span></span>):</span></span><br><span class="line">    input_layer = Input(input_shape)</span><br><span class="line"></span><br><span class="line">    x = inception_resnet_stem(input_layer, small_mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10 x Inception Resnet A</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        x = inception_resnet_v2_A(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reduction A</span></span><br><span class="line">    x = reduction_A(x, k=<span class="number">256</span>, l=<span class="number">256</span>, m=<span class="number">384</span>, n=<span class="number">384</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 20 x Inception Resnet B</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        x = inception_resnet_v2_B(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对32*32*3的数据可以更改pooling层</span></span><br><span class="line">    aout = AveragePooling2D((<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">3</span>, <span class="number">3</span>))(x)</span><br><span class="line">    aout = Conv2D(name=<span class="string">&quot;conv1_1x1/1&quot;</span>,</span><br><span class="line">                  filters=<span class="number">128</span>,</span><br><span class="line">                  kernel_size=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                  activation=<span class="string">&#x27;relu&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    aout = Conv2D(name=<span class="string">&quot;conv1_5x5/1&quot;</span>,</span><br><span class="line">                  filters=<span class="number">768</span>,</span><br><span class="line">                  kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                  strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                  padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                  activation=<span class="string">&#x27;relu&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    aout = Flatten()(aout)</span><br><span class="line">    aout = Dense(nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(aout)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Reduction Resnet B</span></span><br><span class="line">    x = reduction_B(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10 x Inception Resnet C</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        x = inception_resnet_v2_C(<span class="built_in">str</span>(i), x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 需要视情况更改</span></span><br><span class="line">    x = AveragePooling2D((<span class="number">4</span>, <span class="number">4</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dropout</span></span><br><span class="line">    x = Dropout(<span class="number">0.8</span>)(x)</span><br><span class="line">    x = Flatten()(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Output</span></span><br><span class="line">    out = Dense(output_dim=nb_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 简单起见去掉附加目标函数</span></span><br><span class="line">    <span class="comment"># model = Model(input_layer, output=[out, aout], name=&#x27;Inception-Resnet-v2&#x27;)</span></span><br><span class="line">    model = Model(input_layer, output=out, name=<span class="string">&#x27;Inception-Resnet-v2&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:3&#x27;</span>):</span><br><span class="line">        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">1</span>, allow_growth=<span class="literal">True</span>)</span><br><span class="line">        os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;3&quot;</span></span><br><span class="line">        tf.Session(config=K.tf.ConfigProto(allow_soft_placement=<span class="literal">True</span>,</span><br><span class="line">                                           log_device_placement=<span class="literal">True</span>,</span><br><span class="line">                                           gpu_options=gpu_options))</span><br><span class="line">        (x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># reorder dimensions for tensorflow</span></span><br><span class="line">        x_train = np.transpose(x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        x_test = np.transpose(x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.</span>, (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line">        <span class="built_in">print</span>(x_train.shape[<span class="number">0</span>], <span class="string">&#x27;train samples&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(x_test.shape[<span class="number">0</span>], <span class="string">&#x27;test samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">        y_train = np_utils.to_categorical(y_train)</span><br><span class="line">        y_test = np_utils.to_categorical(y_test)</span><br><span class="line"></span><br><span class="line">        s = x_train.shape[<span class="number">1</span>:]</span><br><span class="line">        batch_size = <span class="number">128</span></span><br><span class="line">        nb_epoch = <span class="number">10</span></span><br><span class="line">        nb_classes = <span class="number">10</span></span><br><span class="line">        model = create_inception_resnet_v2(s, nb_classes, <span class="literal">False</span>, <span class="literal">True</span>)</span><br><span class="line">        model.summary()</span><br><span class="line">        plot_model(model, to_file=<span class="string">&quot;GoogLeNet-Inception-Resnet-V2.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adadelta&#x27;</span>,</span><br><span class="line">                      loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">                      metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Model saving callback</span></span><br><span class="line">        checkpointer = ModelCheckpoint(<span class="string">&quot;weights-improvement-&#123;epoch:02d&#125;-&#123;val_acc:.2f&#125;.hdf5&quot;</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                       verbose=<span class="number">0</span>,</span><br><span class="line">                                       save_best_only=<span class="literal">False</span>, save_weights_only=<span class="literal">False</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Using real-time data augmentation.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        datagen_train = ImageDataGenerator(</span><br><span class="line">            featurewise_center=<span class="literal">False</span>,</span><br><span class="line">            samplewise_center=<span class="literal">False</span>,</span><br><span class="line">            featurewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            samplewise_std_normalization=<span class="literal">False</span>,</span><br><span class="line">            zca_whitening=<span class="literal">False</span>,</span><br><span class="line">            rotation_range=<span class="number">0</span>,</span><br><span class="line">            width_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            height_shift_range=<span class="number">0.125</span>,</span><br><span class="line">            horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">            vertical_flip=<span class="literal">False</span>)</span><br><span class="line">        datagen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">        history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=<span class="literal">True</span>),</span><br><span class="line">                                      samples_per_epoch=x_train.shape[<span class="number">0</span>],</span><br><span class="line">                                      nb_epoch=nb_epoch, verbose=<span class="number">1</span>,</span><br><span class="line">                                      validation_data=(x_test, y_test),</span><br><span class="line">                                      callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer])</span><br></pre></td></tr></table></figure></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1befm4g8r8g6sgh1u8n1dth164kp.png" width="800"  />
</center>
<h2 id="模型可视化">5.16 模型可视化</h2>
<h3 id="一些说明">5.16.1 一些说明</h3>
<p>神经网络本身包含了一系列特征提取器，理想的feature map应该是稀疏的以及包含典型的局部信息，通过模型可视化能有一些直观的认识并帮助我们调试模型，比如：feature map与原图很接近，说明它没有学到什么特征；或者它几乎是一个纯色的图，说明它太过稀疏，可能是我们feature map数太多了。可视化有很多种，比如：feature map可视化、权重可视化等等，我以feature map可视化为例。</p>
<p>利用keras，采用在imagenet 1000分类的数据集上预训练好的googLeNet inception v3做实验，以下面两张图作为输入。</p>
<ul>
<li>输入图片 奥迪A7及其分类结果：<a href="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6huue31l0815eh1kh18c53b213.png">原图</a>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hm83q5rk1ttipqt70r14ga9.png" width="600"  />
</center>
北汽绅宝D50及其分类结果：<a href="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6i0g22bdk1upgod01turv7l1g.png">原图</a>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6hrcg0a6s1en84ar12k5biqm.png" width="600"  />
</center></li>
<li>feature map可视化 取网络的前15层，每层取前3个feature map。 奥迪A7 feature map：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6iba8vp69ju84ta17v1p7q2a.png" width="600"  />
</center>
北汽绅宝D50 feature map：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6idndrpt51ausorpq619rh2n.png" width="600"  />
</center></li>
</ul>
<p>从左往右看，可以看到整个特征提取的过程，有的分离背景、有的提取轮廓，有的提取色差，但也能发现10、11层中间两个feature map是纯色的，可能这一层feature map数有点多了，另外北汽绅宝D50的光晕对feature map中光晕的影响也能比较明显看到。</p>
<ul>
<li>Hypercolumns 通常我们把神经网络最后一个fc全连接层作为整个图片的特征表示，但是这一表示可能过于粗糙（从上面的feature map可视化也能看出来），没法精确描述局部空间上的特征，而网络的第一层空间特征又太过精确，缺乏语义信息（比如后面的色差、轮廓等），于是论文《<a href="https://arxiv.org/pdf/1411.5752v2.pdf">Hypercolumns for Object Segmentation and Fine-grained Localization</a>》提出一种新的特征表示方法：Hypercolumns——将一个像素的 hypercolumn 定义为所有 cnn 单元对应该像素位置的激活输出值组成的向量），比较好的tradeoff了前面两个问题，直观地看如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6jjcg313ln151n1o74q9ctm73h.png" width="500"  />
</center>
把奥迪A7 第1、4、7层的feature map以及第1, 4, 7, 10, 11, 14, 17层的feature map分别做平均，可视化如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k09d6q3v1d7mq711i3m1ifr3u.png" width="600"  />
</center>
把北汽绅宝D50 第1、4、7层的feature map以及第1, 4, 7, 10, 11, 14, 17层的feature map分别做平均，可视化如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_5/image_1bf6k67a4p9shmi1tgl1l7e7354r.png" width="600"  />
</center></li>
</ul>
<h3 id="代码实践-5">5.16.2 代码实践</h3>
<p>需要安装opencv，注意它与python的版本兼容性，test_opencv函数可以测试是否安装成功。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> InceptionV3</span><br><span class="line"><span class="keyword">from</span> keras.applications.inception_v3 <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.applications.imagenet_utils <span class="keyword">import</span> decode_predictions</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_opencv</span>():</span></span><br><span class="line">    <span class="comment"># 加载摄像头</span></span><br><span class="line">    cam = VideoCapture(<span class="number">0</span>)  <span class="comment"># 0 -&gt; 摄像头序号，如果有两个三个四个摄像头，要调用哪一个数字往上加嘛</span></span><br><span class="line">    <span class="comment"># 抓拍 5 张小图片</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">        s, img = cam.read()</span><br><span class="line">        <span class="keyword">if</span> s:</span><br><span class="line">            imwrite(<span class="string">&quot;o-&quot;</span> + <span class="built_in">str</span>(x) + <span class="string">&quot;.jpg&quot;</span>, img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_original</span>(<span class="params">img_path</span>):</span></span><br><span class="line">    <span class="comment"># 把原始图片压缩为 299*299大小</span></span><br><span class="line">    im_original = cv2.resize(cv2.imread(img_path), (<span class="number">299</span>, <span class="number">299</span>))</span><br><span class="line">    im_converted = cv2.cvtColor(im_original, cv2.COLOR_BGR2RGB)</span><br><span class="line">    plt.figure(<span class="number">0</span>)</span><br><span class="line">    plt.subplot(<span class="number">211</span>)</span><br><span class="line">    plt.imshow(im_converted)</span><br><span class="line">    <span class="keyword">return</span> im_original</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_fine_tune_googlenet_v3</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="comment"># 加载fine-tuning googlenet v3模型，并做预测</span></span><br><span class="line">    model = InceptionV3(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">    model.summary()</span><br><span class="line">    x = image.img_to_array(img)</span><br><span class="line">    x = np.expand_dims(x, axis=<span class="number">0</span>)</span><br><span class="line">    x = preprocess_input(x)</span><br><span class="line">    preds = model.predict(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted:&#x27;</span>, decode_predictions(preds))</span><br><span class="line">    plt.subplot(<span class="number">212</span>)</span><br><span class="line">    plt.plot(preds.ravel())</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> model, x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">ins, layer_id, filters, layer_num</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取指定模型指定层指定数目的feature map并输出到一幅图上.</span></span><br><span class="line"><span class="string">    :param ins: 模型实例</span></span><br><span class="line"><span class="string">    :param layer_id: 提取指定层特征</span></span><br><span class="line"><span class="string">    :param filters: 每层提取的feature map数</span></span><br><span class="line"><span class="string">    :param layer_num: 一共提取多少层feature map</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(ins) != <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;parameter error:(model, instance)&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    model = ins[<span class="number">0</span>]</span><br><span class="line">    x = ins[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(layer_id) == <span class="built_in">type</span>(<span class="number">1</span>):</span><br><span class="line">        model_extractfeatures = Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(index=layer_id).output)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model_extractfeatures = Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(name=layer_id).output)</span><br><span class="line"></span><br><span class="line">    fc2_features = model_extractfeatures.predict(x)</span><br><span class="line">    <span class="keyword">if</span> filters &gt; <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;layer number error.&#x27;</span>, <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]),<span class="string">&#x27;,&#x27;</span>,filters)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(filters):</span><br><span class="line">        plt.subplots_adjust(left=<span class="number">0</span>, right=<span class="number">1</span>, bottom=<span class="number">0</span>, top=<span class="number">1</span>)</span><br><span class="line">        plt.subplot(filters, layer_num, layer_id + <span class="number">1</span> + i * layer_num)</span><br><span class="line">        plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(fc2_features[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]):</span><br><span class="line">            plt.imshow(fc2_features[<span class="number">0</span>, :, :, i])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 层数、模型、卷积核数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_batch</span>(<span class="params">layer_num, model, filters</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    批量提取特征</span></span><br><span class="line"><span class="string">    :param layer_num: 层数</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param filters: feature map数</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    plt.figure(figsize=(filters, layer_num))</span><br><span class="line">    plt.subplot(filters, layer_num, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layer_num):</span><br><span class="line">        extract_features(model, i, filters, layer_num)</span><br><span class="line"></span><br><span class="line">    plt.savefig(<span class="string">&#x27;sample.jpg&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features_with_layers</span>(<span class="params">layers_extract</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取hypercolumn并可视化.</span></span><br><span class="line"><span class="string">    :param layers_extract: 指定层列表</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    hc = extract_hypercolumn(x[<span class="number">0</span>], layers_extract, x[<span class="number">1</span>])</span><br><span class="line">    ave = np.average(hc.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">    plt.imshow(ave)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_hypercolumn</span>(<span class="params">model, layer_indexes, instance</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    提取指定模型指定层的hypercolumn向量</span></span><br><span class="line"><span class="string">    :param model: 模型</span></span><br><span class="line"><span class="string">    :param layer_indexes: 层id</span></span><br><span class="line"><span class="string">    :param instance: 模型</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    feature_maps = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> layer_indexes:</span><br><span class="line">        feature_maps.append(Model(<span class="built_in">input</span>=model.<span class="built_in">input</span>, output=model.get_layer(index=i).output).predict(instance))</span><br><span class="line">    hypercolumns = []</span><br><span class="line">    <span class="keyword">for</span> convmap <span class="keyword">in</span> feature_maps:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> convmap[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]:</span><br><span class="line">            upscaled = sp.misc.imresize(convmap[<span class="number">0</span>, :, :, i], size=(<span class="number">299</span>, <span class="number">299</span>), mode=<span class="string">&quot;F&quot;</span>, interp=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">            hypercolumns.append(upscaled)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> np.asarray(hypercolumns)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    img_path = <span class="string">&#x27;d:\car3.jpg&#x27;</span></span><br><span class="line">    img = load_original(img_path)</span><br><span class="line">    x = load_fine_tune_googlenet_v3(img)</span><br><span class="line"></span><br><span class="line">    extract_features_batch(<span class="number">15</span>, x, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    extract_features_with_layers([<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>])</span><br><span class="line">    extract_features_with_layers([<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">14</span>, <span class="number">17</span>])</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第五章</tag>
        <tag>CNN</tag>
        <tag>深度神经网络</tag>
        <tag>模型可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第十一章 OCR</title>
    <url>/article/301f2134.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d807hlii1nps1jdtkl0uap1lr69.png" width=266 /> 本章对于机器学习在OCR中的应用过程及早期经典模型做了介绍，抛砖引玉。 <span id="more"></span></p>
<h1 id="ocr">11. OCR</h1>
<h2 id="背景知识">11.1 背景知识</h2>
<p>OCR是将各种带有文字的图像数据中的文本信息定位并识别成可编辑文本的技术。其核心技术包括：文本位置检测、文本内容识别等，OCR的一般过程是：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp69bqmg18b01ieval51a3f2urm.png" width="800" />
</center>
<ul>
<li><p>图片预处理阶段会对光照、清晰度、角度等方面做算法处理，让进入后续流程的图片尽可能质量好；</p></li>
<li><p>针对类似发票、报纸等有固定版面的业务场景，可以对位置、内容做处理，提高后续识别的准确率；</p></li>
<li><p>文本行检测，用来定位图像中的文本行的位置、大小，是OCR的一个难点；</p></li>
<li><p>文本识别，用来对定位好的文本行做文字分类，这里有两类方法：</p>
<ul>
<li>先对单字做切割然后再做单字分类，除去公共流程如预处理、版面分析等，基本流程为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6aofnmqj4j98d3k17bv1erd9.png" width="800" />
</center>
单字分割的准确率是影响最终识别准确率的一个关键点，示例如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6au1aqne91bae1pag1njqufgm.png" width="800" />
</center>
一般训练数据通过自动的方式生成，需要考虑多种字体、大小等因素，最后的softmax分类数为常用字的个数。</li>
<li>直接对一行文本做分类，免去了单字分割操作而直接对一行文本做识别，基本流程为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6b75kt6t01k1sbuenhs1sne13.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6bjmif1gel1tbi7lt9ltmta1g.png" width="800" />
</center>
这类方法实际效果挺不错，同样训练数据也可以通过自动方式生成，具体算法在后面介绍。</li>
</ul></li>
<li><p>文字后处理，由于文本具有上下文语义关系，可以利用NLP技术对识别结果做修正，进一步提高识别准确率。</p></li>
</ul>
<h2 id="数据预处理">11.2 数据预处理</h2>
<h3 id="图像滤波">11.2.1 图像滤波</h3>
滤波本质上是在尽量保持原有图像细节（不破坏诸如边缘、轮廓等信息）的条件下对噪声尽可能抑制（提高图像视觉效果）的操作，完成这个操作，潜在的同时做了两件事：抽取了图像的某种特征和去除了某种噪声（类似的还有深度学习中的AutoEncoder架构），一般架构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6imdo419lggv149d1tiom1e2a.png" width="400" />
</center>
<p>滤波是一个很复杂的课题，简单来说会有时空域滤波和频域滤波两大类，而转换时空与频率的工具就是(逆)傅里叶变换（Transformée de Fourier）:任何周期函数都可以表达为不同频率的正弦和或余弦和的形式，即傅里叶级数，其本质是不同空间的换基分解操作。</p>
<p>1、时空滤波</p>
<p>基本思路是，用一个滤波器（又叫一个模版、窗口）在待处理图像上逐点移动，在每一个点做某种线性或者非线性函数操作（深度学习中的卷积操作是一种典型的滤波）。</p>
<ul>
<li><p>均值滤波</p>
对当前像素点用滤波器领域内的像素点值求<strong>加权平均</strong>后代替该像素点值得到一幅减噪的图像，会对图像产生模糊作用：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6lbrapecvjm91o1n1fdrb3n2n.png" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> scipy.signal</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean_2d</span>(<span class="params">r, n=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[ERROR] Filter&#x27;s size must &gt;= 1.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    win = np.ones((n, n)) / n ** <span class="number">2</span>  <span class="comment"># filter每个元素系数值为1/(n*n)</span></span><br><span class="line">    s = scipy.signal.convolve2d(r, win, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;symm&#x27;</span>) <span class="comment"># 做same padding</span></span><br><span class="line">    <span class="keyword">return</span> s.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">justdoit</span>(<span class="params">r</span>):</span></span><br><span class="line">    sp = []</span><br><span class="line">    <span class="keyword">for</span> dim <span class="keyword">in</span> <span class="built_in">range</span>(r.shape[<span class="number">2</span>]):</span><br><span class="line">        rd = r[:, :, dim]</span><br><span class="line">        sd = mean_2d(rd)</span><br><span class="line">        sp.append(sd)</span><br><span class="line">    s = np.dstack(sp)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">img = PIL.Image.<span class="built_in">open</span>(<span class="string">&#x27;/data1/liyiran/idcard-gen/idcard-gen/angle/star.jpg&#x27;</span>)</span><br><span class="line">img_matrix = ms.fromimage(img)</span><br><span class="line">im_conv_mat = justdoit(img_matrix)</span><br><span class="line">im_conv = PIL.Image.fromarray(im_conv_mat)</span><br><span class="line">im_conv.save(<span class="string">&#x27;mean.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
<li><p>中值滤波/最大值滤波/最小值滤波</p>
对当前像素点用滤波器领域内的像素点值的<strong>中值/最大值/最小值</strong>代替该像素点值得到一幅减噪的图像，对图像脉冲噪声很有作用：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp6mditsqkni2c1tfqptt11713k.png" width="800" />
</center>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> scipy.signal</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">middle_2d</span>(<span class="params">r, n=<span class="number">10</span></span>):</span></span><br><span class="line">    s = scipy.ndimage.median_filter(r, (n, n))</span><br><span class="line">    <span class="keyword">return</span> s.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">justdoit</span>(<span class="params">r</span>):</span></span><br><span class="line">    sp = []</span><br><span class="line">    <span class="keyword">for</span> dim <span class="keyword">in</span> <span class="built_in">range</span>(r.shape[<span class="number">2</span>]):</span><br><span class="line">        rd = r[:, :, dim]</span><br><span class="line">        sd = middle_2d(rd)</span><br><span class="line">        sp.append(sd)</span><br><span class="line">    s = np.dstack(sp)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">img = PIL.Image.<span class="built_in">open</span>(<span class="string">&#x27;/data1/liyiran/idcard-gen/idcard-gen/angle/star.jpg&#x27;</span>)</span><br><span class="line">img_matrix = ms.fromimage(img)</span><br><span class="line">im_conv_mat = justdoit(img_matrix)</span><br><span class="line">im_conv = PIL.Image.fromarray(im_conv_mat)</span><br><span class="line">im_conv.save(<span class="string">&#x27;middle.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>高斯滤波</p>
是一种线性平滑的低通滤波，如果噪声服从高斯分布则效果会很好，它是对图片的每一个像素点的值由滤波器邻域内的其他像素值和该像素值本身加权平均求和后得到，权重的生成服从高斯分布：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cp71jvkee91vqu1dae1i1iaeb41.png" width="800" />
</center>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> scipy.signal</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_win</span>(<span class="params">radius, sigma</span>):</span></span><br><span class="line">    window = np.zeros((radius * <span class="number">2</span> + <span class="number">1</span>, radius * <span class="number">2</span> + <span class="number">1</span>))</span><br><span class="line">    cdf = <span class="number">1</span> / (<span class="number">2</span> * math.pi * sigma ** <span class="number">2</span>) * math.exp((-radius**<span class="number">2</span>) / (<span class="number">2</span> * sigma ** <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-radius, radius + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-radius, radius + <span class="number">1</span>):</span><br><span class="line">            r = (i ** <span class="number">2</span> + j ** <span class="number">2</span>) ** <span class="number">0.5</span></span><br><span class="line">            window[i + radius][j + radius] = cdf</span><br><span class="line">    <span class="keyword">return</span> window / np.<span class="built_in">sum</span>(window)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span>(<span class="params">r</span>):</span></span><br><span class="line">    window = get_win(<span class="number">3</span>, <span class="number">2.5</span>)</span><br><span class="line">    s = scipy.signal.convolve2d(r, window, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;symm&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> s.astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">justdoit</span>(<span class="params">r</span>):</span></span><br><span class="line">    sp = []</span><br><span class="line">    <span class="keyword">for</span> dim <span class="keyword">in</span> <span class="built_in">range</span>(r.shape[<span class="number">2</span>]):</span><br><span class="line">        rd = r[:, :, dim]</span><br><span class="line">        sd = gaussian(rd)</span><br><span class="line">        sp.append(sd)</span><br><span class="line">    s = np.dstack(sp)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">img = PIL.Image.<span class="built_in">open</span>(<span class="string">&#x27;/data1/liyiran/idcard-gen/idcard-gen/angle/star.jpg&#x27;</span>)</span><br><span class="line">img_matrix = ms.fromimage(img)</span><br><span class="line">im_conv_mat = justdoit(img_matrix)</span><br><span class="line">im_conv = PIL.Image.fromarray(im_conv_mat)</span><br><span class="line">im_conv.save(<span class="string">&#x27;gaussian.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>锐化滤波</p>
直接的视觉效果是使模糊的图像变得清晰，主要增强了图像的灰度跳变部分，与图像平滑类滤波器正好相反，原理上主要是对滤波器领域的梯度来实现，常用的有拉普拉斯算子、Robertt交叉梯度算子、Sobel梯度算子等，一个使用拉普拉斯算子的直观例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/sharpen.jpg" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> PIL.Image</span><br><span class="line"><span class="keyword">import</span> scipy.misc <span class="keyword">as</span> ms</span><br><span class="line"><span class="keyword">import</span> scipy.signal</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sharpen</span>(<span class="params">r</span>):</span></span><br><span class="line">    window = np.array([</span><br><span class="line">        [<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [-<span class="number">1</span>, <span class="number">5</span>, -<span class="number">1</span>],</span><br><span class="line">        [<span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    ])</span><br><span class="line">    s = scipy.signal.convolve2d(r, window, mode=<span class="string">&#x27;same&#x27;</span>, boundary=<span class="string">&#x27;symm&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(s.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(s.shape[<span class="number">1</span>]):</span><br><span class="line">            s[i][j] = <span class="built_in">min</span>(<span class="built_in">max</span>(<span class="number">0</span>, s[i][j]), <span class="number">255</span>)</span><br><span class="line">    s = s.astype(np.uint8)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">justdoit</span>(<span class="params">r</span>):</span></span><br><span class="line">    sp = []</span><br><span class="line">    <span class="keyword">for</span> dim <span class="keyword">in</span> <span class="built_in">range</span>(r.shape[<span class="number">2</span>]):</span><br><span class="line">        rd = r[:, :, dim]</span><br><span class="line">        sd = sharpen(rd)</span><br><span class="line">        sp.append(sd)</span><br><span class="line">    s = np.dstack(sp)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">img = PIL.Image.<span class="built_in">open</span>(<span class="string">&#x27;/data1/liyiran/idcard-gen/idcard-gen/angle/star.jpg&#x27;</span>)</span><br><span class="line">img_matrix = ms.fromimage(img)</span><br><span class="line">im_conv_mat = justdoit(img_matrix)</span><br><span class="line">im_conv = PIL.Image.fromarray(im_conv_mat)</span><br><span class="line">im_conv.save(<span class="string">&#x27;sharpen.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure></p></li>
</ul>
<p>2、频域滤波</p>
<p>分析一幅图像信号的频率特性，其中直流分量表示了图像的平均灰度；它的边缘、跳跃部分、噪声及图像细节代表了图像的高频分量；而背景区域和变化缓慢的部分代表了图像的低频分量。</p>
<ul>
<li><p>低通滤波</p>
在频域中利用滤波器函数衰减图像高频信息从而令低频信息畅通无阻的方法叫做低通滤波。在频域实现线性低通滤波器输出会被表达为为： <span class="math display">\[
G(u,v)=H(u,v)F(u,v)
\]</span> 其中<span class="math inline">\(F(u,v)\)</span>是输入，<span class="math inline">\(H(u,v)\)</span>是线性低通滤波器，<span class="math inline">\(G(u,v)\)</span>是输出，即：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvs9f3ia1lpe10231s3a1cq216ne29.png" width="800" />
</center>
几种低通滤波传递函数的剖面图（有没有想到和0-1损失函数及其他损失函数？）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvs9plorseh9okof7133f4of2m.png" width="800" />
</center>
(1)、以理想低通滤波器为例，其传递函数为： <span class="math display">\[ H(u,v)=\left\{
\begin{aligned}
1 &amp;   ,D(u,v)\leq D_0 \\
0 &amp;   ,D(u,v)&gt;D_0
\end{aligned}
\right.
\]</span> 其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
\]</span> 直观上看，理想低通滤波器以<span class="math inline">\(D_0\)</span>为半径的圆内的所有频率分量无损通过，而圆以外的所有频率分量全部衰减，小例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsdr22b1pb5p0s1qp31v8110sb3j.png" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ideal_filter</span>(<span class="params">img,d0=<span class="number">60</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  circle=np.zeros(img.shape,np.uint8)</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          <span class="keyword">if</span> math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>)) &lt;= d0:</span><br><span class="line">              circle[h, w] = <span class="number">255</span></span><br><span class="line">              fx = <span class="number">1</span></span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              fx = <span class="number">0</span></span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> circle,id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">circle,id_img=ideal_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;circle.png&quot;</span>,circle)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;ideal.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure> (2)、以Butterworth（巴特沃斯）低通滤波器为例，其传递函数为：</p>
<p><span class="math display">\[ H(u,v)=\frac{1}{1+(D(u,v)/D_0)^{2n}}\]</span></p>
其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
\]</span> 直观上看，它的通带和阻带之间没有明显的不连续性，即通、阻带之间是平滑的，当<span class="math inline">\(n\)</span>比较大时，Butterworth低通滤波器会退化为理想滤波器，小例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvseqthu3fk1ht3nf01j9cilq40.png" width="800" />
</center>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">butterworth_filter</span>(<span class="params">img,d0=<span class="number">60</span>, n=<span class="number">2</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          fx=<span class="number">1</span>/(<span class="number">1</span>+math.<span class="built_in">pow</span>(math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>)) / d0, <span class="number">2</span>*n))</span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">id_img=butterworth_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;Butterworth.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure>
<p>(3)、以高斯低通滤波器为例，其传递函数为：</p>
<span class="math display">\[ H(u,v)=e^{-(D(u,v)/D_0)^{2n}}\]</span> 其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
  D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
  \]</span> 直观上看，由于函数是平滑的，它的通带和阻带之间同样没有明显的不连续性，效果上比Butterworth模糊一点点，但没有振铃现象，小例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsfl29o1v3212gn1pag1l6bc2g4d.png" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_filter</span>(<span class="params">img,d0=<span class="number">60</span>, n=<span class="number">2</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          fx=math.exp(-<span class="number">1</span>*math.<span class="built_in">pow</span>(math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>)) / d0, <span class="number">2</span>*n))</span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">id_img=gaussian_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;Gaussian.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure> 总的来数，低通滤波可以通过平滑处理使噪声减到不显眼的程度，但这种去噪美化处理是以牺牲清晰度为代价的。</p></li>
<li><p>高通滤波</p>
<p>反过来我们看，由于图像的边缘、线条等细节与图像的高频分量相对应，通过衰减低频分量可以增强高频分量，从而使得图像细节看上去更“清晰”，这便是高通滤波。类比低通滤波，可以有以下几种高通滤波传递函数的剖面图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvskbup216g8148j1ck916plnv44q.png" width="800" />
</center>
<p>(1)、以理想高通滤波器为例，其传递函数为：</p>
<p><span class="math display">\[ H(u,v)=\left\{
  \begin{aligned}
  0 &amp;   ,D(u,v)\leq D_0 \\
  1 &amp;   ,D(u,v)&gt;D_0
  \end{aligned}
  \right.
  \]</span> 其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
  D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
  \]</span></p>
<p>直观上看，理想低通滤波器以<span class="math inline">\(D_0\)</span>为半径的圆内的所有频率分量全部衰减，而圆以外的所有频率分量无损通过，小例子：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsksg0n12vf1do01i3u4naktk57.png" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ideal_filter</span>(<span class="params">img,d0=<span class="number">60</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  circle=np.zeros(img.shape,np.uint8)</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          <span class="keyword">if</span> math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>)) &lt;= d0:</span><br><span class="line">              circle[h, w] = <span class="number">255</span></span><br><span class="line">              fx = <span class="number">0</span></span><br><span class="line">          <span class="keyword">else</span>:</span><br><span class="line">              fx = <span class="number">1</span></span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> circle,id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">circle,id_img=ideal_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;circle.png&quot;</span>,circle)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;ideal.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure></p>
<p>(2)、以Butterworth（巴特沃斯）高通滤波器为例，其传递函数为：</p>
<span class="math display">\[ H(u,v)=\frac{1}{1+(D_0/D(u,v))^{2n}}\]</span> 其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
  D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
  \]</span> 小例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsmpnluqnj14h1d081ct35m85k.png" width="800" />
</center>
<p>代码如下：</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">butterworth_filter</span>(<span class="params">img,d0=<span class="number">60</span>, n=<span class="number">2</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          fx=<span class="number">1</span>/(<span class="number">1</span>+math.<span class="built_in">pow</span>(d0 / (math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>)+<span class="number">0.1</span>)), <span class="number">2</span>*n))</span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">id_img=butterworth_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;Butterworth.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure></p>
<p>(3)、以高斯高通滤波器为例，其传递函数为：</p>
<p><span class="math display">\[H(u,v)=e^{-(D_0/D(u,v))^{2n}}\]</span></p>
其中<span class="math inline">\(D_0\)</span>为非负的截止频率，<span class="math inline">\(D(u,v)\)</span>是从频域的远点到<span class="math inline">\((u,v)\)</span>点的距离： <span class="math display">\[
D(u,v)=\sqrt{(u-M/2)^2+(v-N/2)^2}
\]</span> 小例子：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsmvcts7m1bcv7686jt15t061.png" width="800" />
</center>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian_filter</span>(<span class="params">img,d0=<span class="number">60</span>, n=<span class="number">2</span></span>):</span></span><br><span class="line">  fshift = np.fft.fftshift(np.fft.fft2(img))</span><br><span class="line">  org_fsh=fshift.copy()</span><br><span class="line">  height,weight=fshift.shape</span><br><span class="line">  <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">      <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(weight):</span><br><span class="line">          fx=math.exp(-<span class="number">1</span>*math.<span class="built_in">pow</span>( d0 / (math.sqrt(math.<span class="built_in">pow</span>(h-height/<span class="number">2</span>,<span class="number">2</span>) + math.<span class="built_in">pow</span>(w-weight/<span class="number">2</span>,<span class="number">2</span>))+<span class="number">0.1</span>), <span class="number">2</span>*n))</span><br><span class="line">          org_fsh[h, w] = fx * fshift[h, w]</span><br><span class="line"></span><br><span class="line">  id_img=np.uint8(np.real(np.fft.ifft2(np.fft.ifftshift(org_fsh))))</span><br><span class="line">  <span class="keyword">return</span> id_img</span><br><span class="line"></span><br><span class="line">img=cv2.imread(<span class="string">&#x27;e:/meizi.png&#x27;</span>,cv2.IMREAD_GRAYSCALE)</span><br><span class="line">id_img=gaussian_filter(img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;Gaussian.png&quot;</span>,id_img)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="去模糊去水印">11.2.2 去模糊、去水印</h3>
<h3 id="图片角度识别">11.2.3 图片角度识别</h3>
图片角度识别做法类似构建一个分类和回归问题，套路之前已经讲过就不赘述了，最关键的还是训练数据，可以自己写代码生成各种角度的数据：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1cvsnf77m7noinhq40ggc1hf76r.png" width="800" />
</center>
<h2 id="基于神经网络的文字ocr">11.3 基于神经网络的文字OCR</h2>
<h3 id="行检测模型算法思路">11.3.1 行检测模型算法思路</h3>
<p>文字的检测、物体的检测其实基本原理大同小异，本质上是在学习Bounding Box的边界以及启发式的做Bounding Box合并。以CTPN（https://arxiv.org/pdf/1609.03605.pdf）为例，借鉴Fast R-CNN做文本的行检测，即通过一个“框”把一整行文字的位置检测出来，进而送到后续识别模型，但由于检测文字行不像检测物体，一行字比较长且可能大小不一（尤其垂直方向上），对定位的精度要求更高，所以对于特征提取的基础神经网络需要对位置有较强的敏感性（检测模型要求对位置敏感，而识别模型恰好相反，所以要分场景应用模型）。</p>
CTPN行检测整体思路：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d807rr4a85q1ur81hgt16gef4513.png" width="800" />
</center>
<ul>
<li><p>使用VGG16做特征提取</p>
文中采用的基础网络为VGG16，这个模型前面有介绍，特点是：模型整体偏大，但是较好的保留了图片的局部位置信息：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d8078cbg1l8dp92gd71usk1qgkm.png" width="800" />
</center></li>
<li><p>使用滑动窗口生成一系列文本框序列</p>
<p>与传统检测方法相比：</p>
<ul>
<li>文本有各种各样的字符或文字，没有一个清晰明确的边界可以把它们作为整体框起来；</li>
<li>对位置异常敏感，直接预测位置错误率高，尤其水平位置，如下图：</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d807hlii1nps1jdtkl0uap1lr69.png" width="800" />
</center></li>
<li><p>使用Bounding Box回归预测文本框中心点坐标和高度</p>
<p>为了避免传统方法的问题，CTPN在做BBox回归时采用以下巧妙的Proposal生成方式：</p>
<ul>
<li><p>把生成一个候选框变成生成一系列候选框，并且不关心候选框是框柱了一个完整的字；</p></li>
<li><p>不回归四个坐标，而只回归y轴坐标（中心点与高度）和预测当前候选框中是否为文字；</p></li>
<li>对任何一个候选框，使用k个Anchor（例如k=10）。 原理如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d8084g0mtsu17k81de5qlgs0g1j.png" width="800" />
</center></li>
</ul></li>
<li><p>将文本框序列做合并，构造一整行文字BBox</p>
<p>基本原理为：</p>
<ul>
<li><p>按照水平坐标从左到右排序Anchor；</p></li>
<li><p>依次计算两个Anchor的距离值distance(b1,b2) ；</p>
<p>distance(b1,b2)计算方法：水平正方向寻找与b1水平距离小于50个像素的Anchor；挑出与其垂直方向重合度大于0.7的Anchor；挑出符合上述条件的score值最大的Anchor即为b2。</p></li>
<li><p>最后，利用距离值计算生成连通图，连通图停止生长输出BBox。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d808mv391v2qrfgq7q1n0o11cu20.png" width="800" />
</center></li>
</ul></li>
<li>以行驶证识别为例的行检测效果：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d808v86ii79u77cahu0himu2d.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d8095jue581kkn4on154qgeq2q.png" width="800" />
</center></li>
</ul>
<h3 id="行识别模型算法思路">11.3.2 行识别模型算法思路</h3>
<p>在文本行被检测出来有两种做法，1、切割每个字，然后做字符分类；2、直接对行做分类识别。CTPN采用第二种方式。</p>
<p>1、 整体思路是:</p>
<p>利用CRNN+CTC loss构建神经网络，令特征提取、序列建模和转写在一个统一框架中进行，其特点是：</p>
<ul>
<li><p>不需要手工特征生成或预处理，End to End训练；</p></li>
<li><p>直接从序列学习，不需要精细化标注</p></li>
<li><p>可处理高度统一的任意长度字符串而不用做字符分割或尺度归一化</p></li>
<li><p>与词典本身关系不大</p></li>
<li><p>产生模型相对小故占用存储空间小，Training和Inference效率不错</p></li>
<li><p>当时取得了State of art效果</p></li>
</ul>
RNN类模型在文本相关场景里应用最广泛，本质是因为文本具有上下文关系，而RNN这种网络结构能够很好的捕捉这种序列关系，其变体包括CRNN、LSTM、BiLSTM等：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80a9n5j1dc7h0kc7n19mtbje3k.png" width="500" />
</center>
<p>2、基于CRNN的行识别原理如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d809t59a92bosevbl61l8l37.png" width="400" />
</center>
<p>3、特征序列抽取</p>
<ul>
<li>采用纯卷积和池化操作提取特征</li>
<li>所有图像Resize到相同高度</li>
<li>每列的宽度固定为单个像素</li>
<li>所有Feature Map的第i列组成的向量会成为RNN层的输入
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80ajuecq0318ckhl179pqs74e.png" width="400" />
</center></li>
<li>平移不变性，Feature Map每列对应一个感受野
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80am51a1ldl18np17hmcjo1aom4r.png" width="300" />
</center></li>
</ul>
<p>4、序列标注</p>
<ul>
<li>充分利用文本的上下文信息</li>
<li>RNN支持将误差反向传播至输入，循环层和卷积层可以共用一套训练框架</li>
<li>支持任意长度字符序列操作</li>
<li>使用LSTM除了解决传统RNN的Gradient Vanishing问题，还可以捕捉长距离语义依赖
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80mg4bo7n6cvv6gibg912rn78.png" width="500" />
</center></li>
</ul>
<p>5、转写</p>
<p>将RNN做的每帧预测转换成标签序列的过程。</p>
<ul>
<li><p>利用CTC（它会删除所有重复字符），根据每帧预测找到具有最高概率的标签序列</p></li>
<li><p>可以基于字典或不基于字典做转写，前者受到字典约束</p></li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80mnljsf6u1nht10r1v9vtd47l.png" width="800" />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80mtcpp1ung1qkn18iom68kq8i.png" width="800" />
</center>
基于以上原理，以上面行驶证为例，实现的效果大概如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_11/image_1d80n1jntf9jn80ja31p6e1ee49f.png" width="500" />
</center>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第十一章</tag>
        <tag>OCR</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第六章 循环神经网络与Transformers</title>
    <url>/article/8dd65dea.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E5%85%AD%E7%AB%A0-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8ETransformers-the%20transformer" width=266 /> 本章对机器学习在NLP领域开创性的一些模型做了原理介绍和实践展示，包括RNN、LSTM以及燃烧了整个行业的Transformer。 <span id="more"></span></p>
<h1 id="循环神经网络与transformers">6. 循环神经网络与Transformers</h1>
<h2 id="rnn">6.1 RNN</h2>
<h3 id="基本原理">6.1.1 基本原理</h3>
<p>序列类问题是我们日常生活中常见的一类问题：我们读的文章，我们说话的语音等等，要么是在空间上的序列，要么是在时间的序列，序列的每个单元之间有前驱后继的语义或序列相关性，比如：当我们说，“这是我们伟大的××”，这里××是“祖国”的概率远远大于“板凳”，所以在NLP领域，应用大概可以分为几种：</p>
<p>1、根据当前上下文语义预测接下来出现某个文本的概率；</p>
<p>2、通过语言模型生成新的文本；</p>
<p>3、文本的通用NLP任务，例如词性标注、文本分类等；</p>
<p>4、机器翻译；</p>
<p>5、文本表示及编码解码。</p>
传统的神经网络并没有很好的解决这种序列问题，于是Recurrent Neural Networks这种网络被提了出来：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1d8hvg8ee5bq1msr2ng13sb1cls1m.png" width="600"  />
</center>
<p>乍一看就是节点自带环路的网络，广义来看，可以在这个节点上展开，只是这种展开和输入的字数有关，比如输入为10个字，则展开10层。</p>
<p>从一个角度看，不同于传统神经网络会假设所有输入及输出是相互独立的，RNN正相反，认为节点间天然有相关性；另一个角度是，认为RNN具有“记忆”能力，它能把历史上相关节点状态“全部”记住，但实际情况是，我们当前说的一句话和较久前说的话未必有很强的关系，如果“全部”记住，一没必要、二计算量巨大。</p>
<h3 id="bptt-原理">6.1.2 BPTT 原理</h3>
以最简单的RNN为例，说明背后算法原理：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1d9bnmgsa50b1ksr16kb18vg10gh50.png" width="450"  />
</center>
<p>定义以下符号： <span class="math inline">\(x_i(t)\)</span>：输入层第<span class="math inline">\(i\)</span>个节点；</p>
<p><span class="math inline">\(s_h(t-1)\)</span>：前一个状态的隐藏层第<span class="math inline">\(h\)</span>个节点；</p>
<p><span class="math inline">\(s_j(t)\)</span>：当前状态的隐藏层第<span class="math inline">\(j\)</span>个节点；</p>
<p><span class="math inline">\(y_k(t)\)</span>：输出层第<span class="math inline">\(k\)</span>个节点；</p>
<p><span class="math inline">\(V\)</span>：输入层到隐藏层权重矩阵；</p>
<p><span class="math inline">\(U\)</span>：前一状态隐藏层到后一状态隐藏层权重矩阵；</p>
<p><span class="math inline">\(W\)</span>：隐藏层到输出层权重矩阵;</p>
<p><span class="math inline">\(f\)</span>：隐藏层激活函数；</p>
<p><span class="math inline">\(g\)</span>：输出层激活函数。</p>
<p>网络的前向传播关系为：</p>
<ul>
<li>输入层到隐藏层</li>
</ul>
<p><span class="math display">\[net_j(t)=\sum_{i=0}^nx_i(t)v_{ji}+\sum_{h=0}^m s_h(t-1)u_{jh}+b_j\]</span> <span class="math display">\[s_j(t)=f(net_j(t))\]</span> 常用的<span class="math inline">\(f\)</span>函数为Sigmoid类函数，如：<span class="math display">\[f(net)=\frac{1}{1+e^{-net}}\]</span></p>
<ul>
<li>隐藏层到输出层</li>
</ul>
<p><span class="math display">\[net_k(t)=\sum_{j=0}^ms_j(t)w_{kj}+b_k\]</span> <span class="math display">\[y_k(t)=g(net_k(t))\]</span></p>
<p>常用的<span class="math inline">\(g\)</span>函数为指数族函数，如：</p>
<p><span class="math display">\[g(net_k)=\frac{e^{net_k}}{\sum_pe^{net_p}}\]</span></p>
<p>这里需要注意的一个关键点是：<span class="math inline">\(U\)</span>、<span class="math inline">\(V\)</span>、<span class="math inline">\(W\)</span>权重矩阵在不同时刻是共享的。</p>
<p>网络的反向传播关系：</p>
<p>只要网络的损失函数可微，那么任意一个前馈神经网络都可以通过误差反向传播（BP）做参数学习，BP本质是利用链式求导，使用梯度下降（GD）算法的最优化求解过程，而翻看前面第四章最优化原理，其求解就是给定目标函数，确定搜索步长和搜索方向的故事，GD的权重更新公式为（其中O为目标函数）： <span class="math display">\[\Delta w=-\eta \frac{\partial(O)}{\partial(w)} \]</span></p>
<p>同样回看第四章，目标函数多种多样，比如常见的有: SSE：<span class="math display">\[O=\frac{1}{2}\sum_i\sum_j(\hat{y}_{ij}-y_{ij})^2\]</span> cross entropy:<span class="math display">\[O=\sum_i\sum_j\hat{y}_{ij}ln(y_{ij})+(1-\hat{y}_{ij})(1-lny_{ij})\]</span></p>
<p>但不管哪种目标函数，一般总可以分为线性部分（变量的线性组合）和非线性部分（激活函数），显然求导过程中线性部分最简单，非线性部分最复杂，所以上述权重更新公式可以拆解为：</p>
<p><span class="math display">\[\Delta w=-\eta \frac{\partial(O)}{\partial(net)}\frac{\partial(net)}{\partial(w)} \]</span> 显然：<span class="math inline">\(\frac{\partial(net)}{\partial(w)}\)</span>很容易计算，而<span class="math inline">\(\frac{\partial(O)}{\partial(net)}\)</span>比较难计算，定义： <span class="math inline">\(\delta=-\frac{\partial(O)}{\partial(net)}\)</span>为每个节点的误差向量，那么整个权重的更新核心考量就是怎么计算和传播<span class="math inline">\(\delta\)</span>。</p>
<ul>
<li>输出层任意一个节点<span class="math inline">\(k\)</span></li>
</ul>
<p><span class="math display">\[
\delta_{pk}=\frac{\partial(O)}{\partial(y_{pk})}\frac{\partial(y_{pk})}{\partial(net_{pk})}=\frac{\partial(O)}{\partial(y_{pk})} g^{&#39;}(s_{pk})
\]</span></p>
<ul>
<li>隐藏层任意一个节点<span class="math inline">\(j\)</span></li>
</ul>
<p><span class="math display">\[
\delta_{pj}=-(\sum_k^m\frac{\partial(O)}{\partial(y_{pk})}\frac{\partial(y_{pk})}{\partial(net_{pk})}\frac{\partial(net_{pk})}{\partial(s_{pj})})\frac{\partial(s_{pj})}{\partial(net_{pj})}=\sum_k^m\delta_{pk}w_{kj}f^{&#39;}(s_{pj})
\]</span></p>
<p>基于以上推导得到：</p>
<ul>
<li>当前状态隐藏层到输出层权重更新公式</li>
</ul>
<p><span class="math display">\[\Delta w_{kj}=\eta \sum_p^m \delta_{pk}s_{pj} \]</span></p>
<ul>
<li>输入层到当前状态隐藏层权重更新公式</li>
</ul>
<p><span class="math display">\[\Delta v_{ji}=\eta \sum_p^n \delta_{pj}x_{pi} \]</span></p>
<ul>
<li>上一状态隐藏层到当前状态隐藏层权重更新公式</li>
</ul>
<p><span class="math display">\[\Delta u_{ji}=\eta \sum_p^m \delta_{pj}s_{ph}(t-1) \]</span></p>
<ul>
<li>任一隐层在某个时间状态下的误差</li>
</ul>
<p><strong>注意</strong>，有意思的来了：</p>
<p>对RNN做展开后如图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1d9h56nst1c125o31pdu1u351no75q.png" width="450"  />
</center>
其中<span class="math inline">\(s\)</span>状态前后依赖，所以类似的逻辑，误差会按照时间向后传播，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1d9hecgavrti1hml4le1kbn1lli9.png" width="450"  />
</center>
<p>于是误差反向传播公式变为：</p>
<p><span class="math display">\[
\delta_{pj}(t-1)=-(\sum_h^m\frac{\partial(O)}{\partial(y_{ph})}\frac{\partial(y_{pk})}{\partial(net_{pk})}\frac{\partial(net_{pk})}{\partial(s_{pj})})\frac{\partial(s_{pj})}{\partial(net_{pj})}=\sum_h^m\delta_{ph}(t)u_{hj}f^{&#39;}(s_{pj}(t-1))
\]</span> 其中：<span class="math inline">\(h\)</span>是在<span class="math inline">\(t\)</span>时刻的任何一个隐层节点，<span class="math inline">\(j\)</span>是在<span class="math inline">\(t-1\)</span>时刻的任何一个隐层节点，高层的<span class="math inline">\(\delta\)</span>可以通过循环递归的计算出来，所有<span class="math inline">\(\delta\)</span>计算完毕后累加求和并应用在<span class="math inline">\(U\)</span>、<span class="math inline">\(V\)</span>的权重更新中。</p>
<h3 id="代码实践">6.1.3 代码实践</h3>
<p>问题描述：给定一个字符，生成（预测）之后的n个字符，并使得整个句子看上去有语义含义。</p>
<p>1、训练数据生成如下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ddpb4ckassq1l4b1evk1utu16e613.png" width="600"  />
</center>
2、过程说明如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ddpb61bnag91iu3ce8ivvrq41g.png" width="600"  />
</center>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RnnModeling</span>:</span></span><br><span class="line">    bert_len = <span class="number">768</span>                                                      <span class="comment"># length of bert nector.</span></span><br><span class="line">    txt_data_size = <span class="number">0</span>                                                   <span class="comment"># text data size of char level.</span></span><br><span class="line">    iteration = <span class="number">1000</span>                                                    <span class="comment"># iteration of training.</span></span><br><span class="line">    sequence_length = <span class="number">5</span>                                                 <span class="comment"># window of text context.</span></span><br><span class="line">    batch_size = <span class="number">0</span>                                                      <span class="comment"># training batch.</span></span><br><span class="line">    input_size = <span class="number">0</span>                                                      <span class="comment"># size of input layer.</span></span><br><span class="line">    hidden_size = <span class="number">100</span>                                                   <span class="comment"># size of hidden layer.</span></span><br><span class="line">    output_size = <span class="number">0</span>                                                     <span class="comment"># size of output layer.</span></span><br><span class="line">    learning_rate = <span class="number">0.001</span>                                               <span class="comment"># learning rate of optimization algorithm.</span></span><br><span class="line"></span><br><span class="line">    bert_path = <span class="string">&quot;&quot;</span>                                                      <span class="comment"># the path of bert model,you can download it through https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip.</span></span><br><span class="line">    word2vec_path = <span class="string">&quot;&quot;</span>                                                  <span class="comment"># the path of word2vec model,you can download the pre-train model from internet.</span></span><br><span class="line">    chars_set = []                                                      <span class="comment"># all chars in text data.</span></span><br><span class="line">    check_point_dir = <span class="string">&quot;&quot;</span>                                               <span class="comment"># path of check point.</span></span><br><span class="line"></span><br><span class="line">    char_to_int = &#123;&#125;                                                    <span class="comment"># char level encoding, char-&gt;int</span></span><br><span class="line">    int_to_char = &#123;&#125;                                                    <span class="comment"># char level decoding, int-&gt;char</span></span><br><span class="line">    char_encoded = &#123;&#125;                                                   <span class="comment"># one hot encoding</span></span><br><span class="line"></span><br><span class="line">    V = []                                                              <span class="comment"># weight matrix: from input to hidden.</span></span><br><span class="line">    U = []                                                              <span class="comment"># weight matrix: from hidden to hidden.</span></span><br><span class="line">    W = []                                                              <span class="comment"># weight matrix: from hidden to output.</span></span><br><span class="line"></span><br><span class="line">    b_h = []                                                            <span class="comment"># bias vector of hidden layer.</span></span><br><span class="line">    b_y = []                                                            <span class="comment"># bias vector of output layer.</span></span><br><span class="line">    h_prev = []                                                         <span class="comment"># previous hidden state.</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_fine_tuning_path</span>(<span class="params">self, bert_path=<span class="string">&quot;&quot;</span>, word2vec_path=<span class="string">&quot;&quot;</span>, check_point_dir=<span class="string">&quot;&quot;</span></span>):</span></span><br><span class="line">        self.bert_path = bert_path</span><br><span class="line">        self.word2vec_path = word2vec_path</span><br><span class="line">        self.check_point_dir = check_point_dir</span><br><span class="line">        <span class="keyword">if</span> word2vec_path != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> <span class="keyword">not</span> os.path.exists(word2vec_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[Error] the path of word2vec is not exists.&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> bert_path != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> <span class="keyword">not</span> os.path.exists(bert_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[Error] the path of bert is not exists.&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> check_point_dir != <span class="string">&quot;&quot;</span> <span class="keyword">and</span> <span class="keyword">not</span> os.path.exists(check_point_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[Info] the path of check point is not exists, we&#x27;ll create make it.&quot;</span>)</span><br><span class="line">            os.makedirs(check_point_dir)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">copy_model</span>(<span class="params">self, rnn</span>):</span></span><br><span class="line">        self.bert_len = rnn.bert_len</span><br><span class="line">        self.txt_data_size = rnn.bert_len</span><br><span class="line">        self.iteration = rnn.iteration</span><br><span class="line">        self.sequence_length = rnn.sequence_length</span><br><span class="line">        self.batch_size = rnn.batch_size</span><br><span class="line">        self.input_size = rnn.input_size</span><br><span class="line">        self.hidden_size = rnn.hidden_size</span><br><span class="line">        self.output_size = rnn.output_size</span><br><span class="line">        self.learning_rate = rnn.learning_rate</span><br><span class="line">        self.chars_set = rnn.chars_set</span><br><span class="line">        self.char_to_int = rnn.char_to_int</span><br><span class="line">        self.int_to_char = rnn.int_to_char</span><br><span class="line">        self.char_encoded = rnn.char_encoded</span><br><span class="line">        self.V = rnn.V</span><br><span class="line">        self.U = rnn.U</span><br><span class="line">        self.W = rnn.W</span><br><span class="line">        self.b_h = rnn.b_h</span><br><span class="line">        self.b_y = rnn.b_y</span><br><span class="line">        self.h_prev = rnn.h_prev</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">training_data_analysis</span>(<span class="params">self, txt_data, mode</span>):</span></span><br><span class="line">        self.txt_data_size = <span class="built_in">len</span>(txt_data)</span><br><span class="line">        chars = <span class="built_in">list</span>(<span class="built_in">set</span>(txt_data))</span><br><span class="line">        self.output_size = <span class="built_in">len</span>(chars)</span><br><span class="line">        self.char_to_int = <span class="built_in">dict</span>((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars))</span><br><span class="line">        self.int_to_char = <span class="built_in">dict</span>((i, c) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&quot;one-hot&quot;</span>:</span><br><span class="line">            self.input_size = <span class="built_in">len</span>(chars)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars):</span><br><span class="line">                letter = [<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(chars))]</span><br><span class="line">                letter[self.char_to_int[c]] = <span class="number">1</span></span><br><span class="line">                self.char_encoded[c] = np.array(letter)</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&quot;bert&quot;</span>:</span><br><span class="line">            self.input_size = self.bert_len</span><br><span class="line"></span><br><span class="line">            <span class="keyword">from</span> bert_serving.client <span class="keyword">import</span> BertClient</span><br><span class="line">            bc = BertClient(timeout=<span class="number">1000</span>)</span><br><span class="line">            <span class="comment"># start server: bert-serving-start -model_dir=D:\Github\bert\chinese_L-12_H-768_A-12 -num_worker=1</span></span><br><span class="line">            <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> c.strip():</span><br><span class="line">                    self.char_encoded[c] = np.array(bc.encode([<span class="string">&#x27;&lt;S&gt;&#x27;</span>]))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.char_encoded[c] = np.array(bc.encode([c]))</span><br><span class="line">                <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;[Debug] bert vector length: %d&#x27;</span> % (<span class="built_in">len</span>(self.char_encoded)))</span><br><span class="line">        <span class="keyword">elif</span> mode == <span class="string">&quot;w2v&quot;</span>:</span><br><span class="line">            <span class="keyword">import</span> gensim</span><br><span class="line">            model = gensim.models.KeyedVectors.load_word2vec_format(self.word2vec_path, binary=<span class="literal">False</span>)</span><br><span class="line">            self.input_size = model.vector_size</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(chars):</span><br><span class="line">                <span class="keyword">if</span> model.__contains__(c):</span><br><span class="line">                    self.char_encoded[c] = np.array(model[c])</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    self.char_encoded[c] = np.zeros((self.input_size, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[Error] mode type error. it should be one-hot or bert or w2v.&quot;</span>)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_building</span>(<span class="params">self, itr, seq_len, lr, h_size</span>):</span></span><br><span class="line">        self.iteration = itr</span><br><span class="line">        self.sequence_length = seq_len</span><br><span class="line">        self.learning_rate = lr</span><br><span class="line">        self.batch_size = <span class="built_in">round</span>((self.txt_data_size / self.sequence_length) + <span class="number">0.5</span>)</span><br><span class="line">        self.hidden_size = h_size</span><br><span class="line"></span><br><span class="line">        self.V = np.random.randn(self.hidden_size, self.input_size) * <span class="number">0.01</span>              <span class="comment"># weight input -&gt; hidden.</span></span><br><span class="line">        self.U = np.random.randn(self.hidden_size, self.hidden_size) * <span class="number">0.01</span>             <span class="comment"># weight hidden -&gt; hidden</span></span><br><span class="line">        self.W = np.random.randn(self.output_size, self.hidden_size) * <span class="number">0.01</span>             <span class="comment"># weight hidden -&gt; output</span></span><br><span class="line"></span><br><span class="line">        self.b_h = np.zeros((self.hidden_size, <span class="number">1</span>))</span><br><span class="line">        self.b_y = np.zeros((self.output_size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        self.h_prev = np.zeros((self.hidden_size, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forwardprop</span>(<span class="params">self, labeling, inputs, h_prev</span>):</span></span><br><span class="line">        x, s, y, p = &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;</span><br><span class="line">        s[-<span class="number">1</span>] = np.copy(h_prev)</span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(inputs)):                                                        <span class="comment"># t is a &quot;time step&quot;.</span></span><br><span class="line">            x[t] = self.char_encoded[inputs[t]].reshape(-<span class="number">1</span>, <span class="number">1</span>)                              <span class="comment"># input vector.</span></span><br><span class="line">            s[t] = np.tanh(np.dot(self.V, x[t]) + np.dot(self.U, s[t - <span class="number">1</span>]) + self.b_h)      <span class="comment"># hidden state. f(x(t)*V + s(t-1)*U + b), f=tanh.</span></span><br><span class="line">            y[t] = np.dot(self.W, s[t]) + self.b_y                                          <span class="comment"># f(s(t)*W + b), f=x.</span></span><br><span class="line">            p[t] = np.exp(y[t]) / np.<span class="built_in">sum</span>(np.exp(y[t]))                                      <span class="comment"># softmax. f(x)=exp(x)/sum(exp(x))</span></span><br><span class="line">            loss += -np.log(p[t][self.char_to_int[labeling[t]]])                            <span class="comment"># cross-entropy loss.</span></span><br><span class="line">        <span class="keyword">return</span> loss, p, s, x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backprop</span>(<span class="params">self, p, labeling, inputs, s, x</span>):</span></span><br><span class="line">        dV, dU, dW = np.zeros_like(self.V), np.zeros_like(self.U), np.zeros_like(self.W)    <span class="comment"># make all zero matrices.</span></span><br><span class="line">        dbh, dby = np.zeros_like(self.b_h), np.zeros_like(self.b_y)</span><br><span class="line">        delta_pj_1 = np.zeros_like(s[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># error reversed</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(inputs))):</span><br><span class="line">            dy = np.copy(p[t])                                          <span class="comment"># &quot;dy&quot; means &quot;δpk&quot;</span></span><br><span class="line">            dy[self.char_to_int[labeling[t]]] -= <span class="number">1</span>                      <span class="comment"># when using cross entropy loss, δpk=d-y.</span></span><br><span class="line">            dW += np.dot(dy, s[t].T)                                    <span class="comment"># dw/η=δpk * s(t)</span></span><br><span class="line">            dby += dy</span><br><span class="line">            delta_pk_w = np.dot(self.W.T, dy) + delta_pj_1              <span class="comment"># δpk * w.</span></span><br><span class="line">            delta_pj = (<span class="number">1</span> - s[t] * s[t]) * delta_pk_w                   <span class="comment"># δpj = δpk * w * f&#x27;(x); f(x)=tanh; f&#x27;(x)= tanh&#x27;(x) = 1-tanh^2(x)</span></span><br><span class="line">            dbh += delta_pj</span><br><span class="line">            dV += np.dot(delta_pj, x[t].T)                              <span class="comment"># dv/η = δpj * x(t)</span></span><br><span class="line">            dU += np.dot(delta_pj, s[t - <span class="number">1</span>].T)                          <span class="comment"># du/η = δpj * s(t-1)</span></span><br><span class="line">            delta_pj_1 = np.dot(self.U.T, delta_pj)                     <span class="comment"># δpj (t-1) = δpj * u</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> dparam <span class="keyword">in</span> [dV, dU, dW, dbh, dby]:</span><br><span class="line">            np.clip(dparam, -<span class="number">1</span>, <span class="number">1</span>, out=dparam)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dV, dU, dW, dbh, dby</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_reading</span>(<span class="params">self, model_read_path</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(model_read_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;[Error] the model path %s is not exists.&quot;</span> % model_read_path)</span><br><span class="line">            exit(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        f = <span class="built_in">open</span>(model_read_path, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">        rnn = pickle.load(f)</span><br><span class="line">        ce = pickle.load(f)</span><br><span class="line">        rnn.char_encoded = ce</span><br><span class="line">        f.close()</span><br><span class="line">        self.copy_model(rnn)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_saving</span>(<span class="params">self, model_save_path</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(model_save_path):</span><br><span class="line">            os.system(<span class="string">r&quot;touch &#123;&#125;&quot;</span>.<span class="built_in">format</span>(model_save_path))</span><br><span class="line"></span><br><span class="line">        f = <span class="built_in">open</span>(model_save_path, <span class="string">&#x27;wb&#x27;</span>)</span><br><span class="line">        pickle.dump(self, f, protocol=-<span class="number">1</span>)</span><br><span class="line">        pickle.dump(self.char_encoded, f, protocol=-<span class="number">1</span>)</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_training</span>(<span class="params">self, txt_data, ischeck=<span class="literal">False</span></span>):</span></span><br><span class="line">        chk_path = self.check_point_dir + <span class="string">&quot;/final.p&quot;</span></span><br><span class="line">        <span class="keyword">if</span> ischeck <span class="keyword">and</span> os.path.exists(chk_path):</span><br><span class="line">            rnn.model_reading(chk_path)</span><br><span class="line"></span><br><span class="line">        mV, mU, mW = np.zeros_like(self.V), np.zeros_like(self.U), np.zeros_like(self.W)</span><br><span class="line">        mbh, mby = np.zeros_like(self.b_h), np.zeros_like(self.b_y)</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.iteration):</span><br><span class="line">            self.h_prev = np.zeros((self.hidden_size, <span class="number">1</span>))</span><br><span class="line">            data_pointer = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(self.batch_size):</span><br><span class="line">                inputs = [ch <span class="keyword">for</span> ch <span class="keyword">in</span> txt_data[data_pointer:data_pointer + self.sequence_length]]</span><br><span class="line">                targets = [ch <span class="keyword">for</span> ch <span class="keyword">in</span> txt_data[data_pointer + <span class="number">1</span>:data_pointer + self.sequence_length + <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (data_pointer + self.sequence_length + <span class="number">1</span> &gt;= <span class="built_in">len</span>(txt_data) <span class="keyword">and</span> b == self.batch_size - <span class="number">1</span>):</span><br><span class="line">                    targets.append(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line"></span><br><span class="line">                loss, ps, hs, xs = self.forwardprop(targets, inputs, self.h_prev)</span><br><span class="line"></span><br><span class="line">                dV, dU, dW, dbh, dby = self.backprop(ps, targets, inputs, hs, xs)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> weight, g, his <span class="keyword">in</span> <span class="built_in">zip</span>([self.V, self.U, self.W, self.b_h, self.b_y],</span><br><span class="line">                                              [dV, dU, dW, dbh, dby],</span><br><span class="line">                                              [mV, mU, mW, mbh, mby]):</span><br><span class="line">                    his += g * g                                      <span class="comment"># RMSProp updata</span></span><br><span class="line">                    e = <span class="number">0.5</span> * his / (i + <span class="number">1</span>) + <span class="number">0.5</span> * g * g             <span class="comment"># RMSProp updata</span></span><br><span class="line">                    weight += -self.learning_rate * g / np.sqrt(e + <span class="number">1e-8</span>)   <span class="comment"># RMSProp update</span></span><br><span class="line"></span><br><span class="line">                data_pointer += self.sequence_length</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[Debug] iteration %d, loss value: %f&#x27;</span> % (i, loss))</span><br><span class="line">                <span class="keyword">if</span> ischeck:</span><br><span class="line">                    self.model_saving(self.check_point_dir+<span class="string">&quot;/chk&quot;</span>+<span class="built_in">str</span>(i)+<span class="string">&quot;.p&quot;</span>)</span><br><span class="line">                    self.model_saving(chk_path)</span><br><span class="line"></span><br><span class="line">        self.model_saving(chk_path)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">model_inference</span>(<span class="params">self, test_char, length</span>):</span></span><br><span class="line">        x = self.char_encoded[test_char].reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        idx = []</span><br><span class="line">        h = np.zeros((self.hidden_size,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">            h = np.tanh(np.dot(self.V, x) + np.dot(self.U, h) + self.b_h)</span><br><span class="line">            y = np.dot(self.W, h) + self. b_y</span><br><span class="line">            p = np.exp(y) / np.<span class="built_in">sum</span>(np.exp(y))</span><br><span class="line">            ix = <span class="built_in">list</span>(p).index(<span class="built_in">max</span>(<span class="built_in">list</span>(p)))</span><br><span class="line">            x = self.char_encoded[self.int_to_char[ix]].reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            idx.append(ix)</span><br><span class="line">        txt = <span class="string">&#x27;&#x27;</span>.join(self.int_to_char[i] <span class="keyword">for</span> i <span class="keyword">in</span> idx)</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&#x27;[Debug] %s-%s&#x27;</span> % (test_char, txt))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self, txt_data, bert_path=<span class="string">&quot;&quot;</span>, word2vec_path=<span class="string">&quot;&quot;</span>, check_point_path=<span class="string">&quot;&quot;</span>, ischeck=<span class="literal">True</span>, model_type=<span class="string">&quot;bert&quot;</span>, \</span></span></span><br><span class="line"><span class="params"><span class="function">            itr=<span class="number">1000</span>, seq_len=<span class="number">10</span>, lr=<span class="number">0.001</span>, h_size=<span class="number">100</span></span>):</span></span><br><span class="line">        self.set_fine_tuning_path(bert_path, word2vec_path, check_point_path)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ischeck:</span><br><span class="line">            self.training_data_analysis(txt_data, model_type)</span><br><span class="line">            self.model_building(itr, seq_len, lr, h_size)</span><br><span class="line"></span><br><span class="line">        self.model_training(txt_data, ischeck)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    txt_data = <span class="string">&quot;当地时间6月17日，第53届巴黎-布尔歇国际航空航天展览会（即巴黎航展）开幕。 开幕当天，法国总统马克龙亲自为法国、德国与西班牙三国联合研制的“新一代战斗机”（NGF）的全尺寸模型揭幕。法、德、西三国防长也出席了模型揭幕仪式，并在仪式后签署了三方合作协议，正式欢迎西班牙加入“新一代战机”的联合研制。NGF与美国的F-22、F-35、俄罗斯的苏-57以及中国的歼-20一样，同属第五代战斗机。&quot;</span></span><br><span class="line">    rnn = RnnModeling()</span><br><span class="line">    rnn.set_fine_tuning_path(check_point_dir=<span class="string">&quot;e://&quot;</span>, word2vec_path=<span class="string">&#x27;E:\\BaiduNetdiskDownload\\zhwiki\\zhwiki_2017_03.sg_50d.word2vec&#x27;</span>)</span><br><span class="line">    rnn.run(txt_data, ischeck=<span class="literal">False</span>, check_point_path=<span class="string">&quot;e://&quot;</span>)</span><br><span class="line">    rnn.model_inference(<span class="string">&#x27;法&#x27;</span>, <span class="number">10</span>)</span><br><span class="line">    rnn.model_inference(<span class="string">&#x27;巴&#x27;</span>, <span class="number">10</span>)</span><br><span class="line">    rnn.model_inference(<span class="string">&#x27;歼&#x27;</span>, <span class="number">10</span>)</span><br><span class="line">    rnn.model_inference(<span class="string">&#x27;新&#x27;</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>训练及测试结果： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Debug] iteration 0, loss value: 28.059744</span><br><span class="line">[Debug] iteration 100, loss value: 2.966153</span><br><span class="line">[Debug] iteration 200, loss value: 1.247683</span><br><span class="line">[Debug] iteration 300, loss value: 0.931227</span><br><span class="line">[Debug] iteration 400, loss value: 0.848960</span><br><span class="line">[Debug] iteration 500, loss value: 0.812240</span><br><span class="line">[Debug] iteration 600, loss value: 0.791726</span><br><span class="line">[Debug] iteration 700, loss value: 0.779109</span><br><span class="line">[Debug] iteration 800, loss value: 0.770437</span><br><span class="line">[Debug] iteration 900, loss value: 0.764572</span><br><span class="line">[Debug] 法-国、德国与美国的F-</span><br><span class="line">[Debug] 巴-黎航展）开幕。 开幕</span><br><span class="line">[Debug] 歼--20一样，同属第五</span><br><span class="line">[Debug] 新-一代战斗机”（NGF</span><br></pre></td></tr></table></figure></p>
<h2 id="混沌理论">6.2 混沌理论</h2>
<p>关于混沌(Chaos)一词，西方和东方在哲学认知和神话传说上惊人的相似。例如古希腊神话中描述的：万物之初，先有混沌，是一个无边无际、空空如也的空间，在发生某种扰动后，诞生了大地之母Gaea等等，世界从此开始。中国古代神话中，天地未开之前，宇宙以混沌状模糊一团，盘古开天辟地后世界从此开始。</p>
<p>而在现代自然科学中，混沌理论的发展反映了人们对客观世界认知一步步演化的过程。人类对自然规律的认知，也从确定性(Deterministic)认知主导逐步演进到概率性(Probabilistic)认知主导。</p>
<ul>
<li><p>经典力学与机械决定论</p>
<p>牛顿1686年创立了基于万有引力定律和三大定律的古典力学，即：第一定律，在沒有被外力作用下的物体，会保持静止或匀速直线运动状态；第二定律，物体的加速度与物体所受外力的合力成成正比，与物体本身的质量成反比，且加速度方向与合力方向相同；第三定律，两个物体间的作用力和反作用力大小相等方向相反。牛顿的这种基于确定性认知的绝对时空观在很长一段时间占据主导位置，例如拉普拉斯甚至认为：没有什么是不确定的，宇宙的现在是由其过去决定的，只要给定初始条件，智者可以用一个公式概括整个宇宙，预测宇宙未来的发展。拉普拉斯对于概率论有着巨大的贡献，但他认为概率论只是对决定论的补充而已。</p></li>
<li><p>三体问题</p>
<p>在那个年代，虽然人们对太阳、地球、月亮的运动规律了解的比较清楚，但对三个天体在长时间运动过程中，状态是否保持稳定、能否永远稳定运行等相关问题却没有什么认知，即理论上认为确定性的事情，而事实上却无法用已知的数学模型表达，这个就是天体力学中的经典模型——三体问题。19世纪末，人们已经知道，在一般三体问题中每个天体在其他两个天体引力作用下的运动方程都可以表示成6个一阶常微分方程，这意味着总共需要求18个完全积分才能获得完整解析解，而理论上只能得到10个完全积分，即描述三个或三个以上天体运动的方程组不可积分，更不能得到解析解。 虽然后来欧拉和拉格朗日分别在给定约束条件下求得了限制性三体问题的5个特殊解，即著名的<a href="https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E7%82%B9">拉格朗日点</a>，但通用三体问题依然无解。</p></li>
<li><p>庞加莱的错误</p>
<p>庞加莱(就是那个提出庞加莱猜想的庞加莱)在1887年参加瑞典国王发起的“太阳系是稳定的么”的竞赛中，对限定性三体问题发表了一篇论文，初稿出来后，一个名叫<a href="https://en.wikipedia.org/wiki/Lars_Edvard_Phragm%C3%A9n">弗拉格曼</a>的26岁年轻人发现了其中有不明确的部分，而庞加莱在修改过程中发现了原来的证明有错误，于是在深思熟虑后彻底抛弃了原来通过定量分析求解的方法，转而以定性分析求解并成功给出三体问题的定性解答，而那个错误是由于初始条件的微小误差导致最终结果的南辕北辙，这个观察清晰而定性的开辟了混沌理论。</p></li>
<li><p>蝴蝶效应</p>
<p>现代科学史中，真正意义上的混沌理论是MIT的<a href="https://zh.wikipedia.org/wiki/%E7%88%B1%E5%BE%B7%E5%8D%8E%C2%B7%E8%AF%BA%E9%A1%BF%C2%B7%E6%B4%9B%E4%BC%A6%E8%8C%A8">洛伦茨</a>(Lorenz)提出的，在此之前人们原本以为，只要配上动力学公式和超级计算机，就能模拟出自然界的各种现象，1961年，洛伦茨用Royal McBee LGP-30计算机(16k内存，每秒60次乘法运算)做气象动力学模拟实验时，由于一个偶然的对初始值做四舍五入的处理，导致模拟结果大相径庭。基于这次实验，1963年，洛伦茨在《气象学报》发表了《確定性的非周期流》系列，以物理意义更加明确的数学模型表示和发展了混沌理论。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eck5ab2i1k6en2p110u4ic1i801t.png" width="350"  /> 洛伦茨系统
</center></li>
</ul>
<p>简单看一个关于流体热力传导的问题：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1edgkmmg78npnk1cbq1vmpaq81e.png" width="350"  />
</center>
<p>当温差较小时，热力会以传导的方式从热的板块到冷的板块，当温差较大时，下面的暖流体上升，上面的冷流体下沉，冷、热板块会产生对流滚动。针对这个问题，洛伦茨将他原始方程中除三个傅立叶系数外的其他系数都设为0，得到了简化的微分方程：</p>
<p><span class="math display">\[
\begin{align*}
&amp; \dot{x}=-\sigma x+\sigma y \\
&amp; \dot{y}=-xz+rx-y \\
&amp; \dot{z}=xy-bz \\
\end{align*}
\]</span></p>
<p>其中<span class="math inline">\(\sigma\)</span>是Prandtl系数、<span class="math inline">\(r\)</span>是Rayleigh系数、<span class="math inline">\(b\)</span>是系统参数，决定了循环的宽度(图中<span class="math inline">\(T_u\)</span>与<span class="math inline">\(T_l\)</span>质检的距离)、<span class="math inline">\(x\)</span>与循环流体的流苏成正比，且<span class="math inline">\(x&gt;0\)</span>时流体顺时针对流，<span class="math inline">\(x&lt;0\)</span>时流体逆时针对流、<span class="math inline">\(y\)</span>与温差成正比、<span class="math inline">\(z\)</span>与垂直温度曲线与平衡温度曲线的失真成正比。</p>
<p>洛伦茨发现，当<span class="math inline">\(\sigma=10\)</span>且<span class="math inline">\(b=8/3\)</span>时，只要Rayleigh系数超过<span class="math inline">\(r\approx 24.74\)</span>，系统就会表现为"混沌"，即所有的解似乎对初始条件都很敏感，几乎所有的解显然既不是周期性解，也不收敛于周期性解。换句话说，洛伦茨用一个确定性的方程告诉我们一个热力学动态系统的不可预知性。</p>
<p>回想电视剧里看到的离奇故事：</p>
<p>1、因为一滴雨水掉在了马的眼睛里，马摔倒了；</p>
<p>2、恰好骑马的是一名斥候，斥候受伤了；</p>
<p>3、斥候受伤导致手上的情报没有被及时送到军营，军队战败了；</p>
<p>4、军队战败导致重要城市丢失，敌军长驱直入进入都城；</p>
<p>5、都城被灭，皇帝被杀，国家灭亡。</p>
<p>混沌理论的核心思想是：初始条件的微小差别或变化，可以导致最终结果发生剧烈的变化。</p>
<p>下面从理论方面做一些简单介绍，帮助理解未来我们会用到的一些概念。</p>
<h3 id="一维映射">6.2.1 一维映射</h3>
<p>1、<strong>动态系统(Dynamical System)</strong></p>
<p>一个动态系统由一组可能的状态组成，再加上一个用过去的状态来确定现在的状态的规则。最典型的动态系统是时间离散动态系统(discrete-time dynamical system)和时间连续动态系统(m continuous-time dynamical system)，前面我们介绍的RNN就是一种离散动态系统。</p>
<p>很多现实当中问题往往是随着时间演化的动态系统，例如：模拟细菌生长过程，在给定初始细菌数后，随着时间流逝，细菌数量增长的模型如下：</p>
<p><span class="math display">\[x_n=f(x_{n-1})=2x_{n-1}=f(f(x_{n-2}))=f^n(x_0)=2^nx_0\]</span> <span class="math inline">\(x_0\)</span>表示初始细菌数，<span class="math inline">\(n\)</span>表示随时间演化，显然这个增长过程是以指数增长的。</p>
2、<strong>固点(Fixed Points)</strong> 如果动态系统有映射<span class="math inline">\(f\)</span>，且满足<span class="math inline">\(f(p)=p\)</span>，则<span class="math inline">\(p\)</span>被称为固点。还以上面细菌生长过程为例，几何意义如下图表示：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1echc1m1417va1si31n9l4uqo4813.png" width="450"  />
</center>
<p>利用<span class="math inline">\(y=x\)</span>直线发现动态系统的固点只有x=0这一点，画出动态系统的演化轨迹(虚线部分)，随着时间流逝，细菌种群规模趋向于正无穷。</p>
<p>但真实情况是，受限于环境、资源等因素，细菌种群规模不可能无限大，所以修改动态系统为： <span class="math display">\[x_n=f(x_{n-1})=2x_{n-1}(1-x_{n-1})=f(f(x_{n-2}))=f^n(x_0)\]</span></p>
几何意义如下图表示：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1echc0ujc1crhpl71tov2vt165im.png" width="450"  />
</center>
<p>利用<span class="math inline">\(y=x\)</span>直线发现动态系统的固点有x=0和x=0.5这两个点，画出动态系统的演化轨迹（虚线），随着时间流逝，不管初始种群<span class="math inline">\(x_0\)</span>取多少，细菌种群规模最终趋向于0.5(被吸引到0.5)，用R做个简单模拟：</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">g &lt;- <span class="keyword">function</span>(x)&#123;</span><br><span class="line">  <span class="built_in">return</span>(<span class="number">2</span>*x*(<span class="number">1</span>-x))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gk &lt;- <span class="keyword">function</span>(k, x)&#123;</span><br><span class="line">  <span class="keyword">for</span>(i <span class="keyword">in</span> <span class="number">1</span>:k)&#123;</span><br><span class="line">    x = g(x)</span><br><span class="line">    print(x)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">k=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i <span class="keyword">in</span> <span class="number">1</span>:<span class="number">10</span>)&#123;</span><br><span class="line">  x=runif(<span class="number">1</span>)</span><br><span class="line">  gk(k, x)</span><br><span class="line">  print(<span class="string">&quot;=====&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>部分结果如下：</p>
<table>
<thead>
<tr class="header">
<th>t</th>
<th style="text-align: right;">y(x=0.941631)</th>
<th style="text-align: right;">y(x=0.6455615 )</th>
<th style="text-align: right;">y(x=0.1207315 )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: right;">0.1099241</td>
<td style="text-align: right;">0.4576237</td>
<td style="text-align: right;">0.2123107</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: right;">0.1956815</td>
<td style="text-align: right;">0.4964085</td>
<td style="text-align: right;">0.3344698</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: right;">0.3147805</td>
<td style="text-align: right;">0.4999742</td>
<td style="text-align: right;">0.4451995</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: right;">0.4313875</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.4939938</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: right;">0.4905846</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.4999279</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: right;">0.4998227</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: right;">0.4999999</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">0.5</td>
</tr>
</tbody>
</table>
<p>3、<strong>稳定的固点(Stability of Fixed Points)</strong></p>
<p>假设动态系统的映射为<span class="math inline">\(f(x) =\frac{(3x-x^3)}{2}\)</span>，几何形态如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1echdls5q1f991o6f1bba1fb5bor1g.png" width="450"  />
</center>
<p>利用<span class="math inline">\(y=x\)</span>直线发现动态系统的固点有<span class="math inline">\(x_0=0\)</span>和<span class="math inline">\(x_1=1\)</span>和<span class="math inline">\(x_2=-1\)</span>这三个点，画出动态系统的演化轨迹（虚线），其中<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>两个点被称为稳定固点，在<span class="math inline">\(x_1\)</span>和<span class="math inline">\(x_2\)</span>两个值的某个邻域内，y会分别收敛于1和-1两个值，<span class="math inline">\(x_0\)</span>为不稳定固点，在它的+邻域内y会被推到上半区，-邻域内y会被推到下半区。</p>
<p>4、<strong>吸引固点(Sink)与排斥固点(Source)</strong></p>
<p>首先对点<span class="math inline">\(p\)</span>定义它的邻域：</p>
<p><span class="math display">\[N_\epsilon(p)=\{x\in R:|x-p|&lt;\epsilon\},0&lt;\epsilon&lt;&lt;1\]</span></p>
<p>其次，假设动态系统有映射<span class="math inline">\(f\)</span>，点<span class="math inline">\(p\)</span>为实数值，且满足<span class="math inline">\(f(p)=p\)</span>，如果存在<span class="math inline">\(p\)</span>的邻域<span class="math inline">\(N_\epsilon(p)\)</span>，使得所有邻域内的点会被吸引到<span class="math inline">\(p\)</span>点，即：</p>
<p><span class="math display">\[lim_{k-&gt;\infty}f^k(x)=p,x\in N_\epsilon(p)\]</span></p>
<p>则点<span class="math inline">\(p\)</span>被称作Sink，反之如果邻域内的点会被排斥远离点<span class="math inline">\(p\)</span>，则点<span class="math inline">\(p\)</span>被称作Source。</p>
<p>数学化表示如下，记住这个表示，未来解释为什么RNN无法利用梯度下降学到长依赖关系时会用到：</p>
<p>如果<span class="math inline">\(f\)</span>是一个在实数集上的平滑映射，假设<span class="math inline">\(p\)</span>是<span class="math inline">\(f\)</span>的固点，则：</p>
<p>1、如果<span class="math inline">\(|f&#39;(p)|&lt;1\)</span>，则<span class="math inline">\(p\)</span>是吸引固点Sink；</p>
<p>2、如果<span class="math inline">\(|f&#39;(p)|&gt;1\)</span>，则<span class="math inline">\(p\)</span>是排斥固点Source。</p>
<p><strong>证明</strong>： 假设<span class="math inline">\(\alpha\)</span>是介于<span class="math inline">\(|f&#39;(p)|\)</span>和1之间的任意实数，对于：</p>
<p><span class="math display">\[lim_{x-&gt;p}\frac{|f(x)-f(p)|}{|x-p|}=|f&#39;(p)|\]</span> 存在一个<span class="math inline">\(p\)</span>的邻域<span class="math inline">\(N_\epsilon(p),\epsilon&gt;0\)</span>，使得：</p>
<p><span class="math display">\[\frac{|f(x)-f(p)|}{|x-p|}&lt;a&lt;1,(x\in N_\epsilon(p),x\neq p)\]</span></p>
<p>换句话说，相比<span class="math inline">\(x\)</span>，<span class="math inline">\(f(x)\)</span>更接近<span class="math inline">\(p\)</span>，也说明，如果<span class="math inline">\(x\in N_\epsilon(p)\)</span>，则<span class="math inline">\(f(x)\in N_\epsilon(p)\)</span>，以此类推，<span class="math inline">\(f^2(x)\)</span>、<span class="math inline">\(f^3(x)\)</span>也满足此性质，归纳下变成： <span class="math display">\[|f^k(x)-p|\leq\alpha^k|x-p|,k\geq 1\]</span></p>
<p>所以<span class="math inline">\(p\)</span>是一个吸引固点Sink。</p>
<p>换一个角度，从一阶泰勒展开式或导数的定义来看：</p>
<p>在<span class="math inline">\(p\)</span>点的一阶泰勒展开式： <span class="math display">\[f(p+h)\approx f(p)+hf&#39;(p)\]</span></p>
<p>1、如果<span class="math inline">\(|f&#39;(p)|&lt;1\)</span>，则<span class="math inline">\(p\)</span>是吸引固点Sink；</p>
<p>2、如果<span class="math inline">\(|f&#39;(p)|&gt;1\)</span>，则<span class="math inline">\(p\)</span>是排斥固点Source。</p>
<p>5、<strong>k周期点</strong></p>
举一个例子：<span class="math inline">\(f(x)=3.3x(1-x)\)</span>，其图形如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ecm4fbi01ci51p1bgvj1opf1kag2a.png" width="450"  />
</center>
<p>利用<span class="math inline">\(y=x\)</span>直线发现动态系统的固点有<span class="math inline">\(x_0=0\)</span>和<span class="math inline">\(x_1=\frac{23}{33}\)</span>两个点，而这两个点都是排斥固点，那么吸引固点去哪儿了呢？做一个简单模拟：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">g &lt;- function(x)&#123;</span><br><span class="line">  return(3.3*x*(1-x))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gk &lt;- function(k, x)&#123;</span><br><span class="line">  for(i in 1:k)&#123;</span><br><span class="line">    x = g(x)</span><br><span class="line">    print(x)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">k=20</span><br><span class="line"></span><br><span class="line">for (i in 1:10)&#123;</span><br><span class="line">  x=runif(1)</span><br><span class="line">  gk(k, x)</span><br><span class="line">  print(&quot;=====&quot;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>部分结果如下：</p>
<table>
<thead>
<tr class="header">
<th>t</th>
<th style="text-align: right;">y(x=0.1156445)</th>
<th style="text-align: right;">y(x=0.3317354)</th>
<th style="text-align: right;">y(x=0.0.9131461)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: right;">0.3374938</td>
<td style="text-align: right;">0.7315672</td>
<td style="text-align: right;">0.2617241</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: right;">0.7378527</td>
<td style="text-align: right;">0.6480429</td>
<td style="text-align: right;">0.6376411</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: right;">0.6383061</td>
<td style="text-align: right;">0.7526749</td>
<td style="text-align: right;">0.7624812</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: right;">0.7618757</td>
<td style="text-align: right;">0.6143128</td>
<td style="text-align: right;">0.5976419</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: right;">0.5986897</td>
<td style="text-align: right;">0.7818775</td>
<td style="text-align: right;">0.793538</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: right;">0.7928592</td>
<td style="text-align: right;">0.5627987</td>
<td style="text-align: right;">0.540657</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: right;">0.5419706</td>
<td style="text-align: right;">0.8119858</td>
<td style="text-align: right;">0.8195451</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: right;">0.8191869</td>
<td style="text-align: right;">0.5037939</td>
<td style="text-align: right;">0.48804</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: right;">0.488795</td>
<td style="text-align: right;">0.8249525</td>
<td style="text-align: right;">0.824528</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: right;">0.8245857</td>
<td style="text-align: right;">0.4765394</td>
<td style="text-align: right;">0.4774493</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: right;">0.4773257</td>
<td style="text-align: right;">0.8231837</td>
<td style="text-align: right;">0.8233218</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: right;">0.8233034</td>
<td style="text-align: right;">0.4803226</td>
<td style="text-align: right;">0.4800279</td>
</tr>
<tr class="odd">
<td>13</td>
<td style="text-align: right;">0.4800672</td>
<td style="text-align: right;">0.8237222</td>
<td style="text-align: right;">0.8236837</td>
</tr>
<tr class="even">
<td>14</td>
<td style="text-align: right;">0.8236889</td>
<td style="text-align: right;">0.4791729</td>
<td style="text-align: right;">0.4792553</td>
</tr>
<tr class="odd">
<td>15</td>
<td style="text-align: right;">0.4792442</td>
<td style="text-align: right;">0.8235686</td>
<td style="text-align: right;">0.8235799</td>
</tr>
<tr class="even">
<td>16</td>
<td style="text-align: right;">0.8235784</td>
<td style="text-align: right;">0.4795012</td>
<td style="text-align: right;">0.479477</td>
</tr>
<tr class="odd">
<td>17</td>
<td style="text-align: right;">0.4794803</td>
<td style="text-align: right;">0.8236133</td>
<td style="text-align: right;">0.8236101</td>
</tr>
<tr class="even">
<td>18</td>
<td style="text-align: right;">0.8236105</td>
<td style="text-align: right;">0.4794056</td>
<td style="text-align: right;">0.4794125</td>
</tr>
<tr class="odd">
<td>19</td>
<td style="text-align: right;">0.4794116</td>
<td style="text-align: right;">0.8236004</td>
<td style="text-align: right;">0.8236013</td>
</tr>
<tr class="even">
<td>20</td>
<td style="text-align: right;">0.8236012</td>
<td style="text-align: right;">0.4794332</td>
<td style="text-align: right;">0.4794312</td>
</tr>
</tbody>
</table>
<p>一个有意思的现象出现，<span class="math inline">\(p_1=0.4694\)</span>和<span class="math inline">\(p_2=0.8236\)</span>交替出现且为吸引固点，换个角度就是：<span class="math inline">\(f(p_1)=p_2,f(p_2)=p_1;f^2(p_1)=p_1\)</span>,<span class="math inline">\(f^2(p_2)=p_2\)</span>，也就是吸引固点以2为周期出现，在两个点间循环往复。</p>
<p>形式化<strong>定义</strong>为：</p>
<p>假设动态系统有实数集上的映射<span class="math inline">\(f\)</span>，点<span class="math inline">\(p\)</span>为实数值，且满足<span class="math inline">\(f^k(p)=p\)</span>，<span class="math inline">\(k\)</span>为正整数，则<span class="math inline">\(p\)</span>被称为k周期点。</p>
<p>扩展下之前吸引固点的定义到k周期点：</p>
<p>如果<span class="math inline">\(f\)</span>是一个在实数集上的平滑映射，假设<span class="math inline">\(\{p_1,p_2,...p_k\}\)</span>构成了<span class="math inline">\(f\)</span>的<span class="math inline">\(k\)</span>周期点，则：</p>
<p>1、如果<span class="math inline">\(|f&#39;(p_k)...f&#39;(p_1)|&lt;1\)</span>，则<span class="math inline">\(\{p_1,p_2,...p_k\}\)</span>是吸引固点Sink；</p>
<p>2、如果<span class="math inline">\(|f&#39;(p_k)...f&#39;(p_1)|&gt;1\)</span>，则<span class="math inline">\(\{p_1,p_2,...p_k\}\)</span>是排斥固点Source。</p>
<p>还是上面的那个例子:</p>
<p><span class="math inline">\(f(x)=3.3x(1-x)\)</span></p>
<p>则有： <span class="math inline">\(f&#39;(x)=3.3-6.6x\)</span> k周期点为：<span class="math inline">\(\{0.4694,0.8236\}\)</span></p>
<p>因为<span class="math inline">\(|f&#39;(0.4694)f&#39;(0.8236)|=0.2904&lt;1\)</span>，所以它是吸引固点。</p>
<h3 id="二维映射">6.2.2 二维映射</h3>
<p>把一维映射扩展到多维映射，看看会出现什么有趣的现象，由于二维映射是多维映射的最简单形式且各种性质与多维映射一致，固以此为基础讨论。</p>
<p>1、<strong>邻域</strong></p>
<p>扩展一维映射时的邻域概念如下：</p>
<p>在欧式空间实数域下，向量<span class="math inline">\(v=(x_1,x_2,......x_m)\)</span>的范数定义为：</p>
<p><span class="math display">\[|v|=\sqrt{x_1^2+x_2^2+......+x_m^2}\]</span></p>
<p>对<span class="math inline">\(p=(p_1,p_2,......p_m)\)</span>定义它的邻域：</p>
<p><span class="math display">\[N_\epsilon(p)=\{v\in \mathbb{R}^m:|v-p|&lt;\epsilon\},0&lt;\epsilon&lt;&lt;1\]</span></p>
<p>有时候也叫<span class="math inline">\(p\)</span>的<span class="math inline">\(\epsilon\)</span>-<span class="math inline">\(disk\)</span>，举个例子。</p>
二维下(<span class="math inline">\(p=(1,1)\)</span>)：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2d" width="450"  />
</center>
三维下(<span class="math inline">\(p=(1,1,1)\)</span>)：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/3d" width="450"  />
</center>
<p>2、<strong>固点</strong></p>
<p>其次，假设动态系统有实数域<span class="math inline">\(\mathbb{R}^m\)</span>的映射<span class="math inline">\(f\)</span>，<span class="math inline">\(p\)</span>为实数域<span class="math inline">\(\mathbb{R}^m\)</span>固点，即满足<span class="math inline">\(f(p)=p\)</span>，如果存在<span class="math inline">\(p\)</span>的邻域<span class="math inline">\(N_\epsilon(p)\)</span>，使得所有邻域内<span class="math inline">\(v\)</span>会被吸引到<span class="math inline">\(p\)</span>，即： <span class="math display">\[lim_{k-&gt;\infty}f^k(v)=p,v\in N_\epsilon(p)\]</span></p>
<p>则<span class="math inline">\(p\)</span>被称作<strong>Sink</strong>，反之如果邻域内的点会被排斥远离点<span class="math inline">\(p\)</span>，则点<span class="math inline">\(p\)</span>被称作<strong>Source</strong>。</p>
在二维映射下还会出现一个一维映射时不会出现的固点，叫做鞍点(<strong>Saddle</strong>)，可以把它看做介于吸引固点和排斥固点间的一种状态，它拥有至少一个吸引方向和至少一个排斥方向。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ed8qo1fid0m1rmk1qupdb0s1311.png" width="600"  />
</center>
<p>图中<span class="math inline">\(f\)</span>代表映射，<span class="math inline">\(N\)</span>代表<span class="math inline">\(p\)</span>点的邻域。<span class="math inline">\(a\)</span>图代表<span class="math inline">\(p\)</span>是一个吸引固点，进入其邻域的点会被吸引到<span class="math inline">\(p\)</span>点、<span class="math inline">\(b\)</span>图代表<span class="math inline">\(p\)</span>是一个排斥固点，进入其邻域的点会被排斥而远离<span class="math inline">\(p\)</span>点、<span class="math inline">\(c\)</span>图代表<span class="math inline">\(p\)</span>是一个鞍点，进入其邻域的点先会被吸引到<span class="math inline">\(p\)</span>点，然后会被排斥而远离<span class="math inline">\(p\)</span>点。来个更直观的图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/saddle.gif" width="450"  />
</center>
<p>在《<a href="https://vivounicorn.github.io/page/2021/09/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E6%9C%80%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86/">最优化原理-梯度下降</a>》这一章我们曾经介绍过常用的一阶最优化方法，给定初始值后，不同的优化方法的优化轨迹不一样，但大的方向都是先被迭代吸引到鞍点，然后再从鞍点被排斥走，而因为待优化问题往往有很多局部最优点，所以我们希望优化算法能尽可能跳出当前点去寻找更优的局部最优点。</p>
<p>综上所述，显然排斥固点Source和鞍点Saddle的最大特点是：它们都是固点，都不是稳定固点，因为它们对初始条件很敏感，但对研究一个动态系统它们很重要。</p>
<h3 id="线性映射">6.2.3 线性映射</h3>
<p>1、<strong>线性映射</strong></p>
<p>所谓线性映射是指：</p>
<p>给定实数<span class="math inline">\(a,b\in \mathbb{R}\)</span>及实数向量<span class="math inline">\(v,w \in \mathbb{R}^m\)</span>，有<span class="math inline">\(\mathbb{R}^m\to \mathbb{R}^m\)</span>的映射<span class="math inline">\(A(v)\)</span>满足: <span class="math display">\[A(av+bw)=aA(v)+bA(w)\]</span> 显然原点(0,0)是所有线性映射的固点，且是稳定的，如果它邻域内的点在迭代映射时都趋向于接近固点，则该固点是一个<strong>吸引子</strong>，稍微正式点的定义如下：</p>
<p>在一个随时间演变的动态系统中，吸引子是一个代表某种稳定状态的数值集合，在给定动态系统初始状态后，系统有着朝该集合所表示的稳态演化的趋势，在吸引子的某个邻域(basin of attraction)范围内，即使系统受到扰动，也会趋向于该稳态。</p>
<p>后面会大量出现吸引子这个概念。</p>
<p>2、<strong>鞍点</strong></p>
<p>如果实数<span class="math inline">\(\lambda\)</span>和实数向量<span class="math inline">\(v\)</span>满足：</p>
<p><span class="math display">\[Av=\lambda v\]</span> 则它们分别被称为A的特征值和特征向量。</p>
<p>假设有以下向量关系：</p>
<p><span class="math display">\[v_{n+1}=Av_n\]</span></p>
<p>则有递推关系：</p>
<p><span class="math display">\[
\begin{align*}
&amp; v_1=Av_0=\lambda v_0 \\
&amp; v_2=Av_1=\lambda v_1=\lambda^2v_0 \\
&amp; ...... \\
&amp; v_{n+1}=\lambda^n v_0\\
\end{align*}
\]</span> 以<span class="math inline">\(\mathbb{R}^2\)</span>上的映射为例：</p>
<p><span class="math display">\[A(x,y)=(ax,by)\]</span></p>
<p>表示成矩阵形式： <span class="math display">\[
Av=
\left[
 \begin{matrix}
   a &amp; 0 \\
   0 &amp; b
  \end{matrix}
  \right]
  \left[
 \begin{matrix}
   x\\
   y
  \end{matrix}
  \right]
\]</span> 以上过程迭代了<span class="math inline">\(n\)</span>次后得到： <span class="math display">\[
A^n=
\left[
 \begin{matrix}
   a^n &amp; 0 \\
   0 &amp; b^n
  \end{matrix}
  \right]
\]</span></p>
<p>这里就有意思了，<span class="math inline">\(A\)</span>迭代了<span class="math inline">\(n\)</span>次后，把它映射在一个二维平面上，看上去应该是个椭圆形，其中横坐标长度为<span class="math inline">\(|a|^n\)</span>，纵坐标为<span class="math inline">\(|b|^n\)</span>，对于原点的某个邻域<span class="math inline">\(N_\epsilon(0,0)\)</span>同样也是个椭圆，横纵坐标长度分别为<span class="math inline">\(\epsilon|a|^n\)</span>和<span class="math inline">\(\epsilon|b|^n\)</span>，假设<span class="math inline">\(n\to \infty\)</span>，则会有三种情况：</p>
<p>1、如果<span class="math inline">\(|a|,|b|&lt;1\)</span>，则整个椭圆会收缩到原点(0,0)，原点是Sink；</p>
<p>2、如果<span class="math inline">\(|a|,|b|&gt;1\)</span>，则整个椭圆会无限过大并远离原点(0,0)，原点是Source；</p>
<p>3、如果<span class="math inline">\(|a|&gt;1&gt;|b|\)</span>，则整个椭圆的横坐标会无限扩大，而纵坐标会收缩到0，此时原点既不是Sink也不是Source，人们把它叫做Saddle(鞍点)。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1edj5o3bpprf1te3jlc6c5qmb2v.png" width="600"  />
</center>
<p>假设取：<span class="math inline">\(a=2,b=0.5\)</span>，则： <span class="math display">\[
A=
\left[
 \begin{matrix}
   2 &amp; 0 \\
   0 &amp; 0.5
  \end{matrix}
  \right]
\]</span> 经过<span class="math inline">\(n\)</span>次迭代后，得到下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1edj6hipk4o5138gi491htcbi93c.png" width="300"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1edj6hu8vaf019av52n1d70h263p.png" width="300"  />
</center>
<p>3、<strong>双曲(hyperbolic)</strong></p>
<p>假设A是实数域矩阵，基于它定义了<span class="math inline">\(\mathbb{R}^m\to \mathbb{R}^m\)</span>的线性映射<span class="math inline">\(A(v)\)</span>，则：</p>
<ul>
<li><p>如果<span class="math inline">\(A\)</span>的所有特征值的绝对值都小于1，则原点是一个吸引固点Sink;</p></li>
<li><p>如果<span class="math inline">\(A\)</span>的所有特征值的绝对值都大于1，则原点是一个排斥固点Source;</p></li>
<li><p>如果<span class="math inline">\(A\)</span>的所有特征值中至少有一个其绝对值大于1，且最少有一个其绝对值小于1，则原点是一个鞍点Saddle。</p></li>
</ul>
<p>如果一个映射<span class="math inline">\(A\)</span>，没有一个特征值的绝对值等于1，则我们把<span class="math inline">\(A\)</span>叫做是双曲的，显然有三类双曲映射：Sink、Source、Saddle。</p>
<h3 id="非线性映射">6.2.4 非线性映射</h3>
<p>真实世界中，非线性系统远远多于线性系统，而当非线性程度足够高时，系统将出现混沌状态，不过从概念和定义上与线性映射区别不大。前面说的吸引固点和k周期吸引固点都是运动状态可预测的，它们被叫做平庸吸引子，而运动状态不可预测的叫做奇异吸引子(Strange Attractor)。</p>
<p>同样利用泰勒展开式，在非线性高维空间，导数被扩展为雅克比矩阵(Jacobian matrix)：</p>
<p><span class="math display">\[f(p+h)\approx f(p)+Df(p)\cdot h\]</span> 其中：</p>
<p>1、<span class="math inline">\(f=(f_1,f_2,......f_m)\)</span>是<span class="math inline">\(\mathbb{R}^m\)</span>上的映射，<span class="math inline">\(p\in \mathbb{R}^m\)</span></p>
<p>2、雅可比矩阵<span class="math inline">\(Df(p)\)</span>为： <span class="math display">\[Df(p)=
\left[
 \begin{matrix}
   \frac{\partial f_1}{\partial x_1}(p) &amp; ...... &amp; \frac{\partial f_1}{\partial x_m}(p) \\
   \frac{\partial f_m}{\partial x_1}(p) &amp; ...... &amp; \frac{\partial f_ms}{\partial x_m}(p)
  \end{matrix}
  \right]\]</span></p>
<p>假设<span class="math inline">\(p\)</span>为固点，满足<span class="math inline">\(f(p)=p\)</span>，则： <span class="math display">\[f(p+h)\approx f(p)+Df(p)\cdot h=p+Df(p)\cdot h\]</span> 即，在<span class="math inline">\(p\)</span>点邻域内对其做一个微小扰动，输出会有<span class="math inline">\(Df(p)\cdot h\)</span>的变化，显然类似线性映射，可以有下面结论：</p>
<p>假设：<span class="math inline">\(f\)</span>是<span class="math inline">\(\mathbb{R}^m\)</span>上的映射，且<span class="math inline">\(p\in \mathbb{R}^m\)</span>，满足<span class="math inline">\(f(p)=p\)</span>，则：</p>
<p>1、如果<span class="math inline">\(Df(p)\)</span>没有取值为1的特征值，则<span class="math inline">\(p\)</span>被称作<strong>双曲(hyperbolic)</strong>的，这个词很重要，会在后面多次出现，直观的也挺好理解，1的多少次方都还是1，只有大于1或小于1才会在某个方向上要么吸引要么排斥；</p>
<p>2、如果<span class="math inline">\(Df(p)\)</span>的每个特征值的绝对值都小于1，那么<span class="math inline">\(p\)</span>是一个吸引固点Sink，也有人叫做<strong>双曲吸引子(hyperbolic attractor)</strong>；</p>
<p>3、如果<span class="math inline">\(Df(p)\)</span>的每个特征值的绝对值都大于1，那么<span class="math inline">\(p\)</span>是一个排斥固点Source；</p>
<p>4、如果<span class="math inline">\(m\geq 1\)</span>且<span class="math inline">\(p\)</span>是双曲的，<span class="math inline">\(Df(p)\)</span>至少有一个特征值的绝对值大于1且至少有一个特征值的绝对值小于1，则<span class="math inline">\(p\)</span>是一个鞍点Saddle。</p>
<p><strong>举个例子</strong>：</p>
<p>有非线性映射：</p>
<p><span class="math display">\[f_{a,b}(x,y)=(-x^2+0.4y,x)\]</span> 因为<span class="math inline">\(f(x,y)=(x,y)\)</span>，则有<span class="math inline">\(-x^2+0.4y=x\)</span>且<span class="math inline">\(x=y\)</span> 所以<span class="math inline">\(f\)</span>有两个固点：<span class="math inline">\((0,0),(-0.6,-0.6)\)</span></p>
<p>其雅克比矩阵为：</p>
<p><span class="math display">\[Df(x,y)=
\left[
 \begin{matrix}
   -2x &amp; 0.4 \\
   1 &amp; 0
  \end{matrix}
  \right]
\]</span></p>
<p>于是：</p>
<p><span class="math display">\[Df(0,0)=
\left[
 \begin{matrix}
   0 &amp; 0.4 \\
   1 &amp; 0
  \end{matrix}
  \right]
\]</span></p>
<p>特征值为：<span class="math inline">\(\pm\sqrt{4}\approx\pm0.632\)</span></p>
<p><span class="math display">\[Df(-0.6,-0.6)=
\left[
 \begin{matrix}
   1.2 &amp; 0.4 \\
   1 &amp; 0
  \end{matrix}
  \right]
\]</span></p>
<p>特征值为：<span class="math inline">\(1.472\)</span>和<span class="math inline">\(-0.272\)</span>，显然，<span class="math inline">\((0,0)\)</span>为双曲吸引子，<span class="math inline">\((-0.6,-0.6)\)</span>为鞍点。</p>
<h3 id="混沌的演化及结构">6.2.5 混沌的演化及结构</h3>
<p>用一个简单的抛物线做说明： <span class="math display">\[y=1-rx^2 :0\leq r\leq 1;-1\leq x_n\leq 1\]</span></p>
<p>将其转化为迭代形式（一般来说，越复杂的非线性方程越无解析解，常常用数值计算中的迭代方法得到解）：</p>
<p><span class="math display">\[x_{n+1}=1-rx_n^2\]</span></p>
<p>程序模拟迭代过程： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抛物线函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parabola</span>(<span class="params">r, x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - r * x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_bifu</span>(<span class="params">iterations, r, x0, last</span>):</span></span><br><span class="line">    ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">    x = x0</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        x = parabola(r, x)</span><br><span class="line">        <span class="keyword">if</span> i &gt;= (iterations - last):</span><br><span class="line">            ax.plot(r, x, <span class="string">&#x27;,k&#x27;</span>, alpha=<span class="number">.25</span>)</span><br><span class="line"></span><br><span class="line">    ax.set_xlim(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">    ax.set_title(<span class="string">&quot;Bifurcation: y=1-rx^2&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    n = <span class="number">10000</span></span><br><span class="line">    r = np.linspace(<span class="number">0</span>, <span class="number">2.0</span>, n)</span><br><span class="line">    iterations = <span class="number">1000</span> <span class="comment"># 迭代次数</span></span><br><span class="line">    last = <span class="number">200</span> <span class="comment"># 输出最后若干次迭代</span></span><br><span class="line">    x0 = <span class="number">0.1</span> * np.ones(n) <span class="comment"># 初始点</span></span><br><span class="line">    plot_bifu(iterations, r, x0, last)</span><br></pre></td></tr></table></figure></p>
其分叉图如下，结构上按照<span class="math inline">\(2^n\)</span>指数级周期性分裂，当<span class="math inline">\(r\approx 1.40\)</span>时，系统进入混沌状态：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eei0s9k6138i1ms215b1vut19lc9.png" width="600"  />
</center>
对下图红框部分放大看，可以发现一个有趣的东西:
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eei1f9j81t94tbv1g3g1dn0jsv19.png" width="600"  />
</center>
放大的部分其结构与开始时的整体结构相同，一般叫做分形，于是在混沌中再次出现周期性：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eei1hdcleacos17k51jt31td51m.png" width="600"  />
</center>
<p>随着复杂度的提升，系统经历了：稳定态-&gt;周期态-&gt;类周期态-&gt;混沌态。</p>
<p>还可以再次放大类似的红框区域，但会发现一个普适的规律：</p>
<p><span class="math display">\[\delta=\lim\limits_{n-&gt;\infty}\frac{r_n-r_{n-1}}{r_{n+1}-r_n}=4.669201609109...\]</span></p>
<p>其中<span class="math inline">\(r\)</span>是发生混沌现象时的分界点。上面这个常数叫做Feigenbaum常数，它可能是比圆周率更神秘的常数，我没有做更深入的了解，详情可参见论文《<a href="https://link.springer.com/article/10.1007/BF01020332">Quantitative universality for a class of nonlinear transformations</a>》，换句话说，混沌演化的过程中存在内部规律性，且这种演化过程存在某种“<strong>普适性</strong>”。</p>
<h3 id="rnn长依赖学习问题">6.2.6 RNN长依赖学习问题</h3>
<p>这一节主要基于对Yoshua Bengio《<a href="https://pdfs.semanticscholar.org/d0be/39ee052d246ae99c082a565aba25b811be2d.pdf?_ga=2.228408725.909305177.1596354587-48890951.1581915581">Learning Long-Term Dependencies with Gradient Descent is Difficult</a>》一文的学习，个人认为它是少有的对长依赖学习做出精彩理论研究和证明的文章。</p>
<p>文章从实验和理论角度证明了：梯度下降算法无法有效学习长依赖（模型在时间t的输出依赖更早时间<span class="math inline">\(t^{&#39;}\ll t\)</span>时的系统状态）。</p>
<p>一个能学习长依赖的动态系统，至少应该满足以下几个条件：</p>
<p>1、系统能够存储任意时长的信息； 2、系统鲁棒性强，即使对系统输入做随机波动也不影响系统做出正确输出； 3、系统参数可在合理有限的时间内学习到。</p>
<ul>
<li>单节点RNN实验</li>
</ul>
<p>设计一个满足以上条件的简单的序列二分类问题：</p>
给定任意序列：<span class="math inline">\(u_1,...,u_T\)</span>，二分类器<span class="math inline">\(C(u_1,...,u_T)\in \{0,1\}\)</span>，且分类结果只与序列的前<span class="math inline">\(L\)</span>（<span class="math inline">\(L\ll T\)</span>）个输入有关，即： <span class="math display">\[C(u_1,...,u_T)=C(u_1,...,u_L)\]</span> 显然，<span class="math inline">\(L\)</span>之后的信息都是噪声（文中实验采用高斯噪声），如果系统不能有效存储任意时长的信息则无法做正确分类。换句话说，分类器内置了一个latching subsystem（暂且翻译为锁存子系统），这个子系统可以提取分类的关键信息，并存储于子系统的状态变量中。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1een7h4n513ku1b6uq8e9sjk0h9.png" width="600"  />
</center>
<p>当<span class="math inline">\(t\leq L\)</span>时，<span class="math inline">\(h_t\)</span>为可学习调整的参数，当<span class="math inline">\(L&lt;t\leq T\)</span>时，<span class="math inline">\(h_t\)</span>为高斯噪声，损失函数为：</p>
<p><span class="math display">\[C=\frac{1}{2}\sum_{p}(x_T^p-d^p)^2\]</span> 其中<span class="math inline">\(p\)</span>是训练序列的索引，<span class="math inline">\(d^p\)</span>是目标输出，取值0.8代表分类1，取值-0.8代表分类0，$h_t (t = 1,. . . , L) <span class="math inline">\(代表抽取了分类关键信息后的计算结果，显然，直接学习\)</span>h_t$要比用原始输入学习 <span class="math inline">\(h_t(u_t,\theta)\)</span>来的容易，而且不管以上哪种方式，传播误差梯度<span class="math inline">\(\frac{\partial C}{\partial h_t}\)</span>的方法一样，如果因为梯度消失导致<span class="math inline">\(h_t\)</span>都学不出来，更别说<span class="math inline">\(h_t(u_t,\theta)\)</span>了。</p>
<p>以最简单的RNN为例：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eend2gj51ahg1c30e0id2113u9m.png" width="100"  />
</center>
<p><span class="math display">\[
\begin{align*}
&amp; y_t^k=f(x_t^k)=tanh(x_t^k) \\
&amp; x_t^k=wf(x_{t-1}^k)+h_t^k \quad t=1...T\\
&amp; x_0^0=x_0^1=1\\
&amp; k \in\{0,1\}\\
\end{align*}
\]</span></p>
如果<span class="math inline">\(w&gt;1\)</span>，则以上动态系统有两个双曲吸引子，即下图的<span class="math inline">\((\pm x^*,\pm y^*)\)</span>：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eengrro49501c9ur94d581t541g.png" width="600"  />
</center>
<p>依据《<a href="http://ai.dinfo.unifi.it/paolo/ps/tkde93.pdf">Unified integration of explicit rules and learning by example in recurrent networks</a>》的证明，假设初始状态是<span class="math inline">\((-x^*,-y^*)\)</span>，则存在<span class="math inline">\(h^*\)</span>使得：</p>
<p>1、如果<span class="math inline">\(|h_t|&lt;h^*\)</span>，<span class="math inline">\(\forall t\)</span>，<span class="math inline">\(y_t\)</span>的符号可以保持不变，即在负向<span class="math inline">\((-x^*,-y^*)\)</span>吸引子邻域的点会被吸引；</p>
<p>2、存在有限步数<span class="math inline">\(L_1\)</span>，如果<span class="math inline">\(h_t&gt;h^*\)</span>，<span class="math inline">\(\forall t \leq L_1\)</span>，使得<span class="math inline">\(y_{L1}&gt;y^*\)</span>，即超过<span class="math inline">\((-x^*,-y^*)\)</span>吸引子邻域的点会被吸引到正向吸引子<span class="math inline">\((x^*,y^*)\)</span>。</p>
<p>当<span class="math inline">\(w\)</span>取固定值时，<span class="math inline">\(L_1\)</span> 随着 <span class="math inline">\(|h_t|\)</span> 增加而减小。</p>
<p>总结如下：</p>
<p>1、上述简单的系统可以锁存1 bit信息（即输出的符号变化与否）；</p>
<p>2、系统通过对一个大的输入保持足够长的时间来存储信息（<span class="math inline">\(|h_t|&gt;h^*\)</span>）；</p>
<p>3、对输入做微小的噪声扰动，即使时间很长也不会改变激活函数输出的符号；</p>
<p>4、<span class="math inline">\(w\)</span>也是可学习的，当<span class="math inline">\(T\gg L\)</span>时，要求<span class="math inline">\(w&gt;1\)</span>，此时会生成正负向两个吸引子，且<span class="math inline">\(w\)</span>越大，相应的阈值<span class="math inline">\(h^*\)</span>越大，因此系统鲁棒性越强。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eeniuive1ehfgojdr31s7t4302d.png" width="450"  />
</center>
上图加粗的点展示了系统成功学出来的3个<span class="math inline">\(h_t\)</span>（<span class="math inline">\(h_1,...,h_L\)</span>）。 5、实验结果： 1)、下图a，取<span class="math inline">\(L=3\)</span>，<span class="math inline">\(T=20\)</span>做实验，发现随着高斯噪声的标准差增大，<span class="math inline">\(w_0\)</span>变小，系统收敛性越来越差。 2)、下图b，取高斯噪声<span class="math inline">\(s=0.2\)</span>，<span class="math inline">\(w_0=1.25\)</span>做实验，发现随着<span class="math inline">\(T\)</span> 的增加，系统收敛性越来越差，即在这么简单的系统中，梯度下降算法想长时间稳定的存储1 bit信息都很困难。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eenjfahi1kov1bf4igd13rd10pk37.png" width="600"  />
</center>
<ul>
<li>混沌理论角度的解释</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ef3r2gohi481di0af21v9vn859.png" width="450"  />
</center>
<p>回忆前几节关于映射及吸引子、双曲吸引子的说明，围绕着吸引子(attractor)有几个相关定义：</p>
<p>1、basin of attractor：其实就是吸引子的邻域：</p>
<p><span class="math display">\[\beta(X)=\{p\in \mathbb{R}^m :\forall \epsilon,\exists x \in X s.t.||f(p)-x||&lt;\epsilon \}\]</span></p>
<p>2、reduced attractor set：其实就是被<strong>双曲吸引子</strong>强吸引的点集合：</p>
<p><span class="math display">\[\Gamma(X)=\{p\in \mathbb{R}^m :f&#39;(p)的所有特征值都小于1\}\]</span> 直观展示它们的关系如上图,显然：</p>
<p><span class="math display">\[X \subset \Gamma(X) \subset \beta(X) \]</span> 如果任意时刻对一个锁存子系统的输入做微小扰动后都落在该系统双曲吸引子的reduced attractor set中，即图中<span class="math inline">\(\Gamma(X)\)</span>，则该锁存系统具有鲁棒性。</p>
<p>3、对于双曲吸引子<span class="math inline">\(X\)</span>邻域内的点<span class="math inline">\(a\)</span>，如果在<span class="math inline">\(\beta(X)\)</span>但不在<span class="math inline">\(\Gamma(X)\)</span>中，则不确定性会随着<span class="math inline">\(t\)</span>的增加而呈指数增加，最终微小的扰动会让<span class="math inline">\(a\)</span>远离<span class="math inline">\(x\)</span>而进入其他吸引子的邻域，如下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ef93p7r11rsmv6aop414ud1aqs19.png" width="500"  />
</center>
<p>证明：</p>
<p>假设<span class="math inline">\(\exists u\)</span>，满足<span class="math inline">\(\left\|u\right\|=1\)</span>及<span class="math inline">\(\left\|f&#39;(x)u\right\|&gt;1\)</span>，则根据泰勒展开式，对一个很小的值<span class="math inline">\(\lambda\)</span>有：</p>
<p><span class="math display">\[f(x+\lambda u)=f(x)+f&#39;(x)\lambda u+O(\left\|\lambda u\right\|^2)\]</span></p>
<p>对一个开放集合<span class="math inline">\(U(x)\)</span>，存在一个很小的值<span class="math inline">\(\lambda\)</span>，使得<span class="math inline">\(x+\lambda u \in U(x)\)</span>，且<span class="math inline">\(O(\left\|\lambda u\right\|^2)&lt;\lambda\left\|f&#39;(x)u\right\|-\lambda\)</span>。另<span class="math inline">\(y=x+\lambda u\)</span>，则根据三角不等式有：</p>
<p><span class="math display">\[\left\|-f&#39;(x)\lambda u\right\|-\left\|f(y)-f(x)\right\|&lt;\left\|-f&#39;(x)\lambda u+f(y)-f(x)\right\|\]</span></p>
<p>而：</p>
<p><span class="math display">\[\left\|-f&#39;(x)\lambda u+f(y)-f(x)\right\|=\left\|O(\left\|\lambda u\right\|^2)\right\|&lt;\lambda\left\|f&#39;(x)u\right\|-\lambda\]</span></p>
<p>所以有：</p>
<p><span class="math display">\[\lambda \left\|f&#39;(x)u\right\|-\left\|f(y)-f(x)\right\|&lt;\lambda\left\|f&#39;(x)u\right\|-\lambda\]</span></p>
<p>从而得到：</p>
<p><span class="math display">\[\left\|f(y)-f(x)\right\|&gt;\lambda=\left\|y-x\right\|\]</span></p>
<p>即：对<span class="math inline">\(x\)</span>的微小扰动会使得<span class="math inline">\(f(x)\)</span>的变化“幅度”增大。</p>
<p>4、一个具有鲁棒性的锁存子系统特点是：即使对系统输入有微小扰动，只要每次迭代时<span class="math inline">\(a_t\)</span>都在双曲吸引子<span class="math inline">\(X\)</span>的<span class="math inline">\(\Gamma(X)\)</span>内，则最终会被吸引收敛到双曲吸引子<span class="math inline">\(X\)</span>附近。如下图：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1ef97as8ol8kr301q571g01l012c.png" width="500"  />
</center>
<p>5、动态系统要想做到鲁棒性的锁存信息，则会出现梯度消失现象(gradient vanishing)，鱼与熊掌不可兼得。 一个通用的动态系统可以表示为：</p>
<p><span class="math display">\[a_{t}=f(a_{t-1})+x_t,\{a,x\}\in \mathbb{R}^m\]</span></p>
<p>其中<span class="math inline">\(a_t\)</span>和<span class="math inline">\(x_t\)</span>分别是<span class="math inline">\(t\)</span>时刻系统状态向量和<span class="math inline">\(t\)</span>时刻外部输入向量，根据导数的定义和双曲吸引子的性质有：</p>
<p><span class="math display">\[|\frac{\partial a_t}{\partial_{a_{t-1}}}|=|f&#39;(a_{t-1})|&lt;1\]</span></p>
<p>显然，当<span class="math inline">\(t\rightarrow \infty\)</span>时，<span class="math inline">\(\frac{\partial a_t}{\partial_{a_{0}}}\rightarrow 0\)</span>，梯度消失！</p>
<h2 id="lstm">6.3 LSTM</h2>
<p>上面两节从原理角度说明了RNN为什么很难学到长依赖，而本节的LSTM是一个伟大的和具有里程碑的模型，最著名的论文是Sepp Hochreiter 与 Jurgen Schmidhuber的《<a href="https://www.bioinf.jku.at/publications/older/2604.pdf">Long Short-Term Memory</a> 》（没错，就是那位怼天怼地怼各种权威的Schmidhuber），从原理上分析解决了RNN学习长依赖中的梯度爆炸(blow up)和梯度消失(vanish)问题，大部分文章只介绍了LSTM的结构，我希望通过本文能抛砖引玉，了解作者为什么这么设计结构。</p>
<h3 id="基本原理-1">6.3.1 基本原理</h3>
<p>回忆6.1节末的RNN任意两层隐藏层</p>
<p><span class="math display">\[
\delta_{pj}(t-1)=\sum_h^m\delta_{ph}(t)u_{hj}f^{&#39;}(s_{pj}(t-1))
\]</span></p>
<p>其中：<span class="math inline">\(h\)</span>是在<span class="math inline">\(t\)</span>时刻的任何一个隐层节点，<span class="math inline">\(j\)</span>是在<span class="math inline">\(t-1\)</span>时刻的任何一个隐层节点，高层的<span class="math inline">\(\delta\)</span>可以通过循环递归的计算出来，所有<span class="math inline">\(\delta\)</span>计算完毕后累加求和并应用在<span class="math inline">\(U\)</span>、<span class="math inline">\(V\)</span>的权重更新中。</p>
<p>误差从<span class="math inline">\(t\)</span>时刻的隐藏层<span class="math inline">\(h\)</span>节点经过任意<span class="math inline">\(q\)</span>步往<span class="math inline">\(t-q\)</span>时刻的隐藏层<span class="math inline">\(j\)</span>节点做反向传播的传播速度如下：</p>
<p><span class="math display">\[
\frac{\partial{\delta_{pj}(t-q)}}{\partial{\delta_{ph}(t)}}=\left\{
    \begin{array}{**lr**}
    f^{&#39;}(s_{pj}(t-1))u_{hj} &amp; q=1 \\
    f^{&#39;}(s_{pj}(t-1)) \sum_{i=1}^m \frac{\partial{\delta_{pi}(t-q+1)}}{\partial{\delta_{ph}(t)}}u_{hj}  &amp; q&gt;1
\end{array}
\right.
\]</span></p>
<p>把上面式子完全展开后得到：</p>
<p><span class="math display">\[
\frac{\partial{\delta_{pj}(t-q)}}{\partial{\delta_{ph}(t)}}=\sum_{i_1=1}^m...\sum_{i_{q-1}=1}^m\prod_{m=1}^qf^{&#39;}(s_{i_m}(t-m))u_{i_mi_{m-1}}
\]</span></p>
<p>大家会发现整个误差反向传播速度是由$<em>{m=1}<sup>qf</sup>{'}(s</em>{i_m}(t-m))u_{i_mi_{m-1}} $决定的：</p>
<p>1、如果<span class="math inline">\(|f^{&#39;}(s_{i_m}(t-m))u_{i_mi_{m-1}}|&gt;1\)</span>，则连乘的结果会随着<span class="math inline">\(q\)</span>的增加呈指数形式增大，误差反向传播出现梯度爆炸；</p>
<p>2、如果<span class="math inline">\(|f^{&#39;}(s_{i_m}(t-m))u_{i_mi_{m-1}}|&lt;1\)</span>，则连乘的结果会随着<span class="math inline">\(q\)</span>的增加呈指数形式减小，误差反向传播出现梯度消失。</p>
假设以最简单的RNN为例，即：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1eend2gj51ahg1c30e0id2113u9m.png" width="100"  />
</center>
<p>在<span class="math inline">\(t\)</span>时刻的反向误差传播为：</p>
<p><span class="math display">\[\delta_{h}(t)=\delta_{h}(t+1)u_{hh}f^{&#39;}(s_{h}(t))\]</span> 其中：<span class="math inline">\(s_{h}(t)=f(net_h(t))\)</span>。要想不出现梯度爆炸或消失，只能满足：</p>
<p><span class="math display">\[u_{hh}f^{&#39;}(s_{h}(t))=1\]</span></p>
<p>对上式积分下，得到：</p>
<p><span class="math display">\[f(s_{h}(t))=\frac{s_h(t)}{u_{hh}}\]</span></p>
<p>这意味着，函数<span class="math inline">\(f\)</span>必须是线性的，显然，当<span class="math inline">\(u_{hh}=1\)</span>时，有恒等映射函数<span class="math inline">\(f(x)=x\)</span>，上述关系也叫constant error carrousel(CEC)，CEC在LSTM的结构设计中举足轻重。</p>
以输入权重为例，由于实际场景中除了自连接节点外，还会有其他输入节点，为简单起见，我们只关注一个额外的输入权重<span class="math inline">\(w_{ji}\)</span> 。假设通过响应某个输入而开启神经网络单元<span class="math inline">\(j\)</span>，并为了减少总误差，希望它能被长时间激活。显然，对同一个输入权重一方面要存储某些输入范式，一方面又要忽略其他输入范式，而涉及<span class="math inline">\(j\)</span>节点的函数(上面的CEC)又是线性的，所以对<span class="math inline">\(w_{ji}\)</span>而言，这些信号会试图让它既得通过开启<span class="math inline">\(j\)</span>单元对输入做存储又需要防止<span class="math inline">\(j\)</span>单元被其他输入关闭，这种情况使得学习变得困难。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/lstm-focus%5B0%5D.png" width="450"  />
</center>
<p>对于输出权重，也存在类似的输出冲突，这里就不在赘述。 为了解决上面的输入和输出冲突，LSTM抽象了1个记忆单元（Memory Cel l）、设计了1个基础结构——遗忘门（Forget Gate）和2个组合结构——输入门（Input Gate）和输出门（Output Gate）来解决冲突。</p>
<p>0、记忆单元是对包含CEC线性单元的抽象，如下图（以RNN作为对比），包含当前时刻输入、上个隐层节点的状态、当前时刻输出、当前时刻隐层节点状态。：</p>
<center>
RNN <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/LSTM3-SimpleRNN%5B0%5D..png" width="500"  />
</center>
<center>
LSTM <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/LSTM3-chain%5B0%5D..png" width="500"  />
</center>
1、遗忘门的结构如下图：它将上一个隐层的状态<span class="math inline">\(h_{t-1}\)</span>和当前输入<span class="math inline">\(x_t\)</span>合并后送入logistic函数<span class="math inline">\(f(x)=\frac{1}{1+e^{-w^Tx}}\)</span>，由于该函数输出为0~1之间，输出接近1的被保留，接近0的被丢掉，也就是说，<strong>遗忘门决定了哪些历史信息要被保留</strong>。
<center>
Forget Gate <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/forget-gate.png" width="450"  />
</center>
<p>2、输入门的结构如下图：它将上一个隐层的状态<span class="math inline">\(h_{t-1}\)</span>和当前输入<span class="math inline">\(x_t\)</span>合并后送入Logistic函数，输出介于0～1之间，同样的，0表示信息不重要，1表示信息重要；同时，<span class="math inline">\(h_{t-1}\)</span>和<span class="math inline">\(x_t\)</span>合并后的输入被送入Tanh函数，输出介于-1～1之间，Logistic的输出与Tanh的输出相乘后决定哪些Tanh的输出信息需要保留，哪些要丢掉，也就是说，<strong>输入门决定了哪些新的信息要被加进来</strong>。</p>
<center>
Input Gate <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/input-gate.png" width="450"  />
</center>
前一个记忆单元的输出与遗忘门输出相乘后，可以选择性忘记不重要的信息，之后与输入门的结果相加，把新的输入信息纳入进来，最终得到当前记忆单元的输出，比较好解决了输入冲突，如下图：
<center>
Cell Output <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/output.png" width="450"  />
</center>
<p>3、输出门的结构如下图：它主要解决<strong>隐藏层</strong>状态的输出冲突问题，它将上一个隐层的状态<span class="math inline">\(h_{t-1}\)</span>和当前输入<span class="math inline">\(x_t\)</span>合并后送入Logistic函数，输出介于0～1之间，然后与当前记忆单元的输出通过Tanh函数变换后的结果相乘，得到当前隐藏层的状态，也就是说，<strong>输出门决定了当前隐藏层要携带哪些历史信息</strong>，比较好解决了输出冲突。</p>
<center>
Output Gate <img data-src="https://vivounicorn.github.io/images/ai_chapter_6/output-gate.png" width="450"  />
</center>
<p>以上图片来源于：《<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>》一文，非常不错的一篇LSTM入门文章。后续也有各种各样对经典LSTM的改进（如GRU），但整体上不如LSTM经典（截止2020.10.10在Google Scholar上查寻到该论文已经被引用了37851次，成为20世纪“最火论文”）。</p>
<p>除了比较完美解决了输入输出冲突外，LSTM的计算和存储复杂度并不高，权重更新计算的复杂度为O(W)，即与权重总个数线性相关；存储方面也不像使用全流程BPTT的传统方法，要存储大量历史节点信息，LSTM只需要存储一定历史时间步的局部信息。</p>
<h3 id="代码实践-1">6.3.2 代码实践</h3>
<p>本节以经典的《古诗词生成》为例子，介绍下LSTM的一种应用，以下例子只供娱乐使用。</p>
<p>问题描述如下：</p>
<p>“给定五言绝句的首句，生成整首共4句的五言绝句。”</p>
<p>例如，输入：“月暗竹亭幽，”，输出“月暗竹亭幽，碧昏时尽黄。园春歌雪光，云落分白草。”。</p>
<p><strong>完整代码在：https://github.com/vivounicorn/LstmApp.git</strong>，其中，data文件夹里包含了训练好的word2vec模型和迭代了2k+次的模型，可以直接做fine-tune。</p>
<p><strong>1、算法步骤</strong></p>
<p>Step-1：爬取古诗词作为原始数据；</p>
<p>Step-2：清洗原始数据，去掉不符合五言绝句的诗词；</p>
<p>Step-3：准备训练数据和相应的标注；</p>
<p>Step-4：若使用word2vec生成的词向量，则需要生成相关模型；</p>
<p>Step-5：构建以LSTM层和全连接层为主的神经网络；</p>
<p>Step-6：训练和验证模型，并做应用。</p>
<p><strong>2、实现详情</strong></p>
<ul>
<li><p><strong>Step-1，爬取古诗词作为原始数据</strong></p>
<p>用开源工具爬取：https://www.gushiwen.org/上的诗句。解析结果的基本格式为：“诗词标题：诗词内容”。</p></li>
<li><strong>Step-2，数据清洗</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_build_base</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                file_path,</span></span></span><br><span class="line"><span class="params"><span class="function">                vocab=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                word2idx=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                idx2word=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    To scan the file and build vocabulary and so on.</span></span><br><span class="line"><span class="string">    :param file_path: the file path of poetic corpus, one poem per line.</span></span><br><span class="line"><span class="string">    :param vocab: the vocabulary.</span></span><br><span class="line"><span class="string">    :param word2idx: the mapping of word to index.</span></span><br><span class="line"><span class="string">    :param idx2word: the mapping of index to word</span></span><br><span class="line"><span class="string">    :return: None.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 去掉无关字符</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">u&quot;_|\(|（|《&quot;</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                line = line.strip(<span class="string">u&#x27;\n&#x27;</span>)</span><br><span class="line">                title, content = line.strip(SPACE).split(<span class="string">u&#x27;:&#x27;</span>)</span><br><span class="line">                content = content.replace(SPACE, <span class="string">u&#x27;&#x27;</span>)</span><br><span class="line">                idx = re.search(pattern, content)</span><br><span class="line">                <span class="keyword">if</span> idx <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    content = content[:idx.span()[<span class="number">0</span>]]</span><br><span class="line">                <span class="comment"># 把指定长度的诗词选出来，如：五言绝句。</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(content) &lt; self.embedding_input_length:  <span class="comment"># Filter data according to embedding input</span></span><br><span class="line">                    <span class="comment"># length to improve accuracy.</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                words = []</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(content)):</span><br><span class="line">                    word = content[i:i + <span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">if</span> (i + <span class="number">1</span>) % self.embedding_input_length == <span class="number">0</span> <span class="keyword">and</span> word <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;，&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;。&#x27;</span>]:</span><br><span class="line">                        words = []</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">                    words.append(word)</span><br><span class="line">                    self.all_words.append(word)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(words) &gt; <span class="number">0</span>:</span><br><span class="line">                    self.poetrys.append(words)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                log.error(<span class="built_in">str</span>(e))</span><br><span class="line">    <span class="comment"># 生成词汇表，保留出现频次top n的字</span></span><br><span class="line">    <span class="keyword">if</span> vocab <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        top_n = Counter(self.all_words).most_common(self.vocab_size - <span class="number">1</span>)</span><br><span class="line">        top_n.append(SPACE)</span><br><span class="line">        self.vocab = <span class="built_in">sorted</span>(<span class="built_in">set</span>([i[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> top_n]))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        top_n = <span class="built_in">list</span>(vocab)[:self.vocab_size - <span class="number">1</span>]</span><br><span class="line">        top_n.append(SPACE)</span><br><span class="line">        self.vocab = <span class="built_in">sorted</span>(<span class="built_in">set</span>([i <span class="keyword">for</span> i <span class="keyword">in</span> top_n]))  <span class="comment"># cut vocab with threshold.</span></span><br><span class="line"></span><br><span class="line">    log.debug(self.vocab)</span><br><span class="line">    <span class="comment"># 生成“字”到“编号”的映射，把每个字做了唯一编号，“空格”也做编号</span></span><br><span class="line">    <span class="keyword">if</span> word2idx <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        self.word2idx = <span class="built_in">dict</span>((c, i) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.vocab))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.word2idx = word2idx</span><br><span class="line">    <span class="comment"># 生成“编号”到“字”的映射</span></span><br><span class="line">    <span class="keyword">if</span> idx2word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        self.idx2word = <span class="built_in">dict</span>((i, c) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.vocab))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.idx2word = idx2word</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Function of mapping word to index.</span></span><br><span class="line">    <span class="comment"># 以 “字” 查找 “编号”的函数，没在词汇表的“字”用“空格”的编号代替</span></span><br><span class="line">    self.w2i = <span class="keyword">lambda</span> word: self.word2idx.get(<span class="built_in">str</span>(word)) <span class="keyword">if</span> self.word2idx.get(word) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">else</span> self.word2idx.get(SPACE)</span><br><span class="line">    <span class="comment"># Function of mapping index to word.</span></span><br><span class="line">    <span class="comment"># 以 “编号”查找 “字” 的函数，找不到的“字”用“空格”代替</span></span><br><span class="line">    self.i2w = <span class="keyword">lambda</span> idx: self.idx2word.get(<span class="built_in">int</span>(idx)) <span class="keyword">if</span> self.idx2word.get(<span class="built_in">int</span>(idx)) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">else</span> SPACE</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Full vectors.</span></span><br><span class="line">    <span class="comment"># 把文本表示的诗词变成由“编号”表示的向量，如：“床前明月光，”变成[1,2,3,4,5,6]</span></span><br><span class="line">    self.poetrys_vector = [<span class="built_in">list</span>(<span class="built_in">map</span>(self.w2i, poetry)) <span class="keyword">for</span> poetry <span class="keyword">in</span> self.poetrys]</span><br><span class="line">    self._data_size = <span class="built_in">len</span>(self.poetrys_vector)</span><br><span class="line">    self._data_index = np.arange(self._data_size)</span><br></pre></td></tr></table></figure></li>
<li><p><strong>Step-3：准备训练数据</strong></p>
<p>原理是：根据指定的输入长度(input length)截取序列并生成特征数据，指定这个序列的下一个字为“标注”。</p>
<p>例如：“菩提本无树，明镜亦非台。”，以五言绝句为例，输入长度为6（包括标点符号），可以生成以下样本：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">特征</th>
<th style="text-align: center;">标注</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">菩提本无树，</td>
<td style="text-align: center;">明</td>
</tr>
<tr class="even">
<td style="text-align: center;">提本无树，明</td>
<td style="text-align: center;">镜</td>
</tr>
<tr class="odd">
<td style="text-align: center;">本无树，明镜</td>
<td style="text-align: center;">亦</td>
</tr>
<tr class="even">
<td style="text-align: center;">无树，明镜亦</td>
<td style="text-align: center;">非</td>
</tr>
<tr class="odd">
<td style="text-align: center;">树，明镜亦非</td>
<td style="text-align: center;">台</td>
</tr>
<tr class="even">
<td style="text-align: center;">，明镜亦非台</td>
<td style="text-align: center;">。</td>
</tr>
</tbody>
</table>
<p>对每个字，支持两种编码方式：基于词汇表的one hot和基于语义distributed representation的word2vec。</p>
<p><strong>1、One-hot</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_one_hot_encoding</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    One-hot encoding for a sample, a sample will be split into multiple samples.</span></span><br><span class="line"><span class="string">    :param sample: a sample. [1257, 6219, 3946]</span></span><br><span class="line"><span class="string">    :return: feature and label. feature:[[0,0,0,1,0,0,......],</span></span><br><span class="line"><span class="string">                                        [0,0,0,0,0,1,......],</span></span><br><span class="line"><span class="string">                                        [1,0,0,0,0,0,......]];</span></span><br><span class="line"><span class="string">                                label:  [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0......]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(sample) != <span class="built_in">list</span> <span class="keyword">or</span> <span class="number">0</span> == <span class="built_in">len</span>(sample):</span><br><span class="line">        log.error(<span class="string">&quot;type or length of sample is invalid.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    feature_samples = []</span><br><span class="line">    label_samples = []</span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    <span class="comment"># embedding_input_length即为输入窗口长度，五言绝句为6，当然也可以取其他值，但会影响训练精度和时间。</span></span><br><span class="line">    <span class="keyword">while</span> idx &lt; <span class="built_in">len</span>(sample) - self.embedding_input_length:</span><br><span class="line">        feature = sample[idx: idx + self.embedding_input_length]</span><br><span class="line">        label = sample[idx + self.embedding_input_length]</span><br><span class="line"></span><br><span class="line">        label_vector = np.zeros(</span><br><span class="line">            shape=(<span class="number">1</span>, self.vocab_size),</span><br><span class="line">            dtype=np.<span class="built_in">float</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 序列的下一个字为标注</span></span><br><span class="line">        label_vector[<span class="number">0</span>, label] = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">        feature_vector = np.zeros(</span><br><span class="line">            shape=(<span class="number">1</span>, self.embedding_input_length, self.vocab_size),</span><br><span class="line">            dtype=np.<span class="built_in">float</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 根据词汇表，相应的编号赋值为1，其余都是0.</span></span><br><span class="line">        <span class="keyword">for</span> i, f <span class="keyword">in</span> <span class="built_in">enumerate</span>(feature):</span><br><span class="line">            feature_vector[<span class="number">0</span>, i, f] = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">        feature_samples.append(feature_vector)</span><br><span class="line">        label_samples.append(label_vector)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feature_samples, label_samples</span><br></pre></td></tr></table></figure> 假设输入长度为6，词汇表维度为8000，则，对于一个样本有：</p>
特征矩阵为：1×6<em>8000 标注向量为：1</em>8000
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1emdpl8qlgg6q6l18gt1udq177i9.png" width="600"  />
</center>
<p><strong>2、Word2vec</strong></p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_word2vec_encoding</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    word2vec encoding for sample, a sample will be split into multiple samples.</span></span><br><span class="line"><span class="string">    :param sample: a sample. [1257, 6219, 3946]</span></span><br><span class="line"><span class="string">    :return: feature and label.feature:[[0.01,0.23,0.05,0.1,0.33,0.25,......],</span></span><br><span class="line"><span class="string">                                        [0.23,0.45,0.66,0.32,0.11,1.03,......],</span></span><br><span class="line"><span class="string">                                        [1.22,0.99,0.68,0.7,0.8,0.001,......]];</span></span><br><span class="line"><span class="string">                                label:  [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0......]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">type</span>(sample) != <span class="built_in">list</span> <span class="keyword">or</span> <span class="number">0</span> == <span class="built_in">len</span>(sample):</span><br><span class="line">        log.error(<span class="string">&quot;type or length of sample is invalid.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    feature_samples = []</span><br><span class="line">    label_samples = []</span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> idx &lt; <span class="built_in">len</span>(sample) - self.embedding_input_length:</span><br><span class="line">        feature = sample[idx: idx + self.embedding_input_length]</span><br><span class="line">        label = sample[idx + self.embedding_input_length]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.w2v_model <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            log.error(<span class="string">&quot;word2vec model is none.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        label_vector = np.zeros(</span><br><span class="line">            shape=(<span class="number">1</span>, self.vocab_size),</span><br><span class="line">            dtype=np.<span class="built_in">float</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 序列的下一个字为标注</span></span><br><span class="line">        label_vector[<span class="number">0</span>, label] = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">        feature_vector = np.zeros(</span><br><span class="line">            shape=(<span class="number">1</span>, self.embedding_input_length, self.w2v_model.size),</span><br><span class="line">            dtype=np.<span class="built_in">float</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用训练好的word2vec模型获取相应“字”的语义向量</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.embedding_input_length):</span><br><span class="line">            feature_vector[<span class="number">0</span>, i] = self.w2v_model.get_vector(feature[i])</span><br><span class="line"></span><br><span class="line">        idx += <span class="number">1</span></span><br><span class="line">        feature_samples.append(feature_vector)</span><br><span class="line">        label_samples.append(label_vector)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feature_samples, label_samples</span><br></pre></td></tr></table></figure> 假设输入长度为6，词的语义向量维度为200，则，对于一个样本有：</p>
特征矩阵为：1×6<em>200 标注向量为：1</em>8000
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1emdqc2sgvspaoa18uk1bqs1t87m.png" width="600"  />
</center></li>
<li><p><strong>Step-4：基于word2vec训练词向量</strong></p>
<p>使用dump函数将训练数据相关数据结构dump下来，其中poetrys_words.dat文件可直接作为word2vec的训练数据（注：要训练的是<strong>字粒度</strong>的语义向量），文件内容类似这样，一行一首诗，字与字空格分割：</p>
<p>寒 随 穷 律 变 ， 春 逐 鸟 声 开 。 初 风 飘 带 柳 ， 晚 雪 间 花 梅 。 碧 林 青 旧 竹 ， 绿 沼 翠 新 苔 。 芝 田 初 雁 去 ， 绮 树 巧 莺 来 。 晚 霞 聊 自 怡 ， 初 晴 弥 可 喜 。 日 晃 百 花 色 ， 风 动 千 林 翠 。 池 鱼 跃 不 同 ， 园 鸟 声 还 异 。 寄 言 博 通 者 ， 知 予 物 外 志 。</p>
<p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dump_data</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    To dump: poetry&#x27;s words list, poetry&#x27;s words vectors, poetry&#x27;s words vectors for training,</span></span><br><span class="line"><span class="string">             poetry&#x27;s words vectors for testing, poetry&#x27;s words vectors for validation,</span></span><br><span class="line"><span class="string">             poetry&#x27;s words vocabulary, poetry&#x27;s word to index mapping,poetry&#x27;s index to word mapping.</span></span><br><span class="line"><span class="string">    :return: None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    org_filename = self.dump_dir + <span class="string">&#x27;poetrys_words.dat&#x27;</span></span><br><span class="line">    self._dump_list(org_filename, self.poetrys)</span><br><span class="line"></span><br><span class="line">    vec_filename = self.dump_dir + <span class="string">&#x27;poetrys_words_vector.dat&#x27;</span></span><br><span class="line">    self._dump_list(vec_filename, self.poetrys_vector)</span><br><span class="line"></span><br><span class="line">    train_vec_filename = self.dump_dir + <span class="string">&#x27;poetrys_words_train_vector.dat&#x27;</span></span><br><span class="line">    self._dump_list(train_vec_filename, self.poetrys_vector_train)</span><br><span class="line"></span><br><span class="line">    valid_vec_filename = self.dump_dir + <span class="string">&#x27;poetrys_words_valid_vector.dat&#x27;</span></span><br><span class="line">    self._dump_list(valid_vec_filename, self.poetrys_vector_valid)</span><br><span class="line"></span><br><span class="line">    test_vec_filename = self.dump_dir + <span class="string">&#x27;poetrys_words_test_vector.dat&#x27;</span></span><br><span class="line">    self._dump_list(test_vec_filename, self.poetrys_vector_test)</span><br><span class="line"></span><br><span class="line">    vocab_filename = self.dump_dir + <span class="string">&#x27;poetrys_vocab.dat&#x27;</span></span><br><span class="line">    self._dump_list(vocab_filename, <span class="built_in">list</span>(self.vocab))</span><br><span class="line"></span><br><span class="line">    w2i_filename = self.dump_dir + <span class="string">&#x27;poetrys_word2index.dat&#x27;</span></span><br><span class="line">    self._dump_dict(w2i_filename, self.word2idx)</span><br><span class="line"></span><br><span class="line">    i2w_filename = self.dump_dir + <span class="string">&#x27;poetrys_index2word.dat&#x27;</span></span><br><span class="line">    self._dump_dict(i2w_filename, self.idx2word)</span><br></pre></td></tr></table></figure></p>
<p>模型方面直接使用gensim包，定义如下，根据参数不同，可以训练得到基于CBOW或SkipGram的语义向量，我们这种规模下，本质上没有太大差别，我们这里使用SkipGram。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> LineSentence</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> src.config <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> src.utils <span class="keyword">import</span> Logger</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Word2vecModel</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Word2vec model class.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                 cfg_path=<span class="string">&#x27;/home/zhanglei/Gitlab/LstmApp/config/cfg.ini&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 is_ns=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To initialize model.</span></span><br><span class="line"><span class="string">        :param cfg_path: he path of configration file.</span></span><br><span class="line"><span class="string">        :param model_type:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        cfg = Config(cfg_path)</span><br><span class="line">        <span class="keyword">global</span> log</span><br><span class="line">        log = Logger(cfg.model_log_path())</span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line">        self.is_ns = is_ns</span><br><span class="line">        self.vec_out = cfg.vec_out()</span><br><span class="line">        self.corpus_file = cfg.corpus_file()</span><br><span class="line">        self.window = cfg.window()</span><br><span class="line">        self.size = cfg.size()</span><br><span class="line">        self.sg = cfg.sg()</span><br><span class="line">        self.hs = cfg.hs()</span><br><span class="line">        self.negative = cfg.negative()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_vec</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To train a word2vec model.</span></span><br><span class="line"><span class="string">        :return: None</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        output_model = self.vec_out + <span class="string">&#x27;w2v_size&#123;0&#125;_sg&#123;1&#125;_hs&#123;2&#125;_ns&#123;3&#125;.model&#x27;</span>.<span class="built_in">format</span>(self.size,</span><br><span class="line">                                                                                   self.sg,</span><br><span class="line">                                                                                   self.hs,</span><br><span class="line">                                                                                   self.negative)</span><br><span class="line"></span><br><span class="line">        output_vector = self.vec_out + <span class="string">&#x27;w2v_size&#123;0&#125;_sg&#123;1&#125;_hs&#123;2&#125;_ns&#123;3&#125;.vector&#x27;</span>.<span class="built_in">format</span>(self.size,</span><br><span class="line">                                                                                     self.sg,</span><br><span class="line">                                                                                     self.hs,</span><br><span class="line">                                                                                     self.negative)</span><br><span class="line">        <span class="comment"># 是否做负采样</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.is_ns:</span><br><span class="line">            self.model = Word2Vec(LineSentence(self.corpus_file),</span><br><span class="line">                                  size=self.size,</span><br><span class="line">                                  window=self.window,</span><br><span class="line">                                  sg=self.sg,</span><br><span class="line">                                  hs=self.hs,</span><br><span class="line">                                  workers=multiprocessing.cpu_count())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.model = Word2Vec(LineSentence(self.corpus_file),</span><br><span class="line">                                  size=self.size,</span><br><span class="line">                                  window=self.window,</span><br><span class="line">                                  sg=self.sg,</span><br><span class="line">                                  hs=self.hs,</span><br><span class="line">                                  negative=self.negative,</span><br><span class="line">                                  workers=multiprocessing.cpu_count())</span><br><span class="line"></span><br><span class="line">        self.model.save(output_model)</span><br><span class="line">        self.model.wv.save_word2vec_format(output_vector, binary=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load</span>(<span class="params">self, path</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To load a word2vec model.</span></span><br><span class="line"><span class="string">        :param path: the model file path.</span></span><br><span class="line"><span class="string">        :return: success True otherwise False.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.model = gensim.models.Word2Vec.load(path)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">most_similar</span>(<span class="params">self, word</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Return the most similar words.</span></span><br><span class="line"><span class="string">        :param word: a word.</span></span><br><span class="line"><span class="string">        :return: similar word list.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        word = self.model.most_similar(word)</span><br><span class="line">        <span class="keyword">for</span> text <span class="keyword">in</span> word:</span><br><span class="line">            log.info(<span class="string">&quot;word:&#123;0&#125; similar:&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(text[<span class="number">0</span>], text[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> word</span><br><span class="line">    <span class="comment"># 获取某个字 的语义向量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_vector</span>(<span class="params">self, word</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To get a word&#x27;s vector.</span></span><br><span class="line"><span class="string">        :param word: a word.</span></span><br><span class="line"><span class="string">        :return: word&#x27;s word2vec vector.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> self.model.wv.get_vector(<span class="built_in">str</span>(word))</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">return</span> np.zeros(</span><br><span class="line">                shape=(self.size,),</span><br><span class="line">                dtype=np.<span class="built_in">float</span></span><br><span class="line">            )</span><br><span class="line">    <span class="comment"># 也可以直接把keras的embedding层给拿出来，</span></span><br><span class="line">    <span class="comment"># 为了直观，我这里没有直接用它，如果要用，记着把语义向量的权重冻结下。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding_layer</span>(<span class="params">self, train_embeddings=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        To get keras embedding layer from model.</span></span><br><span class="line"><span class="string">        :param train_embeddings: if frozen the layer.</span></span><br><span class="line"><span class="string">        :return: embedding layer.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> self.model.wv.get_keras_embedding(train_embeddings)</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p><strong>Step-5：构建LSTM模型</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_build</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">           lstm_layers_num,</span></span></span><br><span class="line"><span class="params"><span class="function">           dense_layers_num</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    To build a lstm model with lstm layers and densse layers.</span></span><br><span class="line"><span class="string">    :param lstm_layers_num: The number of lstm layers.</span></span><br><span class="line"><span class="string">    :param dense_layers_num:The number of dense layers.</span></span><br><span class="line"><span class="string">    :return: model.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    units = <span class="number">256</span></span><br><span class="line">    model = Sequential()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 样本特征向量的维度，onehot为词汇表大小，word2vec为语义向量维度</span></span><br><span class="line">    <span class="keyword">if</span> self.mode == WORD2VEC:</span><br><span class="line">        dim = self.data_sets.w2v_model.size</span><br><span class="line">    <span class="keyword">elif</span> self.mode == ONE_HOT:</span><br><span class="line">        dim = self.vocab_size</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;mode must be word2vec or one-hot.&quot;</span>)</span><br><span class="line">    <span class="comment"># embedding_input_length为输入序列窗口大小，如：五言绝句取为6</span></span><br><span class="line">    model.add(Input(shape=(self.embedding_input_length, dim)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以加多个LSTM层提取序列特征，这里会把之前每隔时刻的隐层都输出出来</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lstm_layers_num - <span class="number">1</span>):</span><br><span class="line">        model.add(LSTM(units=units * (i + <span class="number">1</span>),</span><br><span class="line">                       return_sequences=<span class="literal">True</span>))</span><br><span class="line">        model.add(Dropout(<span class="number">0.6</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 注意这里我只要最后一个隐层的输出</span></span><br><span class="line">    model.add(LSTM(units=units * lstm_layers_num,</span><br><span class="line">                   return_sequences=<span class="literal">False</span>))</span><br><span class="line">    model.add(Dropout(<span class="number">0.6</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 可以加多个稠密层，用于对之前提取出来特征的组合</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dense_layers_num - <span class="number">1</span>):</span><br><span class="line">        model.add(Dense(units=units * (i + <span class="number">1</span>)))</span><br><span class="line">        model.add(Dropout(<span class="number">0.6</span>))</span><br><span class="line">    <span class="comment"># 最后一层，用softmax做分类</span></span><br><span class="line">    model.add(Dense(units=self.vocab_size,</span><br><span class="line">                    activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">    <span class="comment"># 使用交叉熵损失函数，优化器选择默认参数的adam（ps：随便选的，没做调参）</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    model.summary()</span><br><span class="line">    <span class="comment"># 可视化输出模型结构</span></span><br><span class="line">    plot_model(model, to_file=<span class="string">&#x27;../model.png&#x27;</span>, show_shapes=<span class="literal">True</span>, expand_nested=<span class="literal">True</span>)</span><br><span class="line">    self.model = model</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>例如：使用200维语义向量、输入长度6、词汇量8000、两层LSTM，一层Dense的模型结构如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1emdtm03k1r4l1mq342e14enu6t13.png" width="300"  />
</center></li>
<li><p><strong>Step-6：模型训练和应用</strong></p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> src.lstm_model <span class="keyword">import</span> LstmModel</span><br><span class="line"><span class="keyword">from</span> src.data_processing <span class="keyword">import</span> PoetrysDataSet</span><br><span class="line"><span class="keyword">from</span> src.word2vec <span class="keyword">import</span> Word2vecModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_word2vec</span>(<span class="params">base_data</span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    w2v = Word2vecModel()</span><br><span class="line">    w2v.train_vec()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test.</span></span><br><span class="line">    a = w2v.most_similar(<span class="built_in">str</span>(base_data.w2i(<span class="string">&#x27;床&#x27;</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line">        <span class="built_in">print</span>(base_data.i2w(a[i][<span class="number">0</span>]), a[i][<span class="number">11</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_lstm</span>(<span class="params">base_data, finetune=<span class="literal">None</span>, mode=<span class="string">&#x27;word2vec&#x27;</span></span>):</span></span><br><span class="line"></span><br><span class="line">    model = LstmModel(cfg_file_path, base_data, mode)</span><br><span class="line">    <span class="comment"># fine tune.</span></span><br><span class="line">    <span class="keyword">if</span> finetune <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        model.load(finetune)</span><br><span class="line"></span><br><span class="line">    model.train_batch(mode=mode)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_lstm</span>(<span class="params">base_data, sentence, model_path=<span class="literal">None</span>, mode=<span class="string">&#x27;word2vec&#x27;</span></span>):</span></span><br><span class="line"></span><br><span class="line">    model = LstmModel(cfg_file_path, base_data, mode)</span><br><span class="line">    <span class="keyword">if</span> model_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        model.load(model_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model.generate_poetry(sentence, mode=mode)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cfg_file_path = <span class="string">&#x27;/home/zhanglei/Gitlab/LstmApp/config/cfg.ini&#x27;</span></span><br><span class="line">    w2vmodel_path = <span class="string">&#x27;/home/zhanglei/Gitlab/LstmApp/data/w2v_models/w2v_size200_sg1_hs0_ns3.model&#x27;</span></span><br><span class="line">    model_path = <span class="string">&#x27;/home/zhanglei/Gitlab/LstmApp/data/models/model-2117.hdf5&#x27;</span></span><br><span class="line"></span><br><span class="line">    base_data = PoetrysDataSet(cfg_file_path)</span><br><span class="line">    train_word2vec(base_data)</span><br><span class="line">    base_data.load_word2vec_model(w2vmodel_path)</span><br><span class="line"></span><br><span class="line">    train_lstm(base_data=base_data, finetune=model_path)</span><br><span class="line"></span><br><span class="line">    sentence = <span class="string">&#x27;惜彼落日暮，&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(test_lstm(base_data=base_data, sentence=sentence, model_path=model_path))</span><br></pre></td></tr></table></figure>
<pre><code>在model.log里会看到训练时的中间信息，如下，随着迭代次数变多，效果会越来越好，包括标点符号的规律也会学进去：

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[2020-11-05 12:58:48,723] - lstm_model.py [Line:127] - [DEBUG]-[thread:140045784893248]-[process:29513] - begin training</span><br><span class="line">[2020-11-05 12:58:48,723] - lstm_model.py [Line:132] - [DEBUG]-[thread:140045784893248]-[process:29513] - batch_size:32,steps_per_epoch:355,epochs:5000,validation_steps152</span><br><span class="line">[2020-11-05 12:59:10,260] - lstm_model.py [Line:194] - [INFO]-[thread:140045784893248]-[process:29513] - ==================Epoch 0, Loss 7.93123197555542=====================</span><br><span class="line">[2020-11-05 12:59:11,968] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 欲别牵郎衣，粳酗蓦釱北，鈒静槃遍衫。恸阳日搦蛆，</span><br><span class="line">[2020-11-05 12:59:12,816] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 金庭仙树枝，莨行查娇乂。具撅日霈韂，帝鸟 维。。</span><br><span class="line">[2020-11-05 12:59:13,659] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 素艳拥行舟，母 佶翕何，藁澡   。一 钺辗。，</span><br><span class="line">[2020-11-05 12:59:14,494] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 白鹭拳一足，芾 乡诏秩，启窑 展赢，酪溜劫騊 ，</span><br><span class="line">[2020-11-05 12:59:15,385] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 恩酬期必报，闾瞢，颾钏。啾，。耴望，薖，州耒朿。</span><br><span class="line">[2020-11-05 12:59:16,277] - lstm_model.py [Line:197] - [INFO]-[thread:140045784893248]-[process:29513] - 君去方为宰，沈乡看一帷，柳跂 仁柳，营空长日韍。</span><br><span class="line">[2020-11-05 12:59:16,278] - lstm_model.py [Line:198] - [INFO]-[thread:140045784893248]-[process:29513] - ==================End=====================</span><br><span class="line">......</span><br><span class="line">[2020-11-06 02:12:12,971] - lstm_model.py [Line:194] - [INFO]-[thread:140348029687616]-[process:31309] - ==================Epoch 2106, Loss 7.458868980407715=====================</span><br><span class="line">[2020-11-06 02:12:13,732] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 新开窗犹偏，回雨草花天。谁因家群应，人年功日未。</span><br><span class="line">[2020-11-06 02:12:14,498] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 此心非一事，白物郡期旧。相爱含将回，更相日见光。</span><br><span class="line">[2020-11-06 02:12:15,274] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 刻舟寻已化，有恨多两开。去闻难乱东，地中当如来。</span><br><span class="line">[2020-11-06 02:12:16,069] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 带水摘禾穗，鸟独光冥客。拂船不自已，远年必年非。</span><br><span class="line">[2020-11-06 02:12:16,846] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 茕茕孤思逼，此前路去地。如事别自以，闻阳近高酒。</span><br><span class="line">[2020-11-06 02:12:17,613] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 西陆蝉声唱，日衣烟东云。春出不饥家，马白贵风御。</span><br><span class="line">[2020-11-06 02:12:17,614] - lstm_model.py [Line:198] - [INFO]-[thread:140348029687616]-[process:31309] - ==================End=====================</span><br><span class="line">[2020-11-06 02:13:56,069] - lstm_model.py [Line:194] - [INFO]-[thread:140348029687616]-[process:31309] - ==================Epoch 2112, Loss 7.728175163269043=====================</span><br><span class="line">[2020-11-06 02:13:56,946] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 旅泊多年岁，发知期东今。君自舟岁未，应当折君新。</span><br><span class="line">[2020-11-06 02:13:57,731] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 吾师师子儿，花其重前相。鸟千人身一，清相无道因。</span><br><span class="line">[2020-11-06 02:13:58,532] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 和吹度穹旻，此外更高可。来闻人成独，故去深看春。</span><br><span class="line">[2020-11-06 02:13:59,317] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 下直遇春日，独与时相飞。江君贤犹名，清清曲河人。</span><br><span class="line">[2020-11-06 02:14:00,089] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 月暗竹亭幽，碧昏时尽黄。园春歌雪光，云落分白草。</span><br><span class="line">[2020-11-06 02:14:00,861] - lstm_model.py [Line:197] - [INFO]-[thread:140348029687616]-[process:31309] - 睢阳陷虏日，远平然多岩。公水三共朝，月看同出人。</span><br><span class="line">[2020-11-06 02:14:00,861] - lstm_model.py [Line:198] - [INFO]-[thread:140348029687616]-[process:31309] - ==================End=====================</span><br><span class="line">[2020-11-06 02:15:22,836] - lstm_model.py [Line:148] - [DEBUG]-[thread:140348029687616]-[process:31309] - end training</span><br></pre></td></tr></table></figure></code></pre>
<h2 id="attention机制">6.4 Attention机制</h2>
<h3 id="什么是attention机制">6.4.1 什么是Attention机制</h3>
<p>在人类的认知过程中，Attention(注意力)是所有感知和认知操作的一种核心属性。由于人类对多来源信息的处理能力有限，Attention机制可以帮助我们选择、调整并聚焦在那些与当前目标行为最相关的的信息上。就像小学生上课，主要行为需要集中在黑板和老师身上，但周围的同学、环境等信息也会涌入大脑并参与竞争，所以集中注意力是成为好学生的必要条件之一。</p>
再比如计算机视觉应用中，Attention机制和感受野类似，都是对人类真实行为的抽象模拟，人类观察事物时，依据自己当时的兴趣点，“天然”会关注“重点”同时忽略无关点，而重点也一定是一些局部信息，不同的人如果关注的“重点”相同，一定程度上就是“臭味相投”。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/image_1fbislg3d5m5221g4d15kl1rbc9.png" width="450"  />
</center>
<p>当然，Attention机制也可以看作是一种通用框架，逻辑类似<a href="https://vivounicorn.github.io/page/2021/09/05/机器学习与人工智能技术分享-第三章-机器学习中的统一框架">第三章</a>中讲的的统一框架，夸张点说它也是某种“上帝视角”，目前它在：<strong><em>计算机视觉</em></strong>(如：图像检测、识别、跟踪等)、<strong><em>自然语言处理</em></strong>(如：翻译、问答、摘要等)、<strong><em>计算机视觉与自然语言处理交叉领域</em></strong>(如：根据图像生成文本描述等)、<strong><em>算法任务</em></strong>(如：神经图灵机)、<strong><em>机器人应用</em></strong>(如：人机交互、控制、导航)等领域的研究和应用遍地开花。</p>
<h3 id="从seq2seq模型说起">6.4.2 从Seq2Seq模型说起</h3>
<p>Sequence-to-sequence模型是一种典型的DNN模型，被广泛应用于处理序列问题，如：机器翻译、内容生成等，最早在《<a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>》一文中被提出，以及更早一些具有类似思想，基于RNN Encoder-Decoder做机器翻译的《<a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>》。 seq2seq问题处理过程类似这样：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337719682456.png" width="">
</center>
<p>以机器翻译：“我是中国人”<span class="math inline">\(\Rightarrow\)</span>“I am from china”为例，如果Seq2seq模型采用Encoder-Decoder框架，那么处理过程类似这样：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337732972491.png" width="">
</center>
<p>其中：</p>
<p>1、<span class="math inline">\(x\)</span>为源输入，像这里的“我是中国人”，进入Encoder模块前一般会被表示为一个语义向量&lt;<span class="math inline">\(x_1,x_2,...,x_n\)</span>&gt;（如：利用word2vec做word embedding进而生成隐语义向量）；</p>
<p>2、接着，Encoder模块负责接收输入序列并将其抽象/压缩/提取/编码输出为一个上下文向量，这个向量隐含了源输入的序列/语义等各种信息，即执行：<span class="math inline">\(Context=E(x_1,x_2,...,x_n)\)</span>；</p>
<p>3、上下文向量做为输入进入Decoder模块，并由Decoder模块生成最终的目标序列<span class="math inline">\(y\)</span>，即执行：<span class="math inline">\(y_i=D(Context,y_1,y_2,...,y_{i-1})\)</span>。</p>
<p>假设： 1、“我是中国人”被表示为以下向量：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337793705067.png" width="260" height="" >
</center>
2、Encoder和Decoder都采用经典的RNN结构：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337791134694.png" width="390" height="" >
</center>
Encoder阶段展开后如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337800556564.png" width="" height="" >
</center>
最终生成的上下文向量为：“<strong><em>隐藏状态#5</em></strong>” 向量，之后将该向量传入Decoder，逐字生成<span class="math inline">\(y\)</span>，上面的非Attention的Seq2Seq模型执行过程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16337807036222.png" width="600" height="" >
</center>
<ceneter><img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16338713082289.png" width="" height="" >
</center>
<p>即：</p>
<p><span class="math inline">\(y_1=D(隐藏状态\#5)\)</span> = I</p>
<p><span class="math inline">\(y_2=D(隐藏状态\#5,y_1)\)</span> = am</p>
<p><span class="math inline">\(y_3=D(隐藏状态\#5,y_1,y_2)\)</span> = from</p>
<p><span class="math inline">\(y_4=D(隐藏状态\#5,y_1,y_2,y_3)\)</span> = China</p>
在没有Attention机制作用时，生成过程使用的是 <strong><em>相同</em></strong> 的上下文向量：“<strong><em>隐藏状态#5</em></strong>”，即，输入序列“我是中国人”中的每个字对翻译结果为“I am from China”的每个单词的贡献是一样的，这显然是不合理的（比如：“是”对China的贡献要远低于“中”和“国”）。为解决此缺点，引入Attention机制，如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-attention.jpg" width="" height="" >
</center>
<ul>
<li><ol type="a">
<li>Encoder阶段，从原来只保留最后一次迭代的隐层向量，改为保留每次迭代的隐层向量，每个隐层向量隐含了相应输入向量的语义信息；</li>
</ol></li>
<li><ol start="2" type="a">
<li>以上所有隐层向量传入Decoder阶段；</li>
</ol></li>
<li><ol start="3" type="a">
<li>以Decoder阶段RNN的第一次迭代为例:</li>
</ol>
<p>1、输入为一个“初始向量”和embedding后的“EOS”（输入结束标识符）向量;</p>
<p>2、第一次迭代产生隐层向量#a；</p>
<p>3、依据函数<span class="math inline">\(f\)</span>，每个Encoder阶段传来的隐层向量(#1,#2,...,#5)分别和隐层向量#a计算得分： <span class="math display">\[s=f(h_{\#i},h_{\#a})\]</span></p>
<p>4、计算出的得分利用Softmax函数做归一化： <span class="math display">\[w_{ia}=\frac{f(h_{\#i},h_{\#a})}{\sum_{i=1}^{n=5}f(h_{\#i},h_{\#a})}\]</span></p>
<p>5、用上面计算出的权重对：隐层向量(#1,#2,...,#5)做加权求和，得到当前迭代的上下文向量： <span class="math display">\[c_{a}=\sum_{i=1}^{n=5}w_{ia}*h_{\#i}\]</span></p>
<p>6、拼接新的上下文向量<span class="math inline">\(c_a\)</span>与当前隐层向量<span class="math inline">\(h_{\#a}\)</span>，得到： <span class="math display">\[v_a=[c_a,h_{\#a}]\]</span></p>
<p>7、将上述向量送入一个前馈神经网络，注意，训练时此网络和整个RNN网络是联合训练的；</p>
<p>8、以上网络的输出向量即为目标内容：<span class="math inline">\(y_1=I\)</span>，其他迭代过程类似就不再赘述。</p></li>
</ul>
这里看一个来源于tensoflow官网的机器翻译例子： 项目目录结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16348962307501.png" width="350" height="" >
</center>
<p><strong>1、训练数据</strong></p>
<p><strong>1)、下载数据集</strong></p>
<p>下载：http://www.manythings.org/anki/cmn-eng.zip 数据集，内容类似这样： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">I received an invitation.	我收到了一张请帖。	CC-BY <span class="number">2.0</span> (France) Attribution: tatoeba.org <span class="comment">#258705 (CK) &amp; #332420 (fucongcong)</span></span><br><span class="line">I saw her clean the room.	我看見了她打掃房間。	CC-BY <span class="number">2.0</span> (France) Attribution: tatoeba.org <span class="comment">#261072 (CK) &amp; #862735 (Martha)</span></span><br><span class="line">I saw her enter the room.	我看見她進了房間。	CC-BY <span class="number">2.0</span> (France) Attribution:</span><br></pre></td></tr></table></figure></p>
<p><strong>2)、安装繁简转换器</strong></p>
<p>由于训练集是繁体的，所以需要做下繁简转换，我这里使用OpenCC库：https://github.com/BYVoid/OpenCC 通常情况使用以下命令可安装：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install opencc</span><br></pre></td></tr></table></figure>
<p>使用方法如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> opencc</span><br><span class="line">converter = opencc.OpenCC(<span class="string">&#x27;t2s.json&#x27;</span>)</span><br><span class="line">converter.convert(<span class="string">&#x27;漢字&#x27;</span>)  <span class="comment"># 汉字</span></span><br></pre></td></tr></table></figure></p>
<p>但如果无法成功，尤其在ubuntu 18.04下，也可以尝试源码安装，不过编译过程很痛苦，你可能会遇到各种各样稀奇古怪的错误，最简单的方案是使用以下项目：https://pypi.org/project/opencc-python-reimplemented/ <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install opencc-python-reimplemented</span><br></pre></td></tr></table></figure></p>
<p>使用方法如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> opencc</span><br><span class="line">converter = opencc.OpenCC(<span class="string">&#x27;t2s&#x27;</span>)</span><br><span class="line">converter.convert(<span class="string">&#x27;漢字&#x27;</span>)  <span class="comment"># 汉字</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3)、安装matplotlib字体</strong> 由于默认matplotlib不支持显示中文，会报错： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RuntimeWarning: Glyph ***** missing <span class="keyword">from</span> current font. font.set_text(s, <span class="number">0.0</span>, flags=flags)</span><br></pre></td></tr></table></figure></p>
<p>网上有一堆所谓解决办法，但真正靠谱的没几种，不想尝试的可以用我下面的方法，该方法适用于：deepin及ubuntu 18.04。</p>
<ul>
<li><p>下载中文字体，如：SimHei(https://github.com/StellarCN/scp_zh/blob/master/fonts/SimHei.ttf)</p></li>
<li><p>在终端查看matplotlib路径</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="built_in">print</span>(matplotlib.matplotlib_fname())</span><br></pre></td></tr></table></figure>
<p>例如输出：</p>
<blockquote>
<p>/home/leon/.local/lib/python3.8/site-packages/matplotlib/mpl-data/matplotlibrc</p>
</blockquote>
<p>进入目录：</p>
<blockquote>
<p>/home/leon/.local/lib/python3.8/site-packages/matplotlib/mpl-data/fonts/ttf</p>
</blockquote>
<p>把上面的字体放入该目录后，删除缓存文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.get_cachedir()</span><br></pre></td></tr></table></figure>
<p>例如输出：</p>
<blockquote>
<p>/home/leon/.cache/matplotlib</p>
</blockquote>
<p>执行：</p>
<blockquote>
<p>rm -rf /home/leon/.cache/matplotlib</p>
</blockquote>
<ul>
<li>修改matplotlibrc配置文件</li>
</ul>
<p>例如路径：</p>
<blockquote>
<p>/home/leon/.local/lib/python3.8/site-packages/matplotlib/mpl-data/matplotlibrc 改三个部分如下：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#small, medium, large, x-large, xx-large, larger, or smaller</span></span><br><span class="line">font.family:  sans-serif</span><br><span class="line"><span class="comment">#font.style:   normal</span></span><br><span class="line"><span class="comment">#font.variant: normal</span></span><br><span class="line"><span class="comment">#font.weight:  normal</span></span><br><span class="line"><span class="comment">#font.stretch: normal</span></span><br><span class="line"><span class="comment">#font.size:    10.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#font.serif:     SimHei,  DejaVu Serif, Bitstream Vera Serif, Computer Modern Roman, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif</span></span><br><span class="line">font.sans-serif: SimHei, DejaVu Sans, Bitstream Vera Sans, Computer Modern Sans Serif, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif</span><br><span class="line"><span class="comment">#font.cursive:    Apple Chancery, Textile, Zapf Chancery, Sand, Script MT, Felipa, Comic Neue, Comic Sans MS, cursive</span></span><br><span class="line"><span class="comment">#axes.spines.right:  True</span></span><br><span class="line"></span><br><span class="line">axes.unicode_minus: <span class="literal">False</span>  <span class="comment"># use Unicode for the minus symbol rather than hyphen.  See</span></span><br><span class="line">                           <span class="comment"># https://en.wikipedia.org/wiki/Plus_and_minus_signs#Character_codes</span></span><br><span class="line"><span class="comment">#axes.prop_cycle: cycler(&#x27;color&#x27;, [&#x27;1f77b4&#x27;, &#x27;ff7f0e&#x27;, &#x27;2ca02c&#x27;, &#x27;d62728&#x27;, &#x27;9467bd&#x27;, &#x27;8c564b&#x27;, &#x27;e377c2&#x27;, &#x27;7f7f7f&#x27;, &#x27;bcbd22&#x27;, &#x27;17becf&#x27;])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>2、数据预处理</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> opencc</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="comment"># 繁体汉字转为简体汉字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">t2s_converter</span>(<span class="params">sentence</span>):</span></span><br><span class="line">    cvt = opencc.OpenCC(<span class="string">&#x27;t2s&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> cvt.convert(sentence)</span><br><span class="line"></span><br><span class="line"><span class="comment"># unicode转ascii</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unicode_to_ascii</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">                   <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找文本中第一个汉字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_first_chinese</span>(<span class="params">s</span>):</span></span><br><span class="line">    han_str = re.<span class="built_in">compile</span>(<span class="string">&#x27;[\u4e00-\u9fff]+&#x27;</span>).findall(s)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(han_str) &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> han_str[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取处理文本中的英文句子</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_ch_en</span>(<span class="params">sen</span>):</span></span><br><span class="line">    idx = sen.find(<span class="string">&#x27;CC-BY&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> idx == -<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    w = unicode_to_ascii(sen[:idx].lower().strip())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在单词与跟在其后的标点符号之间插入一个空格</span></span><br><span class="line">    <span class="comment"># 例如： &quot;he is a boy.&quot; =&gt; &quot;he is a boy .&quot;</span></span><br><span class="line">    <span class="comment"># 参考：https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation</span></span><br><span class="line">    w = re.sub(<span class="string">r&quot;([?.!])&quot;</span>, <span class="string">r&quot; \1 &quot;</span>, w)</span><br><span class="line">    w = re.sub(<span class="string">r&#x27;[&quot; &quot;]+&#x27;</span>, <span class="string">&quot; &quot;</span>, w)</span><br><span class="line"></span><br><span class="line">    w = w.rstrip().strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定位汉语和英语句子所在位置</span></span><br><span class="line">    han = find_first_chinese(w)</span><br><span class="line">    idx = w.find(han)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> idx == -<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    han_str = w[idx:]</span><br><span class="line">		<span class="comment"># 给句子加上开始和结束标记</span></span><br><span class="line">    <span class="comment"># 以便模型知道何时开始和结束预测</span></span><br><span class="line">    en_str = <span class="string">&#x27;&lt;start&gt; &#x27;</span> + w[:idx].strip() + <span class="string">&#x27; &lt;end&gt;&#x27;</span></span><br><span class="line">		<span class="comment"># 返回一个英文句子在前，汉语句子在后的list</span></span><br><span class="line">    w = [en_str, <span class="string">&#x27;&lt;start&gt; &#x27;</span> + chinese_words_cut(t2s_converter(han_str)) + <span class="string">&#x27; &lt;end&gt;&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词，这里采用结巴分词。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chinese_words_cut</span>(<span class="params">sentence</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(jieba.cut(sentence, cut_all=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 去除重音符号</span></span><br><span class="line"><span class="comment"># 2. 清理句子</span></span><br><span class="line"><span class="comment"># 3. 返回这样格式的单词对：[CHINESE, ENGLISH]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span>(<span class="params">path, num_examples</span>):</span></span><br><span class="line">    lines = io.<span class="built_in">open</span>(path, encoding=<span class="string">&#x27;UTF-8&#x27;</span>).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    word_pairs = [extract_ch_en(l) <span class="keyword">for</span> l <span class="keyword">in</span> lines[:num_examples]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">zip</span>(*word_pairs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回最大长度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_length</span>(<span class="params">tensor</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">max</span>(<span class="built_in">len</span>(t) <span class="keyword">for</span> t <span class="keyword">in</span> tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文本预处理、整数序列化：https://keras.io/zh/preprocessing/text/</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span>(<span class="params">lang</span>):</span></span><br><span class="line">    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(</span><br><span class="line">        filters=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    lang_tokenizer.fit_on_texts(lang)</span><br><span class="line"></span><br><span class="line">    tensor = lang_tokenizer.texts_to_sequences(lang)</span><br><span class="line"></span><br><span class="line">    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,</span><br><span class="line">                                                           padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tensor, lang_tokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span>(<span class="params">path, num_examples=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="comment"># 创建清理过的输入输出对</span></span><br><span class="line">    targ_lang, inp_lang = create_dataset(path, num_examples)</span><br><span class="line"></span><br><span class="line">    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)</span><br><span class="line">    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回整数编号和文本的对应关系</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span>(<span class="params">lang, tensor</span>):</span></span><br><span class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> tensor:</span><br><span class="line">    <span class="keyword">if</span> t!=<span class="number">0</span>:</span><br><span class="line">      <span class="built_in">print</span> (<span class="string">&quot;%d ----&gt; %s&quot;</span> % (t, lang.index_word[t]))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>3、实现Encoder编码器</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim, enc_units, batch_sz</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.batch_sz = batch_sz</span><br><span class="line">        self.enc_units = enc_units</span><br><span class="line">        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.gru = tf.keras.layers.GRU(self.enc_units,</span><br><span class="line">                                       return_sequences=<span class="literal">True</span>,</span><br><span class="line">                                       return_state=<span class="literal">True</span>,</span><br><span class="line">                                       recurrent_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 很简单的结构，embedding+GRU单元</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, hidden</span>):</span></span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        output, state = self.gru(x, initial_state=hidden)</span><br><span class="line">        <span class="keyword">return</span> output, state</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机初始化隐层权重</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize_hidden_state</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.zeros((self.batch_sz, self.enc_units))</span><br></pre></td></tr></table></figure>
<p><strong>4、实现Decoder解码器</strong></p>
<ul>
<li><p>BahdanauAttention</p>
<p>Bahdanau在《Neural Machine Translation by Jointly Learning to Align and Translate》这篇论文提出。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BahdanauAttention</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(BahdanauAttention, self).__init__()</span><br><span class="line">        self.W1 = tf.keras.layers.Dense(units)</span><br><span class="line">        self.W2 = tf.keras.layers.Dense(units)</span><br><span class="line">        self.V = tf.keras.layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, query, values</span>):</span></span><br><span class="line">        <span class="comment"># 隐藏层的形状 == （批大小，隐藏层大小）</span></span><br><span class="line">        <span class="comment"># hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）</span></span><br><span class="line">        <span class="comment"># 这样做是为了执行加法以计算分数</span></span><br><span class="line">        hidden_with_time_axis = tf.expand_dims(query, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分数的形状 == （批大小，最大长度，1）</span></span><br><span class="line">        <span class="comment"># 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V</span></span><br><span class="line">        <span class="comment"># 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）</span></span><br><span class="line">        score = self.V(tf.nn.tanh(</span><br><span class="line">            self.W1(values) + self.W2(hidden_with_time_axis)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）</span></span><br><span class="line">        attention_weights = tf.nn.softmax(score, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）</span></span><br><span class="line">        context_vector = attention_weights * values</span><br><span class="line">        context_vector = tf.reduce_sum(context_vector, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> context_vector, attention_weights</span><br></pre></td></tr></table></figure></p></li>
<li><p>Decoder</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> BahdanauAttention <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, embedding_dim, dec_units, batch_sz</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.batch_sz = batch_sz</span><br><span class="line">        self.dec_units = dec_units</span><br><span class="line">        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)</span><br><span class="line">        self.gru = tf.keras.layers.GRU(self.dec_units,</span><br><span class="line">                                       return_sequences=<span class="literal">True</span>,</span><br><span class="line">                                       return_state=<span class="literal">True</span>,</span><br><span class="line">                                       recurrent_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>)</span><br><span class="line">        self.fc = tf.keras.layers.Dense(vocab_size)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 用于注意力</span></span><br><span class="line">        self.attention = BahdanauAttention(self.dec_units)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, hidden, enc_output</span>):</span></span><br><span class="line">        <span class="comment"># 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）</span></span><br><span class="line">        context_vector, attention_weights = self.attention.call(hidden, enc_output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）</span></span><br><span class="line">        x = self.embedding(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）</span></span><br><span class="line">				<span class="comment"># 注意这里是“拼接”操作，可以对比前面的大图理解</span></span><br><span class="line">        x = tf.concat([tf.expand_dims(context_vector, <span class="number">1</span>), x], axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将合并后的向量传送到 GRU</span></span><br><span class="line">        output, state = self.gru(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出的形状 == （批大小 * 1，隐藏层大小）</span></span><br><span class="line">        output = tf.reshape(output, (-<span class="number">1</span>, output.shape[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出的形状 == （批大小，vocab）</span></span><br><span class="line">        x = self.fc(output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x, state, attention_weights</span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>5、模型构建和训练</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.ticker <span class="keyword">as</span> ticker</span><br><span class="line"><span class="keyword">import</span> utils.preprocessor <span class="keyword">as</span> up</span><br><span class="line"><span class="keyword">from</span> Decoder <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> Encoder <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatasetParams</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.inp_lang = <span class="literal">None</span></span><br><span class="line">        self.targ_lang = <span class="literal">None</span></span><br><span class="line">        self.max_length_targ = <span class="number">0</span></span><br><span class="line">        self.max_length_inp = <span class="number">0</span></span><br><span class="line">        self.BATCH_SIZE = <span class="number">64</span></span><br><span class="line">        self.BUFFER_SIZE = <span class="number">0</span></span><br><span class="line">        self.steps_per_epoch = <span class="number">0</span></span><br><span class="line">        self.embedding_dim = <span class="number">256</span></span><br><span class="line">        self.units = <span class="number">1024</span></span><br><span class="line">        self.vocab_inp_size = <span class="number">0</span></span><br><span class="line">        self.vocab_tar_size = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ModelParams</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.encoder = <span class="literal">None</span></span><br><span class="line">        self.decoder = <span class="literal">None</span></span><br><span class="line">        self.optimizer = <span class="literal">None</span></span><br><span class="line">        self.optimizer = <span class="literal">None</span></span><br><span class="line">        self.loss_object = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CheckPointsParams</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.checkpoint_prefix = <span class="string">&#x27;&#x27;</span></span><br><span class="line">        self.checkpoint = <span class="literal">None</span></span><br><span class="line">        self.checkpoint_dir = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_preparing</span>(<span class="params">path_to_file</span>):</span></span><br><span class="line">    params = DatasetParams()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 尝试实验不同大小的数据集</span></span><br><span class="line">    num_examples = <span class="number">30000</span></span><br><span class="line">    input_tensor, target_tensor, params.inp_lang, params.targ_lang = up.load_dataset(path_to_file, num_examples)</span><br><span class="line">    <span class="comment"># 计算目标张量的最大长度 （max_length）</span></span><br><span class="line">    params.max_length_targ, params.max_length_inp = up.max_length(target_tensor), up.max_length(input_tensor)</span><br><span class="line">    <span class="comment"># 采用 80 - 20 的比例切分训练集和验证集</span></span><br><span class="line">    input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor,</span><br><span class="line">                                                                                                    target_tensor,</span><br><span class="line">                                                                                                    test_size=<span class="number">0.2</span>)</span><br><span class="line">    <span class="comment"># 显示长度</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(input_tensor_train), <span class="built_in">len</span>(target_tensor_train), <span class="built_in">len</span>(input_tensor_val), <span class="built_in">len</span>(target_tensor_val))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Input Language; index to word mapping&quot;</span>)</span><br><span class="line">    up.convert(params.inp_lang, input_tensor_train[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Target Language; index to word mapping&quot;</span>)</span><br><span class="line">    up.convert(params.targ_lang, target_tensor_train[<span class="number">0</span>])</span><br><span class="line">    params.BUFFER_SIZE = <span class="built_in">len</span>(input_tensor_train)</span><br><span class="line"></span><br><span class="line">    params.steps_per_epoch = <span class="built_in">len</span>(input_tensor_train) // params.BATCH_SIZE</span><br><span class="line"></span><br><span class="line">    params.vocab_inp_size = <span class="built_in">len</span>(params.inp_lang.word_index) + <span class="number">1</span></span><br><span class="line">    params.vocab_tar_size = <span class="built_in">len</span>(params.targ_lang.word_index) + <span class="number">1</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(params.BUFFER_SIZE)</span><br><span class="line">    dataset = dataset.batch(params.BATCH_SIZE, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params, dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference_model_building</span>(<span class="params">dataset_params</span>):</span></span><br><span class="line"></span><br><span class="line">    params = ModelParams()</span><br><span class="line"></span><br><span class="line">    params.encoder = Encoder(dataset_params.vocab_inp_size, dataset_params.embedding_dim, dataset_params.units,</span><br><span class="line">                             dataset_params.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    params.decoder = Decoder(dataset_params.vocab_tar_size, dataset_params.embedding_dim, dataset_params.units,</span><br><span class="line">                             dataset_params.BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    params.optimizer = tf.keras.optimizers.Adam()</span><br><span class="line">    params.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(</span><br><span class="line">        from_logits=<span class="literal">True</span>, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_building</span>(<span class="params">dataset_params, dataset</span>):</span></span><br><span class="line">	  <span class="comment"># 返回一个batch的数据</span></span><br><span class="line">    example_input_batch, example_target_batch = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataset))</span><br><span class="line">    <span class="built_in">print</span>(example_input_batch.shape, example_target_batch.shape)</span><br><span class="line"></span><br><span class="line">    params = ModelParams()</span><br><span class="line"></span><br><span class="line">    params.encoder = Encoder(dataset_params.vocab_inp_size, dataset_params.embedding_dim, dataset_params.units,</span><br><span class="line">                             dataset_params.BATCH_SIZE)</span><br><span class="line">    <span class="comment"># 样本输入</span></span><br><span class="line">    sample_hidden = params.encoder.initialize_hidden_state()</span><br><span class="line">    sample_output, sample_hidden = params.encoder.call(example_input_batch, sample_hidden)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Encoder output shape: (batch size, sequence length, units) &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(sample_output.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Encoder Hidden state shape: (batch size, units) &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(sample_hidden.shape))</span><br><span class="line">    attention_layer = BahdanauAttention(<span class="number">10</span>)</span><br><span class="line">    attention_result, attention_weights = attention_layer.call(sample_hidden, sample_output)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Attention result shape: (batch size, units) &#123;&#125;&quot;</span>.<span class="built_in">format</span>(attention_result.shape))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Attention weights shape: (batch_size, sequence_length, 1) &#123;&#125;&quot;</span>.<span class="built_in">format</span>(attention_weights.shape))</span><br><span class="line">    params.decoder = Decoder(dataset_params.vocab_tar_size, dataset_params.embedding_dim, dataset_params.units,</span><br><span class="line">                             dataset_params.BATCH_SIZE)</span><br><span class="line">    sample_decoder_output, _, _ = params.decoder.call(tf.random.uniform((<span class="number">64</span>, <span class="number">1</span>)),</span><br><span class="line">                                                      sample_hidden, sample_output)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Decoder output shape: (batch_size, vocab size) &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(sample_decoder_output.shape))</span><br><span class="line">    params.optimizer = tf.keras.optimizers.Adam()</span><br><span class="line">    params.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(</span><br><span class="line">        from_logits=<span class="literal">True</span>, reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">model_params, real, pred</span>):</span></span><br><span class="line">	  <span class="comment"># 逻辑非</span></span><br><span class="line">    mask = tf.math.logical_not(tf.math.equal(real, <span class="number">0</span>))</span><br><span class="line">    loss_ = model_params.loss_object(real, pred)</span><br><span class="line"></span><br><span class="line">    mask = tf.cast(mask, dtype=loss_.dtype)</span><br><span class="line">    loss_ *= mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(loss_)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chk_settings</span>(<span class="params">model_params</span>):</span></span><br><span class="line">    params = CheckPointsParams()</span><br><span class="line">    params.checkpoint_dir = <span class="string">&#x27;./training_checkpoints&#x27;</span></span><br><span class="line">    params.checkpoint_prefix = os.path.join(params.checkpoint_dir, <span class="string">&quot;ckpt&quot;</span>)</span><br><span class="line">    params.checkpoint = tf.train.Checkpoint(optimizer=model_params.optimizer,</span><br><span class="line">                                            encoder=model_params.encoder,</span><br><span class="line">                                            decoder=model_params.decoder)</span><br><span class="line">    <span class="keyword">return</span> params</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">dataset_params, model_params, inp, targ, enc_hidden</span>):</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        enc_output, enc_hidden = model_params.encoder.call(inp, enc_hidden)</span><br><span class="line"></span><br><span class="line">        dec_hidden = enc_hidden</span><br><span class="line"></span><br><span class="line">        dec_input = tf.expand_dims([dataset_params.targ_lang.word_index[<span class="string">&#x27;&lt;start&gt;&#x27;</span>]] * dataset_params.BATCH_SIZE, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 教师强制 - 将目标词作为下一个输入，每个目标词来一下。</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, targ.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># 将编码器输出 （enc_output） 传送至解码器</span></span><br><span class="line">            predictions, dec_hidden, _ = model_params.decoder.call(dec_input, dec_hidden, enc_output)</span><br><span class="line"></span><br><span class="line">            loss += loss_function(model_params, targ[:, t], predictions)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 使用教师强制</span></span><br><span class="line">            dec_input = tf.expand_dims(targ[:, t], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    batch_loss = (loss / <span class="built_in">int</span>(targ.shape[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    variables = model_params.encoder.trainable_variables + model_params.decoder.trainable_variables</span><br><span class="line"></span><br><span class="line">    gradients = tape.gradient(loss, variables)</span><br><span class="line"></span><br><span class="line">    model_params.optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainer</span>(<span class="params">dataset_params, model_params, chk_params, dataset, epochs=<span class="number">100</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        start = time.time()</span><br><span class="line"></span><br><span class="line">        enc_hidden = model_params.encoder.initialize_hidden_state()</span><br><span class="line">        total_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (batch, (inp, targ)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset.take(dataset_params.steps_per_epoch)):</span><br><span class="line">            batch_loss = train_step(dataset_params, model_params, inp, targ, enc_hidden)</span><br><span class="line">            total_loss += batch_loss</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> batch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125; Batch &#123;&#125; Loss &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                                             batch,</span><br><span class="line">                                                             batch_loss.numpy()))</span><br><span class="line">        <span class="comment"># 每 2 个周期（epoch），保存（检查点）一次模型</span></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            chk_params.checkpoint.save(file_prefix=chk_params.checkpoint_prefix)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125; Loss &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>,</span><br><span class="line">                                            total_loss / dataset_params.steps_per_epoch))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Time taken for 1 epoch &#123;&#125; sec\n&#x27;</span>.<span class="built_in">format</span>(time.time() - start))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">dataset_params, model_params, sentence</span>):</span></span><br><span class="line">    attention_plot = np.zeros((dataset_params.max_length_targ, dataset_params.max_length_inp))</span><br><span class="line"></span><br><span class="line">    sentence = up.extract_ch(sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;============================&quot;</span>, sentence)</span><br><span class="line"></span><br><span class="line">    inputs = [dataset_params.inp_lang.word_index[i] <span class="keyword">for</span> i <span class="keyword">in</span> sentence.split(<span class="string">&#x27; &#x27;</span>)]</span><br><span class="line">    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],</span><br><span class="line">                                                           maxlen=dataset_params.max_length_inp,</span><br><span class="line">                                                           padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line">    inputs = tf.convert_to_tensor(inputs)</span><br><span class="line"></span><br><span class="line">    result = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    hidden = [tf.zeros((<span class="number">1</span>, dataset_params.units))]</span><br><span class="line">    enc_out, enc_hidden = model_params.encoder.call(inputs, hidden)</span><br><span class="line"></span><br><span class="line">    dec_hidden = enc_hidden</span><br><span class="line">    dec_input = tf.expand_dims([dataset_params.targ_lang.word_index[<span class="string">&#x27;&lt;start&gt;&#x27;</span>]], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(dataset_params.max_length_targ):</span><br><span class="line">        predictions, dec_hidden, attention_weights = model_params.decoder.call(dec_input,</span><br><span class="line">                                                                               dec_hidden,</span><br><span class="line">                                                                               enc_out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 存储注意力权重以便后面制图</span></span><br><span class="line">        attention_weights = tf.reshape(attention_weights, (-<span class="number">1</span>,))</span><br><span class="line">        attention_plot[t] = attention_weights.numpy()</span><br><span class="line"></span><br><span class="line">        predicted_id = tf.argmax(predictions[<span class="number">0</span>]).numpy()</span><br><span class="line"></span><br><span class="line">        result += dataset_params.targ_lang.index_word[predicted_id] + <span class="string">&#x27; &#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> dataset_params.targ_lang.index_word[predicted_id] == <span class="string">&#x27;&lt;end&gt;&#x27;</span>:</span><br><span class="line">            <span class="keyword">return</span> result, sentence, attention_plot</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 预测的 ID 被输送回模型</span></span><br><span class="line">        dec_input = tf.expand_dims([predicted_id], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result, sentence, attention_plot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意力权重制图函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_attention</span>(<span class="params">attention, sentence, predicted_sentence</span>):</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    ax.matshow(attention, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    fontdict = &#123;<span class="string">&#x27;fontsize&#x27;</span>: <span class="number">15</span>&#125;</span><br><span class="line"></span><br><span class="line">    ax.set_xticklabels([<span class="string">&#x27;&#x27;</span>] + sentence, fontdict=fontdict, rotation=<span class="number">90</span>)</span><br><span class="line">    ax.set_yticklabels([<span class="string">&#x27;&#x27;</span>] + predicted_sentence, fontdict=fontdict)</span><br><span class="line"></span><br><span class="line">    ax.xaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line">    ax.yaxis.set_major_locator(ticker.MultipleLocator(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    plt.savefig(<span class="string">&quot;latest.png&quot;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_model</span>(<span class="params">chk_params</span>):</span></span><br><span class="line">    chk_params.checkpoint.restore(tf.train.latest_checkpoint(chk_params.checkpoint_dir))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate</span>(<span class="params">dataset_params, model_params, sentence</span>):</span></span><br><span class="line">    result, sentence, attention_plot = evaluate(dataset_params, model_params, sentence)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Input: %s&#x27;</span> % sentence)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Predicted translation: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(result))</span><br><span class="line"></span><br><span class="line">    attention_plot = attention_plot[:<span class="built_in">len</span>(result.split(<span class="string">&#x27; &#x27;</span>)), :<span class="built_in">len</span>(sentence.split(<span class="string">&#x27; &#x27;</span>))]</span><br><span class="line">    plot_attention(attention_plot, sentence.split(<span class="string">&#x27; &#x27;</span>), result.split(<span class="string">&#x27; &#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 序列化存储文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">params_dump</span>(<span class="params">params, params_path</span>):</span></span><br><span class="line">    <span class="keyword">if</span> params <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(params_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            pickle.dump(params, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反序列化读取文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">params_load</span>(<span class="params">params_path</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(params_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">return</span> pickle.load(f)</span><br></pre></td></tr></table></figure>
<p><strong>6、跑一下</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> utils.preprocessor <span class="keyword">as</span> up</span><br><span class="line"><span class="keyword">import</span> utils.modelling <span class="keyword">as</span> md</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 是否加载序列化文件</span></span><br><span class="line">    is_load = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据实际情况写</span></span><br><span class="line">    dataset_dump_path = <span class="string">&#x27;/home/leon/PycharmProjects/attention-seq2seq/dump/dataset_params.dat&#x27;</span></span><br><span class="line">    model_dump_path = <span class="string">&#x27;/home/leon/PycharmProjects/attention-seq2seq/dump/model_params.dat&#x27;</span></span><br><span class="line">    chk_dump_path = <span class="string">&#x27;/home/leon/PycharmProjects/attention-seq2seq/dump/chk_params.dat&#x27;</span></span><br><span class="line"></span><br><span class="line">    path_to_file = <span class="string">&#x27;/home/leon/PycharmProjects/attention-seq2seq/cmn-eng/cmn.txt&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> is_load:</span><br><span class="line">        dataset_params = md.params_load(dataset_dump_path)</span><br><span class="line">        model_params = md.inference_model_building(dataset_params)</span><br><span class="line"></span><br><span class="line">        chk_params = md.chk_settings(model_params)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        en, sp = up.create_dataset(path_to_file, <span class="literal">None</span>)</span><br><span class="line">        <span class="built_in">print</span>(en[-<span class="number">1</span>])</span><br><span class="line">        <span class="built_in">print</span>(sp[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        dataset_params, dataset = md.data_preparing(path_to_file)</span><br><span class="line"></span><br><span class="line">        model_params = md.model_building(dataset_params, dataset)</span><br><span class="line"></span><br><span class="line">        chk_params = md.chk_settings(model_params)</span><br><span class="line"></span><br><span class="line">        md.params_dump(dataset_params, dataset_dump_path)</span><br><span class="line"></span><br><span class="line">        md.trainer(dataset_params, model_params, chk_params, dataset)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 恢复检查点目录 checkpoint_dir）中最新的检查点</span></span><br><span class="line">    md.restore_model(chk_params)</span><br><span class="line"></span><br><span class="line">    md.translate(dataset_params, model_params, <span class="string">u&#x27;我认为我们准备好了。&#x27;</span>)</span><br></pre></td></tr></table></figure>
结果：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-企业微信截图_16348992418770.png" width="600" height="" >
</center>
<p>明显可以看到对于某个目标词，输入里的不同词贡献度很不一样，尤其在对角线上有明显对应关系的两个词，例如：(认为，think)、(准备，ready)等等。</p>
<h3 id="attention机制的基本结构">6.4.3 Attention机制的基本结构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-05 15-32-45 的屏幕截图.png" width="300" height="" >
</center>
回头再看生成 <strong><em>Attention Value</em></strong> 的整个过程，会发现可以抽象成以下过程及公式：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-05 16-34-38 的屏幕截图.png" width="500" height="" >
</center>
<p>整个过程就像是用Query去数据库中扫描Key，并取出Key所对应的Value，通过计算Query与Key的相似度，来决定这些Value的最终贡献，<a href="https://arxiv.org/pdf/1706.03762.pdf">公式</a>表示为： <span class="math display">\[
Attention\_Value(Q,K,V)=Normalization(Similarity(Q,K))\cdot V
\]</span> 其中，<span class="math inline">\(Similarity\)</span>为相似度函数，<span class="math inline">\(Normalization\)</span>为归一化函数。 例如： 当<span class="math inline">\(Similarity\)</span>函数为做了尺度变换的点积函数<span class="math inline">\(QK^T\)</span>（反映了两个向量的夹角和向量的范数），<span class="math inline">\(Normalization\)</span>为<span class="math inline">\(Softmax\)</span>函数时，上述公式变为： <span class="math display">\[
Attention\_Value(Q,K,V)=Softmax(\frac{QK^T}{\sqrt{d_k}})\cdot V
\]</span> 其中：<span class="math inline">\(d_k\)</span>为Query向量和Key向量的空间维度，<span class="math inline">\(\frac{1}{\sqrt{d_k}}\)</span>为尺度缩放因子。</p>
<p><strong>一、Scaled Dot-Product Attention</strong></p>
<p>上面的公式在文中被叫做：Scaled Dot-Product Attention，基本结构为：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-10 13-53-21 的屏幕截图.png" width="300" height="" >
</center>
<p>这里唯一需要强调的是Mask函数，其作用是：</p>
<p><strong><em>1、Padding Masked</em></strong></p>
<p>是在Encoder和Decoder都可能使用的Mask操作，因为NLP问题中很大概率会遇到每句话长度不一样，为了平衡效率与效果，我们又经常使用batch的方式训练模型，所以利用padding填充可以让每个batch中的句子长度一样，带来的问题是这些padding的内容不应该被Attention到，所以利用padding masked给padding位置一个非常大的负数值，这样通过Softmax运算后，这些位置上的概率就是0，相当于把padding位置的信息用掩码给遮蔽了。例如pytorch下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">attention = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">attention = attention.masked_fill(mask.<span class="built_in">bool</span>(), -np.inf)</span><br></pre></td></tr></table></figure>
<p><strong><em>2、Sequence Masked</em></strong></p>
<p>是在Decoder使用的masked操作，目的是为了保证以下事实：</p>
待预测的位置<span class="math inline">\(i\)</span>只依赖<span class="math inline">\(i,i-1,i-2,...,0\)</span>时刻的输出，而不能看到<strong><em>未来</em></strong>的信息(<span class="math inline">\(i+1,i+2,...,i+n\)</span>时刻的输出)，例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-11-10 15-36-57 的屏幕截图.png" width="500" height="" >
</center>
<p>其中黄色部分为有效部分，紫色部分为masked部分，pytorch下的实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Scaled Dot-Product Attention &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_k, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 缩放因子</span></span><br><span class="line">        self.scalar = <span class="number">1</span> / np.power(d_k, <span class="number">0.5</span>)</span><br><span class="line">        self.dropout = nn.Dropout(attn_dropout)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 计算q∙k</span></span><br><span class="line">        attn = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 计算q∙k/sqr(d_k)</span></span><br><span class="line">        attn = attn * self.scalar</span><br><span class="line"></span><br><span class="line">        <span class="comment"># attention masked</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            attn = attn.masked_fill(mask.<span class="built_in">bool</span>(), -np.inf)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算softmax(q∙k/sqr(d_k))</span></span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line">        <span class="comment"># 计算softmax(q∙k/sqr(d_k))∙v</span></span><br><span class="line">        output = torch.bmm(attn, v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attn</span><br></pre></td></tr></table></figure>
<p>相似度函数可以随大家定义，比如，可以是Cosine函数、欧氏距离、甚至是一个神经网络。</p>
<p>上面机器翻译的例子是这个公式的特殊情况，即5个隐藏状态向量即是Key又是Value，还以机器翻译为例子，如果输入和输出是一样的，就会产生所谓Self Attention的效果，可以看做是通过Attention机制捕获句子本身的内在关系。 举个例子：</p>
<blockquote>
<p>许多自然环境保护主义者担心持续屠杀鲸鱼正推动这些动物走向灭绝。</p>
</blockquote>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-05 19-12-34 的屏幕截图.png" width="600" height="" >
</center>
<p>从上图可以看到“正”、“推动”、“这些”、“灭绝”对于“推动”这个词的贡献是最大的，这里既包括了距离因素也包括了语义因素，所以引入Self Attention后会更容易捕获句子中长距离依赖特征，而且更容易做并行计算。</p>
<p><strong>二、Multi-Head Attention</strong></p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-11-16%2011-54-31%20%E7%9A%84%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" width="350" height="" >
</center>
<p>Multi-Head机制是把Q、K、V向量通过<span class="math inline">\(f(x)=x \cdot w^T+b\)</span>做仿射映射，使得模型可以“关注”来自不同位置的、不同表示子空间的隐含信息，且由于这些向量是相互独立的，所以可以做并行计算，又因为所有“Head”维度之和等于变换前“Head”维度，所以总的计算成本没变。Multi-Head Attention由以下四部分组成：</p>
<ul>
<li>仿射映射层，将向量映射拆分成若干“Multi-Head” <span class="math display">\[f(X)=X \cdot W^T+B\]</span></li>
<li>对每个“Multi-Head”做Scaled Dot-Product Attention <span class="math display">\[head_i = Scaled\_Dot\_Product\_Attention(QW_i^Q,KW_i^K,VW_i^V)\]</span></li>
<li>把上述输出结果做横向拼接 <span class="math display">\[Multi\_Head\_Vector= Concat(head_1, ..., head_h)\]</span></li>
<li>把拼接结果做线性映射得到最终Attention输出 <span class="math display">\[MultiHead(Q, K, V ) = Multi\_Head\_Vector \cdot W^O\]</span></li>
</ul>
<p>Multi-Head的pytorch实现如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Multi-Head Attention module &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拆分出的attention head数量.</span></span><br><span class="line">        self.num_of_heads = num_of_heads</span><br><span class="line">        <span class="comment"># 模型维度，例如：embedding层为词向量维度.</span></span><br><span class="line">        self.dim_of_model = dim_of_model</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型维度的设置要保证能使拆分出来的所有head维度相同</span></span><br><span class="line">        <span class="keyword">if</span> self.dim_of_model % self.num_of_heads != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Dimensions of the model must be divisible by number of attention heads.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拆分出来的每个head向量的维度</span></span><br><span class="line">        self.depth = self.dim_of_model // self.num_of_heads</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保持输入输出维度的仿射变换</span></span><br><span class="line">        self.w_qs = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line">        self.w_ks = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line">        self.w_vs = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line"></span><br><span class="line">        self.attention = ScaledDotProductAttention(self.depth,</span><br><span class="line">                                                    attn_dropout=dropout)</span><br><span class="line"></span><br><span class="line">        self.layer_norm = nn.LayerNorm(self.dim_of_model)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最终输出层</span></span><br><span class="line">        self.fc = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size, sequence_len_q, dim_of_model)，其中dim_of_model = num_of_heads * depth</span></span><br><span class="line">        batch_size, sequence_len_q, _ = q.size()</span><br><span class="line">        batch_size, sequence_len_k, _ = k.size()</span><br><span class="line">        batch_size, sequence_len_v, _ = v.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类似ResNet，对query保留输入信息</span></span><br><span class="line">        residual = q</span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size, num_of_heads, sequence_len_q, depth)</span></span><br><span class="line">        q = self.w_qs(q).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        k = self.w_qs(k).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        v = self.w_qs(v).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size * num_of_heads, sequence_len_q, depth)</span></span><br><span class="line">        q = q.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line">        k = k.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line">        v = v.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mask操作</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            mask = mask.repeat(self.num_of_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        scaled_attention, attention_weights = self.attention(q, k, v, mask=mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scaled_attention.shape=(batch_size, sequence_len_q, num_of_heads, depth)</span></span><br><span class="line">        scaled_attention = scaled_attention.view(batch_size, self.num_of_heads, sequence_len_q, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># attention_weights.shape=(batch_size, num_of_heads, sequence_len_q, sequence_len_k)</span></span><br><span class="line">        attention_weights = attention_weights.view(batch_size, self.num_of_heads, sequence_len_q, sequence_len_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拼接所有head</span></span><br><span class="line">        <span class="comment"># concat_attention.shape=(batch_size, sequence_len_q, dim_of_model)，其中dim_of_model = num_of_heads * depth</span></span><br><span class="line">        concat_attention = scaled_attention.reshape(batch_size, sequence_len_q, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 全连接层做线性输出</span></span><br><span class="line">        linear_output = self.fc(concat_attention)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加入query残差信息并做Layer Normalization归一化，见论文：https://arxiv.org/pdf/1607.06450.pdf</span></span><br><span class="line">        output = self.layer_norm(linear_output + residual)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># (num_of_heads, dim_of_model)</span></span><br><span class="line">mha = MultiHeadAttention(<span class="number">8</span>, <span class="number">512</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (batch_size, sequence_len_q, dim_of_model)</span></span><br><span class="line">q = torch.Tensor(<span class="number">16</span>, <span class="number">60</span>, <span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">output, attention_weights = mha(q, k=q, v=q, mask=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of output:&quot;&#123;0&#125;&quot;, shape of attention weight:&quot;&#123;1&#125;&quot;&#x27;</span>.<span class="built_in">format</span>(output.shape, attention_weights.shape))</span><br></pre></td></tr></table></figure></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">q.shape:  torch.Size([16, 60, 512])</span><br><span class="line">scaled_attention shape: torch.Size([16, 60, 8, 64])</span><br><span class="line">attention_weights shape: torch.Size([16, 8, 60, 60])</span><br><span class="line">concat_attention: torch.Size([16, 60, 512])</span><br><span class="line">shape of output:&quot;torch.Size([16, 60, 512])&quot;, shape of attention weight:&quot;torch.Size([16, 8, 60, 60])&quot;</span><br></pre></td></tr></table></figure>
<p><strong><em>三、Position-wise Feed-Forward Networks</em></strong></p>
<p>主要用来做Attention信息的非线性组合，类似于使用了1×1卷积操作，输入序列上每个位置的词生成的Attention信息都会有一个前馈网络做这种非线性组合，注意是每个“位置”都会做但不同位置使用相同的线性变换，所以被叫做“position-wise”或“point-wise”，同时也意味着位置间可以做并行计算，公式如下： <span class="math display">\[
FFN(x) = max(0, xW_1 + b_1)W_2 + b_2
\]</span> 两个子层之间采用relu做激活，同样为了更好的保留输入信息和有利于梯度传播，也会增加一个残差连接，代码如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim_of_model, d_ff</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        <span class="comment"># 类似做1×1卷积，self.w_1 = nn.Conv1d(dim_of_model, d_ff, 1)</span></span><br><span class="line">        self.w_1 = nn.Linear(dim_of_model, d_ff)</span><br><span class="line">        <span class="comment"># 类似做1×1卷积，self.w_2 = nn.Conv1d(dim_of_model, d_ff, 1)</span></span><br><span class="line">        self.w_2 = nn.Linear(d_ff, dim_of_model)</span><br><span class="line">        self.layer_norm = nn.LayerNorm(dim_of_model)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line">        output = self.w_2(F.relu(self.w_1(x)))</span><br><span class="line">        output = self.layer_norm(output + residual)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></p>
<p><strong><em>五、Positional Encoding &amp; Positional Embedding</em></strong></p>
<p>我们知道，RNN类神经网络在结构上天然具有序列学习能力，从而将词与词之间的位置关系可以很好的学到，而CNN利用zero-padding及通道编码位置信息，使得空间信息可以被捕获到，相关论文：《<a href="https://arxiv.org/pdf/2108.07884.pdf">Global Pooling, More than Meets the Eye:Position Information is Encoded Channel-Wise in CNNs</a>》，对没有使用这两种结构的网络就需要某种机制帮助考虑词与词在序列中的相对或绝对位置信息。这种机制应该既能隐含位置信息从而捕捉长依赖，又能做并行计算加快训练速度。通过类似word2vec这种机制能够把词的语义压缩在某个低维空间中（即Embedding的维度），且语义相近的词在空间中距离相近，同样的，除了语义距离外，词与词之间的绝对或相对距离也可以通过某种编码或Embedding的方法引入到模型中，这样既考虑了词与词之间的语义相关性又考虑了它们的距离相关性，例如：下面两个句子，分词后的“词”完全一样，语义向量也一样，但词放在不同的位置则意思南辕北辙：</p>
<blockquote>
<p>我喜欢苗苗，因为她从不做作。</p>
</blockquote>
<blockquote>
<p>我从不喜欢苗苗，因为她做作。</p>
</blockquote>
<p>假设，语义向量为:<span class="math inline">\(S_n\)</span>，位置向量为<span class="math inline">\(P_m\)</span>，两种做法：</p>
<p>1、如果<span class="math inline">\(m=n\)</span>，则<span class="math inline">\(S_n+P_n\)</span>相当于把词的位置信息和语义信息压缩到了一个<span class="math inline">\(n\)</span>维空间下，随后通过网络学习权重<span class="math inline">\(W\)</span>；</p>
<p>2、如果<span class="math inline">\(m\neq n\)</span>，则可以通过向量拼接方式实现：<span class="math inline">\([S_n;P_m]\)</span>，随后通过网络学习权重<span class="math inline">\(W_s\)</span>和<span class="math inline">\(W_p\)</span>。</p>
<p>关于<span class="math inline">\(P_m\)</span>的生成同样也是两类方法：编码方式或者学习Embedding方式：</p>
<ul>
<li>Positional Encoding 可以采用固定公式生成位置的绝对编码或者相对编码： 1、按照自然数递增编码，如：1、2、3...：位置间的关系本应“平等”，但顺序编码会使得数值大小严重影响这种“平等”性，产生数据bias； 2、类似one-hot或者dummy方式编码：如：10000，01000，...：编码空间和文本长度有关系，且不能编码到任意空间维度； 3、直觉上词与词局部的相对位置信息会比全局的绝对位置信息来的重要些，所以采用有界周期函数编码，能够做到一定范围内编码与文本长度无关、位置数据无bias、可以体现出词的偏序关系，例如，sine或cosine函数，一种做法是（ps：可以有无数种做法）： 假设，编码维度为<span class="math inline">\(d_{model}\)</span>，则在不同维度上使用不同编码函数如下： <span class="math display">\[
\begin{align*}
PE_{(pos,2i)} &amp;= sin(pos/10000^{2i/d_{model}})\\
PE_{(pos,2i+1)} &amp;= cos(pos/10000^{2i/d_{model}})
\end{align*}
\]</span> 其中<span class="math inline">\(pos\)</span>是位置，<span class="math inline">\(i\)</span>是维度。位置编码的每个维度都对应于一个正弦曲线, 其波长形成从<span class="math inline">\(2\pi\)</span>到<span class="math inline">\(10000 \cdot 2 \pi\)</span>的等比级数。 代码如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line"></span><br><span class="line">        pe = torch.zeros(max_len, d_model, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>).<span class="built_in">float</span>()</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        length = <span class="built_in">input</span>.size(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.pe[:, :length]</span><br></pre></td></tr></table></figure></li>
<li><p>Positional Embedding 不使用固定函数生成位置信息隐向量，类似word embedding，通过学习方式获得，相关论文见：《<a href="https://arxiv.org/pdf/1705.03122.pdf">Convolutional Sequence to Sequence Learning</a>》，虽然从效果上看两者没什么区别，但个人感觉embedding方式更自然，本身被“原生集成”在了模型中，且一旦与输入序列的embedding向量做“加法”操作，计算开销可以忽略不计。</p>
<p>关于位置编码的一些深入研究，可以看以下文章：</p>
<p>1、《<a href="https://openreview.net/pdf?id=09-528y2Fgf">Rethinking Positional Encoding in Language Pre-training</a>》</p>
<p>2、《<a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/">Transformer Architecture:The Positional Encoding</a>》</p>
<p>3、《<a href="https://openreview.net/pdf?id=onxoVA9FxMw">On Position Embeddings in BERT</a>》</p></li>
</ul>
<p>至此，Transformer里会用到的一些基本结构介绍完毕。</p>
<h2 id="transformer">6.5. Transformer</h2>
<h3 id="基本原理-2">6.5.1 基本原理</h3>
<p>与标准Sequence2Sequence模型类似，Transformer版本的模型也是由Encoder和Decoder两大部分组成：</p>
<p>1、输入序列经过若干个Encoder，为序列中每个词生成一个输出。</p>
<p>2、Decoder利用Encoder的输出以及Attention信息预测下一个词。</p>
大的框架如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-25 10-36-09 的屏幕截图.png" width="500" height="" >
</center>
<p>Encoder之间相互独立，每个Encoder又由两大部分组成：自身的Multi-Head Attention模块和前馈神经网络模块组成：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-2021-11-25 10-58-44 的屏幕截图.png" width="330" height="" >
</center>
<p>Decoder之间相互独立，每个Decoder又由三大部分组成：自身的Masked Multi-Head Attention模块、由Encoder产生并输入的Multi-Head Attention信息和前馈神经网络模块组成：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-11-25%2011-12-43%20的屏幕截图.png" width="600" height="" >
</center>
<p>完整的标准Transformer结构如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/2021-09-18-机器学习与人工智能技术分享-第六章-循环神经网络与Transformers-the transformer" width="390" height="" >
</center>
<p>需要注意几个地方：</p>
<ul>
<li>Encoder的输入部分除了Word Embedding外还有描述词序的Positional Embedding，这两个向量维度相同，且执行“加法”操作后输入到Encoder；</li>
<li>Encoder的Multi-Head Attention做了Padding Masked；</li>
<li>Encoder每个子层都有一个残差连接（类似ResNet）帮助梯度更好更深的传播；</li>
<li>Encoder的Position-wise前馈神经网络后面接了归一化层，用于降低模型方差；</li>
<li>Transformer有多个Encoder串联；</li>
<li>Decoder的Masked Multi-Head Attention既做了Padding Masked又做了Sequence Masked；</li>
<li>Decoder的Multi-Head Attention做了Padding Masked；</li>
<li>Decoder除了使用Word Embedding外还有描述词序的Positional Embedding；</li>
<li>Decoder的Position-wise前馈神经网络后面接了归一化层，用于降低模型方差；</li>
<li>Transformer有多个Decoder串联。</li>
</ul>
<h3 id="代码实践-2">6.5.2 代码实践</h3>
<ul>
<li><p>Encoder Layer &amp; Encoder <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># padding填充，为公共方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_attn_pad_mask</span>(<span class="params">seq_q, seq_k</span>):</span></span><br><span class="line">    batch_size, len_q = seq_q.size()</span><br><span class="line">    batch_size, len_k = seq_k.size()</span><br><span class="line">    pad_attn_mask = seq_k.data.eq(<span class="number">0</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> pad_attn_mask.expand(batch_size, len_q, len_k)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;每个Encoder层由两部分组成.</span></span><br><span class="line"><span class="string">      1. multi-head self-attention.</span></span><br><span class="line"><span class="string">      2. position-wise fully connected feed-forward network.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, d_ff, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">      <span class="built_in">super</span>(EncoderLayer, self).__init__()</span><br><span class="line">      self.mul_attn = MultiHeadAttention(num_of_heads, dim_of_model, dropout)</span><br><span class="line">      self.pos_ffn = PositionwiseFeedForward(dim_of_model, d_ff)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, query, padding_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">      output, attention_weights = self.mul_attn.forward(</span><br><span class="line">          query, query, query, mask=padding_mask)</span><br><span class="line"></span><br><span class="line">      output = self.pos_ffn(output)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Transformer有多个Encoder串联.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size, num_of_layers=<span class="number">6</span>, num_of_heads=<span class="number">8</span>, dim_of_model=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">               d_ff=<span class="number">512</span>, dropout=<span class="number">0.1</span>, max_length=<span class="number">2000</span></span>):</span></span><br><span class="line">      <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">      <span class="comment"># vocab_size 词典大小</span></span><br><span class="line">      <span class="comment"># Encoder个数</span></span><br><span class="line">      self.n_layers = num_of_layers</span><br><span class="line">      <span class="comment"># Multi-head数</span></span><br><span class="line">      self.num_of_heads = num_of_heads</span><br><span class="line">      <span class="comment"># 模型维度</span></span><br><span class="line">      self.dim_of_model = dim_of_model</span><br><span class="line">      <span class="comment"># 仿射变换输出维度</span></span><br><span class="line">      self.d_ff = d_ff</span><br><span class="line">      self.dropout_rate = dropout</span><br><span class="line">      <span class="comment"># 序列最大长度</span></span><br><span class="line">      self.max_length = max_length</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 输入的Embedding层</span></span><br><span class="line">      self.input_emb = nn.Embedding(vocab_size, dim_of_model)</span><br><span class="line">      <span class="comment"># 输入的词序embedding层</span></span><br><span class="line">      self.pos_emb = PositionalEncoding(dim_of_model, max_len=max_length)</span><br><span class="line">      self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Encoder层</span></span><br><span class="line">      self.layers = nn.ModuleList([</span><br><span class="line">          EncoderLayer(num_of_heads, dim_of_model, d_ff, dropout=dropout)</span><br><span class="line">          <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_of_layers)])</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, padded_input</span>):</span></span><br><span class="line">      enc_slf_attn_list = []</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 词向量Embedding</span></span><br><span class="line">      enc_outputs = self.input_emb(padded_input)</span><br><span class="line">      <span class="comment"># 词向量Embedding + 词序Embedding</span></span><br><span class="line">      enc_outputs += self.pos_emb(enc_outputs)</span><br><span class="line">      enc_output = self.dropout(enc_outputs)</span><br><span class="line"></span><br><span class="line">      slf_attn_mask = get_attn_pad_mask(padded_input, padded_input)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Encoder层的多级串联</span></span><br><span class="line">      <span class="keyword">for</span> enc_layer <span class="keyword">in</span> self.layers:</span><br><span class="line">          enc_output, enc_slf_attn = enc_layer(enc_output, slf_attn_mask)</span><br><span class="line">          enc_slf_attn_list += [enc_slf_attn]</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> enc_output, enc_slf_attn_list</span><br><span class="line"></span><br><span class="line">sample_encoder = Encoder(<span class="number">200</span>)</span><br><span class="line">q = torch.randint(<span class="number">1</span>, <span class="number">10</span>, (<span class="number">64</span>, <span class="number">62</span>))</span><br><span class="line">sample_encoder_output, enc_slf_attn_list = sample_encoder(q)</span><br><span class="line"><span class="built_in">print</span>(sample_encoder_output.shape)</span><br></pre></td></tr></table></figure></p></li>
<li>Decoder Layer &amp; Decoder <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_subsequent_mask</span>(<span class="params">seq</span>):</span></span><br><span class="line">  sz_b, len_s = seq.size()</span><br><span class="line">  subsequent_mask = torch.triu(</span><br><span class="line">      torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=<span class="number">1</span>)</span><br><span class="line">  subsequent_mask = subsequent_mask.unsqueeze(<span class="number">0</span>).expand(sz_b, -<span class="number">1</span>, -<span class="number">1</span>)  <span class="comment"># b x ls x ls</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> subsequent_mask</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;每个Decoder层由两部分组成.</span></span><br><span class="line"><span class="string">      1. multi-head self-attention.</span></span><br><span class="line"><span class="string">      2. encoder-decoder multi-head self-attention.</span></span><br><span class="line"><span class="string">      3. position-wise fully connected feed-forward network.</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, d_ff, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">      <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">      self.mul_attn = MultiHeadAttention(num_of_heads, dim_of_model, dropout)</span><br><span class="line">      self.enc_attn = MultiHeadAttention(num_of_heads, dim_of_model, dropout)</span><br><span class="line">      self.pos_ffn = PositionwiseFeedForward(dim_of_model, d_ff)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, dec_input, enc_output, dec_self_attn_mask=<span class="literal">None</span>, dec_enc_attn_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">      dec_output, dec_slf_attn = self.mul_attn(</span><br><span class="line">          dec_input, dec_input, dec_input, mask=dec_self_attn_mask)</span><br><span class="line"></span><br><span class="line">      dec_output, dec_enc_attn = self.enc_attn(</span><br><span class="line">          dec_output, enc_output, enc_output, mask=dec_enc_attn_mask)</span><br><span class="line"></span><br><span class="line">      dec_output = self.pos_ffn(dec_output)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> dec_output, dec_slf_attn, dec_enc_attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transformer有多个Decoder串联.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, tgt_vocab_size, num_of_layers=<span class="number">6</span>, num_of_heads=<span class="number">8</span>, dim_of_model=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 d_ff=<span class="number">512</span>, dropout=<span class="number">0.1</span>, max_length=<span class="number">2000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># vocab_size 词典大小</span></span><br><span class="line">        <span class="comment"># Encoder个数</span></span><br><span class="line">        self.n_layers = num_of_layers</span><br><span class="line">        <span class="comment"># Multi-head数</span></span><br><span class="line">        self.num_of_heads = num_of_heads</span><br><span class="line">        <span class="comment"># 模型维度</span></span><br><span class="line">        self.dim_of_model = dim_of_model</span><br><span class="line">        <span class="comment"># 仿射变换输出维度</span></span><br><span class="line">        self.d_ff = d_ff</span><br><span class="line">        self.dropout_rate = dropout</span><br><span class="line">        <span class="comment"># 序列最大长度</span></span><br><span class="line">        self.max_length = max_length</span><br><span class="line"></span><br><span class="line">        self.tgt_emb = nn.Embedding(tgt_vocab_size, dim_of_model)</span><br><span class="line">        self.positional_encoding = PositionalEncoding(dim_of_model, max_len=max_length)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Decoder层串行级联</span></span><br><span class="line">        self.layers = nn.ModuleList([</span><br><span class="line">            DecoderLayer(num_of_heads, dim_of_model, d_ff, dropout=dropout)</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_of_layers)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 映射目标词维度空间到词典表维度空间</span></span><br><span class="line">        self.tgt_word_prj = nn.Linear(dim_of_model, tgt_vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        nn.init.xavier_normal_(self.tgt_word_prj.weight)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, padded_input, encoder_padded_outputs, dec_enc_attn_mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># multi-head self-attention 和 encoder-decoder multi-head self-attention的attention信息</span></span><br><span class="line">        dec_slf_attn_list, dec_enc_attn_list = [], []</span><br><span class="line"></span><br><span class="line">        dec_self_attn_subsequence_mask = get_subsequent_mask(padded_input)</span><br><span class="line">        dec_self_attn_pad_mask = get_attn_pad_mask(padded_input,</span><br><span class="line">                                                   padded_input)</span><br><span class="line">        dec_self_attn_mask = (dec_self_attn_pad_mask + dec_self_attn_subsequence_mask).gt(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        dec_output = self.dropout(self.tgt_emb(padded_input) +</span><br><span class="line">                                  self.positional_encoding(padded_input))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 多个Decoder层串行执行.</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            dec_output, dec_slf_attn, dec_enc_attn = layer(</span><br><span class="line">                dec_output, encoder_padded_outputs,</span><br><span class="line">                dec_self_attn_mask=dec_self_attn_mask,</span><br><span class="line">                dec_enc_attn_mask=dec_enc_attn_mask)</span><br><span class="line"></span><br><span class="line">            dec_slf_attn_list += [dec_slf_attn]</span><br><span class="line">            dec_enc_attn_list += [dec_enc_attn]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 把目标词维度映射到词典维度</span></span><br><span class="line">        seq_logit = self.tgt_word_prj(dec_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> seq_logit, dec_slf_attn_list, dec_enc_attn_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sample_decoder = Decoder(tgt_vocab_size=<span class="number">8000</span>)</span><br><span class="line">q = torch.randint(<span class="number">1</span>, <span class="number">10</span>, (<span class="number">64</span>, <span class="number">26</span>))</span><br><span class="line"></span><br><span class="line">output, dec_slf_attn_list, dec_enc_attn_list = sample_decoder(padded_input=q,</span><br><span class="line">                                                                      encoder_padded_outputs=sample_encoder_output)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure></li>
<li><p>Transformer <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Transformer构建.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, vocab_size=<span class="number">8000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Transformer, self).__init__()</span><br><span class="line">        self.encoder = Encoder(vocab_size)</span><br><span class="line">        self.decoder = Decoder(vocab_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, padded_input, padded_target</span>):</span></span><br><span class="line"></span><br><span class="line">        encoder_padded_outputs, enc_slf_attn_list = self.encoder(padded_input)</span><br><span class="line"></span><br><span class="line">        pred, dec_slf_attn_list, dec_enc_attn_list = self.decoder(padded_target, encoder_padded_outputs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> pred, enc_slf_attn_list, dec_slf_attn_list, dec_enc_attn_list</span><br><span class="line"></span><br><span class="line">model = Transformer()</span><br><span class="line">q = torch.randint(<span class="number">1</span>, <span class="number">10</span>, (<span class="number">64</span>, <span class="number">26</span>))</span><br><span class="line">t = torch.randint(<span class="number">1</span>, <span class="number">10</span>, (<span class="number">64</span>, <span class="number">26</span>))</span><br><span class="line">pred, *_ = model(q, t)</span><br><span class="line"><span class="built_in">print</span>(pred.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
为方便可视化，设置Encoder和Decoder的num_of_layers=1，网络结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_6/trans.png" width="600" height="" >
</center></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>transformer</tag>
        <tag>attention</tag>
        <tag>RNN</tag>
        <tag>LSTM</tag>
        <tag>第六章</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第十三章 ADAS与自动驾驶</title>
    <url>/article/a9650e95.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli89ckr14ka1sqbuno1qbuc366i.png" width=266 /> 本章对于机器学习在自动驾驶及ADAS方面的一些应用和实践做了初步介绍。 <span id="more"></span></p>
<h1 id="adas自动驾驶">13. ADAS&amp;自动驾驶</h1>
<h2 id="openpilot">13.1 Openpilot</h2>
<h3 id="项目简介">13.1.1 项目简介</h3>
<p>Comma.ai是由天才黑客George Hotz（第一个破解iPhone、PS 3的人，相关介绍：https://www.bloomberg.com/features/2015-george-hotz-self-driving-car/） 创立的专注自动驾驶的公司，目标是1000刀实现自动驾驶，但公司由于受到美国国家公路交通安全管理局的严格管制，于是“一怒之下”的把整个系统开源，取名openpilot，从功能上完全具备了目前特斯拉的autopilot具有的能力，主要表现在ACC和LKAS上。目前为止所有自动驾驶汽车都属于level 2，包括Waymo、Cruise、comma.ai、Ford、Tesla，特点是需要驾驶员坐在驾驶位且持续关注行车状态并随时接管汽车，实验室车辆在我看来也就Leve 2+，Level 3阶段，在特定路段驾驶员可以完全不用关注汽车行驶状态，目前没有厂商实现L3。openpilot目前主要能力是在6min内无需人的干预(但人需要盯着)控制本田和讴歌某几款车的加速、刹车、转向，从效果看，是我个人目前最看好的开源项目，且与我之前的构想一致：无需对汽车进行改造，无需昂贵的硬件设备，即插即用实现自动辅助驾驶。另外消费者不一定买同一品牌汽车，他们的数据也可以互相共享，从而降低自动驾驶造成的事故发生几率。</p>
<h3 id="基本概念">13.1.2 基本概念</h3>
1、CAN CAN总线：(Controller Area Network, CAN)即控制器局域网络，是由以研发和生产汽车电子产品著称的德国BOSCH公司开发的，并最终成为国际标准（ISO 11898），是国际上应用最广泛的现场总线之一。不仅用于汽车，也广泛运用于工业，商业等领域。 在汽车领域，CAN是用于连接电子控制单元[ECU]的多主串行总线标准（通讯总线）。CAN网络需要两个或多个节点进行通信。节点的复杂性可以从简单的I / O设备到具有CAN接口和复杂软件的嵌入式计算机。节点还可以是允许标准计算机通过USB或以太网端口与CAN网络上的设备进行通信的网关。所有节点通过两线总线相互连接。电线为120Ω额定双绞线。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli60hpj1j04gi91abv186d16p59.png" width="400"  />
</center>
<p>2、LIN LIN总线：(Local Interconnect Network)本地互联网，是一种低成本的串行通讯网络，用于实现汽车中的分布式电子系统控制。LIN 的目标是为现有汽车网络(例如CAN 总线)提供辅助功能，因此LIN总线是一种辅助的总线网络。在不需要CAN 总线的带宽和多功能的场合，比如智能传感器和制动装置之间的通讯使用LIN 总线可大大节省成本。 在汽车电控系统中，数据交换主要经由CAN总线完成，LIN总线是其补充与完善，不仅仅是出于成本的考量，更是（当今通讯技术发展条件下）充分保证高速数据交互效率的完美结合。 3、NEO 一个开源机器人软件开发平台,目前和 Neo 适配的智能手机只有中国厂商一加生产的一加 3 手机，只有这部手机权限足够开放，而且相机和芯片 （高通骁龙820）都符合要求，且会利用该手机的GPS。硬件成本700刀。 4、panda 通用汽车接口软件，用来控制与CAN和LIN的通信。</p>
<h3 id="系统架构">13.1.3 系统架构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli66io81lrn15221ut21mmi1vf3m.png" width="500"  />
</center>
<ul>
<li><p>汽车平台 目前只支持本田旗下几款车（且它们并没有公司间合作）： Acura ILX 2016 with AcuraWatch Plus、Honda Civic 2016 with Honda Sensing、Honda CR-V Touring 2015-2016这几款车型。通过几个接口可以扩展到其他车型，https://comma.ai/bounties.html 为鼓励计划，目前看汽车本身无需安装其他硬件设备。</p></li>
<li><p>硬件平台</p>
1、NEO/Panda用于支持CAN/LIN通信，前者是一个机器人软件开发平台，后者是与汽车通信接口软硬件，平台开源可以方便支持OpenXC 、 Kvaser、 CANBus Triple。目前在本田上的所有通信实现只依赖2个CAN总线，1个车辆CAN、1个雷达CAN。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6aip6u5sqm2ko03ed4nc2a.png" width="200" />
</center>
<p>2、雷达 使用车载雷达即可，无需安装其他雷达</p>
<p>3、摄像头、GPS、智能手机 没有使用独立的摄像头和GPS模块，而是通过一部智能手机支持，目前全球能够支持的只有一加3手机，因为其权限足够开放，配备骁龙820、6GB RAM、以及光学+电子防抖，但目前看能够承担的运算不能太复杂，例如：车道检测和车辆识别的inference部分，车道线合并等。 相关视频： https://www.youtube.com/watch?v=3lIc3WnAxw8 https://www.youtube.com/watch?v=64Wvt5pYQmE&amp;feature=youtu.be https://www.youtube.com/watch?v=EQJZvVeihZk</p></li>
<li><p>软件平台</p>
<p>1、openpilot 框架比较清晰的软件架构，后面介绍</p>
<p>2、opendbc 依据车型订制的CAN通信消息封装接口</p>
<p>3、panda 与panda硬件配合的用于和汽车CAN/LIN通信的接口，关于它的详细说明：https://medium.com/<span class="citation" data-cites="comma_ai/a-panda-and-a-cabana-how-to-get-started-car-hacking-with-comma-ai-b5e46fae8646">@comma_ai/a-panda-and-a-cabana-how-to-get-started-car-hacking-with-comma-ai-b5e46fae8646</span></p></li>
<li><p>服务平台</p>
1、仿真平台 仿真对于自动驾驶来说至关重要，openpilot目前无UI界面，通过后端跑仿真测试样例，并将结果绘图方式展示：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6mfrk11vnq1q462n091jq37.png" width="800"  />
</center>
加速仿真：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6o9q61qpfni4mfbham1bgu3k.png" width="300"  />
</center>
距离仿真：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6pva419nv18f21jrq1tb21est4h.png" width="300"  />
</center>
踏板仿真：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6t9i11jb4j51nf71iinfms4u.png" width="300"  />
</center>
加速度仿真：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli6tsav1ah0jsh18s1rvb186f5b.png" width="300"  />
</center>
2、chffr 众包的数据收集app应用，目前有 1,000,000 miles的用户上传数据，通过积分、现金鼓励的方式运营，性价比比较高，另外还有一个比较牛的东西是automatic ground truthing engine（未开源），可以自动把chffr上的数据或任意视频数据做自动gt标注。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli70g8p1ok11bp1bie10bjgau5o.png" width="400"  />
</center>
<p>不过大体做法也许可以参考下面论文，基本思路还是利用语义分割做： http://www.es.ele.tue.nl/~sander/publications/icip14.pdf http://vladlen.info/papers/playing-for-data.pdf ps：常规的思路是例如https://commacoloring.herokuapp.com/ 这样的人工标注平台，不过光它产生的这些数据就值不少钱。</p></li>
</ul>
<h3 id="软件架构">13.1.4 软件架构</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli8812s15301q59jnmcf1pjk65.png" width="800"  />
</center>
<p>代码层面，由c/c++和python完成。</p>
<h3 id="汽车基础组建">13.1.5 汽车基础组建</h3>
<p>1、Panda 一个独立的开源项目，与panda硬件配合，是汽车通信的硬件接口，支持手机/pc与汽车的CAN/LIN通信，整个硬件仅需要88刀。</p>
<p>2、Opendbc 封装标准的CAN通信消息，依据车型订制，消息结构为：</p>
identifier +11-bit标准段+29-bit扩展段，整个消息长度可扩展到8 bytes。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli89ckr14ka1sqbuno1qbuc366i.png" width="500"  />
</center>
identifier 标识了如何解析消息，dbc文件是标准的CAN消息格式，例如本田思域的一段转向控制消息： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">BO_ <span class="number">228</span> STEERING_CONTROL: <span class="number">5</span> ADAS</span><br><span class="line">  SG_ STEER_TORQUE : <span class="number">7</span>|<span class="number">16</span>@<span class="number">0</span>- (<span class="number">1</span>,<span class="number">0</span>) [-<span class="number">3840</span>|<span class="number">3840</span>] <span class="string">&quot;&quot;</span>  EPS</span><br><span class="line">  SG_ STEER_TORQUE_REQUEST : <span class="number">23</span>|<span class="number">1</span>@<span class="number">0</span>+ (<span class="number">1</span>,<span class="number">0</span>) [<span class="number">0</span>|<span class="number">1</span>] <span class="string">&quot;&quot;</span>  EPS</span><br><span class="line">  SG_ CHECKSUM : <span class="number">39</span>|<span class="number">4</span>@<span class="number">0</span>+ (<span class="number">1</span>,<span class="number">0</span>) [<span class="number">0</span>|<span class="number">15</span>] <span class="string">&quot;&quot;</span>  EPS</span><br><span class="line">  SG_ COUNTER : <span class="number">33</span>|<span class="number">2</span>@<span class="number">0</span>+ (<span class="number">1</span>,<span class="number">0</span>) [<span class="number">0</span>|<span class="number">3</span>] <span class="string">&quot;&quot;</span>  EPS</span><br></pre></td></tr></table></figure> 第一行表示该消息是转向控制，标识符为228.后面四行为与转向相关消息。每个车型的消息结构可能都不一样，所以需要各自封装：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli89qvj1or51di21oaon311f0q6v.png" width="600"  />
</center>
<p>Dbc文件抽象及其格式解析的通用代码分别在： https://github.com/commaai/openpilot/blob/v0.3.2/common/dbc.py https://github.com/commaai/openpilot/blob/v0.3.2/selfdrive/car/honda/can_parser.py</p>
<h3 id="公共组件">13.1.6 公共组件</h3>
<p>这里封装公用库函数，例如：卡尔曼滤波器、dbc文件管理、异常管理、车系管理、计算加速、参数封装、实时时间读写封装等，全为python代码。</p>
<h3 id="手机组件">13.1.7 手机组件</h3>
智能手机是openpilot的最大硬件，所有通信、数据收集、计算、展现都是通过手机作为载体。整个openpilot采用cap’n proto做消息序列化封装，使用ZMQ做消息通信，很高效，整体架构提前做了ROS 2.0想做的事。 can’n proto(https://capnproto.org/)的效率更加适用于这种嵌入式场景：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli8b4mn1j4bi0uq991fv318jo7c.png" width="200"  />
</center>
<p>ZMQ（ZeroMQ，http://zeromq.org/）是跨平台、高效的分布式消息队列，同样很适用于嵌入式场景。</p>
<ul>
<li><p>cereal 封装所有用于手机端日志记录的消息接口，由两部分组成： log.capnp，封装了手机日志记录相关接口； car.capnp，车相关抽象层，核心是CarStateCarControl接口，如果想新加一种车，需要实现这个。</p></li>
<li><p>phonelibs 封装手机相关库，纯基于c的，有些库只有so。</p></li>
</ul>
<h3 id="自动驾驶组件">13.1.8 自动驾驶组件</h3>
自适应巡航使用传统方法，这里不讲，主要讲车道辅助驾驶部分，整体结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1bli8c8t9kjj1sbo1rlc1m2l1eks89.png" width="800"  />
</center>
<ul>
<li><p>感知 在openpilot中感知主要是车道检测和传感器数据处理，前者使用的是一个深度神经网路，但网络结构没有开源，API开源，所以允许你定义模型： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">struct ModelData &#123;</span><br><span class="line">  frameId @<span class="number">0</span> :UInt32;</span><br><span class="line">  path @<span class="number">1</span> :路径数据;</span><br><span class="line">  leftLane @<span class="number">2</span> :左行车道;</span><br><span class="line">  rightLane @<span class="number">3</span> :右行车道;</span><br><span class="line">  lead @<span class="number">4</span> :前方引领车辆;</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p></li>
<li><p>定位 未看到实现</p></li>
<li><p>预测 在openpilot中预测主要是路径预测，先预测前方某个长度路径是直的还是弯的，然后将这些局部路径合成一个长路径。</p></li>
<li><p>决策 依据当前车道信息、前车距离信息、自动驾驶时长信息做控制命令生成。</p></li>
<li><p>路径规划 一个独立进程，并没有做什么规划动作，主要是根据预测阶段产生的路径及决策信息决定后续路径。</p></li>
<li><p>控制 依据前面的信息产生后续动作并通过CAN/LIN接口执行消息发送以控制汽车姿态。 代码中：</p></li>
</ul>
<p>○ 底层支持层</p>
<p>Assets用于UI字体支持； Common为封装的公共组件函数； Logcatd为独立进程，做Android日志管理，基于zmq和cap’nproto做消息通信； Proclogd为独立进程，做进程日志管理，基于zmq和cap’nproto做消息通信.</p>
<p>○ 对外交互层</p>
<p>Boardd为独立进程，用于车、机USB消息交换； Sensord为GPS/IMU接口代码，但未开源； Visiond为车道检测算法，前面有讲；</p>
<p>○ 行为执行层</p>
<p>Loggerd用于记录车辆行驶过程中的数据，用于后续模型训练； Car为封装的汽车抽象层前面有介绍； Controls为控制单元，是这一层的核心，包括了自适应巡航、距离控制、路径规划等； Radar为交互接口。</p>
<p>○ 前端表现层</p>
<p>UI用于绘制前端显示的行车线、车辆检测框、校准线等； Debug用于调试； Test/plant为相对简单的仿真后台。</p>
<h3 id="总结">13.1.9 总结</h3>
<p>总的来说，自动驾驶最终解决方案一定不是不计成本的硬件投入，而是基于普通摄像头和车载雷达的低成本高性能解决方案。 所以我认为自动驾驶的技术核心是：</p>
<p>1、工程架构能力：如何满足可扩展性、高性能等要求；</p>
<p>2、核心模块的算法能力：主要是基于深度学习，需要tradeoff性能与效果，在嵌入式环境哪怕1ms都需要争取；</p>
<p>3、数据能力：两方面，收集数据的能力和数据标注的能力；</p>
<p>4、仿真能力：决定模型效果迭代能走多快。</p>
<p>目前开源软件能让我们达到Level 2，但要实现更高级别必须解决上面4个问题。</p>
<p>百度的apollo工程架构上设计比较合理，各子系统松耦合，但是目前整个项目是个空壳子，没有相关算法支撑，仿真系统也很粗糙，另外需要车载电脑等硬件支持，在通信性能方面我也有疑虑。 Openpilot在工程架构上比较合理，在资源消耗上比较小，硬件需求不强，我认为思路是未来的发展方向之一，缺点是没有大公司支持，属于个人英雄主义，且很多东西未开源。</p>
<p>整体来说开源自动驾驶技术方面大家都不完善，而自动驾驶的场景很重要，只研究技术是不够的，在我看来未来围绕着它有三大角色：</p>
<p>1、平台</p>
<p>2、主机厂</p>
<p>3、运营商</p>
<p>虽然趋势是合作共赢，但未来大家在这方面人才上的竞争会愈发激烈。</p>
<h2 id="基于视觉的车道检测">13.2 基于视觉的车道检测</h2>
<h3 id="传统车道检测方法">13.2.1 传统车道检测方法</h3>
<p>车道检测(LD)是ADAS/自动驾驶领域中的一个基本问题，可以基于激光雷达、视觉或者多传感器融合去做。但总的来说车道检测是个比较难的问题，原因在于：车道线和道路的多样化，例如：高速路、城乡结合部、土路、不同地区、不同国家对车道线的标准不同等；道路干扰因素较多，比如：树荫、遮挡、强光反射等；恶劣的视觉环境，比如：雨、雪、雾天气等。 其中，基于视觉的方法分为传统方法和深度学习方法。 传统方法一般需要做以下工作：</p>
<ul>
<li>图像预处理 图像去噪；删除图像中不相关部分，如车辆、行人、障碍物；对图像中过暗或过亮部分做归一化修正；去除图像中阴影（如：树荫）；根据摄像头位置提取图像ROI；图像边缘检测；腐蚀膨胀等。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1c46fgh5c1mfbku5no873sfrd9.png" width="400"  />
</center></li>
<li>特征提取 通过人工方法直接在原图或通过原图生成的鸟瞰图提取亮度峰值、HOG、道路纹理、道路分割、车道曲率等特征。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1c46hoq7b1r3bfdm129uh0c1ana9.png" width="400"  />
</center></li>
<li>模型拟合 模型需要做先验假设，可以采用参数学习（典型的像直线、曲线）、半参数学习、非参学习，然后采用合适的损失函数（如Square Loss）做优化求解。典型的传统算法如Hough变换，其本质是对图像进行坐标变换，让变换结果易于检测和识别；当车道线不清晰或存在其他干扰的情况下，传统方法会利用类似Gabor滤波做消失点预测（Vanishing Point：三维空间中的两条平行线在二维空间中的交叉点，简单说就是两个车道线的交点位置），然后利用消失点做车道线预测。也可以用卡尔曼滤波利用前几帧预测下一帧车道线位置。总的来说传统方法的天花板比较明显。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1c46j7d2f3rcotc1o151jtu1etr13.png" width="500"  />
</center></li>
<li><p>上下文信息集成 利用前几帧的信息提高下一帧的预测准确度以及复用前几帧的特征减少计算量。</p></li>
<li><p>图像后处理 对车道线之类的做其他处理使其能在真实世界中表示出来。</p></li>
</ul>
<h3 id="深度学习套路">13.2.2 深度学习套路</h3>
<p>基本上，深度学习的方法出来后大家套路日趋一致：</p>
<p>1、人工或半人工标注数据集（理论上越多样化、越多越好），改进对小物体的标注</p>
<p>2、数据预处理，例如做IPM；</p>
<p>3、选择一个基础网络做自动特征提取；</p>
<p>4、构建一个多任务网络分别做：BBox Regression、Classification、Object Mask、VP Prediction等；</p>
<p>5、使用现有数据集做模型Transfer Learning（fine tune）；</p>
<p>6、使用FCN、FPN、Quantization之类的方法改进网络效果或做加速，裁剪模型降低模型大小；</p>
<p>7、使用scale权衡速度与精度；</p>
<p>8、使用类似RNN或LSTM融合上下文信息。</p>
<p>不管哪种方法，对于硬件和工程的要求越来越高，因为你要保证inference的时间是实时的。当硬件条件不佳时（车联网领域用的较多的MTK8665芯片，采用ARM架构、MALI GPU）就得在工程上做很多优化的事情，例如图片的预处理、矩阵乘法之类的需要在ARM架构下利用寄存器做优化。如果你很有钱，用高端的Nvidia芯片，那这方面麻烦会小些，但你的产品性价比可能下降。</p>
<h3 id="vanishing-point-guided-network">13.2.3 Vanishing Point Guided Network</h3>
<p>这是去年10月份提出的一个基于深度学习的方法，应该是目前为止实测效果最好的之一，亮点有：多种气候环境下的标注数据集；一个带VP预测的多任务网络。</p>
<ul>
<li><p>数据集</p>
<p>车道线数据相比其他检测、分类数据最大的不同是标注数据比较窄（车道线）且不容易标注类似的Bounding Box，而且这种标注会有以下问题：</p>
<p>1)、特征提取阶段由于convolution和pooling操作会导致信息损失甚至消失；</p>
<p>2)、由于一般网络输入会有resize操作，所以车道线的标注信息有可能因为图片太小而看不到。</p>
所以为了解决以上问题，对车道线标注采用grid-level网格级标注，示例如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1c990brk81ppk51c1sk3ki4cvg9.png" width="500"  />
</center>
<p>如果网格中的任意一个像素位于某类车道线的标注线内，则整个网格都会被标记为该类。假设网络输入为640×480，输出为80×60，缩放系数为1/8，所以启发式的可以将网格大小设置为8×8(不一定非得这么设置)。 除车道线外，还需要标注VP（消失点），当然VP的标注是纯人工标注，为道路所有车道线在远端的交叉点。注意，不管道路是直的还是弯的都会有VP。</p></li>
<li><p>整体网络结构</p>
整个网络是一个multi-task网络，可完成对车道线、路上交通标志、以及消失点的检测和识别，共享特征提取部分，有4个分支网络：预测VP的网络（VPP）、多分类网络（Multi-label）、bbox回归网络（Grid Box）、目标检测网络（Object Mask），结构描述如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1cbejbb011k1lom1rhmeiub94m.png" width="800" />
</center>
<p>需要注意，bbox回归对有固定形状的物体可以做一个box来框柱物体，但对车道线没法用一个box框定，所以文中做了一个车道线检测回归的创新：对网格里的像素，回归到与其最近的网格单元（网格粒度的regression），这样对普通物体、道路上的交通标志、车道线在检测回归上得到框架上的统一。在后处理阶段，普通物体分类只需要使用多分类网络的结果，道路上的交通标志、车道线结合bbox回归和多分类网络的结果就可知道。 整个网络的损失函数描述如下： <span class="math display">\[Loss=w_1L_{reg}+w_2L_{om}+w_3L_{ml}+w_4L_{vp}\]</span> 其中<span class="math inline">\(L_{reg}\)</span>是一个<em>grid regression L1</em>损失，<span class="math inline">\(L_{om}、L_{ml}、L_{vp}\)</span>是交叉熵损失。</p></li>
<li><p>消失点预测</p>
<p>消失点（Vanishing Point）在复杂环境下对车道线的检测等应用有较好的辅助作用，它其实是提供了相对全局的地理信息，举个例子：当行驶在没有车道线的乡间小路上，根据VP的位置可以做车道线绘制；下雨天，根据消失点可以做车道线预测。 在确定VPP损失函数上，文章做了几种尝试：</p>
<ul>
<li>使用回归损失函数：由于和其他任务的损失函数在尺度上不一致，所以很难去平衡整体函数损失；</li>
<li>使用二分类交叉熵损失函数：交叉熵本质上衡量的是实际数据的概率分布与我们假设模型的概率分布是否一致，交叉熵损失可以平衡不同任务的梯度传播（思考一个问题：平常我们经常会出于对数值平滑、控制值域范围、概率的乘法转加法等目的对数值做log运算，那么从熵的角度如何考虑这个变换的意义？）。最简单处理VP的方式是，用一个圈把VP圈出来，然后对所有像素做二分类：处于圈内还是圈外，由于天然的样本不平衡，圈外的样本远多于圈内，所以模型的稳定性和收敛性都比较差，比如所有像素倾向于全部分配到圈外。</li>
<li>使用多分类交叉熵：交叉熵的好处同上，我认为文章<strong>最大的亮点</strong>在于提出用象限去识别VP，即：以VP为中心，把图片划分为四个象限，反过来，四个象限的交叉点即为VP；VPP这个模型的通道有5个：默认通道（代表不是VP），象限1、象限2、象限3、象限4；每个像素都会出现在这5个通道中的1个，对于VP中的任何一个像素会被分配到某个象限通道且不会出现在默认通道中，当VP信息较弱时，所有像素趋向于被分配到默认通道，此时默认通道的平均置信度会比较高。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1cbp32u28aco15aso7p1qglrdi9.png" width="600" />
</center>
上图展示了两种不同方式的区别，通过这5个通道的值，可以生成VP的位置（四个象限的交汇点），计算方法如下： <span class="math display">\[P_{avg}=\frac{1-(\sum p_0(x,y))/(m×n)}{4}\]</span> <span class="math display">\[loc_{vp}=argmin_{x,y}\sum_{n=1}^4|p_{avg}-p_n(x,y)|^2\]</span> 其中<span class="math inline">\(p_{avg}\)</span>是图片中存在VP的概率，<span class="math inline">\(p_n(x,y)\)</span>是<span class="math inline">\((x,y)\)</span>在第<span class="math inline">\(n_{th}\)</span>个通道的置信度，<span class="math inline">\(m×n\)</span>是置信区域的大小，<span class="math inline">\(loc_{vp}\)</span>是VP的位置。</li>
</ul>
<p><strong>观察任务特点</strong>：VPP任务的和车道线检测任务有潜在相关性（车道线在远处的交汇点即为VP），所以如果两个任务同时进行会互相影响，因此，训练过程需要分为两个阶段：</p>
<ul>
<li><p>第一阶段仅训练VPP网络：除了VPP外，其他网络的学习率设置为0，虽然如此，可以观察到VPP训练结束后，其他网络的损失函数值会下降20%左右，因为大家共用同一套特征提取网络，也侧面印证了前面说的VPP和其他任务的先验相关性。</p></li>
<li><p>第二阶段所有网络同时训练：通过<span class="math inline">\(w_1\)</span>~<span class="math inline">\(w_4\)</span>控制不同损失的权重，权重初始值为1，当初始损失函数值出现后，这些权重值会被设置为这些损失函数值的倒数，在训练的任何阶段，如果发现损失函数值之间的尺度差异过大，则利用上面方法调整；网络不断学习，直到其在验证集上的精度收敛。</p></li>
</ul></li>
<li><p>图像后处理</p>
<ul>
<li><p>车道线：首先，在多分类网络的车道线通道抽样局部最优值，这些值对应的点是潜在的车道线分割点；其次，通过逆透视变换（IPM）生成鸟瞰图，并把上述点映射到鸟瞰图；再次，应用基于密度的聚类算法（如：DBSCAN）对上述点做聚类，注：这里有个技巧，根据纵坐标对像素点做概率降序排列，然后做分桶操作，通过这个方法降低聚类时间复杂度；最后，利用上述方法生成VP。</p></li>
<li><p>路面交通标志：首先，从多分类网络输出中对每个类以高置信度从网格回归任务中提取网格单元格；然后，我们选择每个网格的角点并将它们与附近的网格单元迭代合并；如果没有更多的相邻网格单元属于同一类，则合并终止。某些道路标记（如人行横道或安全区域）很难通过单个框定义，因此会通过网格采样进行定位。</p></li>
</ul></li>
<li>代码示例 由于三星没有公开数据集，所以只能用<a href="http://www.mohamedaly.info/datasets/caltech-lanes">Caltech Lanes Dataset</a>数据集做测试。
<ul>
<li><p>生成训练数据和测试数据标注（根据原始的点标注生成网格级标注），需要安装MATLAB，代码如下： <figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">clear all;</span><br><span class="line">close all; clc;</span><br><span class="line">category = <span class="string">&#x27;cordova1&#x27;</span>;</span><br><span class="line">addpath(genpath(<span class="string">&#x27;./caltech-lane-detection/matlab&#x27;</span>))</span><br><span class="line">path = <span class="string">&#x27;./&#x27;</span>;</span><br><span class="line">file =  sprintf(<span class="string">&#x27;/%s/labels.ccvl&#x27;</span>, category);</span><br><span class="line">gLabelData = ccvLabel(<span class="string">&#x27;read&#x27;</span>, [path file]);</span><br><span class="line">h = <span class="number">0.02</span>;</span><br><span class="line">height = <span class="number">480</span>;</span><br><span class="line">width = <span class="number">640</span>;</span><br><span class="line">gg = <span class="number">8</span>;</span><br><span class="line">grid_x = <span class="number">1</span>:gg:<span class="number">481</span>;</span><br><span class="line">grid_y = <span class="number">1</span>:gg:<span class="number">641</span>;</span><br><span class="line">thickness = <span class="number">2</span>;</span><br><span class="line">fileID = fopen(sprintf(<span class="string">&#x27;./%s.txt&#x27;</span>, category),<span class="string">&#x27;w&#x27;</span>);</span><br><span class="line">numFrames = <span class="built_in">size</span>(gLabelData.frames,<span class="number">2</span>);</span><br><span class="line">gLabelSubtypes = &#123;<span class="string">&#x27;bw&#x27;</span>, <span class="string">&#x27;sw&#x27;</span>, <span class="string">&#x27;dy&#x27;</span>, <span class="string">&#x27;by&#x27;</span>, <span class="string">&#x27;sy&#x27;</span>&#125;;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:numFrames</span><br><span class="line">    <span class="built_in">disp</span>(sprintf(<span class="string">&#x27;frame: %03d&#x27;</span>,<span class="built_in">i</span>))</span><br><span class="line">    numLanes = <span class="built_in">size</span>(gLabelData.frames(<span class="built_in">i</span>).labels, <span class="number">2</span>);</span><br><span class="line">    segs = [];</span><br><span class="line">    splines = &#123;numLanes&#125;;</span><br><span class="line">    sptypes = &#123;numLanes&#125;;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:numLanes</span><br><span class="line">    splines&#123;<span class="built_in">j</span>&#125; = ccvEvalBezSpline(gLabelData.frames(<span class="built_in">i</span>).labels(<span class="built_in">j</span>).points, h);     <span class="comment">% convert 4 point to spline</span></span><br><span class="line">    sptypes&#123;<span class="built_in">j</span>&#125; = gLabelData.frames(<span class="built_in">i</span>).labels(<span class="built_in">j</span>).subtype;</span><br><span class="line">    splines_x1 = splines&#123;<span class="built_in">j</span>&#125;;</span><br><span class="line">    splines_x2 = splines&#123;<span class="built_in">j</span>&#125;;</span><br><span class="line">    splines_x1(:,<span class="number">1</span>) = splines_x1(:,<span class="number">1</span>) - thickness;</span><br><span class="line">    splines_x2(:,<span class="number">1</span>) = splines_x2(:,<span class="number">1</span>) + thickness;</span><br><span class="line">    splines&#123;<span class="built_in">j</span>&#125; = [splines&#123;<span class="built_in">j</span>&#125;; splines_x1; splines_x2];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k = <span class="number">1</span>:<span class="built_in">size</span>(splines&#123;<span class="built_in">j</span>&#125;,<span class="number">1</span>)    <span class="comment">% make spline points into bounding box</span></span><br><span class="line">        grid_pos_x = <span class="built_in">floor</span>((splines&#123;<span class="built_in">j</span>&#125;(k,<span class="number">1</span>)<span class="number">-1</span>)/gg);</span><br><span class="line">        grid_pos_y = <span class="built_in">floor</span>((splines&#123;<span class="built_in">j</span>&#125;(k,<span class="number">2</span>)<span class="number">-1</span>)/gg);</span><br><span class="line">        xmin = grid_pos_x * gg + <span class="number">1</span>;</span><br><span class="line">        xmax = grid_pos_x * gg + gg;</span><br><span class="line">        ymin = grid_pos_y * gg + <span class="number">1</span>;</span><br><span class="line">        ymax = grid_pos_y * gg + gg;</span><br><span class="line">        grid_width = xmax - xmin;</span><br><span class="line">        grid_height = ymax - ymin;</span><br><span class="line">        inst_id = <span class="built_in">j</span>;</span><br><span class="line">        lane_id = <span class="built_in">find</span>(<span class="built_in">ismember</span>(gLabelSubtypes, sptypes&#123;<span class="built_in">j</span>&#125;));</span><br><span class="line">        segs = [segs; xmin, ymin, xmax, ymax, inst_id, lane_id];</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    segs = unique(segs, <span class="string">&#x27;rows&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">numLaneSegs = <span class="built_in">size</span>(segs, <span class="number">1</span>) - numLanes;</span><br><span class="line">fprintf(fileID,<span class="string">&#x27;/%s/f%05d.png  %d&#x27;</span>,category, <span class="built_in">i</span><span class="number">-1</span>, <span class="built_in">size</span>(segs,<span class="number">1</span>));</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:<span class="built_in">size</span>(segs,<span class="number">1</span>)</span><br><span class="line">    xmin = segs(<span class="built_in">j</span>,<span class="number">1</span>);</span><br><span class="line">    ymin = segs(<span class="built_in">j</span>,<span class="number">2</span>);</span><br><span class="line">    xmax = segs(<span class="built_in">j</span>,<span class="number">3</span>);</span><br><span class="line">    ymax = segs(<span class="built_in">j</span>,<span class="number">4</span>);</span><br><span class="line">    inst_id = segs(<span class="built_in">j</span>,<span class="number">5</span>);</span><br><span class="line">    lane_id = segs(<span class="built_in">j</span>,<span class="number">6</span>);</span><br><span class="line">    fprintf(fileID, <span class="string">&#x27; &#x27;</span>);</span><br><span class="line">    fprintf( fileID, <span class="string">&#x27; %d&#x27;</span>, xmin );</span><br><span class="line">    fprintf( fileID, <span class="string">&#x27; %d&#x27;</span>, ymin );</span><br><span class="line">    fprintf( fileID, <span class="string">&#x27; %d&#x27;</span>, xmax );</span><br><span class="line">    fprintf( fileID, <span class="string">&#x27; %d&#x27;</span>, ymax );</span><br><span class="line">    fprintf( fileID, <span class="string">&#x27; %d&#x27;</span>, lane_id ); <span class="comment">% depth data -&gt; lane_id</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fprintf(fileID,<span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">fclose(<span class="string">&#x27;all&#x27;</span>);</span><br></pre></td></tr></table></figure></p></li>
<li>生成lmdb格式的训练和测试数据，代码： <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Declare <span class="variable">$PATH_TO_DATASET_DIR</span> and <span class="variable">$PATH_TO_DATASET_LIST</span></span></span><br><span class="line">PATH_TO_DATASET_DIR=/data1/workspace/liyiran/VPGNet/caltech-lanes-dataset</span><br><span class="line">PATH_TO_DATASET_LIST=/data1/workspace/liyiran/VPGNet/caltech-lanes-dataset/dataset/all.txt</span><br><span class="line"></span><br><span class="line">../../build/tools/convert_driving_data $PATH_TO_DATASET_DIR $PATH_TO_DATASET_LIST LMDB_train</span><br><span class="line">../../build/tools/compute_driving_mean LMDB_train ./driving_mean_train.binaryproto lmdb</span><br><span class="line"></span><br><span class="line">PATH_TO_DATASET_LIST=/data1/workspace/liyiran/VPGNet/caltech-lanes-dataset/dataset/test.txt</span><br><span class="line">../../build/tools/convert_driving_data $PATH_TO_DATASET_DIR $PATH_TO_DATASET_LIST LMDB_test</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>训练模型:</p>
<ul>
<li>solver.prototxt <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">net: &quot;./train_val.prototxt&quot;</span><br><span class="line"></span><br><span class="line">test_iter: 20</span><br><span class="line">test_interval: 100</span><br><span class="line">test_compute_loss: true</span><br><span class="line"></span><br><span class="line">base_lr: 0.005</span><br><span class="line">lr_policy: &quot;step&quot;</span><br><span class="line">gamma: 0.1</span><br><span class="line">stepsize: 100000</span><br><span class="line">display: 10</span><br><span class="line">max_iter: 100000</span><br><span class="line">momentum: 0.9</span><br><span class="line">weight_decay: 0.0005</span><br><span class="line">snapshot: 2500</span><br><span class="line">snapshot_prefix: &quot;./snapshots/split&quot;</span><br><span class="line">solver_mode: GPU</span><br></pre></td></tr></table></figure></li>
<li>train.sh <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">../../build/tools/caffe train --solver=./solver.prototxt -weights ./snapshots/split_iter_100000.caffemodel -gpu all &gt;&gt; ./output/output.log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></li>
<li>pre-trained model，大概446M，传不上去，有需要单找我吧。</li>
</ul></li>
<li>后处理及模型inference
<ul>
<li>caffe_inference.cpp，inference的c++版本，需要安装配置好caffe： <figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;caffe/caffe.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> caffe;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_INPUT_SIDE 640;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MIN_INPUT_SIDE 480;</span></span><br><span class="line">std::string caffe_root = <span class="string">&quot;/data1/workspace/liyiran/VPGNet/caffe/models/vpgnet-novp/inference/&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//dump caffe feature map</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CaffeDump</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="built_in">CaffeDump</span>(<span class="keyword">const</span> std::string&amp; net_file, <span class="keyword">const</span> std::string&amp; weight_file, <span class="keyword">const</span> <span class="keyword">int</span> GPUID);</span><br><span class="line">	~<span class="built_in">CaffeDump</span>();</span><br><span class="line">	<span class="function"><span class="keyword">void</span> <span class="title">caffe_forward</span><span class="params">(cv::Mat, <span class="keyword">const</span> std::string&amp; , <span class="keyword">int</span>, <span class="keyword">const</span> std::string&amp;, <span class="keyword">int</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	<span class="function"><span class="keyword">void</span> <span class="title">preprocess</span><span class="params">(<span class="keyword">const</span> cv::Mat cv_image)</span></span>;</span><br><span class="line">	<span class="function">cv::Mat <span class="title">image_translation</span><span class="params">(cv::Mat &amp; srcImage, <span class="keyword">int</span> x0ffset, <span class="keyword">int</span> y0ffset)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	shared_ptr&lt;Net&lt;<span class="keyword">float</span>&gt; &gt; net_;</span><br><span class="line">	<span class="keyword">int</span> num_channels_;</span><br><span class="line">	<span class="keyword">float</span> threshold_;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">CaffeDump::<span class="built_in">CaffeDump</span>(<span class="keyword">const</span> std::string&amp; net_file, <span class="keyword">const</span> std::string&amp; weights_file, <span class="keyword">const</span> <span class="keyword">int</span> GPUID)</span><br><span class="line">&#123;</span><br><span class="line">	Caffe::<span class="built_in">SetDevice</span>(GPUID);</span><br><span class="line">	Caffe::<span class="built_in">set_mode</span>(Caffe::GPU);</span><br><span class="line"></span><br><span class="line">	net_.<span class="built_in">reset</span>(<span class="keyword">new</span> Net&lt;<span class="keyword">float</span>&gt;(net_file, caffe::TEST));</span><br><span class="line">	net_-&gt;<span class="built_in">CopyTrainedLayersFrom</span>(weights_file);</span><br><span class="line"></span><br><span class="line">	Blob&lt;<span class="keyword">float</span>&gt;* input_layer = net_-&gt;<span class="built_in">input_blobs</span>()[<span class="number">0</span>];</span><br><span class="line">	num_channels_ = input_layer-&gt;<span class="built_in">channels</span>();</span><br><span class="line">	<span class="built_in">CHECK_EQ</span>(num_channels_, <span class="number">3</span>) &lt;&lt; <span class="string">&quot;Input layer should have 3 channels.&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CaffeDump::~<span class="built_in">CaffeDump</span>() &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">CaffeDump::caffe_forward</span><span class="params">(cv::Mat cv_image, <span class="keyword">const</span> std::string&amp; layer_name, <span class="keyword">int</span> channel, <span class="keyword">const</span> std::string&amp; filepath, <span class="keyword">int</span> factor)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (cv_image.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">		std::cout &lt;&lt; <span class="string">&quot;Can not reach the image&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">preprocess</span>(cv_image);</span><br><span class="line"></span><br><span class="line">	net_-&gt;<span class="built_in">ForwardFrom</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">	shared_ptr&lt;caffe::Blob&lt;<span class="keyword">float</span>&gt;&gt; layerData =net_-&gt;<span class="built_in">blob_by_name</span>(layer_name);</span><br><span class="line">	<span class="keyword">int</span> batch_size = layerData-&gt;<span class="built_in">num</span>();</span><br><span class="line">	<span class="keyword">int</span> dim_features = layerData-&gt;<span class="built_in">count</span>() / batch_size;</span><br><span class="line">	<span class="keyword">int</span> channels = layerData-&gt;<span class="built_in">channels</span>();</span><br><span class="line">	<span class="keyword">int</span> height = layerData-&gt;<span class="built_in">height</span>();</span><br><span class="line">	<span class="keyword">int</span> width = layerData-&gt;<span class="built_in">width</span>();</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;batch size:&quot;</span> &lt;&lt; batch_size &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;dimension:&quot;</span> &lt;&lt; dim_features &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;channels:&quot;</span> &lt;&lt; channels &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;height:&quot;</span> &lt;&lt; height &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;width:&quot;</span> &lt;&lt; width &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;channels*height*width:&quot;</span> &lt;&lt; channels*height*width &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">CHECK_LT</span>(channel, channels) &lt;&lt; <span class="string">&quot;Input channel number should small than channels.&quot;</span>;</span><br><span class="line">	<span class="keyword">float</span>* feature_blob_data;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; batch_size; ++n)</span><br><span class="line">	&#123;</span><br><span class="line">		feature_blob_data = layerData-&gt;<span class="built_in">mutable_cpu_data</span>() +</span><br><span class="line">			layerData-&gt;<span class="built_in">offset</span>(n);</span><br><span class="line"></span><br><span class="line">		<span class="keyword">float</span> *arr = (<span class="built_in"><span class="keyword">float</span></span>(*))<span class="built_in">malloc</span>(height*width*<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>));</span><br><span class="line">		<span class="keyword">int</span> idx = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> d = <span class="number">0</span>; d &lt; dim_features; ++d)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">if</span> (idx &lt; height*width)&#123;</span><br><span class="line">				arr[idx] = feature_blob_data[idx+channel*height*width];</span><br><span class="line">				idx++;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">int</span> len = height*width;</span><br><span class="line">		<span class="keyword">float</span> min_val = *std::<span class="built_in">min_element</span> (arr,arr+len);</span><br><span class="line">		<span class="keyword">float</span> max_val = *std::<span class="built_in">max_element</span>(arr,arr+len);</span><br><span class="line">		std::cout &lt;&lt; <span class="string">&quot;size of feature:&quot;</span> &lt;&lt; idx &lt;&lt; <span class="string">&quot;,max &quot;</span></span><br><span class="line">			&lt;&lt; *std::<span class="built_in">max_element</span>(arr,arr+len) &lt;&lt; <span class="string">&quot;,min &quot;</span> &lt;&lt;*std::<span class="built_in">min_element</span> (arr,arr+len)&lt;&lt;std::endl;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;len;i++)&#123;</span><br><span class="line">			arr[i] = <span class="number">255</span>*(arr[i]-min_val)/(max_val-min_val);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="function"><span class="keyword">const</span> cv::Mat <span class="title">img</span><span class="params">(cv::Size(width, height), CV_32FC1, arr)</span></span>;</span><br><span class="line"></span><br><span class="line">		cv::<span class="built_in">imwrite</span>(filepath+<span class="string">&quot;.jpg&quot;</span>, img);</span><br><span class="line">		<span class="function"><span class="keyword">const</span> cv::Mat <span class="title">scale_img</span><span class="params">(cv::Size(width*factor, height*factor), CV_32FC1, arr)</span></span>;</span><br><span class="line">		cv::<span class="built_in">imwrite</span>(filepath+<span class="string">&quot;_&quot;</span>+std::<span class="built_in">to_string</span>(factor)+<span class="string">&quot;x.jpg&quot;</span>, scale_img);</span><br><span class="line"></span><br><span class="line">		cv::Mat srcImage=cv::<span class="built_in">imread</span>(filepath+<span class="string">&quot;_&quot;</span>+std::<span class="built_in">to_string</span>(factor)+<span class="string">&quot;x.jpg&quot;</span>);</span><br><span class="line">		<span class="keyword">int</span> x0ffset = <span class="number">-180</span>;</span><br><span class="line">		<span class="keyword">int</span> y0ffset = <span class="number">-180</span>;</span><br><span class="line">		<span class="comment">//图像左平移不改变大小</span></span><br><span class="line">		cv::Mat resultImage1 = <span class="built_in">image_translation</span>(srcImage, x0ffset, y0ffset);</span><br><span class="line">		cv::<span class="built_in">imwrite</span>(filepath+<span class="string">&quot;_&quot;</span>+std::<span class="built_in">to_string</span>(factor)+<span class="string">&quot;x-off.jpg&quot;</span>, resultImage1);</span><br><span class="line">		std::cout &lt;&lt; (<span class="string">&quot;\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">	&#125;  <span class="comment">// for (int n = 0; n &lt; batch_size; ++n)</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">cv::Mat <span class="title">CaffeDump::image_translation</span><span class="params">(cv::Mat &amp; srcImage, <span class="keyword">int</span> x0ffset, <span class="keyword">int</span> y0ffset)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> nRows = srcImage.rows;</span><br><span class="line">	<span class="keyword">int</span> nCols = srcImage.cols;</span><br><span class="line">	<span class="function">cv::Mat <span class="title">resultImage</span><span class="params">(srcImage.size(), srcImage.type())</span></span>;</span><br><span class="line">	<span class="comment">//int nRows = srcImage.rows + abs(y0ffset);</span></span><br><span class="line">	<span class="comment">//int nCols = srcImage.cols + abs(x0ffset);</span></span><br><span class="line">	<span class="comment">//cv::Mat resultImage(nRows, nCols, srcImage.type());</span></span><br><span class="line">	<span class="comment">//遍历图像</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nRows; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nCols; j++)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="comment">//映射变换</span></span><br><span class="line">			<span class="keyword">int</span> x = j - x0ffset;</span><br><span class="line">			<span class="keyword">int</span> y = i - y0ffset;</span><br><span class="line">			<span class="comment">//边界判断</span></span><br><span class="line">			<span class="keyword">if</span> (x &gt;= <span class="number">0</span> &amp;&amp; y &gt;= <span class="number">0</span> &amp;&amp; x &lt; nCols &amp;&amp; y &lt; nRows)</span><br><span class="line">			&#123;</span><br><span class="line">				resultImage.at&lt;cv::Vec3b&gt;(i, j) = srcImage.ptr&lt;cv::Vec3b&gt;(y)[x];</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> resultImage;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">CaffeDump::preprocess</span><span class="params">(<span class="keyword">const</span> cv::Mat cv_image)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="function">cv::Mat <span class="title">cv_new</span><span class="params">(cv_image.rows, cv_image.cols, CV_32FC3, cv::Scalar(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span></span>;</span><br><span class="line">	<span class="keyword">int</span> height = cv_image.rows;</span><br><span class="line">	<span class="keyword">int</span> width = cv_image.cols;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Mean normalization (in this case it may not be the average of the training) */</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> h = <span class="number">0</span>; h &lt; height; ++h) &#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> w = <span class="number">0</span>; w &lt; width; ++w) &#123;</span><br><span class="line">			cv_new.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">0</span>] = <span class="built_in"><span class="keyword">float</span></span>(cv_image.at&lt;cv::Vec3b&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">0</span>]);<span class="comment">// - float(102.9801);</span></span><br><span class="line">			cv_new.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">1</span>] = <span class="built_in"><span class="keyword">float</span></span>(cv_image.at&lt;cv::Vec3b&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">1</span>]);<span class="comment">// - float(115.9465);</span></span><br><span class="line">			cv_new.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">2</span>] = <span class="built_in"><span class="keyword">float</span></span>(cv_image.at&lt;cv::Vec3b&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">2</span>]) ;<span class="comment">//- float(122.7717);</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* Max image size comparation to know if resize is needed */</span></span><br><span class="line">	<span class="keyword">int</span> max_side = <span class="built_in">MAX</span>(height, width);</span><br><span class="line">	<span class="keyword">int</span> min_side = <span class="built_in">MIN</span>(height, width);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">float</span> max_side_scale = <span class="built_in"><span class="keyword">float</span></span>(max_side) / MAX_INPUT_SIDE;</span><br><span class="line">	<span class="keyword">float</span> min_side_scale = <span class="built_in"><span class="keyword">float</span></span>(min_side) / MIN_INPUT_SIDE;</span><br><span class="line">	<span class="keyword">float</span> max_scale = <span class="built_in">MAX</span>(max_side_scale, min_side_scale);</span><br><span class="line">	<span class="keyword">float</span> img_scale = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (max_scale &gt; <span class="number">1</span>)</span><br><span class="line">		img_scale = <span class="built_in"><span class="keyword">float</span></span>(<span class="number">1</span>) / max_scale;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> height_resized = <span class="built_in"><span class="keyword">int</span></span>(height * img_scale);</span><br><span class="line">	<span class="keyword">int</span> width_resized = <span class="built_in"><span class="keyword">int</span></span>(width * img_scale);</span><br><span class="line"></span><br><span class="line">	cv::Mat cv_resized;</span><br><span class="line">	cv::<span class="built_in">resize</span>(cv_new, cv_resized, cv::<span class="built_in">Size</span>(width_resized, height_resized));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">float</span> data_buf[height_resized*width_resized * <span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> h = <span class="number">0</span>; h &lt; height_resized; ++h)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> w = <span class="number">0</span>; w &lt; width_resized; ++w)</span><br><span class="line">		&#123;</span><br><span class="line">			data_buf[(<span class="number">0</span> * height_resized + h)*width_resized + w] = <span class="built_in"><span class="keyword">float</span></span>(cv_resized.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">0</span>]);</span><br><span class="line">			data_buf[(<span class="number">1</span> * height_resized + h)*width_resized + w] = <span class="built_in"><span class="keyword">float</span></span>(cv_resized.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">1</span>]);</span><br><span class="line">			data_buf[(<span class="number">2</span> * height_resized + h)*width_resized + w] = <span class="built_in"><span class="keyword">float</span></span>(cv_resized.at&lt;cv::Vec3f&gt;(cv::<span class="built_in">Point</span>(w, h))[<span class="number">2</span>]);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	net_-&gt;<span class="built_in">blob_by_name</span>(<span class="string">&quot;data&quot;</span>)-&gt;<span class="built_in">Reshape</span>(<span class="number">1</span>, num_channels_, height_resized, width_resized);</span><br><span class="line">	Blob&lt;<span class="keyword">float</span>&gt; * input_blobs = net_-&gt;<span class="built_in">input_blobs</span>()[<span class="number">0</span>];</span><br><span class="line">	<span class="built_in"><span class="keyword">switch</span></span> (Caffe::<span class="built_in">mode</span>()) &#123;</span><br><span class="line">		<span class="keyword">case</span> Caffe::CPU:</span><br><span class="line">			<span class="built_in">memcpy</span>(input_blobs-&gt;<span class="built_in">mutable_cpu_data</span>(), data_buf, <span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>) * input_blobs-&gt;<span class="built_in">count</span>());</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">case</span> Caffe::GPU:</span><br><span class="line">			<span class="built_in">caffe_gpu_memcpy</span>(<span class="built_in"><span class="keyword">sizeof</span></span>(<span class="keyword">float</span>)* input_blobs-&gt;<span class="built_in">count</span>(), data_buf, input_blobs-&gt;<span class="built_in">mutable_gpu_data</span>());</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">default</span>:</span><br><span class="line">			<span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Unknow Caffe mode&quot;</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> * argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (argc &lt; <span class="number">2</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Usage caffe_test &lt;net.prototxt&gt; &lt;net.caffemodel&gt; &lt;inputFile_txt&gt; &lt;outputDirectory&gt; &lt;output_prefix&gt;\n&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> GPUID = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">	std::string  prototxt_file = argv[<span class="number">1</span>];</span><br><span class="line">	std::string caffemodel_file = argv[<span class="number">2</span>];</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">char</span> * input_files_path = argv[<span class="number">3</span>];</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">char</span> * output_directory = argv[<span class="number">4</span>];</span><br><span class="line"></span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;Reading the given prototxt file : &quot;</span> &lt;&lt; prototxt_file &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;Reading the given caffemodel file: &quot;</span> &lt;&lt; caffemodel_file &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">	FILE * fs;</span><br><span class="line">	<span class="keyword">char</span> * image_path = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">size_t</span> buff_size = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">ssize_t</span> read;</span><br><span class="line"></span><br><span class="line">	fs = <span class="built_in">fopen</span>(input_files_path, <span class="string">&quot;r&quot;</span>);</span><br><span class="line">	<span class="keyword">if</span> (!fs) &#123;</span><br><span class="line">		std::cout &lt;&lt; <span class="string">&quot;Unable to open the file.&quot;</span> &lt;&lt; input_files_path &lt;&lt; std::endl;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function">CaffeDump <span class="title">dump</span><span class="params">(prototxt_file.c_str(), caffemodel_file.c_str(), GPUID)</span></span>;</span><br><span class="line"></span><br><span class="line">	cv::Mat image = cv::<span class="built_in">imread</span>(input_files_path, CV_LOAD_IMAGE_COLOR);</span><br><span class="line">	std::cout &lt;&lt; input_files_path &lt;&lt; std::endl;</span><br><span class="line">	<span class="comment">//dump.caffe_forward(image, &quot;bb-output-tiled&quot;, 0);</span></span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">5</span>; i++)&#123;</span><br><span class="line">		dump.<span class="built_in">caffe_forward</span>(image, <span class="string">&quot;multi-label&quot;</span>, i, <span class="string">&quot;./l&quot;</span>+std::<span class="built_in">to_string</span>(i), <span class="number">8</span>);&#125;</span><br><span class="line">	dump.<span class="built_in">caffe_forward</span>(image, <span class="string">&quot;data&quot;</span> ,<span class="number">2</span>, <span class="string">&quot;./org&quot;</span>, <span class="number">1</span>);</span><br><span class="line">	<span class="comment">//dump.caffe_forward(image, &quot;type-conv-tiled&quot; ,0);</span></span><br><span class="line"></span><br><span class="line">	BlobProto blob_proto;</span><br><span class="line">	string mean_file = <span class="string">&quot;/data1/workspace/liyiran/VPGNet/caffe/models/vpgnet-novp/driving_mean_train.binaryproto&quot;</span>;</span><br><span class="line">	<span class="built_in">ReadProtoFromBinaryFileOrDie</span>(mean_file, &amp;blob_proto);</span><br><span class="line">	Blob&lt;<span class="keyword">float</span>&gt; data_mean_;</span><br><span class="line">	data_mean_.<span class="built_in">FromProto</span>(blob_proto);</span><br><span class="line">	std::cout &lt;&lt; <span class="string">&quot;mean file:&quot;</span> &lt;&lt; data_mean_.<span class="built_in">num</span>() &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; data_mean_.<span class="built_in">channels</span>() &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; data_mean_.<span class="built_in">height</span>() &lt;&lt; std::endl;</span><br><span class="line">	std::cout &lt;&lt; data_mean_.<span class="built_in">width</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>make.sh，具体路径根据实际机器情况自行配置： <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=/usr/local/boost/lib:/usr/local/cuda/lib64:/usr/local/lib</span><br><span class="line">g++ -std=c++11 caffe_inference.cpp `pkg-config --libs opencv` -I /data1/workspace/liyiran/VPGNet/caffe/build/ -I /data1/workspace/liyiran/VPGNet/caffe/build/src/  -L /data1/workspace/liyiran/VPGNet/caffe/build/lib/ -o caffe_inference -lboost_system -lcaffe -lglog -g</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><p>python版inference及后处理</p>
<ul>
<li><p>deploy.prototxt</p>
<p><a href="https://vivounicorn.github.io/images/ai_chapter_13/deploy.prototxt">点击下载 deploy.prototxt 文件</a></p></li>
<li><p>py_inference.py: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;Agg&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> NaN, Inf, arange, isscalar, asarray, array</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> scipy.signal <span class="keyword">as</span> signal</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"><span class="keyword">from</span> compiler.ast <span class="keyword">import</span> flatten</span><br><span class="line"></span><br><span class="line">caffe_root = <span class="string">&#x27;/data1/workspace/liyiran/VPGNet/caffe/&#x27;</span></span><br><span class="line"></span><br><span class="line">deployPrototxt = <span class="string">&#x27;../deploy.prototxt&#x27;</span></span><br><span class="line">modelFile = <span class="string">&#x27;../snapshots/split_iter_100000.caffemodel&#x27;</span></span><br><span class="line">meanFile = <span class="string">&#x27;/models/vpgnet-novp/driving_mean_train.binaryproto&#x27;</span></span><br><span class="line">imageListFile = <span class="string">&#x27;./image_list.txt&#x27;</span></span><br><span class="line">resultFile = <span class="string">&#x27;PredictResult.txt&#x27;</span></span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"></span><br><span class="line">colors = &#123;<span class="number">1</span>:<span class="string">&#x27;r&#x27;</span>, <span class="number">2</span>:<span class="string">&#x27;b&#x27;</span>, <span class="number">3</span>:<span class="string">&#x27;g&#x27;</span>, <span class="number">4</span>:<span class="string">&#x27;k&#x27;</span>, <span class="number">5</span>:<span class="string">&#x27;y&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#网络初始化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initilize</span>():</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;initilize ... &#x27;</span></span><br><span class="line">    caffe.set_mode_gpu()</span><br><span class="line">    caffe.set_device(<span class="number">0</span>)</span><br><span class="line">    net = caffe.Net(deployPrototxt, modelFile,caffe.TEST)</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_mean</span>(<span class="params">binMean,npyMean</span>):</span></span><br><span class="line">    blob = caffe.proto.caffe_pb2.BlobProto()</span><br><span class="line">    bin_mean = <span class="built_in">open</span>(binMean, <span class="string">&#x27;rb&#x27;</span> ).read()</span><br><span class="line">    blob.ParseFromString(bin_mean)</span><br><span class="line">    arr = np.array( caffe.io.blobproto_to_array(blob) )</span><br><span class="line">    npy_mean = arr[<span class="number">0</span>]</span><br><span class="line">    np.save(npyMean, npy_mean )</span><br><span class="line"></span><br><span class="line"><span class="comment">#取出网络中的params和net.blobs的中的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">image, net</span>):</span></span><br><span class="line">    <span class="comment"># input preprocessing: &#x27;data&#x27; is the name of the input blob == net.inputs[0]</span></span><br><span class="line">    transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>: net.blobs[<span class="string">&#x27;data&#x27;</span>].data.shape&#125;)</span><br><span class="line">    transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    binMean=caffe_root + meanFile</span><br><span class="line">    npyMean=caffe_root+<span class="string">&#x27;/models/vpgnet-novp/driving_mean_train.npy&#x27;</span></span><br><span class="line">    convert_mean(binMean,npyMean)</span><br><span class="line">    transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, np.load(npyMean).mean(<span class="number">1</span>).mean(<span class="number">1</span>)) <span class="comment"># mean pixel</span></span><br><span class="line">    transformer.set_raw_scale(<span class="string">&#x27;data&#x27;</span>, <span class="number">255</span>)</span><br><span class="line">    <span class="comment"># the reference model operates on images in [0,255] range instead of [0,1]</span></span><br><span class="line">    transformer.set_channel_swap(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))</span><br><span class="line">    <span class="comment"># the reference model has channels in BGR order instead of RGB</span></span><br><span class="line"></span><br><span class="line">    net.blobs[<span class="string">&#x27;data&#x27;</span>].data[...] = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, caffe.io.load_image(image))</span><br><span class="line">    out = net.forward()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;# blob info of net...&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n&#x27;</span>.join(<span class="built_in">str</span>(k)+<span class="string">&quot;:&quot;</span>+<span class="built_in">str</span>(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> [(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.blobs.items()])</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;# param info of net...&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n&#x27;</span>.join(<span class="built_in">str</span>(k)+<span class="string">&quot;:&quot;</span>+<span class="built_in">str</span>(v) <span class="keyword">for</span> k,v <span class="keyword">in</span> [(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.params.items()])</span><br><span class="line">    <span class="comment">#网络提取L6c的卷积核</span></span><br><span class="line">    <span class="comment">#filters = net.params[&#x27;L6c&#x27;][0].data</span></span><br><span class="line">    <span class="comment">#with open(&#x27;FirstLayerFilter.pickle&#x27;,&#x27;wb&#x27;) as f:</span></span><br><span class="line">    <span class="comment">#   pickle.dump(filters,f)</span></span><br><span class="line">    <span class="comment">#vis_square(filters.transpose(0, 2, 3, 1))</span></span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span>(<span class="params">net,layer_name,channels,fname,single_layer=<span class="number">0</span>,factor=<span class="number">8</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> net.blobs.has_key(layer_name):</span><br><span class="line"> 	<span class="built_in">print</span> <span class="string">&quot;layer&#x27;s name is not exist.&quot;</span></span><br><span class="line">	<span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> channels &lt; <span class="number">1</span>:</span><br><span class="line">    	fea = net.blobs[layer_name].data[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">elif</span> single_layer == <span class="number">0</span>:</span><br><span class="line">   	fea = net.blobs[layer_name].data[<span class="number">0</span>][<span class="number">0</span>:channels]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fea = net.blobs[layer_name].data[<span class="number">0</span>][channels-<span class="number">1</span>:channels]</span><br><span class="line"></span><br><span class="line">    <span class="comment">#multi_label_shifted = fea</span></span><br><span class="line">    multi_label_shifted = np.zeros(fea.shape)</span><br><span class="line">    multi_label_shifted[:,<span class="number">1</span>:,<span class="number">1</span>:] = fea[:,:-<span class="number">1</span>,:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    vis_and_resize(multi_label_shifted,<span class="number">0</span>,<span class="number">0</span>,factor,fname)</span><br><span class="line">    <span class="keyword">if</span> channels &gt;= <span class="number">1</span>:</span><br><span class="line">    	prob_histogram(multi_label_shifted,fname)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_and_resize</span>(<span class="params">data, padsize=<span class="number">1</span>, padval=<span class="number">0</span>, factor=<span class="number">8</span>, fname=<span class="string">&#x27;heatmap.jpg&#x27;</span></span>):</span></span><br><span class="line">    data -= data.<span class="built_in">min</span>()</span><br><span class="line">    data /= data.<span class="built_in">max</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#让合成图为方</span></span><br><span class="line">    n = <span class="built_in">int</span>(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</span><br><span class="line">    padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</span><br><span class="line">    data = np.pad(data, padding, mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=(padval, padval))</span><br><span class="line">    <span class="comment">#合并卷积图到一个图像中</span></span><br><span class="line"></span><br><span class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</span><br><span class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(data.shape[<span class="number">1</span>], data.shape[<span class="number">0</span>]),dpi=<span class="number">1</span>)</span><br><span class="line">    plt.subplots_adjust(top=<span class="number">1</span>,bottom=<span class="number">0</span>,left=<span class="number">0</span>,right=<span class="number">1</span>,hspace=<span class="number">0</span>,wspace=<span class="number">0</span>)</span><br><span class="line">    frame = plt.gca()</span><br><span class="line">    frame.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    frame.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    plt.imshow(data)</span><br><span class="line">    plt.savefig(fname)</span><br><span class="line">    plt.close(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    img = cv2.imread(fname)</span><br><span class="line">    height, width = img.shape[:<span class="number">2</span>]</span><br><span class="line">    img = cv2.resize(img, <span class="literal">None</span>, fx=factor, fy=factor, interpolation=cv2.INTER_AREA)</span><br><span class="line">    name = fname.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(name)==<span class="number">2</span>:</span><br><span class="line">    	cv2.imwrite(name[<span class="number">0</span>]+<span class="string">&quot;_8x.&quot;</span>+name[<span class="number">1</span>], img)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">	cv2.imwrite(fname+<span class="string">&quot;_8x.jpg&quot;</span>, img)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prob_histogram</span>(<span class="params">prob,fname=<span class="string">&#x27;heatmap_his.jpg&#x27;</span></span>):</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">30</span>, <span class="number">15</span>))</span><br><span class="line">    plt.plot(prob.flat)</span><br><span class="line">    name = fname.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(name)==<span class="number">2</span>:</span><br><span class="line">	plt.savefig(name[<span class="number">0</span>]+<span class="string">&quot;_his.&quot;</span>+name[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">	plt.savefig(fname+<span class="string">&quot;_his.jpg&quot;</span>)</span><br><span class="line">    plt.close(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line">    width = prob.shape[<span class="number">1</span>] * prob.shape[<span class="number">2</span>]</span><br><span class="line">    x_vals = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, width))</span><br><span class="line">    y_vals = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, width))</span><br><span class="line">    z_vals = []</span><br><span class="line">    <span class="keyword">for</span> p1 <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,prob.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="comment">#print smapling_peaks(prob.tolist()[0][p1])</span></span><br><span class="line">	<span class="keyword">for</span> p2 <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,prob.shape[<span class="number">2</span>]):</span><br><span class="line">		z_vals.append(prob.tolist()[<span class="number">0</span>][p1][p2])</span><br><span class="line">    ax.plot(x_vals, y_vals, z_vals)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(name)==<span class="number">2</span>:</span><br><span class="line">	plt.savefig(name[<span class="number">0</span>]+<span class="string">&quot;_3d.&quot;</span>+name[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">       	plt.savefig(fname+<span class="string">&quot;_3d.jpg&quot;</span>)</span><br><span class="line">    plt.close(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">peakdet</span>(<span class="params">v, delta, x = <span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Converted from MATLAB script at http://billauer.co.il/peakdet.html</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns two arrays</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    function [maxtab, mintab]=peakdet(v, delta, x)</span></span><br><span class="line"><span class="string">    %PEAKDET Detect peaks in a vector</span></span><br><span class="line"><span class="string">    %        [MAXTAB, MINTAB] = PEAKDET(V, DELTA) finds the local</span></span><br><span class="line"><span class="string">    %        maxima and minima (&quot;peaks&quot;) in the vector V.</span></span><br><span class="line"><span class="string">    %        MAXTAB and MINTAB consists of two columns. Column 1</span></span><br><span class="line"><span class="string">    %        contains indices in V, and column 2 the found values.</span></span><br><span class="line"><span class="string">    %</span></span><br><span class="line"><span class="string">    %        With [MAXTAB, MINTAB] = PEAKDET(V, DELTA, X) the indices</span></span><br><span class="line"><span class="string">    %        in MAXTAB and MINTAB are replaced with the corresponding</span></span><br><span class="line"><span class="string">    %        X-values.</span></span><br><span class="line"><span class="string">    %</span></span><br><span class="line"><span class="string">    %        A point is considered a maximum peak if it has the maximal</span></span><br><span class="line"><span class="string">    %        value, and was preceded (to the left) by a value lower by</span></span><br><span class="line"><span class="string">    %        DELTA.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    % Eli Billauer, 3.4.05 (Explicitly not copyrighted).</span></span><br><span class="line"><span class="string">    % This function is released to the public domain; Any use is allowed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    maxtab = []</span><br><span class="line">    mintab = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> x <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        x = arange(<span class="built_in">len</span>(v))</span><br><span class="line"></span><br><span class="line">    v = asarray(v)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(v) != <span class="built_in">len</span>(x):</span><br><span class="line">        sys.exit(<span class="string">&#x27;Input vectors v and x must have same length&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isscalar(delta):</span><br><span class="line">        sys.exit(<span class="string">&#x27;Input argument delta must be a scalar&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> delta &lt;= <span class="number">0</span>:</span><br><span class="line">        sys.exit(<span class="string">&#x27;Input argument delta must be positive&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    mn, mx = Inf, -Inf</span><br><span class="line">    mnpos, mxpos = NaN, NaN</span><br><span class="line">    lookformax = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> arange(<span class="built_in">len</span>(v)):</span><br><span class="line">        this = v[i]</span><br><span class="line">        <span class="keyword">if</span> this &gt; mx:</span><br><span class="line">            mx = this</span><br><span class="line">            mxpos = x[i]</span><br><span class="line">        <span class="keyword">if</span> this &lt; mn:</span><br><span class="line">            mn = this</span><br><span class="line">            mnpos = x[i]</span><br><span class="line">        <span class="keyword">if</span> lookformax:</span><br><span class="line">            <span class="keyword">if</span> this &lt; mx-delta:</span><br><span class="line">                maxtab.append((mxpos, mx))</span><br><span class="line">                mn = this</span><br><span class="line">                mnpos = x[i]</span><br><span class="line">                lookformax = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> this &gt; mn+delta:</span><br><span class="line">                mintab.append((mnpos, mn))</span><br><span class="line">                mx = this</span><br><span class="line">                mxpos = x[i]</span><br><span class="line">                lookformax = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> array(maxtab), array(mintab)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smapling_peaks</span>(<span class="params">series</span>):</span></span><br><span class="line">    window = signal.general_gaussian(<span class="number">51</span>, p=<span class="number">1</span>, sig=<span class="number">5</span>)</span><br><span class="line">    filtered = signal.fftconvolve(window, series)</span><br><span class="line">    filtered = (np.average(series) / np.average(filtered)) * filtered</span><br><span class="line">    filtered = np.roll(filtered, -<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line">    maxtab, mintab = peakdet(filtered,<span class="built_in">abs</span>(<span class="built_in">min</span>(filtered)))</span><br><span class="line">    <span class="comment">#plot(filtered, color=&#x27;red&#x27;)</span></span><br><span class="line">    <span class="comment">#plot(series, color=&#x27;blue&#x27;)</span></span><br><span class="line">    <span class="comment">#scatter(array(maxtab)[:,0], array(maxtab)[:,1], color=&#x27;blue&#x27;)</span></span><br><span class="line">    <span class="keyword">return</span> array(maxtab)[:,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post_processing</span>(<span class="params">oname, fname, clo, th=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> colors.has_key(clo):</span><br><span class="line">    	<span class="built_in">print</span> <span class="string">&#x27;color key error!&#x27;</span></span><br><span class="line">  	<span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    name = fname.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line">    img2 = cv2.imread(name[<span class="number">0</span>]+<span class="string">&quot;_8x.&quot;</span>+name[<span class="number">1</span>],<span class="number">0</span>)</span><br><span class="line">    height, width = img2.shape[:<span class="number">2</span>]</span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    min_val = <span class="built_in">min</span>(flatten(img2.tolist()))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(height):</span><br><span class="line">        peaks = smapling_peaks(img2[i].tolist()).tolist()</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> peaks[:]:</span><br><span class="line">		<span class="keyword">if</span> <span class="built_in">abs</span>(img2[i].tolist()[<span class="built_in">int</span>(item)]-min_val)&lt;=th:</span><br><span class="line">			peaks.remove(item)</span><br><span class="line"></span><br><span class="line">    	y.extend([i]*<span class="built_in">len</span>(peaks))</span><br><span class="line">        x.extend(peaks)</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(width, height),dpi=<span class="number">1</span>)</span><br><span class="line">    plt.subplots_adjust(top=<span class="number">1</span>,bottom=<span class="number">0</span>,left=<span class="number">0</span>,right=<span class="number">1</span>,hspace=<span class="number">0</span>,wspace=<span class="number">0</span>)</span><br><span class="line">    frame = plt.gca()</span><br><span class="line">    frame.axes.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    frame.axes.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    org = cv2.imread(oname)</span><br><span class="line">    plt.imshow(org)</span><br><span class="line">    plt.xticks([]), plt.yticks([])</span><br><span class="line">    plt.plot(x,y, marker=<span class="string">&#x27;o&#x27;</span>, c=colors[clo],markersize=<span class="number">200</span>)</span><br><span class="line">    plt.savefig(name[<span class="number">0</span>]+<span class="string">&quot;_post.&quot;</span>+name[<span class="number">1</span>])</span><br><span class="line">    plt.close(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y, clo</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    net = initilize()</span><br><span class="line">    testimage = <span class="string">&#x27;f00125.png&#x27;</span></span><br><span class="line">    newt = testimage.split(<span class="string">&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    layer_name = <span class="string">&#x27;multi-label&#x27;</span></span><br><span class="line">    net = inference(testimage, net)</span><br><span class="line">    <span class="comment">#extract_features(net,layer_name, channels=2,fname=&#x27;data_2_&#x27;+testimage,single_layer=1,factor=8)</span></span><br><span class="line">    extract_features(net,layer_name, channels=<span class="number">3</span>,fname=<span class="string">&#x27;data_3_&#x27;</span>+testimage,single_layer=<span class="number">1</span>,factor=<span class="number">8</span>)</span><br><span class="line">    extract_features(net,layer_name, channels=<span class="number">4</span>,fname=<span class="string">&#x27;data_4_&#x27;</span>+testimage,single_layer=<span class="number">1</span>,factor=<span class="number">8</span>)</span><br><span class="line">    extract_features(net,layer_name, channels=<span class="number">5</span>,fname=<span class="string">&#x27;data_5_&#x27;</span>+testimage,single_layer=<span class="number">1</span>,factor=<span class="number">8</span>)</span><br><span class="line">    <span class="comment">#extract_features(net,layer_name, channels=6,fname=&#x27;data_6_&#x27;+testimage,single_layer=1,factor=8)</span></span><br><span class="line">    <span class="comment">#post_processing(testimage, &#x27;data_2_&#x27;+testimage, 1)</span></span><br><span class="line">    x1,y1,z1 = post_processing(testimage, <span class="string">&#x27;data_3_&#x27;</span>+testimage, <span class="number">1</span>)</span><br><span class="line">    x2,y2,z2 = post_processing(<span class="string">&#x27;data_3_&#x27;</span>+newt[<span class="number">0</span>]+<span class="string">&#x27;_post.&#x27;</span>+newt[<span class="number">1</span>], <span class="string">&#x27;data_4_&#x27;</span>+testimage, <span class="number">4</span>)</span><br><span class="line">    x3,y3,z3 = post_processing(<span class="string">&#x27;data_4_&#x27;</span>+newt[<span class="number">0</span>]+<span class="string">&#x27;_post.&#x27;</span>+newt[<span class="number">1</span>], <span class="string">&#x27;data_5_&#x27;</span>+testimage, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    x = []</span><br><span class="line">    x.extend(x1)</span><br><span class="line">    x.extend(x2)</span><br><span class="line">    x.extend(x3)</span><br><span class="line">    y = []</span><br><span class="line">    y.extend(y1)</span><br><span class="line">    y.extend(y2)</span><br><span class="line">    y.extend(y3)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> x,<span class="string">&#x27;,&#x27;</span>,y</span><br><span class="line">    data = np.c_[x,y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(data)):</span><br><span class="line">    	<span class="built_in">print</span> <span class="string">&#x27;[&#x27;</span>,data[i][<span class="number">0</span>],<span class="string">&#x27;,&#x27;</span>,data[i][<span class="number">4</span>],<span class="string">&#x27;],&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#post_processing(&#x27;data_5_&#x27;+newt[0]+&#x27;_post.&#x27;+newt[1], &#x27;data_6_&#x27;+testimage, 5)</span></span><br></pre></td></tr></table></figure></p></li>
</ul>
不同通道后处理后演示如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_13/image_1cbr4iu57354pdj1a331jnhhie9.png" width="800"  />
</center></li>
</ul></li>
</ul>
<h1 id="references">References</h1>
<p>如有遗漏请提醒我补充：</p>
<p align="left">
1、《Understanding the Bias-Variance Tradeoff》http://scott.fortmann-roe.com/docs/BiasVariance.html
</p>
<p align="left">
2、《Boosting Algorithms as Gradient Descent in Function Space》http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.6893&amp;rep=rep1&amp;type=pdf
</p>
<p align="left">
3、《Optimal Action Extraction for Random Forests and Boosted Trees》http://www.cse.wustl.edu/~ychen/public/OAE.pdf
</p>
<p align="left">
4、《Applying Neural Network Ensemble Concepts for Modelling Project Success》http://www.iaarc.org/publications/fulltext/Applying_Neural_Network_Ensemble_Concepts_for_Modelling_Project_Success.pdf
</p>
<p align="left">
5、《Introduction to Boosted Trees》https://homes.cs.washington.edu/~tqchen/data/pdf/BoostedTree.pdf
</p>
<p align="left">
6、《Machine Learning:Perceptrons》http://ml.informatik.uni-freiburg.de/_media/documents/teaching/ss09/ml/perceptrons.pdf
</p>
<p align="left">
7、《An overview of gradient descent optimization algorithms》http://sebastianruder.com/optimizing-gradient-descent/
</p>
<p align="left">
8、《Ad Click Prediction: a View from the Trenches》https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf
</p>
<p align="left">
9、《ADADELTA: AN ADAPTIVE LEARNING RATE METHOD》http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf
</p>
<p align="left">
9、《Improving the Convergence of Back-Propagation Learning with Second Order Methods》http://yann.lecun.com/exdb/publis/pdf/becker-lecun-89.pdf
</p>
<p align="left">
10、《ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION》https://arxiv.org/pdf/1412.6980v8.pdf
</p>
<p align="left">
11、《Adaptive Subgradient Methods for Online Learning and Stochastic Optimization》http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf
</p>
<p align="left">
11、《Sparse Allreduce: Efficient Scalable Communication for Power-Law Data》https://arxiv.org/pdf/1312.3020.pdf
</p>
<p align="left">
12、《Asynchronous Parallel Stochastic Gradient Descent》https://arxiv.org/pdf/1505.04956v5.pdf
</p>
<p align="left">
13、《Large Scale Distributed Deep Networks》https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf
</p>
<p align="left">
14、《Introduction to Optimization —— Second Order Optimization Methods》https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/13-Optimization/04-secondOrderOpt.pdf
</p>
<p align="left">
15、《On the complexity of steepest descent, Newton’s and regularized Newton’s methods for nonconvex unconstrained optimization》http://www.maths.ed.ac.uk/ERGO/pubs/ERGO-09-013.pdf
</p>
<p align="left">
16、《On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes 》http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf
</p>
<p align="left">
17、《Parametric vs Nonparametric Models》http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf
</p>
<p align="left">
18、《XGBoost: A Scalable Tree Boosting System》https://arxiv.org/abs/1603.02754
</p>
<p align="left">
19、一个可视化CNN的网站 http://shixialiu.com/publications/cnnvis/demo/
</p>
<p align="left">
20、《Computer vision: LeNet-5, AlexNet, VGG-19, GoogLeNet》http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html
</p>
<p align="left">
21、François Chollet在Quora上的专题问答：https://www.quora.com/session/Fran%C3%A7ois-Chollet/1
</p>
<p align="left">
22、《将Keras作为tensorflow的精简接口》https://keras-cn.readthedocs.io/en/latest/blog/keras_and_tensorflow/
</p>
<p align="left">
23、《Upsampling and Image Segmentation with Tensorflow and TF-Slim》https://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/
</p>
<p align="left">
24、《DENSELY CONNECTED CONVOLUTIONAL NETWORKS》http://www.cs.cornell.edu/~gaohuang/papers/DenseNet-CVPR-Slides.pdf
</p>
<p align="left">
25、https://github.com/vivounicorn/convnet-study
</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>自动驾驶</tag>
        <tag>ADAS</tag>
        <tag>第十三章</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第十二章 机器学习框架</title>
    <url>/article/b539fa9.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png" width=266 /> 本章对于机器学习任务的一些通用框架做了介绍，包括经典架构以及AutoML。 <span id="more"></span></p>
<h1 id="机器学习框架">12. 机器学习框架</h1>
<h2 id="通用机器学习框架">12.1 通用机器学习框架</h2>
<h3 id="典型场景浅析">12.1.1 典型场景浅析</h3>
<p>机器学习的应用场景几乎涵盖了生活中的各个领域，最典型的场景有：</p>
<ul>
<li><p>面向C端的互联网场景 典型的有搜索、推荐、广告、风控，特点是：</p>
<p>1、<strong>数据量巨大</strong>，每天的样本量在亿~百亿量级，甚至更高，这个规模对数据处理有极大地挑战，基本都需要分布式存储和计算系统的支持，例如：Hadoop、Spark平台。</p>
<p>2、<strong>模型复杂、特征维度高、可解释性差</strong>，由于有丰富的数据(如：文本、图像、点击行为、浏览行为、下单行为等等)，所以在此基础上可以提取及交叉生成大量特征，例如，在计算广告中，广告本身的素材、广告的位置、广告的曝光量、广告的出价、用户的Demographic画像、用户的Geographic画像、用户的浏览路径、用户的点击行为、用户所处上下文、用户使用浏览器、广告+用户+上下文环境交叉产生的各种特征。机器学习本质上只揭示相关性不得出因果性，最终的模型每个特征会对这个相关性起到一定作用，所谓三个臭皮匠顶一个诸葛亮，所以理论上数据量越大、特征越丰富、反馈越及时，模型效果越好。当然，正是为了效果而使用了大量类似DNN的模型，导致可解释性变差。</p>
<p>3、<strong>在线实时性、并发性要求高</strong>，包含两方面：模型效果的实时性和系统响应的实时性。当用户行为能更快的反馈到模型中时，模型出现好效果的概率越大，一方面模型可以实时学习，一方面特征可以实时改变，这样通过反馈数据可以迅速调整模型，就像人一样，正常来说都是吃一堑长一智，通过发生行为-&gt;得到结果-&gt;进行调整-&gt;发生行为......的不断循环而进步。成功的互联网产品流量较高且对用户体验要求很高，势必要求请求量很高时系统依然能保证实时性，所以系统返回结果到用户面前一般都是毫秒级的，这就需要一方面系统并发性要好，一方面特征处理速度要快，另一方面模型单机Inference速度要够快。</p>
<p>4、<strong>离线模型训练时效性要求高</strong>，即使采用Online Learning，也需要离线模型的支持，一般为保证模型质量，每个模型每天至少训练一次，在特征维度和样本量这么高且实验模型数量可观的场景下(最典型的如：DNN，动辄上千万、上亿、上百亿的参数规模，学一次成本又高，产生的模型又大)，势必会影响模型训练时间，甚至量大了模型训练都跑不起来，而抽样又会破坏数据的真实分布，所以对离线大规模机器学习平台的要求就很高了。</p>
<p>5、<strong>数据采集和处理速度要求高</strong>，前面也说了，内容给用户展示后势必会产生用户反馈，这个反馈日志要尽快的解析、存储和处理，并及时推给模型训练或特征更新使用，当然这里对日志丢失的容忍度相对较高。</p>
<p>6、<strong>模型线上试错成本相对较低</strong>，以广告为例，利用E&amp;E算法，通过损失曝光机会进而损失部分收益来测算模型效果，但由于反馈时间短，可以很快的做调整。</p></li>
<li><p>面向B端的场景</p>
<p>对于大B端，一类是拥有和互联网C端类似场景的B端，数据量大、样本量大、实时性和并发性高，只是特征维度未必有那么高，但带来的系统挑战一点都不低，另一类是平台提供方，例如阿里云、腾讯云，更多的是通用工程层面和产品层面的挑战。 对于中小B端，一类会上云，利用平台方提供的IaaS、PaaS甚至SaaS，另一类会搭建自己的系统，典型的应用如面向汽车金融、融资租赁的风控平台，其特点是：</p>
<p>1、<strong>数据量中等但单条数据价值高</strong>，例如，假设汽车融资租赁的客单价为7w，每年卖出100w辆车，以融后资产质量数据为例，原始标注数据量为百万级别，远远小于传统互联网数据量，但极端的看，每条数据是花了7w的成本付出验证出来的。</p>
<p>2、<strong>模型相对复杂，特征维度一般，可解释性强</strong>，受限于数据量和场景，风控模型特征维度一般不高，但对可解释性要求很高，一方面风控业务向销售以及销售要向客户解释，另一方面风控业务要通过这种解释性反向影响风控政策或调整公司整体策略。</p>
<p>3、<strong>比较重视外部合规数据合作</strong>，由于平台本身的数据量及场景限制，需要寻找外部数据合作，这种合作可以是数据粒度的也可以是模型粒度的，但一定要保证所有合作数据的授权、获取是合规的，以及用户隐私能够被很好的保护，近年来的联邦学习可能是未来一种主流合作模式。</p>
<p>4、<strong>数据效果反馈滞后，对欺诈容忍度很低</strong>，金融资产总有个还款周期，例如典型的以“月”为周期，意味着资产被放出后过了1个月才能看到资产质量，如果发生欺诈，则第1~3个MOB就可能会批量出现问题，如果出现逾期也至少要等待1个月，所以客户真实反馈很滞后。</p>
<p>5、<strong>模型试错成本高</strong>，由于客单价较高，采用传统E&amp;E算法的试错成本会很高，所以其实用性一般较差，只有小额现金贷勉强可以使用此类方法，所以离线模型训练时需要想各种办法尽量模拟真实场景，一类重要的方法是拒绝推断，另一类是订单回放对比。另外模型测试指标要求更高，以AUC为例，在计算广告场景，AUC达到0.8就可以放心上去试跑了，在汽车消费风控场景，AUC超过0.85都心中打鼓。</p>
<p>6、<strong>系统实时性、并发性要求一般但稳定性要求更高</strong>，一方面业务单量没有那么大，并发性很低，另一方面由于使用外部数据，系统响应时间达到s级都很常见，但由于一个单子就影响到一个销售的业绩和前端竞争，所以稳定性很重要，要尽量保证系统不卡壳。</p></li>
</ul>
<h3 id="系统流程">12.1.2 系统流程</h3>
一般的建模系统流程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/ml.png" width="800"  />
</center>
<p>以广告和推荐系统为例：</p>
<ul>
<li><p>数据准备和数据标注 样本生成分两部分：</p>
<p>1、<strong>离线部分</strong>，主要通过收集用户线上行为日志、已上线模型特征日志数据、业务日志数据而来，实时性要求低，一般会通过日志Stream服务收集到集群(如：hadoop集群)并持久化，所以日志设计非常关键，一方面是内容格式，要求扩展性要好，表达信息清晰而不易混淆，例如：已上线的不同版本模型的特征直接会被记录到日志中，如何区分模型、区分版本而又不会占用过多位是个有讲究的工作；另一方面是传输格式，常用的有非二进制的Xml、Json等和二进制的Pb、Thrift等，前者的好处是可读性好方便调试，但日志内容如果较为复杂传输成本高，隐私安全性低，后者反之，一般来说我们会采用后者。</p>
<p>2、<strong>在线部分</strong>，除了用日志Stream收集服务外一般还会辅以实时计算服务，实时收集和解析日志并做特征加工，一方面用于更新线上模型的离线特征，一方面为online learning算法提供实时特征，另一方面辅助类似频次控制这样的线上策略实施。</p>
<p>3、<strong>数据标注</strong>，对标注定义比较简单的场景，可以做到实时且无需人工介入的标注，例如：用户的点击行为、成交行为等，而对于图像分类、分割等复杂场景，需要专门平台甚至专人去做标注。由于目前机器学习的主流依然是监督学习，所以期待未来某天能从“人工+智能”过渡到人工智能，让机器去做人类做不了的事儿。</p></li>
<li><p>数据预处理及特征工程 我们收集到日志数据并做解析和简单处理后，一方面需要对数据做进一步清洗，例如：缺失值处理、丢弃、数据质检等，另一方面就是利用特征工程生成各种特征以备模型使用，特征要么是算法人员根据先验知识不断做实验打磨出来，要么利用特征生成算法(如：FM系列)或工具(如：FeatureTools)辅助生成，纯粹的End to End并不普遍，尤其是传统机器学习覆盖的场景，这个与原始特征的结构化复杂度有关，比如：图像识别，其原始特征是像素，很单一；一般的自然语言处理，其原子特征是字或词，相对单一，而像CTR预估的传统机器学习场景，其原始特征千差万别。</p></li>
<li><p>模型训练和融合 依据不同业务目标定义样本和构建模型，利用离线单机或并行机器学习工具训练模型，通过人工先验知识或启发式算法方式调整模型参数，得到最终离线模型。由于每个模型有各自特长，如：有的善于处理分类特征、有的则是连续特征、有的是文本特征等等，很多情况下需要融合这些模型的效果到一个大模型中，相应的可能带来效率上的挑战。当模型满足一定效果指标后(如，AUC)即可有资格到线上做实验，通过AB Test方式辅以E&amp;E策略做线上测试，效果好者逐渐扩大流量。</p></li>
<li><p>模型线上inference 真正做线上模型预测的服务，一方面取特征或生成特征，另一方面执行y=f(x)并返回结果，同步，日志系统会实时收集效果反馈。</p></li>
</ul>
<h3 id="系统架构">12.1.3 系统架构</h3>
<p>一个典型的机器学习框架如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/arch.png" width="550"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/%E7%AE%97%E6%B3%95%E6%9E%B6%E6%9E%84.png" width="800"  />
</center>
<ul>
<li>离线日志，数据存储在HDFS等分布式存储介质上，方便使用类似MapReduce方式做离线大规模数据处理，还可以复用自己或其他团队产生的用户画像信息作为特征。</li>
<li>离线特征工程，对数据做清洗和预处理后，可以利用单机或集群方式生成特征，从类型上说包括计数统计类特征、聚合类特征、单或交叉的Target Encoding特征、Embedding特征、图像特征、利用AutoML技术生成的组合特征等等，从时间切片上说包括实时特征、近实时特征、时间序列特征、T+1特征、T+N特征等等，生成的特征通过导出工具推送到线上特征工程微服务供大家使用，特征层面各个模型尽量复用。</li>
<li>在线特征工程，利用实时流微服务收集到的日志大多是用户反馈行为类日志，这部分时效性比较强的行为日志适合做实时特征，例如，用户点击了某个内容，同一地址用户短时集中点击了某个内容等等，特征生成后会自动推送到线上特征工程微服务，随后依照不同版本自动流入高响应的kv类存储介质中。</li>
<li>模型训练，以成熟的大规模机器学习框架及其他成熟机器学习框架为底层框架，中层提供常用算法组件和AutoML训练器，上层提供可视化模型构建平台，让使用者相对低成本做模型。对于大规模数据做训练，一般少不了参数服务器，其大致原理可以看<a href="https://www.zybuluo.com/vivounicorn/note/446478#432-%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8parameter-server">这里</a>。</li>
<li>模型管理器，这里对模型的参数配置、版本、效果做管理和监控，训练好的模型会被推送到线上高响应的kv类存储介质中。</li>
<li>模型应用，以微服务方式，对每个版本的模型提供Inference服务，服务间互相独立且可横向扩展，既保证了稳定性又保证了并发性。</li>
<li>AB test，应用方的AB测试服务会根据实验策略不同实时配置相应的模型应用。</li>
</ul>
<h2 id="nni-automl框架介绍">12.2 NNI AutoML框架介绍</h2>
<h3 id="automl综述">12.2.1 AutoML综述</h3>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e77na1ljmmu1fsi1718112hshi9.png" width="800"  />
</center>
<p>上图选自<a href="https://arxiv.org/pdf/1810.13306.pdf">《Taking the Human out of Learning Applications:A Survey on Automated Machine Learning》</a>一文。 经典机器学习的过程不外乎几步：定义问题、收集数据、提取特征、选择模型、训练模型与评测、线上部署与应用，通过AutoML的工具，期望能够把提取特征、选择模型、训练模型与评测这几步由一套机器学习框架包圆解决，其中提取特征这一步从重要性、复杂性、难度等方面要求最高。 形式化定义AutoML如下：</p>
<p><span class="math display">\[
\begin{eqnarray} \label{eq}
\mathop{max}\limits_{config}&amp;\quad&amp;机器学习工具的效率和效果  \nonumber  \\
s.t.&amp;\quad&amp;没有或少做人工干预 \nonumber  \\
&amp;\quad&amp;可负担的有限计算资源 \nonumber
\end{eqnarray}
\]</span></p>
其框架大致如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/automl.png" width="800"  />
</center>
<p>在经典机器学习问题中：</p>
<ul>
<li><p>特征提取</p>
1、简单组合搜索，可以采用事先定义简单组合策略，通过排列组合方式做特征生成，特征生成大多基于统计类方法，经典的工具如FeatureTools，例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/sim.png" width="400"  />
</center>
2、经典机器学习方法，利用FM、GBDT这类非线性模型作自动特征组合能够产生二阶以上特征，也可以做到特征提取+模型训练一体化，经典的论文如：<a href="https://research.fb.com/wp-content/uploads/2016/11/practical-lessons-from-predicting-clicks-on-ads-at-facebook.pdf">《Practical Lessons from Predicting Clicks on Ads at Facebook》</a>。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79lhrr214or1nrls9c1pj21q9t11.png" width="400"  />
</center>
3、DeepFM等深度学习方法，利用神经网络做更复杂特征的生成，也可以做到特征提取+模型训练一体化，但需要注意tradeoff效率和效果。 以下是DeepFM的经典结构，左边的FM部分是经典的因式分解机模式，可以高效的发现一阶和二阶特征，右边是深度网络部分，是一个前馈神经网络，用来生成二阶以上高阶特征，由于类似CTR预估问题的特征一般维度比较高且特征稀疏，大量类别特征与连续特征混排，所以神经网络的输入层一般会通过Embedding方式处理原始特征。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e79mkt3r1h1818pquqhjtm9h01e.png" width="500"  />
</center></li>
<li><p>模型选择</p>
1、不管候选集、贪心还是启发式方法，都需要定义搜索空间，在有限搜索空间内选择并训练不同模型，同时做参数搜索调优，最终得到效果最好的模型，一般框架如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/model.png" width="500"  />
</center>
2、直接指定模型，但使用别人已经训练好的不同权重做初始化，即Transfer Learning，一般框架
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/tl.png" width="500"  />
</center></li>
<li><p>模型训练</p>
<p>1、基于泰勒展开式的一阶和二阶优化算法，用来做目标函数最优化求解，代表算法：基于梯度的SGD、GD等和基于Hessian矩阵的L-BFGS等，详情可以见<a href="https://www.zybuluo.com/vivounicorn/note/446478">第四章 最优化原理</a></p>
2、非梯度优化算法，典型的有： 坐标下降法(Coordinate Descent)，属于一种非梯度优化的方法，它的每步迭代会沿某一个坐标的方向做一维搜索，通过切换不同坐标来求得目标函数局部最优解，可以看做是把一个优化问题分解为一组优化问题，直观的看：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image.png" width="400"  />
</center>
遗传算法，也是一种非梯度优化方法，更多的是利用生物进化思想做最优化求解，一般框架如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/tt.png" width="450"  />
</center></li>
<li><p>模型评测</p>
<p>1、监督学习问题 对于分类问题，常用AUC、KS、F-Measure等，对于回归问题常用MSE、RMSE、MAE等。</p>
<p>2、非监督学习问题 开放性的无监督学习，效果评价一般看实际应用问题情况，也比较需要人工做评测。</p></li>
</ul>
<p>在深度学习问题中，最经典的是通过Neural Architecture Search(NAS)的方法寻找最优网络结构，<a href="https://zhuanlan.zhihu.com/p/60414004">这里</a>有一个不错的资料。</p>
<h3 id="nni框架介绍">12.2.2 NNI框架介绍</h3>
<ul>
<li>NNI概述 NNI是18年MSRA发布的轻量级AutoML开源框架，Python编写，主要支持自动特征工程、NAS、最优模型参数搜索、模型压缩几个方面。整体设计和代码上比较简洁，上手难度比较低，支持可视化模式和命令行模式，大体情况如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7a3p3rekds1ca71b7u1uf8htl3b.png" width="600"  />
</center>
<p>1、<strong>机器学习框架方面</strong>，它基本支持市面上所有主流的框架：<a href="https://github.com/pytorch/pytorch">PyTorch</a>、<a href="https://github.com/tensorflow/tensorflow">TensorFlow</a>、<a href="https://github.com/keras-team/keras">Keras</a>、<a href="https://github.com/apache/incubator-mxnet">MXNet</a>、<a href="https://github.com/BVLC/caffe">Caffe2</a>、<a href="https://github.com/microsoft/CNTK">CNTK</a>、<a href="http://spark.apache.org/mllib/">Spark MLlib</a>、<a href="https://chainer.org/">Chainer</a>、<a href="https://pypi.org/project/Theano/">Theano</a>。</p>
<p>2、<strong>机器学习库方面</strong>，工业界用的比较多的它都支持，如：<a href="https://scikit-learn.org/stable/">Scikit-learn</a>、<a href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a>、<a href="https://catboost.ai/">CatBoost</a>、<a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a>。</p>
<p>3、<strong>模型参数搜索方面</strong>，它支持： 暴力搜索算法，包括：<a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">Random Search</a>、Grid Search、Batch； 启发式搜索算法，包括：<a href="https://arxiv.org/pdf/1703.01041.pdf">Naïve Evolution</a>、Anneal、<a href="https://arxiv.org/pdf/1603.06560.pdf">Hyperband</a>、<a href="https://arxiv.org/abs/1711.09846v1">PBT</a>； 贝叶斯优化算法，包括：<a href="https://arxiv.org/abs/1807.01774">BOHB</a>、<a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">TPE</a>、<a href="https://www.cs.ubc.ca/~hutter/papers/10-TR-SMAC.pdf">SMAC</a>、<a href="https://www.microsoft.com/en-us/research/publication/metis-robustly-tuning-tail-latencies-cloud-systems/">Metis</a>、<a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf">Gaussian Process</a>； 基于强化学习的算法，包括：<a href="https://arxiv.org/abs/1707.06347">PPO</a>。</p>
<p>4、<strong>NAS方面</strong>，几乎支持所有主流算法：<a href="https://arxiv.org/abs/1802.03268">ENAS</a>、<a href="https://arxiv.org/abs/1806.09055">DARTS</a>、P-DARTS、<a href="https://github.com/microsoft/nni/blob/master/docs/en_US/NAS/CDARTS.md#reference">CDARTS</a>、<a href="https://arxiv.org/abs/1904.00420">SPOS</a>、<a href="https://arxiv.org/pdf/1812.00332.pdf">ProxylessNAS</a>、<a href="https://arxiv.org/abs/1806.10282">Network Morphism</a>、<a href="https://arxiv.org/pdf/1912.10729.pdf">TextNAS</a>。</p>
<p>5、<strong>模型压缩方面</strong> 模型剪枝：<a href="https://arxiv.org/abs/1710.01878">AGP Pruner</a>、<a href="https://arxiv.org/pdf/1708.06519.pdf">Slim Pruner</a>、<a href="https://arxiv.org/pdf/1811.00250.pdf">FPGM Pruner</a>； 模型量化：<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Jacob_Quantization_and_Training_CVPR_2018_paper.pdf">QAT Quantizer</a>、<a href="https://arxiv.org/abs/1606.06160">DoReFa Quantizer</a>。</p>
<p>6、<strong>特征工程方面</strong>，支持<a href="https://arxiv.org/pdf/1908.10382.pdf">基于梯度搜索的算法</a>和<a href="https://github.com/microsoft/LightGBM">基于LightGBM(一种GBDT实现)的算法</a>。在自动特征工程方面，整体偏弱。</p>
<p>7、<strong>迭代停止算法方面</strong>，支持<a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46180.pdf">Medianstop</a>和<a href="http://aad.informatik.uni-freiburg.de/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf">Curve Fitting</a>，整体上够用。</p>
<p>8、<strong>部署方面</strong>，支持本地化部署、远程集群部署、基于K8s的部署。</p></li>
<li><p>逻辑框架</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/ex.png" width="600"  />
</center>
<p>1、<strong>Configuration</strong>，NNI通过配置文件指定各种策略和运行环境，一个典型的配置如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">authorName: zhanglei</span><br><span class="line">experimentName: auto-catboost</span><br><span class="line"><span class="comment"># trial的最大并发数</span></span><br><span class="line">trialConcurrency: <span class="number">10</span></span><br><span class="line"><span class="comment"># 实验最多执行时间</span></span><br><span class="line">maxExecDuration: 1h</span><br><span class="line"><span class="comment"># Trial的个数</span></span><br><span class="line">maxTrialNum: <span class="number">1000</span></span><br><span class="line"><span class="comment"># 训练平台，可选项有: local, remote, pai</span></span><br><span class="line">trainingServicePlatform: local</span><br><span class="line"><span class="comment"># 参数或结构搜索空间定义</span></span><br><span class="line">searchSpacePath: search_space.json</span><br><span class="line"><span class="comment"># 取值为false，则上面的搜索空间json文件需要定义</span></span><br><span class="line"><span class="comment"># 取值为true，则需要在代码中以Annotation方式加入搜索空间定义，例如：</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"><span class="comment"># &quot;&quot;&quot;@nni.variable(nni.choice(0.1, 0.5), name=dropout_rate)&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">#        dropout_rate = 0.5</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"><span class="comment"># 表示dropout_rate这个变量有两个取值选择：0.1或0.5</span></span><br><span class="line">useAnnotation: false</span><br><span class="line">tuner:</span><br><span class="line">  <span class="comment"># 参数或结构搜索策略定义，可选项有:</span></span><br><span class="line">  <span class="comment"># TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner, SMAC等，有些需要单独安装</span></span><br><span class="line">  builtinTunerName: TPE</span><br><span class="line">  classArgs:</span><br><span class="line">    <span class="comment"># 选择求解目标函数最大值还是最小值: maximize, minimize</span></span><br><span class="line">    optimize_mode: maximize</span><br><span class="line">trial:</span><br><span class="line">  <span class="comment"># Trial代码所在目录位置、可执行文件及GPU配置</span></span><br><span class="line">  command: python3 catboost_trainer.py</span><br><span class="line">  codeDir: .</span><br><span class="line">  gpuNum: <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>2、<strong>Search Space</strong>，搜索空间定义，一种方式是通过一个json文件定义，一种方式是代码里加Annotation，一个典型的例子如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;num_leaves&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;randint&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">20</span>, <span class="number">150</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;learning_rate&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.01</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;bagging_fraction&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.5</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;feature_fraction&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0.5</span>, <span class="number">1.0</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;reg_alpha&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;reg_lambda&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.08</span>, <span class="number">0.3</span>, <span class="number">0.5</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;lambda_l1&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">10</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;lambda_l2&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;uniform&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">0</span>, <span class="number">10</span>]&#125;,</span><br><span class="line">    <span class="string">&quot;bagging_freq&quot;</span>:&#123;<span class="string">&quot;_type&quot;</span>:<span class="string">&quot;choice&quot;</span>,<span class="string">&quot;_value&quot;</span>:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>, <span class="number">10</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> _type为choice，表示参数选择范围是_value指定的候选参数； _type为randint，表示参数选择范围是_value指定的上下界之间的整数； _type为uniform，表示参数选择范围是_value指定的上下界之间通过均匀分布得到的数； _type为uniform，表示参数选择范围是_value指定的上下界，并用均匀分布生成的参数，此外还有quniform、loguniform、qloguniform、normal、qnormal、lognormal、qlognormal几种分布。</p>
<p>3、<strong>Tuner</strong>，是参数或结构的搜索策略，利用它可以为每个Trial生成相应的参数集合，除了内置的Tuner算法外，也可以自定义Tuner，例如： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> nni.tuner <span class="keyword">import</span> Tuner</span><br><span class="line"><span class="comment"># 自定义的Tuner需要继承Tuner基类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomizedTuner</span>(<span class="params">Tuner</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, ...</span>):</span></span><br><span class="line">        ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">receive_trial_result</span>(<span class="params">self, parameter_id, parameters, value, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    返回一个Trial的最终效果指标，可以是字典(但必须由默认key)，也可以是某个值</span></span><br><span class="line"><span class="string">    parameter_id: int类型</span></span><br><span class="line"><span class="string">    parameters: 由&#x27;generate_parameters()&#x27;函数生成</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 你的代码实现</span></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate_parameters</span>(<span class="params">self, parameter_id, **kwargs</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    生成一个Trial所需的参数，并以序列化方式存储</span></span><br><span class="line"><span class="string">    parameter_id: int类型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 你的代码实现.</span></span><br><span class="line">    <span class="keyword">return</span> your_parameters</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure> 使用时需要在配置文件的tuner属性中指定，例如： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tuner:</span><br><span class="line">  <span class="comment"># 代码目录</span></span><br><span class="line">  codeDir: /home/abc/mytuner</span><br><span class="line">  <span class="comment"># 自定义Tuner类名</span></span><br><span class="line">  classFileName: my_customized_tuner.py</span><br><span class="line">  className: CustomizedTuner</span><br><span class="line">  <span class="comment"># 自定义Tuner的构造函数参数指定</span></span><br><span class="line">  classArgs:</span><br><span class="line">    arg1: value1</span><br></pre></td></tr></table></figure></p>
<p>4、<strong>Trial</strong>，是一次模型学习的尝试，它使用Tuner生成的参数初始化模型，而后做模型训练，并返回最终训练效果，一个CatBoost做AutoML的例子如下：</p>
<p>1)、定义CatBoost类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    class CatBoostModel</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> catboost <span class="keyword">as</span> cb</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> cat_fea_cleaner</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatBoostModel</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.catboost_params = kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        self.eval_ratio = kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        self.early_stopping_rounds = kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        self.num_boost_round = kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        self.cat_features = kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        self.all_features = kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.selected_features_ = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.y = <span class="literal">None</span></span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y, **kwargs</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Paramters</span></span><br><span class="line"><span class="string">        ---------</span></span><br><span class="line"><span class="string">        X : array-like numpy matrix</span></span><br><span class="line"><span class="string">            The training input samples, which shape is [n_samples, n_features].</span></span><br><span class="line"><span class="string">        y : array-like numpy matrix</span></span><br><span class="line"><span class="string">            The target values (class labels in classification, real numbers in</span></span><br><span class="line"><span class="string">            regression). Which shape is [n_samples].</span></span><br><span class="line"><span class="string">        catboost_params : dict</span></span><br><span class="line"><span class="string">            Parameters of lightgbm</span></span><br><span class="line"><span class="string">        eval_ratio : float</span></span><br><span class="line"><span class="string">            The ratio of data size. It&#x27;s used for split the eval data and train data from self.X.</span></span><br><span class="line"><span class="string">        early_stopping_rounds : int</span></span><br><span class="line"><span class="string">            The early stopping setting in lightgbm.</span></span><br><span class="line"><span class="string">        num_boost_round : int</span></span><br><span class="line"><span class="string">            num_boost_round in lightgbm.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        self.X = X</span><br><span class="line">        self.y = y</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = train_test_split(self.X,</span><br><span class="line">                                                            self.y,</span><br><span class="line">                                                            test_size=self.eval_ratio,</span><br><span class="line">                                                            random_state=random.seed(<span class="number">41</span>))</span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_sets=catboost_eval,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_selected_features</span>(<span class="params">self, topk</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        list :</span></span><br><span class="line"><span class="string">                Return the index of imprtant feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> topk &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.selected_features_ = self.feature_importance.argsort()[-topk:][::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.selected_features_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, num_iteration=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.model.predict(X, num_iteration)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_fea_importance</span>(<span class="params">self, clf, columns</span>):</span></span><br><span class="line">        importances = clf.feature_importances_</span><br><span class="line">        indices = np.argsort(importances)[::-<span class="number">1</span>]</span><br><span class="line">        importance_list = []</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columns)):</span><br><span class="line">            importance_list.append((columns[indices[f]], importances[indices[f]]))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % (f + <span class="number">1</span>, <span class="number">30</span>, columns[indices[f]], importances[indices[f]]))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;another feature importances with prettified=True\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(clf.get_feature_importance(prettified=<span class="literal">True</span>))</span><br><span class="line">        importance_df = pd.DataFrame(importance_list, columns=[<span class="string">&#x27;Features&#x27;</span>, <span class="string">&#x27;Importance&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> importance_df</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span>(<span class="params">self, X, y, test_size, random_state=<span class="number">2020</span></span>):</span></span><br><span class="line">        sss = <span class="built_in">list</span>(StratifiedShuffleSplit(</span><br><span class="line">            n_splits=<span class="number">1</span>, test_size=test_size, random_state=random_state).split(X, y))</span><br><span class="line">        X_train = np.take(X, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        X_eval = np.take(X, sss[<span class="number">0</span>][<span class="number">46</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_train = np.take(y, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_eval = np.take(y, sss[<span class="number">0</span>][<span class="number">47</span>], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [X_train, X_eval, y_train, y_eval]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">catboost_model_train</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                        df,</span></span></span><br><span class="line"><span class="params"><span class="function">                        finetune=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        target_name=<span class="string">&#x27;Label&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        id_index=<span class="string">&#x27;Id&#x27;</span></span>):</span></span><br><span class="line">        df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">        feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> self.cat_features:</span><br><span class="line">                <span class="comment">#df[i].fillna(-999, inplace=True)</span></span><br><span class="line">                <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = self.train_test_split(df[feature_name],</span><br><span class="line">                                                          df[target_name].values,</span><br><span class="line">                                                          self.eval_ratio,</span><br><span class="line">                                                          random.seed(<span class="number">41</span>))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               init_model=finetune,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_set=catboost_eval,</span><br><span class="line">                               verbose_eval=<span class="number">50</span>,</span><br><span class="line">                               plot=<span class="literal">True</span>,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line">        metrics = self.model.eval_metrics(data=catboost_eval,metrics=[<span class="string">&#x27;AUC&#x27;</span>],plot=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;AUC values:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.array(metrics[<span class="string">&#x27;AUC&#x27;</span>])))</span><br><span class="line">        <span class="keyword">return</span> self.feature_importance, metrics, self.model</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2)、定义模型训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> bz2</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_svmlight_file</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> nni</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> models.auto_catboost.catboost_model <span class="keyword">import</span> CatBoostModel</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> write_feature_importance</span><br><span class="line"><span class="keyword">from</span> feature_engineering.feature_data_processing.dataset_formater <span class="keyword">import</span> read_columns2list</span><br><span class="line"><span class="keyword">from</span> tools.feature_utils <span class="keyword">import</span> name2feature, get_default_parameters, cat_fea_cleaner</span><br><span class="line"><span class="keyword">from</span> tools.CONST <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;auto_catboost&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainer_and_tester_run</span>(<span class="params">feature_file_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                           train_file_name,</span></span></span><br><span class="line"><span class="params"><span class="function">                           test_file_name_list,</span></span></span><br><span class="line"><span class="params"><span class="function">                           feature_imp_name</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    以批量方式训练CatBoost模型</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    fea = read_columns2list(feature_file_name, <span class="number">1</span>)</span><br><span class="line">    cat_fea = [item <span class="keyword">for</span> item <span class="keyword">in</span> fea <span class="keyword">if</span> item.startswith(<span class="string">&#x27;C&#x27;</span>)]</span><br><span class="line">    chunker = pd.read_csv(train_file_name,</span><br><span class="line">                          sep=<span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                          chunksize=<span class="number">10000000</span>,</span><br><span class="line">                          low_memory=<span class="literal">False</span>,</span><br><span class="line">                          header=<span class="number">0</span>,</span><br><span class="line">                          usecols=[ColumnType.TARGET_NAME] + fea)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从Tuner获得参数</span></span><br><span class="line">    RECEIVED_PARAMS = nni.get_next_parameter()</span><br><span class="line">    logger.debug(RECEIVED_PARAMS)</span><br><span class="line">    PARAMS = get_default_parameters(<span class="string">&#x27;catboost&#x27;</span>)</span><br><span class="line">    PARAMS.update(RECEIVED_PARAMS)</span><br><span class="line">    logger.debug(PARAMS)</span><br><span class="line"></span><br><span class="line">    cb = CatBoostModel(catboost_params=PARAMS,</span><br><span class="line">                    eval_ratio=<span class="number">0.33</span>,</span><br><span class="line">                    early_stopping_rounds=<span class="number">20</span>,</span><br><span class="line">                    cat_features=cat_fea,</span><br><span class="line">                    all_features=fea,</span><br><span class="line">                    num_boost_round=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is starting...&quot;</span>)</span><br><span class="line">    clf = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 数据量太大需要分片训练</span></span><br><span class="line">    <span class="keyword">for</span> df <span class="keyword">in</span> chunker:</span><br><span class="line">        df = cat_fea_cleaner(df, ColumnType.TARGET_NAME, ColumnType.ID_INDEX, cat_fea)</span><br><span class="line">        feature_imp, val_score, clf = \</span><br><span class="line">            cb.catboost_model_train(df,</span><br><span class="line">                                clf,</span><br><span class="line">                                target_name=ColumnType.TARGET_NAME,</span><br><span class="line">                                id_index=ColumnType.ID_INDEX)</span><br><span class="line"></span><br><span class="line">        logger.info(feature_imp)</span><br><span class="line">        logger.info(val_score)</span><br><span class="line">        write_feature_importance(feature_imp,</span><br><span class="line">                                 feature_file_name,</span><br><span class="line">                                 feature_imp_name, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">del</span> df</span><br><span class="line">    gc.collect()</span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is ended.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(test_file_name_list) == <span class="number">0</span>:</span><br><span class="line">        logger.debug(<span class="string">&quot;No testing file is found.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    av_auc = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> fname <span class="keyword">in</span> test_file_name_list:</span><br><span class="line">        av_auc = av_auc + inference(clf, fea, cat_fea, fname)</span><br><span class="line">    av_auc = av_auc/<span class="built_in">len</span>(test_file_name_list)</span><br><span class="line">    nni.report_final_result(av_auc)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">clf, fea, cat_fea, test_file_name</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    线上CatBoost模型预测</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(test_file_name):</span><br><span class="line">        logger.error(<span class="string">&quot;the file &#123;0&#125; is not exist.&quot;</span>.<span class="built_in">format</span>(test_file_name))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The testing process is starting...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        df = pd.read_csv(test_file_name,</span><br><span class="line">                         sep=<span class="string">&quot;\t&quot;</span>,</span><br><span class="line">                         header=<span class="number">0</span>,</span><br><span class="line">                         usecols=[ColumnType.TARGET_NAME] + fea)</span><br><span class="line"></span><br><span class="line">        df = cat_fea_cleaner(df, ColumnType.TARGET_NAME, ColumnType.ID_INDEX, cat_fea)</span><br><span class="line">        y_pred = clf.predict(df[fea])</span><br><span class="line">        auc = roc_auc_score(df[ColumnType.TARGET_NAME].values, y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;0&#125;&#x27;s auc of prediction:&#123;1&#125;&quot;</span>.<span class="built_in">format</span>(os.path.split(test_file_name)[<span class="number">1</span>], auc))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">&quot;The inference process is ended.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> auc</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        logger.error(<span class="string">&quot;inference error with file:&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(test_file_name))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_offline</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    离线模型训练</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    base_dir = <span class="string">&#x27;/home/liyiran/PycharmProjects/DeepRisk/data/fresh.car/&#x27;</span></span><br><span class="line">    train_file_name = base_dir + <span class="string">&#x27;tt&#x27;</span></span><br><span class="line">    test_file_name_list = [base_dir + <span class="string">&#x27;outer_test_2019-01.tsv&#x27;</span>]</span><br><span class="line">    feature_file_name = base_dir + <span class="string">&#x27;features.dict&#x27;</span></span><br><span class="line">    feature_imp_name = base_dir + <span class="string">&#x27;features.imp&#x27;</span></span><br><span class="line">    trainer_and_tester_run(feature_file_name, train_file_name, test_file_name_list, feature_imp_name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run_online()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>5、<strong>Assessor</strong>，使用提前停止迭代策略评估Trial是否可以结束训练。</p></li>
<li>基本架构
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/nni.png" width="800"  />
</center>
<p><strong>NNIManager</strong>是管理中枢，负责管理串联Trial、Rest接口服务、中间数据存储、日志调用服务、配置文件服务、训练平台服务等。 <strong>SDK</strong>是一系列核心类的实现，包括MsgDispatcher、通信协议、Tuner、Trial、Assessor等，其中MsgDispatcher是整个消息处理的中心。</p></li>
<li><p>基本流程</p>
<p>NNI运转流程可用以下伪码描述：</p>
<blockquote>
<p><strong>输入</strong>: 参数搜索空间、Trial类实现、配置文件</p>
</blockquote>
<blockquote>
<p><strong>输出</strong>: 最优模型参数</p>
</blockquote>
<blockquote>
<p><strong>算法</strong>：</p>
</blockquote>
<p><span class="math display">\[
\begin{align*}
&amp; 1: For \ t = 0, ..., trial个数:\\
&amp; 2: \qquad    超参数 = 从搜索空间选择一组参数\\
&amp; 3: \qquad    最终结果= 用上步给定超参数训练trial并做效果评估\\
&amp; 4: \qquad    将执行结果反馈给nni\\
&amp; 5: \qquad    如果到达最大迭代次数或满足提前停止迭代条件:\\
&amp; 6: \qquad\qquad         结束实验\\
&amp; 7: 返回最优超参数和相应模型权重
\end{align*}
\]</span></p></li>
<li>执行效果 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nnictl stop</span><br><span class="line">nnictl create --config models/auto_catboost/config.yml -p <span class="number">8070</span></span><br></pre></td></tr></table></figure> 1、控制台上会显示一次实验的概览以及webUI地址：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7aeluhr5ab1fah1iom1gfm6g04g.png" width="800"  />
</center>
2、首页展示实验当前状态，包括参数、运行时长、当前最优模型、效果最好的Top 10 Trial情况。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7af9i68u73g1ldg8u8pd084t.png" width="800"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afap11cas11ov1najdq4150r5a.png" width="800"  />
</center>
3、详情页会展示超参数搜索情况、每个Trial执行时间和它的执行日志、参数情况，这里有个缺点是查看日志不方便，需要拷贝日志路径到宿主机上看，另外调试也不太方便。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afdp411us7ve5bepauo1src5n.png" width="800"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7afegfu1qfo1jom11hvq3p7nd64.png" width="800"  />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_12/image_1e7affike1bo6k5k5bv36619nu6h.png" width="800"  />
</center></li>
</ul>
<p>总的来说，NNI是一个非常优秀的AutoML工具，文档也比较完善，还有中文版，本文抛砖引玉，期望未来框架能更加完善，尤其在自动特征工程方面，也希望大家能贡献自己的力量上去。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第十二章</tag>
        <tag>机器学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title>有趣的微积分</title>
    <url>/article/ecf91ad8.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-%E6%9C%89%E8%B6%A3%E7%9A%84%E5%BE%AE%E7%A7%AF%E5%88%86-%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_1632901737842.png" width="266"/> 本文从无穷小的角度对微积分的来由做了简单介绍，希望从另外一个视角看待微分与积分。 <span id="more"></span></p>
<h1 id="有趣的微积分">有趣的微积分</h1>
<p>印象里我是上大一才开始学习微积分的，那个时候觉得学这个只是为了考试，抱着考高分拿奖学金的心态，没太意识到它的真实作用，随着工作年头的增加，对它的认识也从粗浅变得没那么粗浅了，微积分真的是一个伟大的发明，它已经改变了人类的进程并且在未来也将继续改变。 本文是对相关知识的回顾，大部分学习内容来源于《微积分的力量》这本书，温故而知新。（ps：中国先秦时代的思想依然指引着我们）</p>
<h2 id="变化率与导数">变化率与导数</h2>
<p>俗话说变化才是这个世界永恒不变的主题，有变化就有变化率，而世间因果或者相关关系总是由因变量和自变量组成：<span class="math inline">\(y=f(x)\)</span>，变化率即是刻画由于自变量的变化导致因变量变化的“多块？”、“多陡？”、“多不稳定？”、“多......？”，通常表示为：<span class="math inline">\(\frac{\Delta y}{\Delta x}\)</span>，想象我们去爬下面的两座山：</p>
<center>
<img alt="图1" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_1632901737842.png" width="390" height="" >
</center>
<p>显然,黑色的山，我们从山脚爬到山顶的加速度是恒定不变的，在任何一个点爬山难度都一样(忽略越往高空气越稀薄之类的因素:))，而红色的山陡峭不一，山脚的加速度和山腰的加速度完全不一样，在任何一点爬山难度不一样且越往高处爬越难。其实现实中的问题变化率几乎不太可能是恒定的，所以如何定义不断改变的变化率是微积分要解决的大难题之一。</p>
<p>最直观的理解是：变化率不再是一个恒定值，它是一个函数。怎么定义这个函数呢？我们的祖先给了答案，当一个大的问题太复杂无法一下子解决，古人教我们先把它变成一系列小问题，所有小问题解决则大问题也随之解决。这就是微分学要做的事：依据无穷小法则把这些小问题拆解为无穷小的小问题，分析和解决这些小问题后，利用积分学把它们重新组合起来，而定义变化率函数的这个问题就是通过定义导数来拆解解决的，即：<span class="math inline">\(\frac{dy}{dx}\)</span>，里面的<span class="math inline">\(dx\)</span>、<span class="math inline">\(dy\)</span>就是这些无穷小的问题，所以从另一个角度看，微积分就是描述“变化”的数学。</p>
<p>微积分有三大核心问题：</p>
<blockquote>
<ul>
<li>问题1：已知曲线的函数形式，求曲线任意一点的斜率</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>问题2：已知曲线的斜率函数，求曲线函数形式</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>问题3：已知曲线的函数形式及其上任意一点，求曲线在该点下方的面积</li>
</ul>
</blockquote>
<center>
<img alt="图2" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329647262537.png" width="390" height="" >
</center>
<p>看这个图，可以得出3个基本结论：</p>
<p>1、斜率衡量的是这条曲线的变化率</p>
<p>2、问题1与问题2是对偶问题（Duality）</p>
<p>3、面积衡量的是变化率的累积(Cumulative)</p>
<h3 id="线性函数变化率">线性函数变化率</h3>
<p>自变量和因变量呈现线性关系可以近似生活中的很多场景，比如，汽车的均速直线运动，再比如上面的理想爬山运动：</p>
<center>
<img alt="图3" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329697454285.png" width="390" height="" >
</center>
<p>不管是大人迈一次步子，还是3岁小孩儿迈一次步子，高度的变化率总是一定的。 在机器学习中有一类叫广义线性模型（GLM）的方法就是把现实问题做了一系列假设，让它变成一个线性问题，这样问题建模和求解起来就简单了很多。</p>
<h3 id="非线性函数变化率">非线性函数变化率</h3>
<p>自变量和因变量呈现非线性关系其实才是现实世界的主流，比如，钟摆运动画出的弧线、爬山运动等等。这些函数的特点是其上任何一点的变化率都不一样，以<span class="math inline">\(y=x^2\)</span>为例：</p>
<center>
<img alt="图4" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329716348114.png" width="390" height="" >
</center>
<p>我们要解决的问题是：如何得到这个抛物线上任何一点的切线斜率？ 从最简单情况来看，原点(0,0)的切线显然是横轴，它是水平的，所以切线斜率为0，其他点就没那么明显了，我们模仿2000年前阿基米德求圆周率的做法，用无穷原则把曲线切分成无穷多个小线段，以图中(0.5,0.25)为例，取上图<span class="math inline">\(x&lt;0.7\)</span>那部分的图像：</p>
<center>
<img alt="图5" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329832823188.png" width="390" height="" >
</center>
<p>可以看到曲线没那么弯曲了，更进一步，我们取<span class="math inline">\(0.49&lt;x&lt;0.51\)</span>这部分图像：</p>
<center>
<img alt="图6" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329834441777.png" width="390" height="" >
</center>
<p>曲线看上去几乎成为直线了，这个时候切线的斜率是：<span class="math inline">\(\frac{dy}{dx}=\lim\limits_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}\)</span>，写个小程序模拟这个无穷小和自变量的关系： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># Write Python 3 code in this online editor and run it.</span></span><br><span class="line">i=<span class="number">0</span></span><br><span class="line">x1=<span class="number">0.5</span></span><br><span class="line">y1=<span class="number">0.25</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">	i=i+<span class="number">1</span></span><br><span class="line">	x2=<span class="number">0.51</span>-<span class="number">0.0001</span>*i</span><br><span class="line">	y2=x2*x2</span><br><span class="line">	deltax=x2-x1</span><br><span class="line">	deltay=y2-y1</span><br><span class="line">	<span class="keyword">if</span> x2&lt;=<span class="number">0.5</span>:</span><br><span class="line">		<span class="keyword">break</span></span><br><span class="line">	<span class="built_in">print</span>(deltay/deltax,<span class="string">&#x27;|&#x27;</span>,<span class="number">2</span>*x1)</span><br></pre></td></tr></table></figure> 得到关系：</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\frac{dy}{dx}\)</span></th>
<th><span class="math inline">\(2x\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1.0098999999999982</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.009800000000002</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0096999999999992</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0096000000000007</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0095000000000014</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.009400000000001</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0092999999999994</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0092000000000028</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0090999999999988</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0089999999999997</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0088999999999995</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0087999999999981</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.008700000000002</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0085999999999982</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0084999999999995</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0083999999999997</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0082999999999986</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0082000000000029</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0080999999999993</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0080000000000011</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0079000000000016</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0078000000000007</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0076999999999987</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0076000000000023</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0074999999999972</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0073999999999983</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0072999999999979</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0072000000000034</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0071</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.007000000000003</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0068999999999966</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0067999999999964</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0067000000000028</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0065999999999997</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0065000000000033</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0063999999999966</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.006299999999997</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0061999999999955</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0061000000000015</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0059999999999967</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0058999999999994</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0058000000000002</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0056999999999994</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0055999999999965</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0055000000000016</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.005399999999995</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0052999999999963</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0051999999999959</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.005100000000004</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0049999999999994</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.004900000000004</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0047999999999946</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0046999999999946</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0046000000000044</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0044999999999997</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0044000000000055</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.004299999999996</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0041999999999967</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0040999999999947</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.004000000000004</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.003899999999997</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0038000000000011</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.003700000000003</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0036000000000016</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0034999999999974</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0034000000000063</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0032999999999956</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0031999999999983</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0030999999999979</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0029999999999937</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0029000000000048</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0027999999999933</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0026999999999975</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.002599999999998</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0024999999999942</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0024000000000088</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0022999999999962</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0022000000000026</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0021000000000049</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.002000000000002</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0018999999999934</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0018000000000085</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0016999999999867</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0015999999999905</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0014999999999876</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0014000000000165</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.001299999999999</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.001200000000016</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0010999999999761</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0009999999999732</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0009000000000197</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0007999999999952</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0007000000000281</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0005999999999617</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0004999999999589</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.000400000000067</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.000300000000027</td>
<td>1.0</td>
</tr>
<tr class="even">
<td>1.0001999999998947</td>
<td>1.0</td>
</tr>
<tr class="odd">
<td>1.0000999999999474</td>
<td>1.0</td>
</tr>
</tbody>
</table>
<p>随着<span class="math inline">\(\Delta x\)</span>越来越小，<span class="math inline">\(\frac{dy}{dx}\)</span>的取值越来越接近<span class="math inline">\(2x\)</span>，可以猜测函数<span class="math inline">\(y=x^2\)</span>上的任意一点切斜斜率为<span class="math inline">\(2x\)</span>,即<span class="math inline">\(\frac{dy}{dx}=2x\)</span>，由于上学时老师直接讲的是导数的结论，我们是站在牛顿、莱布尼茨巨人们的肩上的，所以大家想当然就觉得这不是很简单的么，我们都知道答案，大家试着把认知退回到知道答案前，思考下怎么证明以上观察到的结果是普适的，怎么抽象出一般范式？</p>
<h2 id="微积分隐秘的力量">微积分隐秘的力量</h2>
<h3 id="无穷小量">无穷小量</h3>
<p>无穷小量是一种概念里存在的东西，它大于0但又无限接近0的数。并且无穷小量的大小是不同的。一个无穷小量的无穷小部分还要更加小得多，我们称之为二阶无穷小量，类似的还有三阶无穷小，......，<span class="math inline">\(n\)</span>阶无穷下。</p>
<p>还是上面的例子：<span class="math inline">\(0.5^2=0.25\)</span>，那么<span class="math inline">\(0.50001^2\)</span>呢？</p>
<p>我们知道它肯定大于<span class="math inline">\(0.25\)</span>，但到底大多少呢？</p>
<p>答案是：<span class="math inline">\(0.50001^2=0.25001000009999996\)</span>，而小数点两位后(<span class="math inline">\(0.25\)</span>后)的这个小数又是由两个部分组成的，即：</p>
<p><span class="math inline">\(0.00001000009999996=0.00001+0.00000000009999996\)</span>，显然前半部分“很小”，后半部分则“超级小”。</p>
<p>假设：上面例子中<span class="math inline">\(x\)</span>发生了正向的微小扰动<span class="math inline">\(\Delta x\)</span>，变成了<span class="math inline">\(x+\Delta x\)</span>，则有：</p>
<p><span class="math display">\[(x+\Delta x)^2=x^2+2x\Delta x+{\Delta x}^2\]</span> 把<span class="math inline">\(x=0.5\)</span>代进去，则有： <span class="math display">\[(0.5+\Delta x)^2=0.25+\Delta x+{\Delta x}^2\]</span> <span class="math inline">\(\Delta x\)</span>和<span class="math inline">\({\Delta x}^2\)</span>分别对应“很小”的那部分一阶无穷小和“超级小”的那部分二阶无穷小。</p>
<h3 id="微分">微分</h3>
<p>古人教导我们，关注问题的主要矛盾和矛盾的主要方面，对于上面的无穷小量，可以关注“很小”这个矛盾的主要方面，忽略“超级小”这个次要方面，这个是微积分背后的核心观点，这种忽略思维会给我们带来巨大好处，还是上面的例子： <span class="math display">\[(0.5+\Delta x)^2=0.25+\Delta x+{\Delta x}^2\]</span> 抛弃掉“超级小”部分，并做下符号变换，得到： <span class="math display">\[(0.5+d x)^2=0.25+d x\]</span> 那么要计算<span class="math inline">\(y=x^2\)</span>这个曲线上任意一点<span class="math inline">\(x\)</span>的切线斜率<span class="math inline">\(\frac{dy}{dx}\)</span>，还需要计算<span class="math inline">\(dy\)</span>出来，方法如下： <span class="math display">\[y+dy=(x+dx)^2\]</span> 推导下得到： <span class="math display">\[y+dy=x^2+2xd x+{d x}^2\]</span> 忽略掉“超级小”的二阶无穷小，得到： <span class="math display">\[y+dy=x^2+2xd x\]</span> 因为：<span class="math inline">\(y=x^2\)</span>，所以得到： <span class="math display">\[dy=2xdx\]</span> 于是斜率公式为： <span class="math display">\[\frac{dy}{dx}=2x\]</span> 当<span class="math inline">\(x=0.5\)</span>时，该点切斜斜率为：<span class="math inline">\(2 \times0.5=1\)</span>，和上面结果一致，至此也就推导出了这个范式。</p>
<h3 id="面积与斜率的关系">面积与斜率的关系</h3>
微积分基本定理认为，当横坐标<span class="math inline">\(x\)</span>取值向右滑动时，曲线下方的面积会以<span class="math inline">\(f(x)\)</span>的速率逐渐增大。因此，<span class="math inline">\(f(x)\)</span>是<span class="math inline">\(A(x)\)</span>的导数，总结下就是： <span class="math display">\[A(x)\Rightarrow^{导数}y(x)\Rightarrow^{导数}\frac{dy}{dx}\]</span> 其中：<span class="math inline">\(A(x)\)</span>为曲线下方面积，<span class="math inline">\(y(x)\)</span>为曲线本身，<span class="math inline">\(\frac{dy}{dx}\)</span>为曲线斜率。
<center>
<img alt="图7" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329897968787.png" width="390" height="" >
</center>
给<span class="math inline">\(x\)</span>增加一个无穷小量<span class="math inline">\(dx\)</span>，面积<span class="math inline">\(A(x)\)</span>会变化多少？逻辑上应该是<span class="math inline">\(dA\)</span>，新的面积是：<span class="math inline">\(A+dA\)</span>，直观展示为：
<center>
<img alt="图8" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329900071127.png" width="390" height="" >
</center>
显然<span class="math inline">\(dA\)</span>等于<span class="math inline">\(x\)</span>和<span class="math inline">\(x+dx\)</span>之间这个灰色的无限细长竖条的面积。这个竖条是一个高为<span class="math inline">\(y\)</span>、底为<span class="math inline">\(dx\)</span>的矩形，它的面积等于<span class="math inline">\(ydx\)</span>，即<span class="math inline">\(f(x)dx\)</span>，而这里我们忽略的那个“超级小”的无穷量就是这个矩形上面的小帽子：
<center>
<img alt="图9" data-src="https://vivounicorn.github.io/images/calculus/2021-09-29-有趣的微积分-企业微信截图_16329902784866.png" width="50" height="" >
</center>
<p>整理一下就得到： <span class="math display">\[\frac{dA(x)}{dx}=f(x)\]</span> 当曲线下方的面积由无穷多个无穷小的矩形竖条面积组成时，就可以得到经典形式： <span class="math display">\[A(x)=\int_0^xf(x)dx\]</span></p>
<p>积分符号<span class="math inline">\(\int\)</span>是莱布尼茨1677年引入并在1686年正式发表的，当时他把“微积分”叫做“a calculus”和“my calculus”（有点我的小甜甜的味道）。</p>
<p>至此，总结下，从无穷量角度去看待微积分，会发现它最初的“原味”，我们解决实际问题时因为有太多的“历史经验”，让我们觉得很多东西想当然，需要意识到并练习抛开这些想当然的“<strong>法</strong>”去理解“<strong>道</strong>”。</p>
]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>微积分</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第十章-Vision Transformers (ViT)</title>
    <url>/article/c0a9d987.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit.jpg" width=266 /> 本章对Transformer在计算机视觉中的算法和应用做了原理介绍和效果展示。 <span id="more"></span></p>
<h1 id="vision-transformers">10. Vision Transformers</h1>
<h2 id="初版vit">10.1 初版Vit</h2>
<p><strong>1、整体概览</strong></p>
<p>第一次将Transformer机制引入CV领域（准确的说是图像分类）的是Google Brain的Neil Houlsby, Alexey Dosovitskiy等人在ICLR 2021提交的《<a href="https://arxiv.org/pdf/2010.11929.pdf">An Image is Worth 16*16 Words: Transformers for Image Recognition at Scale</a>》一文，本节对这篇文章做个概要介绍。</p>
<p>ViT用于图像分类有以下优缺点，优点：完全不使用CNN结构，自然也就避免了CNN的缺点、在分类效果上甚至好于CNN类模型（如：ResNet）；缺点：需要比较大的数据集生成预训练模型、在新任务上做fine-tuning时要特别小心、想效果好，模型要很大。</p>
<p>ViT整体结构我认为比较原汁原味的继承了NLP中的Transformer，所以原理没什么好重复讲的，更多的是在做实验。</p>
<p>通用的结构包括：</p>
<ul>
<li>具有标准Multi-Head Self-Attention的Transformer encoder</li>
<li>Channel方向做归一化的Layer norm</li>
<li>位置编码Position embeddings。</li>
</ul>
<p>个性化的结构包括：</p>
<ul>
<li>由于标准Transformer接收1维序列，所以需要把2维的图片通过等大小切片并横向拼接转化为1维序列，即： 假设原始图片大小为：<span class="math inline">\(H×W×C\)</span>，每个切片分辨率大小为<span class="math inline">\(P×P\)</span>，则一共会有<span class="math inline">\(N=HW/P^2\)</span>个切片，输入序列patch embeddings维度为：<span class="math inline">\(N×(P^2\cdot C)\)</span>。</li>
<li>类似BERT，通过embedding一个class token（下图中加*的部分），来“概括”整幅图的语义表示，从而用于下游分类任务。</li>
<li>Transformer encoder后面接一个多层感知机层(MLP layer)。</li>
</ul>
ViT运转过程如图：
<center>
<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit.gif" width=600 /></p>
<a href="https://github.com/lucidrains/vit-pytorch">动图来源于这里</a>
</center>
网络结构如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-org.png" width=600 />
</center>
<p><strong>2、代码实践</strong></p>
<ul>
<li><p>Embedding</p>
整个过程分几步：切片、引入class token、切片铺平、与位置编码相加，过程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-emb.png" width=800 />
</center>
<p>1、需要确保图片长×宽可以整除切片大小，例如，图片为224×224、切片大小为16×16，则满足要求</p>
<p>2、通过对原图做CNN卷积得到切片（patch），并把切片铺平</p>
<p>3、把class token向量拼接到切片铺平后的向量的最前面位置</p>
<p>5、将第3步得到的向量与位置编码向量相加，用dropout做下正则化后返回</p></li>
<li><p>MultiHeadAttention</p>
稍作修改，把Normlayer去掉，沿用之前在第六章介绍的MultiHeadAttention结构，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-mh.png" width=800 />
</center></li>
<li><p>MLP</p>
使用BERT中的GELU激活函数，并构建一个两层感知机，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-mlp.png" width=800 />
</center></li>
<li><p>Block</p>
组合Normlayer、MultiHeadAttention和MLP，得到一个基础的、可复制多个的最小Block结构，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-bk.png" width=800 />
</center></li>
<li><p>Encoder</p>
若干个Block组成一个Encoder，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-encoder.png" width=800 />
</center></li>
<li><p>TransformerEncoder</p>
Embedding和Encoder共同组合成Transformer Encoder结构，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-te.png" width=800 />
</center></li>
<li><p>VisionTransformer</p>
构建一个用于多分类的vision transformer，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-vit.png" width=800 />
</center>
<p>以上过程的完整代码如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Dropout, Linear, Conv2d, LayerNorm</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Scaled Dot-Product Attention &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_k, attn_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 缩放因子</span></span><br><span class="line">        self.scalar = <span class="number">1</span> / np.power(d_k, <span class="number">0.5</span>)</span><br><span class="line">        self.dropout = nn.Dropout(attn_dropout)</span><br><span class="line">        self.softmax = nn.Softmax(dim=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="comment"># 计算q∙k</span></span><br><span class="line">        attn = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 计算q∙k/sqr(d_k)</span></span><br><span class="line">        attn = attn * self.scalar</span><br><span class="line"></span><br><span class="line">        <span class="comment"># attention masked</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            attn = attn.masked_fill(mask.<span class="built_in">bool</span>(), -np.inf)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算softmax(q∙k/sqr(d_k))</span></span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line">        <span class="comment"># 计算softmax(q∙k/sqr(d_k))∙v</span></span><br><span class="line">        sdp_output = torch.bmm(attn, v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sdp_output, attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Multi-Head Attention module &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拆分出的attention head数量.</span></span><br><span class="line">        self.num_of_heads = num_of_heads</span><br><span class="line">        <span class="comment"># 模型维度，例如：embedding层为词向量维度.</span></span><br><span class="line">        self.dim_of_model = dim_of_model</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 模型维度的设置要保证能使拆分出来的所有head维度相同</span></span><br><span class="line">        <span class="keyword">if</span> self.dim_of_model % self.num_of_heads != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;Dimensions of the model must be divisible by number of attention heads.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拆分出来的每个head向量的维度</span></span><br><span class="line">        self.depth = self.dim_of_model // self.num_of_heads</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保持输入输出维度的仿射变换</span></span><br><span class="line">        self.w_qs = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line">        self.w_ks = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line">        self.w_vs = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line"></span><br><span class="line">        self.attention = ScaledDotProductAttention(self.depth,</span><br><span class="line">                                                   attn_dropout=dropout)</span><br><span class="line"></span><br><span class="line">        self.layer_norm = nn.LayerNorm(self.dim_of_model)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最终输出层</span></span><br><span class="line">        self.fc = nn.Linear(self.dim_of_model, self.dim_of_model)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size, sequence_len_q, dim_of_model)，其中dim_of_model = num_of_heads * depth</span></span><br><span class="line">        batch_size, sequence_len_q, _ = q.size()</span><br><span class="line">        batch_size, sequence_len_k, _ = k.size()</span><br><span class="line">        batch_size, sequence_len_v, _ = v.size()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 类似ResNet，对query保留输入信息</span></span><br><span class="line">        <span class="comment"># residual = q</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size, num_of_heads, sequence_len_q, depth)</span></span><br><span class="line">        q = self.w_qs(q).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        k = self.w_qs(k).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        v = self.w_qs(v).view(batch_size, -<span class="number">1</span>, self.num_of_heads, self.depth).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="built_in">print</span>(q.shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># q.shape=(batch_size * num_of_heads, sequence_len_q, depth)</span></span><br><span class="line">        q = q.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line">        k = k.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line">        v = v.reshape(batch_size * self.num_of_heads, -<span class="number">1</span>, self.depth)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mask操作</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            mask = mask.repeat(self.num_of_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        scaled_attention, attention_weights = self.attention(q, k, v, mask=mask)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scaled_attention.shape=(batch_size, sequence_len_q, num_of_heads, depth)</span></span><br><span class="line">        scaled_attention = scaled_attention.view(batch_size, self.num_of_heads, sequence_len_q, self.depth).permute(<span class="number">0</span>,</span><br><span class="line">                                                                                                                    <span class="number">2</span>,</span><br><span class="line">                                                                                                                    <span class="number">1</span>,</span><br><span class="line">                                                                                                                    <span class="number">3</span>)</span><br><span class="line">        <span class="comment"># attention_weights.shape=(batch_size, num_of_heads, sequence_len_q, sequence_len_k)</span></span><br><span class="line">        attention_weights = attention_weights.view(batch_size, self.num_of_heads, sequence_len_q, sequence_len_k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 拼接所有head</span></span><br><span class="line">        <span class="comment"># concat_attention.shape=(batch_size, sequence_len_q, dim_of_model)，其中dim_of_model = num_of_heads * depth</span></span><br><span class="line">        concat_attention = scaled_attention.reshape(batch_size, sequence_len_q, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 全连接层做线性输出</span></span><br><span class="line">        linear_output = self.fc(concat_attention)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> linear_output, attention_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># (num_of_heads, dim_of_model)</span></span><br><span class="line">mha = MultiHeadAttention(<span class="number">12</span>, <span class="number">768</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># (batch_size, sequence_len_q, dim_of_model)</span></span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">197</span>, <span class="number">768</span>)</span><br><span class="line"></span><br><span class="line">output, attention_weights = mha(q, k=q, v=q, mask=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of output:&quot;&#123;0&#125;&quot;, shape of attention weight:&quot;&#123;1&#125;&quot;&#x27;</span>.<span class="built_in">format</span>(output.shape, attention_weights.shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mlp</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multilayer perceptron.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim_of_model, dim_of_mlp, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.fc1 = Linear(dim_of_model, dim_of_mlp)</span><br><span class="line">        self.fc2 = Linear(dim_of_mlp, dim_of_model)</span><br><span class="line">        self.active_fn = torch.nn.functional.gelu</span><br><span class="line">        self.dropout = Dropout(dropout)</span><br><span class="line"></span><br><span class="line">        nn.init.xavier_uniform_(self.fc1.weight)</span><br><span class="line">        nn.init.xavier_uniform_(self.fc2.weight)</span><br><span class="line">        nn.init.normal_(self.fc1.bias, std=<span class="number">1e-8</span>)</span><br><span class="line">        nn.init.normal_(self.fc2.bias, std=<span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.active_fn(x)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mp = Mlp(<span class="number">768</span>, <span class="number">3072</span>)</span><br><span class="line">r = mp(output)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of mlp:&quot;&#123;0&#125;&quot;&quot;&#x27;</span>.<span class="built_in">format</span>(r.shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Block</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Multi-head attention and MLP block.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.hidden_size = dim_of_model</span><br><span class="line">        <span class="comment"># Multi-head attention norma layer</span></span><br><span class="line">        self.mh_attention_norm = LayerNorm(dim_of_model, eps=<span class="number">1e-8</span>)</span><br><span class="line">        <span class="comment"># Mlp norma layer</span></span><br><span class="line">        self.mlp_norm = LayerNorm(dim_of_model, eps=<span class="number">1e-8</span>)</span><br><span class="line">        <span class="comment"># Mlp</span></span><br><span class="line">        self.mlp = Mlp(dim_of_model, dim_of_mlp, mlp_dropout)</span><br><span class="line">        <span class="comment"># Multi-head attention</span></span><br><span class="line">        self.mh_attention = MultiHeadAttention(num_of_heads, dim_of_model, atten_dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        residual = x</span><br><span class="line">        x = self.mh_attention_norm(x)</span><br><span class="line">        x, weights = self.mh_attention(x, x, x)</span><br><span class="line">        x = x + residual</span><br><span class="line"></span><br><span class="line">        residual = x</span><br><span class="line">        x = self.mlp_norm(x)</span><br><span class="line">        x = self.mlp(x)</span><br><span class="line">        x = x + residual</span><br><span class="line">        <span class="keyword">return</span> x, weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b = Block(<span class="number">12</span>, <span class="number">768</span>, <span class="number">3072</span>)</span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">197</span>, <span class="number">768</span>)</span><br><span class="line">output, attention_weights = b(q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of output:&quot;&#123;0&#125;&quot;, shape of attention weight:&quot;&#123;1&#125;&quot;&#x27;</span>.<span class="built_in">format</span>(output.shape, attention_weights.shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Encoder with n blocks.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, num_layers, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.layers = nn.ModuleList()</span><br><span class="line"></span><br><span class="line">        self.encoder_norm = LayerNorm(dim_of_model, eps=<span class="number">1e-8</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">            layer = Block(num_of_heads, dim_of_model, dim_of_mlp, atten_dropout, mlp_dropout)</span><br><span class="line">            self.layers.append(copy.deepcopy(layer))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        attn_weights_list = []</span><br><span class="line">        <span class="keyword">for</span> layer_block <span class="keyword">in</span> self.layers:</span><br><span class="line">            x, weights = layer_block(x)</span><br><span class="line">            attn_weights_list.append(weights)</span><br><span class="line"></span><br><span class="line">        encoded = self.encoder_norm(x)</span><br><span class="line">        <span class="keyword">return</span> encoded, attn_weights_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">encoder = Encoder(<span class="number">12</span>, <span class="number">768</span>, <span class="number">3072</span>, <span class="number">1</span>)</span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">197</span>, <span class="number">768</span>)</span><br><span class="line">output, attention_weights = encoder(q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of output:&quot;&#123;0&#125;&quot;, shape of attention weight:&quot;&#123;1&#125;&quot;&#x27;</span>.<span class="built_in">format</span>(output.shape, attention_weights[<span class="number">0</span>].shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Construct the embeddings from patch, position embeddings.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, image_hw, dim_of_model, channels=<span class="number">3</span>, patch_size=<span class="number">16</span>, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        height = image_hw[<span class="number">0</span>]</span><br><span class="line">        width = image_hw[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> height % patch_size == <span class="number">0</span> <span class="keyword">and</span> width % patch_size == <span class="number">0</span>, <span class="string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span></span><br><span class="line">        n_patches = (height * width) // (patch_size ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对原图做CNN卷积，提取特征，卷积核大小和卷积步长为切片大小，所以输出向量的后两个维度等于n_patches开根号</span></span><br><span class="line">        self.patch_embeddings = Conv2d(in_channels=channels,</span><br><span class="line">                                       out_channels=dim_of_model,</span><br><span class="line">                                       kernel_size=(patch_size, patch_size),</span><br><span class="line">                                       stride=(patch_size, patch_size))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># shape=(1, n_patches+1, dim_of_model)</span></span><br><span class="line">        self.position_embeddings = nn.Parameter(torch.zeros(<span class="number">1</span>, n_patches + <span class="number">1</span>, dim_of_model))</span><br><span class="line"></span><br><span class="line">        self.class_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, dim_of_model))</span><br><span class="line"></span><br><span class="line">        self.dropout = Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        cls_tokens = self.class_token.expand(batch_size, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        x = self.patch_embeddings(x)</span><br><span class="line">        x = x.flatten(<span class="number">2</span>)</span><br><span class="line">        x = x.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line">        embeddings = x + self.position_embeddings</span><br><span class="line">        embeddings = self.dropout(embeddings)</span><br><span class="line">        <span class="keyword">return</span> embeddings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">emb = Embeddings((<span class="number">224</span>, <span class="number">224</span>), <span class="number">768</span>)</span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">r = emb(q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of embedding:&quot;&#123;0&#125;&quot;&quot;&#x27;</span>.<span class="built_in">format</span>(r.shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransformerEncoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Embedding layer and Encoder Layer.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span></span></span><br><span class="line"><span class="params"><span class="function">                 image_hw, channels=<span class="number">3</span>, patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 em_dropout=<span class="number">0.1</span>, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.embeddings = Embeddings(image_hw, dim_of_model, channels, patch_size, em_dropout)</span><br><span class="line">        self.transformer_encoder = Encoder(num_of_heads, dim_of_model, dim_of_mlp, num_layers, atten_dropout,</span><br><span class="line">                                           mlp_dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        embedded = self.embeddings(x)</span><br><span class="line">        encoded, attention_weights = self.transformer_encoder(embedded)</span><br><span class="line">        <span class="keyword">return</span> encoded, attention_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trans = TransformerEncoder(<span class="number">12</span>, <span class="number">768</span>, <span class="number">3072</span>, <span class="number">2</span>, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">r, _ = trans(q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of transformer encoder:&quot;&#123;0&#125;&quot;&quot;&#x27;</span>.<span class="built_in">format</span>(r.shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VisionTransformer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Vit.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span></span></span><br><span class="line"><span class="params"><span class="function">                 image_hw=(<span class="params"><span class="number">224</span>, <span class="number">224</span></span>), channels=<span class="number">3</span>, patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 em_dropout=<span class="number">0.1</span>, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span>, num_classes=<span class="number">1000</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        self.transformer = TransformerEncoder(num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span><br><span class="line">                                              image_hw, channels, patch_size,</span><br><span class="line">                                              em_dropout, atten_dropout, mlp_dropout)</span><br><span class="line"></span><br><span class="line">        self.vit_head = Linear(dim_of_model, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        encoded, attention_weights = self.transformer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.vit_head(encoded[:, <span class="number">0</span>]), attention_weights</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vit = VisionTransformer(<span class="number">12</span>, <span class="number">768</span>, <span class="number">3072</span>, <span class="number">2</span>, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">q = torch.Tensor(<span class="number">32</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">r, _ = vit(q)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;shape of vision transformer:&quot;&#123;0&#125;&quot;&quot;&#x27;</span>.<span class="built_in">format</span>(r.shape))</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchviz <span class="keyword">import</span> make_dot</span><br><span class="line">architecture = make_dot(r, params=<span class="built_in">dict</span>(<span class="built_in">list</span>(vit.named_parameters())))</span><br><span class="line">architecture.<span class="built_in">format</span> = <span class="string">&quot;png&quot;</span></span><br><span class="line">architecture.directory = <span class="string">&quot;data&quot;</span></span><br><span class="line">architecture.view()</span><br></pre></td></tr></table></figure></p>
假设，采用12个head，模型隐层维度为768，感知机维度为3072，block个数为2，图片大小为224×224，batch大小为32，则网络结构可视化后如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/ark.png" width=800 />
</center>
<p>直观看个transformer机制在图像中的作用更有感觉：随着attention机制作用的层数越深，对柯基的注意力越来越集中，分类的准确率非常高：</p>
对每个block的header求平均attention值，类似这样： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">resolution = (<span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">num_of_heads = <span class="number">12</span></span><br><span class="line">dim_of_model = <span class="number">768</span></span><br><span class="line">dim_of_mlp = <span class="number">3072</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.Resize(resolution),</span><br><span class="line">    transforms.ToTensor()])</span><br><span class="line"></span><br><span class="line">im = Image.<span class="built_in">open</span>(<span class="string">&quot;attention_data/ship.jpeg&quot;</span>).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">x = transform(im)</span><br><span class="line"></span><br><span class="line">vit = VisionTransformer(num_of_heads, dim_of_model, dim_of_mlp, num_layers, resolution)</span><br><span class="line">q = x.reshape(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line"><span class="comment"># attention_matrix is a list.</span></span><br><span class="line">result, attention_matrix = vit(q)</span><br><span class="line"><span class="comment"># attention_matrix size: (num_layers, attention map resolution, attention map resolution)=(2, 197, 197)</span></span><br><span class="line">attention_matrix = torch.mean(torch.stack(attention_matrix).squeeze(<span class="number">1</span>), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure> 取出最后一个block的attention分布图，如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit_mask.png" width=600 />
</center>
<p>逐层展示attention分布图（同样是每层所有header的attention值求平均），如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/dog.png" width=600 />
</center>
在cifar10数据集训练模型后，对柯基做分类的结果如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/dogcls.png" width=600 />
</center>
其他例子可视化：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-cmp.png" width=600 />
</center></li>
<li><p>模型训练 以cifar10分类问题为例，利用torchvision的datasets模块自动下载和组织训练与测试数据集，并利用transforms模块做样本处理，类似这样： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">transform_train = transforms.Compose([</span><br><span class="line">      transforms.RandomResizedCrop(img_size, scale=(<span class="number">0.05</span>, <span class="number">1.0</span>)),</span><br><span class="line">      transforms.ToTensor(),</span><br><span class="line">      transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]),</span><br><span class="line">  ])</span><br><span class="line">transform_test = transforms.Compose([</span><br><span class="line">    transforms.Resize(img_size),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], std=[<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>]),</span><br><span class="line">])</span><br><span class="line">trainset = datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">                                  train=<span class="literal">True</span>,</span><br><span class="line">                                  download=<span class="literal">True</span>,</span><br><span class="line">                                  transform=transform_train)</span><br><span class="line">testset = datasets.CIFAR10(root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">                           train=<span class="literal">False</span>,</span><br><span class="line">                           download=<span class="literal">True</span>,</span><br><span class="line">                           transform=transform_test)</span><br></pre></td></tr></table></figure> 之后以batch方式训练和验证模型，如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  training the model</span></span><br><span class="line"><span class="string">  :return: None</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">  self.load_model()</span><br><span class="line">  <span class="comment"># 加载训练数据和测试数据</span></span><br><span class="line">  train_loader, test_loader = data_loader(self.config.items.img_size,</span><br><span class="line">                                          self.config.items.train_batch_size,</span><br><span class="line">                                          self.config.items.test_batch_size)</span><br><span class="line">  <span class="comment"># 选择一个一阶最优化方法</span></span><br><span class="line">  <span class="keyword">if</span> self.config.items.optimizer == <span class="string">&#x27;adam&#x27;</span>:</span><br><span class="line">      optimizer = torch.optim.Adam(self.model.parameters(),</span><br><span class="line">                                   lr=self.config.items.learning_rate)</span><br><span class="line">  <span class="keyword">elif</span> self.config.items.optimizer == <span class="string">&#x27;adagrad&#x27;</span>:</span><br><span class="line">      optimizer = torch.optim.Adagrad(self.model.parameters(),</span><br><span class="line">                                      lr=self.config.items.learning_rate)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      optimizer = torch.optim.SGD(self.model.parameters(),</span><br><span class="line">                                  lr=self.config.items.learning_rate,</span><br><span class="line">                                  momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 总的迭代步数</span></span><br><span class="line">  t_total = self.config.items.num_steps</span><br><span class="line">  <span class="comment"># 以此步数做学习率分段函数</span></span><br><span class="line">  warmup_steps = self.config.items.warmup_steps</span><br><span class="line">  <span class="comment"># 随着迭代步数增加，调整学习率的策略(cosine法|S)</span></span><br><span class="line">  <span class="comment">#        *</span></span><br><span class="line">  <span class="comment">#       *   *</span></span><br><span class="line">  <span class="comment">#      *      *</span></span><br><span class="line">  <span class="comment">#     *        *</span></span><br><span class="line">  <span class="comment">#    *          *</span></span><br><span class="line">  <span class="comment">#   *            *</span></span><br><span class="line">  <span class="comment">#  *               *</span></span><br><span class="line">  <span class="comment"># *                   *</span></span><br><span class="line">  <span class="comment"># *                       *   *    *</span></span><br><span class="line">  scheduler = LambdaLR(optimizer=optimizer,</span><br><span class="line">                       lr_lambda=<span class="keyword">lambda</span> step: <span class="built_in">float</span>(step) / warmup_steps <span class="keyword">if</span> step &lt; warmup_steps <span class="keyword">else</span> <span class="number">0.5</span> * (</span><br><span class="line">                               math.cos(math.pi * <span class="number">0.6</span> * <span class="number">2.0</span> * (step - warmup_steps) / (</span><br><span class="line">                                       t_total - warmup_steps)) + <span class="number">1.0</span>))</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;\r\n***** Running training *****&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 模型所有参数梯度值初始化为0</span></span><br><span class="line">  self.model.zero_grad()</span><br><span class="line">  <span class="comment"># 计算平均损失</span></span><br><span class="line">  loss_sum = <span class="number">0</span></span><br><span class="line">  loss_count = <span class="number">0</span></span><br><span class="line">  <span class="comment"># 当前迭代步数</span></span><br><span class="line">  current_step = <span class="number">0</span></span><br><span class="line">  <span class="comment"># 当前最佳精度</span></span><br><span class="line">  current_best_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">      self.model.train()</span><br><span class="line">      <span class="comment"># 初始化进度条</span></span><br><span class="line">      epoch_iterator = tqdm(train_loader,</span><br><span class="line">                            desc=<span class="string">&quot;Training Progress [x / x Total Steps] &#123;loss=x.x&#125;&quot;</span>,</span><br><span class="line">                            bar_format=<span class="string">&quot;&#123;l_bar&#125;&#123;r_bar&#125;&quot;</span>,</span><br><span class="line">                            dynamic_ncols=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(epoch_iterator):</span><br><span class="line">          <span class="comment"># 获取一个batch，并把数据发送到相应设备上（如：GPU卡）</span></span><br><span class="line">          batch = <span class="built_in">tuple</span>(t.to(self.config.items.device) <span class="keyword">for</span> t <span class="keyword">in</span> batch)</span><br><span class="line">          <span class="comment"># 特征与标注数据</span></span><br><span class="line">          features, label = batch</span><br><span class="line">          loss, _ = self.model(features, label)</span><br><span class="line">          <span class="comment"># 自动反向传播求梯度</span></span><br><span class="line">          loss.backward()</span><br><span class="line">          <span class="comment"># 全局平均损失</span></span><br><span class="line">          loss_sum += loss.item()</span><br><span class="line">          loss_count += <span class="number">1</span></span><br><span class="line">          <span class="comment"># 梯度正则化，缓解过拟合</span></span><br><span class="line">          torch.nn.utils.clip_grad_norm_(self.model.parameters(), <span class="number">1</span>)</span><br><span class="line">          <span class="comment"># 执行一步最优化方法</span></span><br><span class="line">          optimizer.step()</span><br><span class="line">          <span class="comment"># 执行学习率调整策略</span></span><br><span class="line">          scheduler.step()</span><br><span class="line">          <span class="comment"># 梯度清零</span></span><br><span class="line">          optimizer.zero_grad()</span><br><span class="line">          <span class="comment"># 存储当前迭代步数</span></span><br><span class="line">          current_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">          epoch_iterator.set_description(</span><br><span class="line">              <span class="string">&quot;Training Progress [%d / %d Total Steps] &#123;loss=%2.5f&#125;&quot;</span> % (</span><br><span class="line">                  current_step, t_total, loss_sum / loss_count)</span><br><span class="line">          )</span><br><span class="line"></span><br><span class="line">          self.writer.add_scalar(<span class="string">&quot;train/loss&quot;</span>, scalar_value=loss_sum / loss_count, global_step=current_step)</span><br><span class="line">          self.writer.add_scalar(<span class="string">&quot;train/lr&quot;</span>, scalar_value=scheduler.get_last_lr()[<span class="number">0</span>], global_step=current_step)</span><br><span class="line"></span><br><span class="line">          <span class="comment"># 每迭代若干步后做测试集验证</span></span><br><span class="line">          <span class="keyword">if</span> current_step % self.config.items.test_epoch == <span class="number">0</span>:</span><br><span class="line">              accuracy = self.test(test_loader, current_step)</span><br><span class="line">              <span class="comment"># 测试集上表现好的模型被存储，并更新当前最佳精度</span></span><br><span class="line">              <span class="keyword">if</span> current_best_acc &lt; accuracy:</span><br><span class="line">                  self.save_model()</span><br><span class="line">                  current_best_acc = accuracy</span><br><span class="line">              <span class="comment"># 接着训练</span></span><br><span class="line">              self.model.train()</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> current_step % t_total == <span class="number">0</span>:</span><br><span class="line">              <span class="keyword">break</span></span><br><span class="line">      loss_sum = <span class="number">0</span></span><br><span class="line">      loss_count = <span class="number">0</span></span><br><span class="line">      <span class="keyword">if</span> current_step % t_total == <span class="number">0</span>:</span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">  self.writer.close()</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Best Accuracy: \t%f&quot;</span> % current_best_acc)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;***** End Training *****&quot;</span>)</span><br></pre></td></tr></table></figure></p>
需要注意，为了提升训练效果，学习率采用分段函数调整，训练前期猛一点，采用线性增长，过了一定阈值后逐步平缓，采用cosine下降。 另外将训练的过程数据写入日志，可以利用tensorboard可视化的查看训练过程，执行命令诸如： <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tensorboard --logdir=*** --port 8123</span><br></pre></td></tr></table></figure> 可以在浏览器查看，如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/vit-training.png" width=800 />
</center>
<p>以上是对最初transformer机制被应用于CV的简单介绍和代码实践，完整代码<a href="https://github.com/vivounicorn/ViT"><strong>在这里</strong></a>。</p></li>
</ul>
<p><strong>3、小结</strong></p>
<p>ViT有两个很关键的点：</p>
<ul>
<li><p>采用self-attention机制捕获序列中元素的长依赖（long term dependencies）；</p></li>
<li><p>利用在大规模数据集（如：ImageNet）上训练的模型作为预训练模型（pre-training）会有好的效果，反过来说，如果数据集不够大，预训练模型的泛化性会比较差。</p></li>
</ul>
<p>实践证明得益于Transformer这种结构带来的优点，使得它有比较大的潜力，也成为了后续CV的重点研究领域，期待未来有更好的表现。</p>
<h2 id="deit">10.2 DeiT</h2>
<p>初版ViT有一个很大的问题是：要想模型效果好，训练数据集要很大，不管是数据集获取难度还是训练速度都受限，FB在《<a href="https://arxiv.org/pdf/2012.12877.pdf">Training data-efficient image transformers &amp; distillation through attention</a>》一文提出一种解决该问题的方法，</p>
<p>优点是：只是用ImageNet这样的公开数据集做训练，纯Transformer结构，对初版ViT只做了比较小的改动，由于使用蒸馏机制，使得训练速度大大提升，单机8卡训练了3天，DeiT-B 384在只使用88M参数量规模下达到了<strong>Top 1 Accuracy 85.2%</strong> 的效果，<strong><em>Image Classification on ImageNet</em></strong> 榜单排名<strong>84</strong>（截止2022.1.6）。</p>
<p>缺点是：需要一个预训练好的CNN模型当teacher，所以显然最终效果受teacher影响极大。</p>
<strong>1、模型结构</strong> 相比初版ViT，它主要在Embedding层增加了一个类似class token的distillation token，前者表征了对真实标签的全局隐语义概括，后者表征了对teacher模型的预测标签的全局隐语义概括。具体结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-distill.png" width=300 />
</center>
<p>损失函数方面，初版ViT采用预测值与真实标签的交叉熵损失，DeiT除此之外增加了蒸馏损失，即预测值与teacher模型的预测标签的交叉熵损失，细节如下：</p>
<ul>
<li><p>软蒸馏（Soft Distillation） <span class="math display">\[
\mathcal{L}_{global}=(1-\lambda)\mathcal{L}_{CE}(\psi(Z_s),y)+\lambda \tau ^2KL(\psi(Z_s/\tau),\psi(Z_t/\tau))
\]</span> 其中，<span class="math inline">\(y\)</span>为真实标签，<span class="math inline">\(\psi\)</span>为softmax函数，<span class="math inline">\(\tau\)</span>为蒸馏参数，<span class="math inline">\(\lambda\)</span> 是用来平衡交叉熵损失和e Kullback–Leibler divergence 损失的，<span class="math inline">\(\mathcal{L}_{CE}\)</span>为交叉熵损失。</p></li>
<li><p>硬蒸馏（Hard-label Distillation） <span class="math display">\[
\mathcal{L}_{global}^{hardDistill}=\frac{1}{2}\mathcal{L}_{CE}(\psi(Z_s),y)+\frac{1}{2}\mathcal{L}_{CE}(\psi(Z_s),y_t)
\]</span> 其中，$ y_t = argmax_cZ_t(c) $是把teacher的预测标签当做真实标签。 一个有趣的现象是：class token和distillation token会朝不同方向收敛，且随着迭代次数和层数，这两个向量的cosine相似度会越来越接近（但不会相等）。</p></li>
</ul>
<p><strong>2、实验结论</strong></p>
不同的DeiT结构及效果如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-ark.png" width=500 />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-cmp.png" width=300 />
</center>
<ul>
<li>CNN类模型作为teacher比transformer类模型效果更好，原因可能是transformer通过蒸馏继承了归纳偏置导致，具体解释可以看<a href="https://arxiv.org/pdf/2006.00555.pdf">这篇</a>论文。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-t.png" width=300 />
</center>
<p>上图中：384代表fine-tuning得到的模型使用了分辨率为384×384图像做训练，⚗代表蒸馏后得到的模型。</p></li>
<li>硬蒸馏效果好于软蒸馏和不蒸馏，同时使用class token和distillation token效果好于只是用其中一个 。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-exm.png" width=500 />
</center></li>
<li>效率与精度对比
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-ea.png" width=500 />
</center></li>
<li>只使用从ImageNet数据集训练出来的模型作为预训练模型，各个模型迁移到不同任务的效果对比如下，DeiT更胜一筹。 数据集使用：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-dt.png" width=300 />
</center>
效果对比：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-trans.png" width=500 />
</center></li>
<li>相对来说Transformers模型对优化器的参数更敏感
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-opt.png" width=500 />
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_10/deit-opt2.png" width=300 />
</center></li>
</ul>
<p><strong>3、代码实践</strong></p>
<p>继承之前的VisionTransformer实现并增加distillation token向量： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DistillationEmbeddings</span>(<span class="params">Embeddings</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, image_hw, dim_of_model, channels=<span class="number">3</span>, patch_size=<span class="number">16</span>, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(image_hw, dim_of_model, channels, patch_size, dropout)</span><br><span class="line"></span><br><span class="line">        self.distillation_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, dim_of_model))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        batch_size = x.shape[<span class="number">0</span>]</span><br><span class="line">        cls_tokens = self.class_token.expand(batch_size, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        dis_tokens = self.distillation_token.expand(batch_size, -<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        x = self.patch_embeddings(x)</span><br><span class="line">        x = x.flatten(<span class="number">2</span>)</span><br><span class="line">        x = x.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line">        x = torch.cat((cls_tokens, x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        embeddings = x + self.position_embeddings</span><br><span class="line">        embeddings = torch.cat((embeddings, dis_tokens), dim=<span class="number">1</span>)</span><br><span class="line">        embeddings = self.dropout(embeddings)</span><br><span class="line">        <span class="keyword">return</span> embeddings</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DistillationTransformerEncoder</span>(<span class="params">TransformerEncoder</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span></span></span><br><span class="line"><span class="params"><span class="function">                 image_hw, channels=<span class="number">3</span>, patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 em_dropout=<span class="number">0.1</span>, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span><br><span class="line">                         image_hw, channels, patch_size,</span><br><span class="line">                         em_dropout, atten_dropout, mlp_dropout)</span><br><span class="line"></span><br><span class="line">        self.embeddings = DistillationEmbeddings(image_hw, dim_of_model, channels, patch_size, em_dropout)</span><br><span class="line">        self.transformer_encoder = Encoder(num_of_heads, dim_of_model, dim_of_mlp, num_layers, atten_dropout,</span><br><span class="line">                                           mlp_dropout)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DistillationVisionTransformer</span>(<span class="params">VisionTransformer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span></span></span><br><span class="line"><span class="params"><span class="function">                 image_hw=(<span class="params"><span class="number">224</span>, <span class="number">224</span></span>), channels=<span class="number">3</span>, patch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 em_dropout=<span class="number">0.1</span>, atten_dropout=<span class="number">0.1</span>, mlp_dropout=<span class="number">0.1</span>, num_classes=<span class="number">10</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 teacher=<span class="literal">None</span>, is_hard=<span class="literal">False</span>, temperature=<span class="number">3.0</span>, balancing=<span class="number">0.1</span></span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__(num_of_heads, dim_of_model, dim_of_mlp, num_layers,</span><br><span class="line">                         image_hw, channels, patch_size,</span><br><span class="line">                         em_dropout, atten_dropout, mlp_dropout, num_classes)</span><br><span class="line"></span><br><span class="line">        self.transformer = DistillationTransformerEncoder(self.num_of_heads, self.dim_of_model, self.dim_of_mlp,</span><br><span class="line">                                                          self.num_layers,</span><br><span class="line">                                                          self.image_hw, self.channels, self.patch_size,</span><br><span class="line">                                                          self.em_dropout, self.atten_dropout, self.mlp_dropout)</span><br><span class="line">        self.teacher = teacher</span><br><span class="line">        self.is_hard = is_hard</span><br><span class="line">        self.temperature = temperature</span><br><span class="line">        self.balancing = balancing</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, labels=<span class="literal">None</span></span>):</span></span><br><span class="line">        encoded, attention_weights = self.transformer(x)</span><br><span class="line">        student_logits = self.vit_head(encoded[:, <span class="number">0</span>])</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            teacher_logits = self.teacher(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self.is_hard:</span><br><span class="line">                loss = soft_distillation(teacher_logits, student_logits,</span><br><span class="line">                                         self.temperature, self.balancing, labels, self.num_classes)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss = hard_distillation(teacher_logits, student_logits,</span><br><span class="line">                                         self.balancing, labels, self.num_classes)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> loss, student_logits</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> student_logits, attention_weights</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_distillation</span>(<span class="params">teacher_logits, student_logits, temperature, balancing, labels, num_classes</span>):</span></span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line">    kl_loss = F.kl_div(</span><br><span class="line">        F.log_softmax(student_logits / temperature, dim=-<span class="number">1</span>),</span><br><span class="line">        F.softmax(teacher_logits / temperature, dim=-<span class="number">1</span>).detach(),</span><br><span class="line">        reduction=<span class="string">&#x27;batchmean&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    kl_loss *= (balancing * temperature ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    student_loss = loss_function(student_logits.view(-<span class="number">1</span>, num_classes), labels.view(-<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span> - balancing) * student_loss + kl_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hard_distillation</span>(<span class="params">teacher_logits, student_logits, balancing, labels, num_classes</span>):</span></span><br><span class="line">    loss_function = torch.nn.CrossEntropyLoss()</span><br><span class="line">    teacher_labels = teacher_logits.argmax(dim=-<span class="number">1</span>)</span><br><span class="line">    teacher_loss = loss_function(teacher_logits.view(-<span class="number">1</span>, num_classes), teacher_labels.view(-<span class="number">1</span>))</span><br><span class="line">    student_loss = loss_function(student_logits.view(-<span class="number">1</span>, num_classes), labels.view(-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span> - balancing) * student_loss + balancing * teacher_loss</span><br></pre></td></tr></table></figure>
<p>完整代码<a href="https://github.com/vivounicorn/ViT"><strong>在这里</strong></a>。</p>
<p>总结来说，DeiT的贡献主要是能够只在ImageNet数据集上训练出一个纯Transformer模型，并利用蒸馏技术可以使得Transformer在较小的数据集上就能达到较好的效果，其缺点也很明显，依赖一个CNN模型作为teacher且Transformer的效果依赖teacher的效果。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>transformer</tag>
        <tag>Vit</tag>
        <tag>vision transformers</tag>
        <tag>第十章</tag>
        <tag>Transformer机制</tag>
        <tag>Attention机制</tag>
        <tag>DeiT</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中的自动微分(Automatic Differentiation)</title>
    <url>/article/1b1480ce.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ad/bp.png" width="266"/> 本文对自动微分机器原理做了简单介绍。 <span id="more"></span></p>
<h1 id="机器学习中的自动微分">机器学习中的自动微分</h1>
<p>计算机求解微分可以分成四类方法：</p>
<h2 id="手工求解">手工求解</h2>
<p>在《<a href="https://vivounicorn.github.io/article/ad2261a2.html">机器学习与人工智能技术分享-第四章 最优化原理</a>》中介绍了大量手工求解微分的算法，它们大都是通过泰勒展开式推导出的，只利用梯度求优化问题的叫一阶优化算法，如SGD，利用Hessians矩阵求解的是二阶优化算法，如L-BFGS， 这些算法的特点是能够很灵活自主高效的求解优化问题，包括一些目标函数不可微的问题，研究人员需要有很强的数学背景和代码实现能力，缺点是耗时且容易出错，代码调试也比较复杂。</p>
<h2 id="数值微分">数值微分</h2>
<p>原理很简单，就是利用导数的定义求解，所以实现起来也不复杂，形式化描述是： 假设有<span class="math inline">\(n\)</span>元目标函数<span class="math inline">\(f(X)=f(x_1,x_2,....x_n):\mathbb{R} \rightarrow \mathbb{R}\)</span>，求解其梯度，可以对它的每个维度分别使用导数定义求解： <span class="math display">\[\frac{\partial f(X)}{\partial x_i} \approx \frac{f(X+he_i)-f(X)}{h}\]</span> 其中<span class="math inline">\(e_i\)</span>是第<span class="math inline">\(i\)</span>维的单位向量，<span class="math inline">\(0&lt;h\ll 1\)</span>是一个微小步长，最后得到： <span class="math display">\[\nabla f(X)=(\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n})^T\]</span></p>
<p>例如，求解<span class="math inline">\(f(x_1,x_2)=x_1+x_2^2\)</span>，假设取<span class="math inline">\(h=0.000001\)</span>，则： <span class="math display">\[\begin{equation}
\frac{\partial f(X)}{\partial x_i}\approx\left\{
\begin{aligned}
\frac{f(x_1+0.000001,x_2)-f(x_1,x_2)}{0.000001}&amp;=1 \\
\frac{f(x_1,x_2+0.000001)-f(x_1,x_2)}{0.000001}&amp;=2x_2+0.000001
\end{aligned}
\right.
\end{equation}
\]</span> 如<span class="math inline">\(f&#39;(1,1)=(1,2.000001)^T\)</span>。</p>
<p>不过由于这种方法的缺点是：</p>
<p><strong>1)</strong>、多元函数的每个维度都要算一遍，即<span class="math inline">\(O(n)\)</span>的时间复杂度，尤其在当今的机器学习问题中，这个维度非常大，会导致这种方法完全无法落地；</p>
<p><strong>2)</strong>、由于这种求解方法天然是病态（ill-conditioned）且不稳定的（比如计算机的计算精度本来就是有限的），所以每个维度的每个<span class="math inline">\(h\)</span>的取值要很小心，否则就会出现较大误差，这种误差一般有两种：截断误差(Truncation error)和舍入误差(Roundoff error)，</p>
<p><a href="https://en.wikipedia.org/wiki/Truncation_error">截断误差</a>，简单说就是因为截断操作导致的误差，例如：无穷级数: <span class="math display">\[S_n=\lim_{n \to \infty} \sum_{1}^n\frac{1}{2^n}=1\]</span> 我们只能在有限的步数内做估计，如取：<span class="math inline">\(n=6\)</span>，则<span class="math inline">\(S_6=\frac{63}{64}\)</span>，截断误差为：<span class="math inline">\(0.015625\)</span>。</p>
<p><a href="https://mathworld.wolfram.com/RoundoffError.html">舍入误差</a>，简单说就是类似四舍五入这样的操作导致的误差，计算机在表示数字的能力上存在数量级和精度限制，某些数值操作对舍入误差非常敏感，且误差会被累积放大。</p>
<p>为了缓解上面的误差，人们想了很多办法，例如使用center difference估计法，如下： <span class="math display">\[\frac{\partial f(X)}{\partial x_i} = \frac{f(X+he_i)-f(X-he_i)}{2h}+O(h^2)\]</span></p>
以函数<span class="math inline">\(f(x)=64x(1−x)(1−2x)^2(1−8x+8x^2)^2\)</span>为例，两种方法比较如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/error.png" width="500"/>
</center>
<p>其中： <span class="math inline">\(E_{forward} (h, x_0 ) =\left|\frac{f(x_0+h)-f(x_0)}{h}-\frac{d}{dx}f(x)|_{x_0}\right|\)</span>， <span class="math inline">\(E_{center} (h, x_0 )=\left|\frac{f(x_0+h)-f(x_0-h)}{2h}-\frac{d}{dx}f(x)|_{x_0}\right|\)</span>，<span class="math inline">\(x_0=0.2\)</span> ，对截断误差和舍入误差的tradeoff体现在<span class="math inline">\(h\)</span>的取值上，即使是改进后的Center difference，稍有不慎误差也会被放大。</p>
<h2 id="符号微分">符号微分</h2>
<p>符号微分，顾名思义就是把微分的基本规则符号化，通过自动操作表达式从而获得各种衍生表达式，例如下面的积分规则： <span class="math display">\[\begin{equation}
\left\{
\begin{aligned}
&amp;\frac{d}{dx}(f(x)+g(x))\rightarrow\frac{d}{dx}f(x)+\frac{d}{dx}g(x) \\
&amp;\frac{d}{dx}(f(x)g(x))\rightarrow g(x)\frac{d}{dx}f(x)+f(x)\frac{d}{dx}g(x)
\end{aligned}
\right.
\end{equation}
\]</span></p>
<p>有了这些规则后，可以把输入变成一个由一系列符号表达式组成的树形结构，以前比较著名的深度学习框架Theano用的就是这种方式，但也正是由于这种比较“机械式”的展开，而没有通过复用和仅存储中间子表达式值的方式来简化计算，导致出现表达式成指数级膨胀。 例如函数：<span class="math inline">\(h(x) = f (x)g(x)\)</span>，对其应用导数的乘法规则有： <span class="math display">\[
\frac{d}{dx}h(x)= g(x)\frac{d}{dx}f(x)+f(x)\frac{d}{dx}g(x)
\]</span> 这个式子中，<span class="math inline">\(g(x)\)</span>与<span class="math inline">\(\frac{d}{dx}g(x)\)</span>是相互独立各算各的，显然一个不小心，它们的公用部分就无法复用，随便一个例子：<span class="math inline">\(g(x)=6+e^x\)</span>，<span class="math inline">\(\frac{d}{dx}g(x)=e^x\)</span>，公共部分重复计算。</p>
如果我们更关心输入函数的导数能否准确被算出，而不是它的符号表达本身的话，是可以通过复用及仅存储中间子表达式值的方式来简化计算的，这种思想也是自动微分的基础之一，如下图的例子，对函数<span class="math inline">\(l_{n+1} = 4l_n (1 − l_n ), l_1 = x\)</span>做表达式展开：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/sd.png" width="600"/>
</center>
<p>其中第三列是以符号微分形式展开，显然随着式子复杂度上升，展开式复杂度急剧上升，第四列是中间字表达式简化后的形式，复杂度比原始形式大大下降。</p>
<h2 id="自动微分ad">自动微分(AD)</h2>
<p>通过定义一个有限基本运算的集合，这些基本运算的求导数方法已知，包括一元运算（如：负数、开根号等）、二元运算（如：加、减、乘、除等）、超越函数（如：指数函数、三角函数、反三角函数、对数函数等），利用链式法则结合这些基本运算的导数，通过延迟 计算的方式来计算整个函数的导数，相比符号微分等其他方法，不但能处理封闭表达式（closed-form expressions），还可以支持控制流，如分支、循环、递归和过程调用等，这里解释下什么叫封闭表达式。</p>
<h3 id="封闭表达式closed-form-expressions">封闭表达式(Closed-Form Expressions)</h3>
<p>简单说就是能用固定数量操作符表达的式子。</p>
<p>例如：<span class="math inline">\(y=2+4+6+...+2n\)</span>不是封闭表达式，而<span class="math inline">\(y=\sum\limits_{i=1}^{n}2i=n(n+1)\)</span>就是封闭表达式。常见的封闭形式举例： <span class="math display">\[
\begin{aligned}
&amp; \sum\limits_{i=m}^{n}c=(n - m +1)c\\
&amp; \sum\limits_{i=1}^{n}i=\frac{n(n+1)}{2}\\
&amp; \sum\limits_{i=1}^{n}i^2=\frac{n(n+1)(2n+1)}{6}\\
&amp; \sum\limits_{i=0}^{n}a^i=\frac{a^{n+1}-1}{a-1}(a\neq1)\\
&amp; \sum\limits_{i=1}^{n}ia^i=\frac{a-(n+1)a^{n+1}+na^{n+2}}{(a-1)^2}\\
\end{aligned}
\]</span></p>
<p>问题：找到<span class="math inline">\(2 + 2^2 \cdot 7 + 2^3 \cdot 14 +...+ 2^n (n-1)\cdot 7\)</span>的封闭形式。 解： <span class="math display">\[
\begin{aligned}
y=&amp; 2 + 2^2 \cdot 7 + 2^3 \cdot 14 +...+ 2^n (n-1)\cdot 7\\
=&amp; 2+\sum\limits_{i=2}^{n}2^i(i-1)\cdot 7\\
=&amp; 2+7\sum\limits_{i=2}^{n}(i-1)2^i\\
=&amp; 2+7\sum\limits_{i=1}^{n-1}i2^{i+1}\\
=&amp; 2+14\sum\limits_{i=1}^{n-1}i2^i\\
=&amp; 2+14(2-n2^n+(n-1)2^{n+1})
\end{aligned}
\]</span></p>
<h3 id="对偶数">对偶数</h3>
数学本质上是由人类通过逻辑抽象思维对事物主观定义出结构和模式并以工具形式存在，用于解决实际问题的。而抽象逻辑是需要自洽的，所以在不同应用范围会产生递进的不同工具：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/math.png" width="600"/>
</center>
<p>例如，复数定义为： <span class="math display">\[z=a+bi\]</span> 其中<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>都是实数且<span class="math inline">\(i^2=1\)</span>，复数在实际中有广泛的应用。(ps：我最喜欢欧拉公式：<span class="math inline">\(e^{ix}=\cos x+i\sin x\)</span>，尤其当<span class="math inline">\(x=\pi\)</span>时，<span class="math inline">\(e^{i\pi}+1=0\)</span>)</p>
<p>类似复数，在19世纪后期，W. Clifford定义和发展出了对偶数，即： <span class="math display">\[z=a+b\epsilon\]</span> 其中<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>都是实数且<span class="math inline">\(\epsilon^2=0\)</span>。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ad/clifford.png" width="300"/>
</center>
<p>那么对偶数有什么用呢？看到这个定义，我第一个想到的是微分定义中的无穷小量<span class="math inline">\(dx\)</span>，第二个想到的是，函数的泰勒展开式的2阶及以上的余项部分。 假设<span class="math inline">\(f:\mathbb{R} \rightarrow \mathbb{R}\)</span>是任意函数，那么在<span class="math inline">\(x+\epsilon\)</span>处做泰勒展开，如下： <span class="math display">\[
f(x+\epsilon)=f(x)+f&#39;(x)\epsilon+ O(\epsilon^2)
\]</span> 其中<span class="math inline">\(O(\epsilon^2) \rightarrow0\)</span>。显然<span class="math inline">\(f(x)+f&#39;(x)\epsilon\)</span>就是个对偶数，所以有对偶函数： <span class="math display">\[
\hat f(\hat x)=f(x)+f&#39;(x)\epsilon
\]</span> 简化表示为： <span class="math display">\[
\hat f(\hat x)=\{f_0,f_1\},\text{where } f_0=f(x) \text{ and }f_1=f&#39;(x).
\]</span> 对复合函数<span class="math inline">\(f(g(x))\)</span>，根据链式法则有：<span class="math inline">\((f(g(x)))&#39;=f&#39;(g(x))g&#39;(x)\)</span>有： <span class="math display">\[
\hat f(\hat g)=f(g(x))+(f(g(x)))&#39;\epsilon=f(g(x))+f&#39;(g(x))g&#39;(x)\epsilon
\]</span> 简写为： <span class="math display">\[
\hat f(\hat g)=\{f_0(g_0),f_1(g_0)g_1\}
\]</span> 对更复杂的函数<span class="math inline">\(h(x)=f(g(u(x)))\)</span>有 <span class="math display">\[
\hat f(\hat g(\hat u))=\{f_0(g_0(u_0)),f_1(g_0(u_0))g_1(u_0)u_1\}
\]</span> 也就是只需要执行一次链式求导就能直接求出<span class="math inline">\(h&#39;(x)\)</span>（隐含链式求导是延迟执行的），这就是利用对偶数求解某个函数导数的威力，这个就是自动微分前向模式(Forward Mode of AD)的理论依据。</p>
<p>再进一步，定义新的对偶数： <span class="math display">\[
\widetilde r=a+b\epsilon_1+c\epsilon_2, \widetilde r=\{a,b,c\}
\]</span> 其中<span class="math inline">\(\{a,b,c\}\in \mathbb{R}\)</span>，<span class="math inline">\(i,j\in\{1,2\}\)</span>满足关系： <span class="math display">\[
\begin{equation}
\epsilon_i\cdot \epsilon_j=\left\{
  \begin{aligned}
  &amp;0&amp;\text{ if }i+j&gt;2, \\
  &amp;2\epsilon_{i+j}&amp;\text{ otherwise.}
  \end{aligned}
  \right.
\end{equation}
\]</span> 把泰勒展开式展开到二阶： <span class="math display">\[
\begin{aligned}
f(\widetilde x)=&amp;f(x)+f&#39;(x)\epsilon_1+\frac{1}{2}f&#39;&#39;(x)\epsilon_1^2\\
=&amp;f(x)+f&#39;(x)\epsilon_1+f&#39;&#39;(x)\epsilon_2
\end{aligned}
\]</span> 简写为： <span class="math display">\[
\begin{aligned}
\widetilde f(\widetilde x)=&amp;\{f(x),f&#39;(x),f&#39;&#39;(x)\}\\
=&amp;\{f_0,f_1,f_2\}
\end{aligned}
\]</span></p>
<p>以矩阵形式看，定义： <span class="math display">\[
\begin{aligned}
I=&amp;\left[
 \begin{matrix}
   1 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 1
  \end{matrix}
  \right]\\
\epsilon_1=&amp;\left[
 \begin{matrix}
   0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 1 \\
   0 &amp; 0 &amp; 0
  \end{matrix}
  \right]\\
\epsilon_2=&amp;\left[
 \begin{matrix}
   0 &amp; 0 &amp; 1/2 \\
   0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0
  \end{matrix}
  \right]\\
\end{aligned}
\]</span> <span class="math inline">\(X=xI+\epsilon_1\)</span>，则： <span class="math display">\[
f(X)=f(x)I+f&#39;(x)\epsilon_1+f&#39;&#39;(x)\epsilon_2
\]</span> 同样有： <span class="math display">\[
\widetilde f(\widetilde x)=\{f_0,f_1,f_2\},\text{ and }f_0=f(x),f_1=f&#39;(x),f_2=f&#39;&#39;(x).
\]</span> 对复合函数<span class="math inline">\(f(g(x))\)</span>就有： <span class="math display">\[
\widetilde f(\widetilde g)=\{f_0(g_0),f_1(g_0)g_1,f_2(g_0)g_1^2+f_1(g_0)g_2\}.
\]</span> 这个式子最核心的价值除了前面说的<strong>只需要执行一次链式求导就能直接求出目标函数的导数（这个导数就是对偶数的第二/对偶部分）</strong>外，导数结果<strong>不存在截断误差和舍入误差</strong>。</p>
<p>常用的对偶数推论有： <span class="math display">\[
\begin{aligned}
1.&amp;(a+b \epsilon)+(c+d \epsilon)=a+c+(b+d)\epsilon\\
2.&amp;(a+b \epsilon)\cdot(c+d \epsilon)=ac+(ad+bc)\epsilon\\
3.&amp;\frac{a+b \epsilon}{c+d \epsilon}=\frac{a}{c}+\frac{bc-ad}{c^2}\epsilon\\
4.&amp;-(a+b \epsilon)=-a-b\epsilon\\
5.&amp;P(a) = p_0 + p_1a + p_2a^2 + · · · + p_na^n \text{ 在}a+b\epsilon\text{处对偶形式为}p(a+b\epsilon)=p(a)+p&#39;(a)b\epsilon\\
6.&amp;sin(a+b\epsilon )=sin(a)+cos(a)b\epsilon\\
7.&amp;cos(a+b\epsilon )=cos(a)-sin(a)b\epsilon\\
8.&amp;e^{a+b\epsilon}=e^a+be^a\epsilon\\
9.&amp;log(a+b\epsilon)=log(a)+\frac{b}{a}\epsilon \text{ and }a\neq 0\\
10.&amp;\sqrt{a+b\epsilon}=\sqrt{a}+\frac{b}{2\sqrt{a}}\epsilon \text{ and }a\neq 0\\
11.&amp;(a+b\epsilon)^n=a^n+na^{n-1}b\epsilon\\
\end{aligned}
\]</span></p>
<p>举个例子：求函数<span class="math inline">\(f(x)=x-e^{-sin(x)}\)</span>的导数<span class="math inline">\(f&#39;(x)\)</span>，有： <span class="math display">\[
\begin{aligned}
f(x+\epsilon)&amp;=x+\epsilon-e^{-sin(x+\epsilon)}\\
&amp;=x+\epsilon-e^{-(sin(x)+cos(x)\epsilon)}\\
&amp;=x-e^{-sin(x)}+(1+cos(x)\cdot e^{-sin(x)})\epsilon
\end{aligned}
\]</span> 即：<span class="math inline">\(\widetilde f(\widetilde x)=\{x-e^{-sin(x)},1+cos(x)\cdot e^{-sin(x)}\}\)</span> 所以可以取出对偶部，直接得到<span class="math inline">\(f&#39;(x)=1+cos(x)\cdot e^{-sin(x)}\)</span>。</p>
<h3 id="前向模式自动微分forward-mode-ad">前向模式自动微分(Forward mode AD)</h3>
<p>前向模式的自动微分等价于执行基于对偶数的函数，举个例子，求函数<span class="math inline">\(f(x)=x\sin(x^2)\)</span>在点<span class="math inline">\(x=6\)</span>处的导数：</p>
<table>
<thead>
<tr class="header">
<th>原始问题</th>
<th style="text-align: left;">前向模式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(w_1=x\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{w_1}=1\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(w_2=w_1^2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{w_2}=2w_1\dot{w_1}=2x\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(w_3=\sin(w_2)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{w_3}=\cos(w_2)\dot{w_2}=2x\cos(x^2)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(w_4=w_1w_3\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{w_1}w_3+w_1\dot{w_3}=\sin(x^2)+2x^2\cos(x^2)\)</span></td>
</tr>
</tbody>
</table>
计算图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/fad.png" width="400"/>
</center>
<p>所以在<span class="math inline">\(x=6\)</span>处原函数的导数为：<span class="math inline">\(f&#39;(6)=\sin(36)+52\cos(36)=-10.205\)</span>，用对偶数推导如下： <span class="math display">\[
\begin{aligned}
\text{set}&amp;\\
x&amp;=6+\epsilon \\
u&amp;=x^2\\
&amp;=(6+\epsilon)^2\\
&amp;=36+12\epsilon\\
\text{then}&amp;\\
v&amp;=\sin(u)\\
&amp;=\sin(36+12\epsilon)\\
&amp;=\sin(36)+12\cos(36)\epsilon\\
\text{finally}&amp;\\
w&amp;=x\sin(v)\\
&amp;=(6+\epsilon)(\sin(36)+12\cos(36)\epsilon)\\
&amp;=6\sin(36)+(\sin(36)+72\cos(36))\epsilon
\end{aligned}
\]</span> 所以利用对偶数同时求得：<span class="math inline">\(f(6)=6\sin(36)=-5.95\)</span>和<span class="math inline">\(f&#39;(6)=\sin(36)+72\cos(36)=-10.205\)</span>。</p>
<p>多元函数的例子，计算函数<span class="math inline">\(f(x,y,z)=xy\cos(xz)\)</span>在点<span class="math inline">\((-2,3,-6)\)</span>处的梯度向量：</p>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 77%" />
</colgroup>
<thead>
<tr class="header">
<th>原始问题</th>
<th style="text-align: left;">前向模式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(t=xy\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{t}=[y,x,0]\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(u=xz\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{u}=[z,0,x]\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(v=\cos(u)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{v}=-\sin(u)\dot{u}=[-\sin(xz)z,0,-\sin(xz)x]\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(w=tv\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\dot{w}=\dot{t}v+t\dot{v}=[y\cos(xz)-xyz\sin(xz),x\cos(xz),-x^2y\sin(xz)]\)</span></td>
</tr>
</tbody>
</table>
计算图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/vectorad.png" width="400"/>
</center>
<p>利用对偶数原理和one-hot方式表示，有： <span class="math display">\[
\begin{aligned}
\text{set}&amp;\\
x&amp;=-2+\epsilon[1,0,0] \\
y&amp;=3+\epsilon[0,1,0]\\
z&amp;=-6+\epsilon[0,0,1]\\
\text{then}&amp;\\
t&amp;=xy\\
&amp;=(-2+\epsilon[1,0,0])(3+\epsilon[0,1,0])\\
&amp;=-6+\epsilon[3,-2,0]\\
u&amp;=xz\\
&amp;=(-2+\epsilon[1,0,0])(-6+\epsilon[0,0,1])\\
&amp;=12+\epsilon[-6,0,-2]\\
v&amp;=\cos(u)\\
&amp;=\cos(12+\epsilon[-6,0,-2])\\
&amp;=\cos(12)-\epsilon\sin(12)[-6,0,-2]\\
w&amp;=tv\\
&amp;=(-6+\epsilon[3,-2,0])(\cos(12)-\epsilon\sin(12)[-6,0,-2])\\
&amp;=-6\cos(12)+\epsilon[-36\sin(12)+3\cos(12),-2\cos(12),-12\sin(12)]\\
&amp;=-5.063+\epsilon[21.848, -1.688, 6.439]
\end{aligned}
\]</span></p>
<p>所以利用对偶数同时求得：<span class="math inline">\(f(-2,3,-6)=-5.063\)</span>和<span class="math inline">\(\bigtriangledown f(-2,3,-6)=[21.848, -1.688, 6.439]\)</span>。</p>
<h3 id="前向ad代码实践">前向AD代码实践</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> deprecated.sphinx <span class="keyword">import</span> deprecated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dual</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    封装对偶数及其常用操作符.</span></span><br><span class="line"><span class="string">    Wraps dual number and its common operators.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, f0, f1=<span class="number">0.0</span>, var_name=<span class="string">&#x27;x&#x27;</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化对偶数.</span></span><br><span class="line"><span class="string">        :param f0: 对偶数函数值部分.</span></span><br><span class="line"><span class="string">        :param f1: 对偶数一阶导数部分.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.f0 = f0</span><br><span class="line">        self.f1 = f1</span><br><span class="line">        self.var_name = var_name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数正向加法操作.</span></span><br><span class="line"><span class="string">        :param obj: 加数.</span></span><br><span class="line"><span class="string">        :return: 加和结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 + obj.f0, self.f1 + obj.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 + obj, self.f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__radd__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数反向加法操作.</span></span><br><span class="line"><span class="string">        :param obj: 被加数.</span></span><br><span class="line"><span class="string">        :return: 加和结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 + obj.f0, self.f1 + obj.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 + obj, self.f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__sub__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数正向减法操作.</span></span><br><span class="line"><span class="string">        :param obj: 减数.</span></span><br><span class="line"><span class="string">        :return: 减法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 - obj.f0, self.f1 - obj.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 - obj, self.f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rsub__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数反向减法操作.</span></span><br><span class="line"><span class="string">        :param obj: 被减数.</span></span><br><span class="line"><span class="string">        :return: 减法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(obj.f0 - self.f0, obj.f1 - self.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(obj - self.f0, -self.f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__mul__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数正向乘法操作.</span></span><br><span class="line"><span class="string">        :param obj: 乘数.</span></span><br><span class="line"><span class="string">        :return: 乘法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 * obj.f0, self.f0 * obj.f1 + self.f1 * obj.f0)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 * obj, self.f1 * obj)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rmul__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数逆向乘法操作.</span></span><br><span class="line"><span class="string">        :param obj: 被乘数.</span></span><br><span class="line"><span class="string">        :return: 乘法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 * obj.f0, self.f0 * obj.f1 + self.f1 * obj.f0)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 * obj, self.f1 * obj)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__truediv__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数正向除法操作.</span></span><br><span class="line"><span class="string">        :param obj: 除数.</span></span><br><span class="line"><span class="string">        :return: 除法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual) <span class="keyword">and</span> obj.f0 != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 / obj.f0, (self.f1 * obj.f0 - self.f0 * obj.f1) / obj.f0 ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>) <span class="keyword">and</span> obj != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 / obj, self.f1 / obj)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rtruediv__</span>(<span class="params">self, obj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数反向除法操作，obj若为整数或浮点数会被自动转为对偶数.</span></span><br><span class="line"><span class="string">        :param obj: 被除数.</span></span><br><span class="line"><span class="string">        :return: 除法结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(obj, Dual) <span class="keyword">and</span> self.f0 != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> Dual(obj.f0 / self.f0, (obj.f1 * self.f0 - obj.f0 * self.f1) / self.f0 ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(obj, <span class="built_in">float</span>) <span class="keyword">and</span> self.f0 != <span class="number">0</span>:</span><br><span class="line">            obj = Dual(obj)</span><br><span class="line">            <span class="keyword">return</span> Dual(obj.f0 / self.f0, (obj.f1 * self.f0 - obj.f0 * self.f1) / self.f0 ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__neg__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数取负数操作.</span></span><br><span class="line"><span class="string">        :return: 取负结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> Dual(-self.f0, -self.f1)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pow__</span>(<span class="params">self, n</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数幂函数操作，要求n必须为整数.</span></span><br><span class="line"><span class="string">        :param n: 幂.</span></span><br><span class="line"><span class="string">        :return: 幂函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(n, <span class="built_in">int</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(self.f0 ** n, n * self.f0 ** (n - <span class="number">1</span>) * self.f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        重载对偶数字符串函数.</span></span><br><span class="line"><span class="string">        :return: 对偶数的格式化字符串.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.f1 &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125; = &#123;&#125; + &#123;&#125; ε&#x27;</span>.<span class="built_in">format</span>(self.var_name, self.f0, self.f1)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125; = &#123;&#125; - &#123;&#125; ε&#x27;</span>.<span class="built_in">format</span>(self.var_name, self.f0, math.fabs(self.f1))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_dual</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        格式化打印对偶数.</span></span><br><span class="line"><span class="string">        :return: 控制台输出.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(self)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sin</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对偶数sine函数.</span></span><br><span class="line"><span class="string">        :param x: 输入变量.</span></span><br><span class="line"><span class="string">        :return: 对偶数形式的函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> Dual:</span><br><span class="line">            <span class="keyword">return</span> Dual(math.sin(x.f0), math.cos(x.f0) * x.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(x, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(math.sin(x))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cos</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对偶数cosine函数.</span></span><br><span class="line"><span class="string">        :param x: 输入变量.</span></span><br><span class="line"><span class="string">        :return: 对偶数形式的函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> Dual:</span><br><span class="line">            <span class="keyword">return</span> Dual(math.cos(x.f0), -math.sin(x.f0) * x.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(x, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(math.cos(x))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exp</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对偶数e^x函数.</span></span><br><span class="line"><span class="string">        :param x: 输入变量.</span></span><br><span class="line"><span class="string">        :return: 对偶数形式的函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> Dual:</span><br><span class="line">            <span class="keyword">return</span> Dual(math.exp(x.f0), math.exp(x.f0) * x.f1)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(x, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(math.exp(x))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">log</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对偶数log函数.</span></span><br><span class="line"><span class="string">        :param x: 输入变量.</span></span><br><span class="line"><span class="string">        :return: 对偶数形式的函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> Dual <span class="keyword">and</span> x.f0 != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> Dual(math.log(x.f0), x.f1 / x.f0)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(x, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(math.log(x))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sqrt</span>(<span class="params">x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对偶数开根号函数.</span></span><br><span class="line"><span class="string">        :param x: 输入变量.</span></span><br><span class="line"><span class="string">        :return: 对偶数形式的函数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(x) <span class="keyword">is</span> Dual:</span><br><span class="line">            <span class="keyword">return</span> Dual(math.sqrt(x.f0), x.f1 / (<span class="number">2</span> * math.sqrt(x.f0)))</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(x, <span class="built_in">float</span>):</span><br><span class="line">            <span class="keyword">return</span> Dual(math.sqrt(x))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line"><span class="meta">    @deprecated(<span class="params">version=<span class="string">&#x27;1.0&#x27;</span>, reason=<span class="string">&quot;This function will be removed soon.&quot;</span></span>)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">derive</span>(<span class="params">func, f1=<span class="number">1</span>, *args</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        求函数一阶导数.</span></span><br><span class="line"><span class="string">        :param func: 待求解函数.</span></span><br><span class="line"><span class="string">        :param f1: 函数一阶导数初始化.</span></span><br><span class="line"><span class="string">        :param args: 函数参数.</span></span><br><span class="line"><span class="string">        :return: 一阶导数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        paras = []</span><br><span class="line">        <span class="keyword">for</span> para <span class="keyword">in</span> args:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(para, Dual):</span><br><span class="line">                paras.append(Dual(para, f1))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                paras.append(para)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(paras) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> func(paras[<span class="number">0</span>]).f1</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(paras) == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> func(paras[<span class="number">0</span>], paras[<span class="number">1</span>]).f1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">func, *args</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        求解指定多元函数的梯度，依据从左到右的变量顺序给出梯度值，</span></span><br><span class="line"><span class="string">        例如：函数 f(x,y)的梯度为：▽f(x,y)=[f&#x27;(x),f&#x27;(y)].</span></span><br><span class="line"><span class="string">        :param func: 待求解函数.</span></span><br><span class="line"><span class="string">        :param args: 函数输入参数.</span></span><br><span class="line"><span class="string">        :return: 梯度向量.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        gs = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args)):</span><br><span class="line">            paras = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args)):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(args[j], Dual):</span><br><span class="line">                    <span class="keyword">if</span> i == j:</span><br><span class="line">                        paras.append(Dual(args[j], <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        paras.append(Dual(args[j], <span class="number">0</span>))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">if</span> i == j:</span><br><span class="line">                        paras.append(Dual(args[j].f0, <span class="number">1</span>))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        paras.append(Dual(args[j].f0, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">            gs.append(func(paras).f1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> gs</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">newton_raphson</span>(<span class="params">func, x0, u0, n</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        二元函数牛顿-拉森夫法.</span></span><br><span class="line"><span class="string">        :param func: 待求解函数.</span></span><br><span class="line"><span class="string">        :param x0: 输入变量1.</span></span><br><span class="line"><span class="string">        :param u0: 输入变量2.</span></span><br><span class="line"><span class="string">        :param n: 算法迭代次数.</span></span><br><span class="line"><span class="string">        :return: 对偶数结果.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x0d = Dual(x0, <span class="number">1</span>)</span><br><span class="line">        u0d = Dual(u0)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            fx = func(u0d, x0d)</span><br><span class="line">            fu = Dual.gradient(func, Dual(u0d.f0, <span class="number">1</span>), x0d)</span><br><span class="line">            u0d = u0d - fx / fu[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;k=&#123;&#125;, &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(k, u0d))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> u0d</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">excf1</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    复合函数示例：f(u(x),x) = cos(u(x)x)−u(x)^3+x+ sin(u(x)^2x)</span></span><br><span class="line"><span class="string">    :param args: 输入参数(u(x),x).</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(args[<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">        u = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        x = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        u = args[<span class="number">0</span>]</span><br><span class="line">        x = args[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Dual.cos(u * x) - u ** <span class="number">3</span> + x + Dual.sin(u ** <span class="number">2</span> * x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">excf2</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    示例函数：f(u(x),x) = sin(u(x))+x</span></span><br><span class="line"><span class="string">    :param args: 输入参数(u(x),x).</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(args[<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">        u = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        x = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        u = args[<span class="number">0</span>]</span><br><span class="line">        x = args[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Dual.sin(u) + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exf0</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    示例函数：f(x) = 6x^3 + 2x^2.</span></span><br><span class="line"><span class="string">    :param args: 输入参数x.</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(args[<span class="number">0</span>], <span class="built_in">list</span>):</span><br><span class="line">        x = args[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">6</span> * x ** <span class="number">3</span> + <span class="number">2</span> * x ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dexf0</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    一元函数示例：f(x) = 6x^3 + 2x^2的梯度值.</span></span><br><span class="line"><span class="string">    :param x: 输入参数(x).</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> Dual.gradient(exf0, x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exf1</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    二元函数示例：f(x) = 3x+10y的梯度向量.</span></span><br><span class="line"><span class="string">    :param x: 输入参数(x,y).</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">3</span> * x + <span class="number">10</span> * y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exf2</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    三元函数示例：f(x,y,z)=xysin(yz)的梯度向量.</span></span><br><span class="line"><span class="string">    :param args: 输入参数(x,y,z)</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    z = args[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> x * y * Dual.sin(y * z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exf3</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    二元函数示例：f(x1,x2)=log(x1)+x1*x2-sin(x2)的梯度向量.</span></span><br><span class="line"><span class="string">    :param args: 输入参数(x,y,z)</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x1 = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    x2 = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> Dual.log(x1) + x1 * x2 - Dual.sin(x2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exfox</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    二元函数示例：f(x1,x2)=log(x1)+x1*x2-sin(x2)的梯度向量.</span></span><br><span class="line"><span class="string">    :param args: 输入参数(x,y,z)</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x1 = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    x2 = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> x1 * x2 + Dual.sin(x1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exfams</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    二元函数示例：f(x1,x2)=log(x1)+x1*x2-sin(x2)的梯度向量.</span></span><br><span class="line"><span class="string">    :param args: 输入参数(x,y,z)</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span> <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(args[<span class="number">0</span>], <span class="built_in">list</span>):</span><br><span class="line">        x = args[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> x * Dual.sin(x ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exf5</span>(<span class="params">*args</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    三元函数示例：f(x,y,z)=xycos(xz)的梯度向量.</span></span><br><span class="line"><span class="string">    :param args: 输入参数(x,y,z)</span></span><br><span class="line"><span class="string">    :return: 对偶数结果.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = args[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    y = args[<span class="number">0</span>][<span class="number">1</span>]</span><br><span class="line">    z = args[<span class="number">0</span>][<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> x * y * Dual.cos(x * z)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x0 = <span class="number">0.7</span></span><br><span class="line">    u0 = <span class="number">1.6</span></span><br><span class="line">    n = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    u = Dual.newton_raphson(excf1, x0, u0, n)</span><br><span class="line">    u.print_dual()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[31mf(u(x),x) = cos(u(x)x)−u(x)^3+x+ sin(u(x)^2x) use the newton-raphson algorithm to find u(x) at the &quot;</span></span><br><span class="line">          <span class="string">&quot;initial value (x0,u0)=(&#123;&#125;, &#123;&#125;): \033[0m&quot;</span>.<span class="built_in">format</span>(x0, u0))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[31mu(x0)=&#123;&#125; and u&#x27;(x0)=&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(u.f0, u.f1))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[32mf(u(x),x) = sin(u(x))+x at the &quot;</span></span><br><span class="line">          <span class="string">&quot;initial value (x0,u0)=(&#123;&#125;, &#123;&#125;): \033[0m&quot;</span>.<span class="built_in">format</span>(x0, u0))</span><br><span class="line">    g = excf2(u, x0) + Dual(<span class="number">0</span>, Dual.gradient(excf2, u, x0)[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[32mg(x0)=&#123;&#125; and g&#x27;(x0)=&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(g.f0, g.f1))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[33mf(x) = 6x^3 + 2x^2: f(1) = &#123;&#125; then f&#x27;(1) = &#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(exf0(<span class="number">1</span>), dexf0(<span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[31mf(x,y) =3x + 10y gradient vector at point(&#123;&#125;,&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(<span class="number">1</span>, <span class="number">1</span>, Dual.gradient(exf1, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[32mf(x,y,z) =xysin(yz) gradient vector at point(&#123;&#125;,&#123;&#125;,&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(<span class="number">3</span>, -<span class="number">1</span>, <span class="number">2</span>,</span><br><span class="line">                                                                                            Dual.gradient(exf2, <span class="number">3</span>, -<span class="number">1</span>,</span><br><span class="line">                                                                                                          <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[32mf(x,y,z) =xycos(xz) gradient vector at point(&#123;&#125;,&#123;&#125;,&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(-<span class="number">2</span>, <span class="number">3</span>, -<span class="number">6</span>,</span><br><span class="line">                                                                                             Dual.gradient(exf5, -<span class="number">2</span>, <span class="number">3</span>,</span><br><span class="line">                                                                                                           -<span class="number">6</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[33mf(x1,x2)=log(x1)+x1*x2-sin(x2) gradient vector at point(&#123;&#125;,&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(<span class="number">2</span>, <span class="number">5</span>,</span><br><span class="line">                                                                                                    Dual.gradient(exf3,</span><br><span class="line">                                                                                                                  <span class="number">2</span>,</span><br><span class="line">                                                                                                                  <span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[33mf(x1,x2)=x1*x2+sin(x1) gradient vector at point(&#123;&#125;,&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(<span class="number">2</span>, <span class="number">5</span>,</span><br><span class="line">                                                                                            Dual.gradient(exfox,</span><br><span class="line">                                                                                                          <span class="number">2</span>,</span><br><span class="line">                                                                                                          <span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\033[33mf(x)=xsin(x**2) gradient vector at point(&#123;&#125;):&#123;&#125;\033[0m&quot;</span>.<span class="built_in">format</span>(<span class="number">6</span>,</span><br><span class="line">                                                                                  Dual.gradient(exfams,</span><br><span class="line">                                                                                                <span class="number">6</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">k=0, x = 1.3745071326929446 - 0.11382505528565992 ε</span><br><span class="line">k=1, x = 1.3128464318221855 + 0.058350216540021926 ε</span><br><span class="line">k=2, x = 1.3085520610889037 + 0.11245296805019295 ε</span><br><span class="line">k=3, x = 1.3085322280402245 + 0.11635228047793793 ε</span><br><span class="line">k=4, x = 1.3085322276188782 + 0.11637033108795897 ε</span><br><span class="line">k=5, x = 1.3085322276188782 + 0.11637033147144211 ε</span><br><span class="line">k=6, x = 1.3085322276188782 + 0.11637033147144209 ε</span><br><span class="line">k=7, x = 1.3085322276188782 + 0.11637033147144213 ε</span><br><span class="line">k=8, x = 1.3085322276188782 + 0.1163703314714421 ε</span><br><span class="line">k=9, x = 1.3085322276188782 + 0.1163703314714421 ε</span><br><span class="line">x = 1.3085322276188782 + 0.1163703314714421 ε</span><br><span class="line">f(u(x),x) = cos(u(x)x)−u(x)^3+x+ sin(u(x)^2x) use the newton-raphson algorithm to find u(x) at the initial value (x0,u0)=(0.7, 1.6):</span><br><span class="line">u(x0)=1.3085322276188782 and u&#x27;(x0)=0.1163703314714421</span><br><span class="line">f(u(x),x) = sin(u(x))+x at the initial value (x0,u0)=(0.7, 1.6):</span><br><span class="line">g(x0)=1.6658054458395304 and g&#x27;(x0)=1.0301710907484147</span><br><span class="line">f(x) = 6x^3 + 2x^2: f(1) = 8 then f&#x27;(1) = [22]</span><br><span class="line">f(x,y) =3x + 10y gradient vector at point(1,1):[3, 10]</span><br><span class="line">f(x,y,z) =xysin(yz) gradient vector at point(3,-1,2):[0.9092974268256817, -0.23101126119419035, -1.2484405096414273]</span><br><span class="line">f(x,y,z) =xycos(xz) gradient vector at point(-2,3,-6):[21.848186924213135, -1.6877079174649843, 6.43887501600522]</span><br><span class="line">f(x1,x2)=log(x1)+x1*x2-sin(x2) gradient vector at point(2,5):[5.5, 1.7163378145367738]</span><br><span class="line">f(x1,x2)=x1*x2+sin(x1) gradient vector at point(2,5):[4.583853163452858, 2.0]</span><br><span class="line">f(x)=xsin(x**2) gradient vector at point(6):[-10.205164506616253]</span><br></pre></td></tr></table></figure>
<h3 id="反向模式自动微分reverse-mode-ad">反向模式自动微分(Reverse mode AD)</h3>
反向模式的自动微分等价于广义上的反向传播算法(BP)，都是从输出反向传播梯度，并用 <strong>伴随变量</strong> <span class="math inline">\(\overline{v}_i=\frac{\partial{y_j}}{\partial v_i}\)</span>补全中间变量， 即，反向AD计算分两个阶段，第一个阶段执行前向AD以计算中间变量导数并记录计算图中的依赖关系，第二个阶段通过将伴随变量反向传播回输入来计算所有导数。 如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/bp.png" width="600"/>
</center>
<p>依然以函数<span class="math inline">\(f(x,y,z)=xy\cos(xz)\)</span>在点<span class="math inline">\((-2,3,-6)\)</span>为例，计算每个中间变量：</p>
<table>
<colgroup>
<col style="width: 22%" />
<col style="width: 77%" />
</colgroup>
<thead>
<tr class="header">
<th>原始问题</th>
<th style="text-align: left;">反向模式</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x=-2\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{x}=\overline{t}\cdot\frac{\partial t}{\partial x}+\overline{u}\cdot\frac{\partial{u}}{\partial{x}}=vy-tz\sin(u)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(y=3\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{y}=\overline{t}\cdot\frac{\partial t}{\partial y}=vx\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(z=-6\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{z}=\overline{u}\cdot\frac{\partial u}{\partial z}=-tx\sin(u)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(t=xy\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{t}=\overline{w}\cdot\frac{\partial w}{\partial t}=v\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(u=xz\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{u}=\overline{v}\cdot\frac{\partial v}{\partial u}=-t\sin(u)\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(v=\cos(u)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{v}=\overline{w}\cdot\frac{\partial w}{\partial v}=t\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(w=tv\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\overline{w}=\frac{\partial {w}}{\partial {w}}=1\)</span></td>
</tr>
</tbody>
</table>
计算图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ad/bpad.png" width="500"/>
</center>
<p>中间变量和伴随变量计算如下：</p>
<p><span class="math display">\[
\begin{aligned}
\overline{w}&amp;=\frac{\partial {w}}{\partial {w}}=1\\
\overline{v}&amp;=\overline{w}\cdot\frac{\partial w}{\partial v}=t=xy=-6\\
\overline{u}&amp;=\overline{v}\cdot\frac{\partial v}{\partial u}=-t\sin(u)=-xy\sin(xz)=-3.219\\
\overline{t}&amp;=\overline{w}\cdot\frac{\partial w}{\partial t}=v=0.8439\\
\overline{z}&amp;=\overline{u}\cdot\frac{\partial u}{\partial z}=-tx\sin(u)=6.4389\\
\overline{y}&amp;=\overline{t}\cdot\frac{\partial t}{\partial y}=vx=-1.6877\\
\overline{x}&amp;=\overline{t}\cdot\frac{\partial t}{\partial x}+\overline{u}\cdot\frac{\partial{u}}{\partial{x}}=vy-tz\sin(u)=21.8482
\end{aligned}
\]</span></p>
<p>计算机求解以上问题有很多方法，其中一种是利用线性代数求解，如下：</p>
<p>把上面的中间变量和伴随变量重新整理下，定义变量：<span class="math inline">\(x=[\overline{x},\overline{y},\overline{z},\overline{t},\overline{u},\overline{v},\overline{w}]^T\)</span>： <span class="math display">\[
\begin{aligned}
\overline{x}-3\overline{t}+6\overline{u}=0\\
\overline{y}+2\overline{t}=0\\
\overline{z}+2\overline{u}=0\\
\overline{t}-\overline{w}v=0\\
\overline{u}+\overline{v}\sin(u)=0\\
\overline{v}-\overline{w}t=0\\
\overline{w}=1
\end{aligned}
\]</span> 令： <span class="math display">\[
\begin{aligned}
A&amp;=
\left[
 \begin{matrix}
   1 &amp; 0 &amp; 0 &amp; -3 &amp; 6 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; -v \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; \sin(u) &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; -t \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
  \end{matrix}
  \right]\\
\\
&amp;=
\left[
 \begin{matrix}
   1 &amp; 0 &amp; 0 &amp; -3 &amp; 6 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0 &amp; 2 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; -0.8439 \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; -0.5366 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 6 \\
   0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
  \end{matrix}
  \right]\\
\\
b&amp;=[0,0,0,0,0,0,1]^T
\end{aligned}
\]</span> 有： <span class="math display">\[
Ax=b
\]</span> 显然<span class="math inline">\(A\)</span>是一个稀疏的上三角矩阵，且对角线所有元素<span class="math inline">\(a_{ij}\neq 0\)</span>，根据Back Substitution回代定理可知，以上式子有唯一解。</p>
<h3 id="反向ad代码实践">反向AD代码实践</h3>
<p><strong>1、Back Substitution求解反向AD</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">back_substitution</span>(<span class="params">A, b</span>):</span></span><br><span class="line">    n = b.shape[<span class="number">0</span>]</span><br><span class="line">    x = np.zeros_like(b)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>):</span><br><span class="line">        x[k] = (b[k] - np.dot(A[k, k + <span class="number">1</span>:n], x[k + <span class="number">1</span>:n])) / A[k, k]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    A = np.array([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, -<span class="number">3</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, -math.cos(<span class="number">12</span>)],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, math.sin(<span class="number">12</span>), <span class="number">0</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">6</span>],</span><br><span class="line">                  [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line">    b = np.array([<span class="number">0.0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    x = back_substitution(A, b)</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">21.84818692</span> -<span class="number">1.68770792</span>  <span class="number">6.43887502</span>  <span class="number">0.84385396</span> -<span class="number">3.21943751</span> -<span class="number">6.</span></span><br><span class="line">  <span class="number">1.</span>        ]</span><br></pre></td></tr></table></figure>
<p><strong>2、计算图求解反向AD</strong></p>
<p>还有一种方式是类似tensorflow计算图的方式求反向AD，以下为代码实践：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ComputeGraphNode</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    定义计算图节点</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, value=<span class="number">0.0</span>, tag=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        初始化函数</span></span><br><span class="line"><span class="string">        :param value: 计算图节点值</span></span><br><span class="line"><span class="string">        :param tag: 计算图节点名字</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.in_nodes = []  <span class="comment"># input nodes</span></span><br><span class="line">        self.op = <span class="literal">None</span>  <span class="comment"># operator</span></span><br><span class="line">        self.tag = tag  <span class="comment"># node&#x27;s tag</span></span><br><span class="line">        self.fod = []  <span class="comment"># first order derivative</span></span><br><span class="line">        self.val = value  <span class="comment"># node&#x27;s value</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;%s:%s&quot;</span> % (self.tag, self.val)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(other, ComputeGraphNode):</span><br><span class="line">            next_node = AddOp()(self, other)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(other, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(other, <span class="built_in">float</span>):</span><br><span class="line">            node_right = Variable(other, tag=<span class="built_in">str</span>(other))</span><br><span class="line">            next_node = AddOp()(self, node_right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of __add__()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__radd__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self + other</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__sub__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(other, ComputeGraphNode):</span><br><span class="line">            next_node = SubOp()(self, other)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(other, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(other, <span class="built_in">float</span>):</span><br><span class="line">            node_right = Variable(other, tag=<span class="built_in">str</span>(other))</span><br><span class="line">            next_node = SubOp()(self, node_right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of __sub__()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rsub__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span> * self + other</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__mul__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(other, ComputeGraphNode):</span><br><span class="line">            next_node = MulOp()(self, other)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(other, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(other, <span class="built_in">float</span>):</span><br><span class="line">            node_right = Variable(other, tag=<span class="built_in">str</span>(other))</span><br><span class="line">            next_node = MulOp()(self, node_right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of __mul__()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rmul__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self * other</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pow__</span>(<span class="params">self, power, modulo=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(power, ComputeGraphNode):</span><br><span class="line">            next_node = PowOp()(self, power)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(power, <span class="built_in">int</span>):</span><br><span class="line">            node_right = Variable(power, tag=<span class="built_in">str</span>(power))</span><br><span class="line">            next_node = PowOp()(self, node_right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of __pow__()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rpow__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        node_left = Variable(other, tag=<span class="built_in">str</span>(other))</span><br><span class="line">        <span class="keyword">return</span> node_left ** self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__truediv__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(other, ComputeGraphNode):</span><br><span class="line">            next_node = DivOp()(self, other)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(other, <span class="built_in">int</span>) <span class="keyword">or</span> <span class="built_in">isinstance</span>(other, <span class="built_in">float</span>):</span><br><span class="line">            node_right = Variable(other, tag=<span class="built_in">str</span>(other))</span><br><span class="line">            next_node = DivOp()(self, node_right)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of __div__()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__rtruediv__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> other * self ** (-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cos</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> CosOp()(self)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sin</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> SinOp()(self)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Variable</span>(<span class="params">ComputeGraphNode</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    变量类型的计算图节点</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, value, tag=<span class="string">&#x27;&#x27;</span></span>):</span></span><br><span class="line">        ComputeGraphNode.__init__(self, value, tag=tag)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Operator</span>(<span class="params">ABC</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    操作符基类</span></span><br><span class="line"><span class="string">    1、每个节点输入、输出和导数计算出来</span></span><br><span class="line"><span class="string">    2、反向链式法则计算</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        next_node = ComputeGraphNode(tag=<span class="string">&#x27;default&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(args) == <span class="number">1</span>:</span><br><span class="line">            node = args[<span class="number">0</span>]</span><br><span class="line">            next_node.in_nodes = [node]</span><br><span class="line">            next_node.tag = <span class="string">&quot;%s(%s)&quot;</span> % (self.tag, node.tag)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">len</span>(args) == <span class="number">2</span>:</span><br><span class="line">            node_left, node_right = args[<span class="number">0</span>], args[<span class="number">1</span>]</span><br><span class="line">            next_node.in_nodes = [node_left, node_right]</span><br><span class="line">            next_node.tag = <span class="string">&quot;%s%s%s&quot;</span> % (node_left.tag, self.tag, node_right.tag)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;Operator() takes either 1 or 2 arguments (&#123;&#125; given).&#x27;</span></span><br><span class="line">                            .<span class="built_in">format</span>(<span class="built_in">len</span>(args)))</span><br><span class="line"></span><br><span class="line">        next_node.val = self.forward(next_node)</span><br><span class="line"></span><br><span class="line">        next_node.op = self</span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;forward() must be implemented.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;gradient() must be implemented.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AddOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27;+&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> node.in_nodes[<span class="number">0</span>].val + node.in_nodes[<span class="number">1</span>].val</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: <span class="number">1.</span>, node.in_nodes[<span class="number">1</span>]: <span class="number">1.</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SubOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27;-&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> node.in_nodes[<span class="number">0</span>].val - node.in_nodes[<span class="number">1</span>].val</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: <span class="number">1.</span>, node.in_nodes[<span class="number">1</span>]: -<span class="number">1.</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MulOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27; \cdot &#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> node.in_nodes[<span class="number">0</span>].val * node.in_nodes[<span class="number">1</span>].val</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: node.in_nodes[<span class="number">1</span>].val, node.in_nodes[<span class="number">1</span>]: node.in_nodes[<span class="number">0</span>].val&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DivOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27;/&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> node.in_nodes[<span class="number">0</span>].val / node.in_nodes[<span class="number">1</span>].val</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        x = node.in_nodes[<span class="number">0</span>].val</span><br><span class="line">        y = node.in_nodes[<span class="number">1</span>].val</span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: <span class="number">1.</span> / y, node.in_nodes[<span class="number">1</span>]: -x / y ** <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CosOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27; \cos &#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> math.cos(node.in_nodes[<span class="number">0</span>].val)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: -math.sin(node.in_nodes[<span class="number">0</span>].val)&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SinOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27; \sin &#x27;</span></span><br><span class="line">        <span class="keyword">return</span> Operator.__call__(self, *args, **kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> math.sin(node.in_nodes[<span class="number">0</span>].val)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: math.cos(node.in_nodes[<span class="number">0</span>].val)&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PowOp</span>(<span class="params">Operator</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">        self.tag = <span class="string">&#x27;^&#x27;</span></span><br><span class="line">        next_node = Operator.__call__(self, *args, **kwargs)</span><br><span class="line">        next_node.tag = <span class="string">&quot;%s%s%s&quot;</span> % (next_node.in_nodes[<span class="number">0</span>].tag, self.tag, next_node.in_nodes[<span class="number">1</span>].tag)</span><br><span class="line">        <span class="keyword">return</span> next_node</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        <span class="keyword">return</span> node.in_nodes[<span class="number">0</span>].val ** node.in_nodes[<span class="number">1</span>].val</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradient</span>(<span class="params">self, node</span>):</span></span><br><span class="line">        x = node.in_nodes[<span class="number">0</span>].val</span><br><span class="line">        y = node.in_nodes[<span class="number">1</span>].val</span><br><span class="line">        <span class="keyword">return</span> &#123;node.in_nodes[<span class="number">0</span>]: y * x ** (y - <span class="number">1</span>), node.in_nodes[<span class="number">1</span>]: x ** y * math.log(x)&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExecutorTools</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reverse_order_dfs_sort</span>(<span class="params">compute_node</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(compute_node, ComputeGraphNode):</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">&#x27;type of reverse_dfs_sort()\&#x27;s arguments should be \&#x27;ComputeGraphNode\&#x27;.&#x27;</span>)</span><br><span class="line">        visited = <span class="built_in">set</span>()</span><br><span class="line">        positive_order_dfs = []</span><br><span class="line">        ExecutorTools.post_order_dfs(compute_node, visited, positive_order_dfs)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">reversed</span>(positive_order_dfs)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post_order_dfs</span>(<span class="params">compute_node, visited, topo_order</span>):</span></span><br><span class="line">        <span class="keyword">if</span> compute_node <span class="keyword">in</span> visited:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        visited.add(compute_node)</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> compute_node.in_nodes:</span><br><span class="line">            ExecutorTools.post_order_dfs(n, visited, topo_order)</span><br><span class="line">        topo_order.append(compute_node)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gradients</span>(<span class="params">compute_node, var_list</span>):</span></span><br><span class="line">        <span class="comment"># 对计算图的节点做dfs，为了方便后续计算反向梯度值，对列表做了逆序排列。</span></span><br><span class="line">        compute_node_grapth = ExecutorTools.reverse_order_dfs_sort(compute_node)</span><br><span class="line">        <span class="comment"># 存储每个节点的反向自动微分值，对应符号$\overline&#123;&#125;$对应的变量， 跟节点梯度值为1。</span></span><br><span class="line">        each_node_grad = &#123;compute_node: <span class="number">1</span>&#125;</span><br><span class="line">        <span class="comment"># 遍历计算图中的每个节点。</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> compute_node_grapth:</span><br><span class="line">            <span class="comment"># 对有操作符的中间节点做反向梯度传播。</span></span><br><span class="line">            <span class="keyword">if</span> node.op <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 求父节点node的所有输入节点的导数值</span></span><br><span class="line">                input_grads_list = node.op.gradient(node)</span><br><span class="line">                <span class="comment"># 遍历当前节点的所有输入节点。</span></span><br><span class="line">                <span class="keyword">for</span> i_node <span class="keyword">in</span> node.in_nodes:</span><br><span class="line">                    <span class="comment"># 如果一个节点被共用，则梯度需要做累加</span></span><br><span class="line">                    <span class="keyword">if</span> i_node <span class="keyword">in</span> each_node_grad:</span><br><span class="line">                        each_node_grad[i_node] += each_node_grad[node] * input_grads_list[i_node]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        each_node_grad[i_node] = each_node_grad[node] * input_grads_list[i_node]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># for i in each_node_grad:</span></span><br><span class="line">        <span class="comment">#     print(&quot;%s:%s&quot; % (i.tag, each_node_grad[i]))</span></span><br><span class="line"></span><br><span class="line">        var_grad_list = [each_node_grad[node] <span class="keyword">for</span> node <span class="keyword">in</span> var_list]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> each_node_grad, var_grad_list</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">visualize</span>(<span class="params">cp_nodes</span>):</span></span><br><span class="line">        G = nx.DiGraph()</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> cp_nodes:</span><br><span class="line">            tag_root = <span class="string">&quot;%s:%s&quot;</span> % (node.tag, cp_nodes[node])</span><br><span class="line">            G.add_node(tag_root, attr_dict=&#123;<span class="string">&#x27;color&#x27;</span>: <span class="string">&quot;red&quot;</span>&#125;)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(node.in_nodes) == <span class="number">1</span>:</span><br><span class="line">                tag_child = <span class="string">&quot;%s:%s&quot;</span> % (node.in_nodes[<span class="number">0</span>].tag, cp_nodes[node.in_nodes[<span class="number">0</span>]])</span><br><span class="line">                G.add_node(tag_child, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">                G.add_edge(tag_child, tag_root)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">len</span>(node.in_nodes) == <span class="number">2</span>:</span><br><span class="line">                tag_left = <span class="string">&quot;%s:%s&quot;</span> % (node.in_nodes[<span class="number">0</span>].tag, cp_nodes[node.in_nodes[<span class="number">0</span>]])</span><br><span class="line">                tag_right = <span class="string">&quot;%s:%s&quot;</span> % (node.in_nodes[<span class="number">1</span>].tag, cp_nodes[node.in_nodes[<span class="number">1</span>]])</span><br><span class="line">                G.add_node(tag_right, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">                G.add_edge(tag_right, tag_root)</span><br><span class="line">                G.add_node(tag_left, color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">                G.add_edge(tag_left, tag_root)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">get_root_leaves_node</span>(<span class="params">G</span>):</span></span><br><span class="line">            root_node, leaf_nodes = <span class="literal">None</span>, []</span><br><span class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> G.nodes:</span><br><span class="line">                pre_node = G.neighbors(n)</span><br><span class="line">                child_node = G.predecessors(n)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">list</span>(pre_node)) == <span class="number">0</span>:</span><br><span class="line">                    root_node = n</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">list</span>(child_node)) == <span class="number">0</span>:</span><br><span class="line">                    leaf_nodes.append(n)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> root_node, leaf_nodes</span><br><span class="line"></span><br><span class="line">        root, leaves = get_root_leaves_node(G)</span><br><span class="line"></span><br><span class="line">        color_map = []</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> G.nodes:</span><br><span class="line">            <span class="keyword">if</span> node == root:</span><br><span class="line">                color_map.append(<span class="string">&#x27;tab:red&#x27;</span>)</span><br><span class="line">            <span class="keyword">elif</span> node <span class="keyword">in</span> leaves:</span><br><span class="line">                color_map.append(<span class="string">&#x27;tab:green&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                color_map.append(<span class="string">&#x27;tab:blue&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        labels = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> G.nodes:</span><br><span class="line">            text = node.split(<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line">            label = text[<span class="number">0</span>]</span><br><span class="line">            value = <span class="built_in">str</span>(<span class="built_in">round</span>(<span class="built_in">float</span>(text[<span class="number">1</span>]), <span class="number">2</span>))</span><br><span class="line">            labels[node] = <span class="string">&quot;$%s=%s$&quot;</span> % (label, value)</span><br><span class="line"></span><br><span class="line">        pos = nx.circular_layout(G)</span><br><span class="line">        nx.draw_networkx(G, node_color=color_map, node_size=<span class="number">1000</span>, pos=pos, with_labels=<span class="literal">False</span>)</span><br><span class="line">        nx.draw_networkx_labels(G, pos, labels, font_size=<span class="number">22</span>, font_color=<span class="string">&quot;black&quot;</span>)</span><br><span class="line"></span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    x = Variable(-<span class="number">2</span>, <span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    y = Variable(<span class="number">3</span>, <span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    z = Variable(-<span class="number">6</span>, <span class="string">&#x27;z&#x27;</span>)</span><br><span class="line">    f = x * y * ComputeGraphNode.cos(x * z)</span><br><span class="line"></span><br><span class="line">    nodes, gradients = ExecutorTools.gradients(f, [x, y, z])</span><br><span class="line">    <span class="built_in">print</span>(gradients)</span><br><span class="line">    ExecutorTools.visualize(nodes)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<center>
<img data-src="https://vivounicorn.github.io/images/ad/rad.png" width="800"/>
</center>
<p>以上代码均可在 <strong><a href="https://github.com/vivounicorn/automatic_differentiation">这里</a></strong> 下载。</p>
<h2 id="总结">总结</h2>
<p>自动微分是目前所有主流机器学习框架的根基之一，而前向模式AD和反向模式AD又是求解自动微分的两类核心方法，本质上，对多元函数<span class="math inline">\(f:\mathbb{R}^n \rightarrow \mathbb{R}^m\)</span>求导，是在求该函数的雅克比矩阵（Jacobi matrix），它是<span class="math inline">\(m×n\)</span>的矩阵，所以显然，当<span class="math inline">\(n\ll m\)</span>，即输入维度远小于输出维度时，此时进行<span class="math inline">\(n\)</span>次前向模式AD得到雅克比矩阵的计算代价比较低，反之，则使用反向模式AD更合适。在机器学习问题中，往往输入变量的维度远远大于输出，所以反向模式AD几乎是各大计算框架的唯一选择。</p>
<h2 id="参考文献">参考文献</h2>
<p>《<a href="https://www.redalyc.org/journal/467/46761359006/html/#redalyc_46761359006_ref33">Dual Numbers for Algorithmic Differentiation</a>》</p>
<p>《<a href="https://londmathsoc.onlinelibrary.wiley.com/doi/10.1112/plms/s1-4.1.381">Preliminary sketch of biquaternions</a>》</p>
<p>《<a href="http://www.ams.org/publicoutreach/feature-column/fc-2017-12">How to Differentiate with a Computer</a>》</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>自动微分</tag>
        <tag>Automatic Differentiation</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第一章 基本概念</title>
    <url>/article/f082dc68.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjqpcau16kj17d5iupnob1rco9.png" width=266 /> 本章介绍关于机器学习的一些基本概念，包括生成式模型和判别式模型、非参学习等。 <span id="more"></span></p>
<h1 id="一些基本概念">1. 一些基本概念</h1>
<h2 id="生成式模型与判别式模型">1.1 生成式模型与判别式模型</h2>
<p>从概率分布的角度看待模型。 给个例子感觉一下: 如果我想知道一个人A说的是哪个国家的语言，我应该怎么办呢?</p>
<ul>
<li><p>生成式模型</p>
<p>我把每个国家的语言都学一遍，这样我就能很容易知道A说的是哪国语言，并且C、D说的是哪国的我也可以知道，进一步我还能自己讲不同国家语言。</p></li>
<li><p>判别式模型</p>
<p>我只需要学习语言之间的差别是什么，学到了这个界限自然就能区分不同语言，我能说出不同语言的区别，但我可能不会讲。</p></li>
</ul>
<p>如果我有输入数据<span class="math inline">\(x\)</span>，并且想通过标注<span class="math inline">\(y\)</span>去区分不同数据属于哪一类，生成式模型是在学习样本和标注的联合概率分布 <span class="math inline">\(p(x,y)\)</span> 而判别式模型是在学习条件概率 <span class="math inline">\(p(y|x)\)</span>。 生成式模型<span class="math inline">\(p(x,y)\)</span>可以通过贝叶斯公式转化为<span class="math inline">\(p(y|x)=\frac{p(x,y)}{p(x)}\)</span>，并用于分类，而联合概率分布<span class="math inline">\(p(x,y)\)</span>也可用于其他目的，比如用来生成样本对<span class="math inline">\((x,y)\)</span>。</p>
<p>判别式模型的主要任务是找到一个或一系列超平面，利用它(们)划分给定样本<span class="math inline">\(x\)</span>到给定分类<span class="math inline">\(y\)</span>，这也能直白的体现出“判别”模型这个名称。</p>
<p>最后给一个很简单的例子说明一下： 假如我有以下独立同分布的若干样本<span class="math inline">\((x,y)\)</span>，其中<span class="math inline">\(x\)</span>为特征，<span class="math inline">\(y\in\{0,1\}\)</span>为标注,<span class="math inline">\((x,y)\in\{(2,-1),(2,-1),(3,-1),(3,1),(3,1)\}\)</span>，则：</p>
<ul>
<li><p><span class="math inline">\(p(x,y)\)</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(p(x,y)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y=-1\)</span></th>
<th><span class="math inline">\(y=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x=2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(2/5\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x=3\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1/5\)</span></td>
<td><span class="math inline">\(2/5\)</span></td>
</tr>
</tbody>
</table></li>
<li><p><span class="math inline">\(p(y|x)\)</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(p(y|x)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y=-1\)</span></th>
<th><span class="math inline">\(y=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x=2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x=3\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1/3\)</span></td>
<td><span class="math inline">\(2/3\)</span></td>
</tr>
</tbody>
</table></li>
</ul>
<p>一些理论可看：<a href="http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf">On Discriminative vs Generative classifiers: A comparison of logistic regression and naive Bayes</a>。</p>
<ol type="1">
<li><p>常见生成式模型</p>
<ul>
<li><p>Naive Bayes</p></li>
<li><p>Gaussians</p></li>
<li><p>Mixtures of Gaussians</p></li>
<li><p>Mixtures of Experts</p></li>
<li><p>Mixtures of Multinomials</p></li>
<li><p>HMM</p></li>
<li><p>Markov random fields</p></li>
<li><p>Sigmoidal belief networks</p></li>
<li><p>Bayesian networks</p></li>
</ul></li>
<li><p>常见判别式模型</p>
<ul>
<li><p>Linear regression</p></li>
<li><p>Logistic regression</p></li>
<li><p>SVM</p></li>
<li><p>Perceptron</p></li>
<li><p>Traditional Neural networks</p></li>
<li><p>Nearest neighbor</p></li>
<li><p>Conditional random fields</p></li>
</ul></li>
</ol>
<h2 id="参数学习与非参学习">1.2 参数学习与非参学习</h2>
<p>从参数与样本的关系角度看待模型。</p>
<h3 id="参数学习">1.2.1 参数学习</h3>
<p>参数学习的特点是：</p>
<ol type="1">
<li>选择某种形式的函数并通过机器学习用一系列固定个数的参数尽可能表征这些数据的某种模式；</li>
<li>不管数据量有多大，函数参数的个数是固定的，即参数个数不随着样本量的增大而增加，从关系上说它们相互独立；</li>
<li>往往对数据有较强的假设，如分布的假设，空间的假设等。</li>
<li><p>常用参数学习的模型有：</p>
<ul>
<li><p>Logistic Regression</p></li>
<li><p>Linear Regression</p></li>
<li><p>Polynomial regression</p></li>
<li><p>Linear Discriminant Analysis</p></li>
<li><p>Perceptron</p></li>
<li><p>Naive Bayes</p></li>
<li><p>Simple Neural Networks</p></li>
<li><p>使用线性核的SVM</p></li>
<li><p>Mixture models</p></li>
<li><p>K-means</p></li>
<li><p>Hidden Markov models</p></li>
<li><p>Factor analysis / pPCA / PMF</p></li>
</ul></li>
</ol>
<h3 id="非参学习">1.2.2 非参学习</h3>
<p>注意不要被名字误导，<strong>非参不等于无参</strong>。</p>
<ol type="1">
<li>数据决定了函数形式，函数参数个数不固定；</li>
<li>随着数据量的增加，参数个数一般也会随之增长；</li>
<li>对数据本身做较少的先验假设。</li>
<li><p>一些常用的非参学习模型：</p>
<ul>
<li><p>k-Nearest Neighbors</p></li>
<li><p>Decision Trees like CART and C4.5</p></li>
<li><p>使用非线性核的SVM</p></li>
<li><p>Gradient Boosted Decision Trees</p></li>
<li><p>Gaussian processes for regression</p></li>
<li><p>Dirichlet process mixtures</p></li>
<li><p>infinite HMMs</p></li>
<li><p>infinite latent factor models</p></li>
</ul></li>
</ol>
<p>进一步知识可以看：<a href="http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf">Parametric vs Nonparametric Models</a>。</p>
<h2 id="监督学习非监督学习与强化学习">1.3 监督学习、非监督学习与强化学习</h2>
<h3 id="监督学习">1.3.1 监督学习</h3>
<p>对于每一个样本都会提供一个明确的学习目标（标注），有自变量也有因变量，学习机接收样本进行学习并通过对该样本预测后的结果和事先给定的目标比较后修正学习过程，这里的每一个样本都是标注好的，所以好处是歧义较低，坏处是万一有一定量样本标错了或者没标会对最终应用效果影响较大。通常监督学习过程如下：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjqpcau16kj17d5iupnob1rco9.png" width="500"/> picture from <a href="http://en.proft.me/2015/12/24/types-machine-learning-algorithms/">here</a>
</center>
<h3 id="非监督学习">1.3.2 非监督学习</h3>
对于每个样本不提供明确的学习目标（标注），有自变量但无因变量，学习机接收样本后会按事先指定的必要参数，依据某种相似度衡量方式自动学习样本内部的分布模式，好处是没有过多先验假设，能够体现数据内在模式并应用，坏处是有“盲目”性，并会混在噪声数据。比如：常用LDA做主题聚类，但如果使用场景不是降维而是想得到可输出的主题词，基本上没有人肉的干预无法直接使用（虽然整体上看感觉可能不错）。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjrioa912r21h0n1u571vh11go3m.png" width="500"/> picture from <a href="http://en.proft.me/2015/12/24/types-machine-learning-algorithms/">here</a>
</center>
<h3 id="强化学习">1.3.3 强化学习</h3>
<p>我认为强化学习是最接近人类学习过程的，很多情况下我们无法直接表达什么是正确的什么是错误的（比如：我正在爬山，迈了一大步，又迈了一小步，那么没法儿说我迈了大步正确还是错误），但是可以通过惩罚不好的结果或者奖励好的结果来强化学习的效果（我迈了个大步，导致没有站稳，那么对迈大步做惩罚，然后接下来我会迈小一点）。所以强化学习是一个序列的决策过程，学习机的学习目标是通过在给定状态下选择某种动作，寻找合适动作的策略序列使得它可以获得某种最优结果的过程。 强化学习的几个要素，体现其序列、交互性：</p>
<ul>
<li>环境(environment)：强化学习所处的上下文；</li>
<li>学习器(agent)：与环境的交互并学习的对象，具有主动性；</li>
<li>动作(action)：处于环境下的可行动作集合；</li>
<li>反馈(feedback)：对动作的回报或惩罚；</li>
<li>策略(policy)：学习到的策略链。</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjski0i16221ae2rdd1789l3n13.png" width="400"/> picture from <a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/followup.html">here</a>
</center>
经典的训练狗的实验就是一种强化学习的过程：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asju6357fv9q891abinifjkf2a.png" width="500" /> picture from <a href="http://www.krigolsonteaching.com/reinforcement-learning.html">here</a>
</center>
<p>强化学习的有趣应用例如：</p>
<ul>
<li><a href="https://deepmind.com/research/alphago/">AlphaGo</a> <a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf">Mastering the Game of Go with Deep Neural Networks and Tree Search</a></li>
<li>Atari 2600 games <a href="http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html#ref12">Human-level control through deep reinforcement learning</a> <a href="https://arxiv.org/pdf/1507.04296.pdf">Massively Parallel Methods for Deep Reinforcement Learning</a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第一章</tag>
        <tag>基本概念</tag>
      </tags>
  </entry>
  <entry>
    <title>0-1规划及其现实应用(0-1 Programming)</title>
    <url>/article/d0a635cc.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/op/0-1t.png" width="266"/> 本文对0-1规划及其实际应用做了简单介绍。 <span id="more"></span></p>
<h1 id="规划及其实际应用">0-1规划及其实际应用</h1>
<h2 id="什么是最优化问题">什么是最优化问题</h2>
<h3 id="最优化问题历史">最优化问题历史</h3>
<p>以下发展史部分主要参考《<a href="http://www.mitrikitti.fi/opthist.html">History of Optimization</a>》一文。</p>
<p><strong>1、古代</strong></p>
<p>公元前3000年左右，古埃及、古印度、古巴比伦就出现了最早的、文字记录的关于几何（如，长度、角度等）的经验性总结。 而最早的优化问题在古希腊数学家研究几何相关问题时出现，尤其是到了 <strong><em>公元前300年，欧几里得(Euclid)</em></strong> 完成了著名的数学巨著《几何原本》，他在研究关于点与线之间最小距离的问题时，证明了在给定总边长的矩形中，正方形的面积最大，而其本质就是个最优化问题求解。</p>
<p><strong><em>公元前200年，Zenodorus</em></strong> 在研究Dido问题（即等周问题：在平面上，所有给定周长的闭合曲线中，是否有具有最大面积的曲线？【圆】)时，同样是在研究一个最优化问题。</p>
<p><strong><em>公元前100年，Heron</em></strong> 在研究光在镜面的反射问题时，证明光在两点之间通过最短长度的路径传播，这个问题也是个最优化问题。</p>
<p><strong>2、在变分法（微积分的一种推广）</strong> 被发明之前，数学家们仅是在非系统性的研究一些优化问题的个例。</p>
<p><strong><em>1615年，开普勒(J.Kepler)</em></strong> 提出了求解酒桶最佳尺寸的方法，以及求解秘书问题（要聘请一名秘书，有<span class="math inline">\(n\)</span>个应聘者，每次只能面试1人且结束后要立刻决定是否通过，如果当时拒绝则候选人不会再回来。假设，面试过程能完全了解候选人的能力，且能与之前所有面试了的候选人做比较。那么采取什么策略，可以使最优候选人被留下的概率最大？【<span class="math inline">\(\frac{1}{e}\)</span>】）的方法。</p>
<p><strong><em>1638年，伽利略(G.Galilei )</em></strong> 研究但失败的<a href="https://www.cantorsparadise.com/determining-the-shape-of-a-hanging-cable-using-basic-calculus-453305d1cb65">吊链形状问题</a>，最终由莱布尼茨(Leibniz)和雅各布·伯努利(Johann Bernoullii)分别独立解决。</p>
<p><strong><em>1636年，费马(P.de Fermat )</em></strong> 证明了对于连续可微函数在极值点处的导数为0，以及光会沿着两点之间最短距离传播，此时传播的时间最短。</p>
<p><strong>3、牛顿(I.Newton)和莱布尼茨(G.W. von Leibniz)</strong> 分别发明微积分后，为变分法的出现提供了基础理论。</p>
<p><strong><em>1687年，牛顿</em></strong> 研究了<a href="https://www.win.tue.nl/~mpeletie/Research/PubsNewton.shtml">最小阻力体问题</a>，它是历史上第一个变分法问题。</p>
<strong><em>1696年，伯努利兄弟(Johann and Jacob Bernoulli)</em></strong> 研究 Brachistochrone问题时诞生了变分法。
<center>
<img data-src="https://vivounicorn.github.io/images/op/bs.gif" width="450"/>
</center>
<p><strong><em>1740年，欧拉(L.Euler)</em></strong> 出版了关于变分法一般理论的研究。</p>
<p><strong><em>1746年，皮埃尔·路易·莫佩尔蒂(P.L.M. de Maupertuis)</em></strong> 使用最小作用量原理(或叫平稳作用量原理)来解释物理现象，它是一种变分原理，为后续分析力学（高度数学表达的经典力学）奠定了核心基础。</p>
<p><strong><em>1754年，拉格朗日(J.-L. Lagrange)</em></strong> 在其19岁时首次做出他在变分法研究上的发现，并在1760年提出关于<a href="https://en.wikipedia.org/wiki/Plateau&#39;s_problem">极小曲面的问题</a>（Plateau's problem，研究当边界固定时极小表面的存在性问题）。该问题在1936年才被道格拉斯(J. Douglas)解决并因此获得了数学界的诺贝尔奖——菲尔兹奖(Fields Medal)，1974年邦别里(E.Bombieri)也因为对这个问题的研究获得了菲尔兹奖。</p>
<p><strong><em>1784年，加斯帕尔·蒙日(G.Monge)</em></strong> 提出了关于组合优化的问题，被称作最优运输问题（optimal transport），简单描述是，假设有已知位置的<span class="math inline">\(N\)</span>个仓库，每个仓库有<span class="math inline">\(G\)</span>个物资，需要将这些物资分发到已知位置和需求量的<span class="math inline">\(M\)</span>个不同的地方，怎么运输才能使总的运输效率最高？这个问题非常经典，二战后苏联的列昂尼德·坎托罗维奇在该领域取得了重大进展，对原始问题做了松弛处理，使得该问题在实际应用中发扬光大，一般也叫做Monge-Kantorovich问题，围绕着这个问题也使多人获得菲尔兹奖，这个问题也为后续线性规划的发展奠定了基础， 同时在机器学习领域，该问题也是近几年的热点，大家熟知的对抗生成神经网络Wasserstein GAN背后就有其理论的支撑。</p>
<p><strong>4、19世纪，数学家们提出了第一个优化算法，并在后续对变分法的逐步完善中走向实际应用</strong>，在经济活动研究中扮演了重要角色，比较有代表性的成果有：</p>
<p><strong><em>1860年，勒让德(Legendre)和高斯(Gauss)</em></strong> 分别提出了最小二乘法(least square method)，之前章节也聊过，最小二乘法另一个视角是假设数据的概率分布服从<span class="math inline">\(Gaussian(0,\sigma ^2)\)</span>，做极大似然估计后的结果。</p>
<p><strong><em>1826年，傅立叶(J.B.J. Fourier )</em></strong> 提出线性规划(LP)以解决力学和概率论中出现的问题。</p>
<strong><em>1847年，柯西(A.L. Cauchy)</em></strong> 提出了梯度法。
<center>
<img data-src="https://vivounicorn.github.io/images/op/gr.jpg" width="450"/>
</center>
<p><strong>5、20世纪，变分法</strong> 得到了更进一步的发展。</p>
<p><strong><em>1902年，法卡斯(J. Farkas)</em></strong> 提出了其著名引理，并被后人用于证明Karush-Kuhn-Tucker定理，KKT条件是非线性最优化问题能有最优解的必要条件。</p>
<p><strong><em>1905年，詹森(JJ.L.W.V. Jensen)</em></strong> 提出了凸概念并引入凸函数，这一思想最早在哈达玛(J.S. Hadamard，1883年)，霍尔德(O.L. Hölder，1889年)和奥斯托尔(O. Stolz，1893年)等人的研究中出现。</p>
<p><strong><em>1911年，明可夫斯基(H. Minkowski)</em></strong> 做出了他关于凸集的第一个研究成果。</p>
<p><strong><em>1917年，汉考克(H. Hancock)</em></strong> 出版了第一本关于最优化的书：《极小值和极大值理论(Theory of Minima and Maxima)》。</p>
<p><strong><em>1917年，生物数学家汤普森(D.W. Thompson)</em></strong> 在《成长与形式(On Growth and Form)》一书中运用最优化算法分析生物体的形式。</p>
<p><strong><em>1928年，弗兰克拉姆齐(F.P. Ramsey)</em></strong> 在他关于最优经济增长的研究中应用了变分法，他的研究与实践在最优增长理论发展中起到了重要作用，后者占据了现代资本理论和规划、宏观经济学、可耗尽资源、自然资源、发展经济学、金融和动态博弈的动态模型的核心部分。</p>
<p><strong><em>1931年，维纳(J. Viner)</em></strong> 提出了广义包络理论(Viner-Wong envelope theorem)。</p>
<p><strong><em>1932年，门格尔(K. Menger)</em></strong> 提出了旅行推销员问题的一般表述(即著名的TSP问题，给定一系列城市和每对城市之间的距离，求解访只访问每座城市一次且可以回到起始城市的最短路径)，它是组合优化中的一个NP-Hard问题。</p>
<p><strong><em>1939年，坎托罗维奇(L.V. Kantorovich)</em></strong> 提出了线性规划模型及其求解算法。1975年，他与T.C. Koopmans因对线性规划问题的贡献而获得了诺贝尔经济学奖。</p>
<p>二战后最优化与运筹学同步发展，冯·诺伊曼又是运筹学发展背后的重要人物，伴随着电子计算的发展，优化算法领域的研究不断深化和扩大。</p>
<p><strong><em>1944年，冯·诺伊曼(J. Von Neumann）和莫根斯坦 （Morgenstern）</em></strong> 通过使用动态规划的思想解决了顺序决策问题。</p>
<p><strong><em>1947年，在美国空军工作的 丹齐格(G. Dantzig)</em></strong> 提出了用于解决线性规划问题的单纯形法(Simplex method)，同时冯·诺依曼也建立了线性规划问题的对偶理论。 1949年，第一届关于优化的“国际数学规划研讨会”在芝加哥举行，大会上一共收录了34篇论文。</p>
<p><strong><em>1951年，库恩(H.W. Kuhn)和塔克(A.W.Tucker)</em></strong> 提出了非线性问题最优解的必要条件——KKT条件。ps：F.John(1948年)和W.Karush(1939年)提出过类似条件。</p>
<p><strong><em>1951年，马科维茨(H. Markowitz)</em></strong> 提出了基于二次优化的投资组合理论，并在1990年获得诺贝尔经济学奖。</p>
<p><strong><em>1954年，福特(L.R. Ford)和富尔克森(D.R. Fulkerson)</em></strong> 对网络问题的研究是组合优化研究的起点。 另外像拟牛顿法和共轭梯度法这类优秀的最优化算法也是在这个时期被提出。</p>
<p><strong><em>1954年，IEEE(Institute of Electrical and Electronics Engineers)</em></strong> 控制系统协会成立。</p>
<p><strong><em>1956年，苏联数学家庞特里亚金(L.S. Pontryagin)</em></strong> 的研究小组提出了最大值原理(Pontryagin's maximum principle)。</p>
<p><strong><em>1957年，理查德·贝尔曼(R.Bellman)</em></strong> 提出了最优性原理，它是求解动态规划的基本原则之一。</p>
<p><strong><em>1960年，约坦狄克(Zoutendijk)</em></strong> 提出了可行方向法来推广非线性规划的单纯形法。罗森(Rosen)、沃尔夫(Wolfe，著名的wolfe condition)和鲍威尔(Powell)也提出了类似算法。</p>
<p><strong><em>1963年，威尔逊(Wilson)</em></strong> 首次提出序列二次规划。Han在1975年以及Powell在1977年重新提出了该方法。</p>
<p><strong><em>1973年，Mathematical Optimization Society(MOS)</em></strong> 成立，是一个致力于促进和维护数学优化主题的高专业标准的国际组织。2010年前，它的名称是“Mathematical Programming Society”。</p>
<p><strong><em>1984年，卡马尔卡(N. Karmarkar)</em></strong> 利用内点法在多项式时间内求解线性规划问题带来了内点法的繁荣发展。ps：1979年Khachiyan已经提出了第一个多项式时间算法——椭球法。</p>
<p>60年代和70年代发展起来的复杂性分析开始对优化理论产生影响，80年代随着计算机变得更加强大和高效，使得全局优化和大规模问题的启发式算法开始流行，90年代内点法的使用扩展到半定优化。</p>
<p>关于最优化原理有一本很经典的书：《Numerical Optimization》Second Edition（ps：相比国外，国内这方面书的质量就很差点意思了）。</p>
<h3 id="最优化问题分类及解法">最优化问题分类及解法</h3>
最优化问题的分类方法有很多种，比如可以这么分：
<center>
<img data-src="https://vivounicorn.github.io/images/op/op.jpeg" width="800"/>
</center>
<p>最优化问题顾名思义就是针对某个问题找到解决它的最佳方案的方法，大体上分为无约束最优化问题和约束最优化问题，对优化问题的求解，泰勒展开式是一个非常核心的基础，很多优化算法都是基于它推导出来的，这一类算法都是基于导数的，我也在《机器学习与人工智能技术分享-第四章 最优化原理》中有粗浅介绍， 基于导数的算法里又根据泰勒展开式展开到了第几项分为一阶算法和二阶算法。</p>
<p>最优化求解形象化来看就是：当我在沙漠中行走，希望以最快速度找到沙漠里的水源地，主要围绕着两个动作做策略，且这两个动作是连续迭代发生的：</p>
<p>1、往哪个方向行走；</p>
<p>2、行走步长如何。</p>
<p>最优化问题的形式化表示如下（以最小化问题为例）： <span class="math display">\[
\begin{align*}
\min \text{ } &amp; f(x)\\
\text{s.t. } &amp; x \in X
\end{align*}
\]</span> 其中<span class="math inline">\(x\)</span>为一系列自变量，<span class="math inline">\(X\)</span>为关于<span class="math inline">\(x\)</span>的约束集合(就是对<span class="math inline">\(x\)</span>的取值有什么限制)，<span class="math inline">\(s.t.\)</span>是"<span class="math inline">\(\text{subject to}\)</span>"的缩写。上面描述的最优化求解过程就变成这样： <span class="math display">\[
x_{t+1}=x_t-\alpha_t p_t
\]</span> 其中<span class="math inline">\(\alpha_t\)</span>为当前阶段的步长，<span class="math inline">\(p_t\)</span>为当前阶段的前进方向。不同的对步长的选择和方向的选择的策略会产生不同的算法，例如，当方向选择梯度方向，那么算法就变成了梯度下降算法，采用不同步长策略又会产生类似Momentum梯度下降算法、Adam、RMSprop等一阶算法，当方向选择用hessian矩阵生成时，不同估计方法又会产生牛顿法、BFGS等算法。</p>
<p>如果函数不可微，或者规模巨大，或者其他原因导致无法用基于导数的方法做优化，还可以选择坐标下降、遗传算法、模拟退火、粒子群这类优化算法，这里就不展开讨论了。</p>
<h2 id="规划问题概述">0-1规划问题概述</h2>
<h3 id="规划问题定义">0-1规划问题定义</h3>
<p>0-1规划属于线性规划中的整数规划中的一类特殊问题，通常用来执行“指派”任务。它的特点是：所有函数都是线性的且所有变量取值都只能是0或者1，一般形式如下： <span class="math display">\[
\begin{align*}
\min \text{ } &amp; c^Tx\\
\text{s.t. } &amp; Ax \leq b\\
\text{     } &amp; x\in \{0,1\}
\end{align*}
\]</span> 其中<span class="math inline">\(x\)</span>是一系列决策变量且只能取值0或1。</p>
<p>看一个非常简单的例子，假设有以下坐席数据：</p>
<table>
<thead>
<tr class="header">
<th>坐席</th>
<th style="text-align: right;">解决时间</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: right;">3min/通</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: right;">5min/通</td>
</tr>
</tbody>
</table>
<p>当线上同时来了3个用户时，怎么分配坐席能让总的解决时间最短？</p>
<p>这是典型的任务分配问题，先做变量定义：</p>
<p>假设<span class="math inline">\(i\in\{1,2\}\)</span>为某个坐席，<span class="math inline">\(j\in \{1,2,3\}\)</span>为某个用户，<span class="math inline">\(x_{ij}\in\{0,1\}\)</span>为第<span class="math inline">\(j\)</span>个用户被非配给了第<span class="math inline">\(i\)</span>个坐席变量，且该坐席解决问题时间为<span class="math inline">\(t_i\)</span>； 每个坐席一天最多处理2个用户且每个用户必须被接待。</p>
<p>那么上述问题就变成了以下最优化问题： <span class="math display">\[
\begin{align*}
\min \text{ } &amp; \sum_{i=1}^2\sum_{j=1}^3 x_{ij}t_i\\
\text{s.t. } &amp; \sum_{i=1}^2x_{ij}=1;j=1,2,3\\
\text{     } &amp; \sum_{j=1}^3x_{ij}\leq 2;i=1,2\\
\text{     } &amp; x_{ij}\in \{0,1\}
\end{align*}
\]</span></p>
<p>显然这个问题的其中一个最优解是：坐席1接待用户2和3，坐席2接待用户1，总的处理时效为：11min。</p>
<h3 id="规划问题解法">0-1规划问题解法</h3>
<p>把上面那个问题展开： <span class="math display">\[
\begin{align*}
\min \text{ } &amp; 3x_{11} + 3x_{12} + 3x_{13} + 5x_{21} + 5x_{22} + 5x_{23}\\
\text{s.t. }  &amp; x_{11} + x_{21}=1\tag{a}\\
\text{     }  &amp; x_{12} + x_{22}=1\tag{b}\\
\text{     }  &amp; x_{13} + x_{23}=1\tag{c}\\
\text{     }  &amp; x_{11} + x_{12} + x_{13}\leq 2\tag{d}\\
\text{     }  &amp; x_{21} + x_{22} + x_{23}\leq 2\tag{e}\\
\text{     }  &amp; x_{ij}\in \{0,1\}
\end{align*}
\]</span></p>
<p>解决0-1规划常用方法之一是：<strong>隐枚举法</strong>，思路如下：</p>
<p>1、枚举所有变量组合，如果有<span class="math inline">\(n\)</span>个变量，则有<span class="math inline">\(2^n\)</span>种组合，本例<span class="math inline">\(n=6\)</span>，则有64种组合方案；</p>
<p>2、扫描每个方案并计算目标函数值，同时按序扫描约束条件，只要有一个不满足即放弃该组合；</p>
<p>3、如果所有方案扫完都没有找到解则输出：无解，否则只要找到一个符合所有约束的解，因为这是个求最小值问题，所以可以增加一个隐条件：目标值必须小于(或者小于等于)这个解，例如： 上面那个例子在第15次搜索时找到一个解，则增加一个隐过滤条件：<span class="math inline">\(3x_{11}+3x_{12}+3x_{13}+5x_{21}+5x_{22}+5x_{23}≤13\)</span>，后续扫描只要不满足的方案直接过滤，无需扫描约束条件。</p>
完整过程如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/op/imop.png" width="800"/>
</center>
<p>还有其他解法，如分枝界定法、匈牙利法等，这里就不一一讨论了。</p>
<h2 id="实际问题应用">实际问题应用</h2>
<h3 id="问题描述">问题描述</h3>
<p>平台为用户推荐最适合的资源，在满足双方诉求的前提下最大化平台利益是一种常见场景。平台的左边是渠道用户方，右边是资源方(资源可以是资金、产品、服务等)，平台居中做撮合， 随着多元化资源端入驻的越来越多，必然出现越来越复杂的多维度匹配需求，而传统的人工配置规则方式很难满足平台运营需求，所以需要有一种智能的资源与用户匹配算法。</p>
<p>整个资源分配的过程可以看做两个阶段：</p>
<p><strong>1、定向阶段</strong></p>
抽象出用户方和资源方的所有标签，通过标签做人群定向，初步得到用户与资源的多对多关系，包括有特殊需求的(如定向准入某个资源方)情况，进而得到当前时点的所有用户和所有资源方的二部图关系；
<center>
<img data-src="https://vivounicorn.github.io/images/op/targeting.png" width="450"/>
</center>
<ul>
<li><p>用户方 围绕着用户订单产生多种用户tag，用于后续定向，包括用户的demographic(性别、年龄等)、geographic(地域、城市、位置等)、金融需求(融资额、融资期限等)、车辆需求(品牌、车型等)、违约概率等。</p></li>
<li><p>资源方 围绕资源方的准入需求及资源方属性产生多种tag，例如：金融领域的授信额度、授信有效期、定向需求、逾期率要求、资金成本、展业业务范围等或者广告领域的流量需求、点击率要求、定向需求等。 用户方与资源方之间是多对多的关系，以金融领域为例，每个风控通过的用户逻辑上都要有拖底资源方承接，即用户与资源方间至少有一条边相连； 另外出于用户体验的考虑，某些情况下还会要求重新定向时匹配指定的资源方。 这一阶段的匹配，全量用户和资源方的tag都是离线生成的，当前时点新增用户的tag是在线生成的，当前时点新增资源方不予考虑（因为频率极低且会在头一天上线，离线处理即可），离线二部图的用户、资源方属性及关系会在每日做全量更新。</p></li>
</ul>
<p><strong>2、最优化求解阶段</strong></p>
<p>基于平衡风险控制(或用户体验或其他要求)及订单收入的EVA最大化为优化目标，附带围绕用户与资源方关系及资源方要求为约束条件，构建0-1规划问题，当每个订单到来后，实时求解该问题的最优解，得到用户和资源方的分配方案并执行。</p>
<h3 id="数学建模">数学建模</h3>
<p>以金融领域资金撮合为例，一种算法框架如下： <span class="math display">\[
\begin{align*}
&amp;\max\quad \sum\limits_{i=1,j=1}^{n,m} x_{i,j}\cdot m_i \cdot (e(i)-pd_i\cdot lgd_i-c_j) \\
&amp; \begin{array}{l@{\quad}r@{}l@{\quad}l}
s.t. &amp;\sum\limits_{i=1}^{n}x_{ij}\cdot m_i&amp;\leq (1-e^{\frac{\sum\limits_{k\in \Gamma({t\leq v_j})}^{}x_{kj}\cdot m_k}{s_j}-1})\cdot s_j, &amp;j=1,2,\ldots,m &amp;\text{(a.) 资方$j$准入的所有用户的融资总额不能超过其授信额，且基于授信有效期，每日做额度的平滑消耗，注意对于循环额度，取消或完成订单会释放额度} \\
     &amp;\frac{\sum\limits_{i=1}^{n}x_{ij}}{\sum\limits_{i=1,j=1}^{n,m}x_{ij}}&amp;\leq \frac{d_j\cdot(\frac{p_j}{\sum\limits_{k=1}^{m}p_k})}{\sum\limits_{j=1}^{m}d_j\cdot(\frac{p_j}{\sum\limits_{k=1}^{m}p_k})},  &amp;j=1,2,\ldots,m  &amp;\text{(b.) 资方$j$承接订单的占比不能超过设定值，若其值为1则表示不受限，若通过率高则优先分配订单}\\
     &amp;\frac{\sum\limits_{i=1}^{n}x_{ij}\cdot m_i\cdot b(i)}{\sum\limits_{i=1,j=1}^{n,m}x_{ij}\cdot m_i}&amp;\leq td_k,  &amp;i=1,2,\ldots,n;j=1,2,\ldots,m;k=1,2,\ldots,q  &amp;\text{(c.) $k$类型的业务放款额占比不能超过设定值，若其值为1则表示不受限}\\
     &amp;b(i)&amp;=\left\{
           \begin{array}{rcl}
              1 &amp; &amp; {t(i)=k}\\
              0 &amp; &amp; {otherwise}
           \end{array} \right. ,&amp;i=1,2,\ldots,n;k=1,2,\ldots,q&amp;\text{用户$i$所属业务类型是$k$时指示函数取值为1，其他为0}\\
     &amp;\frac{\sum\limits_{i=1}^{n}x_{ij}\cdot pscore_i}{n}&amp;\leq dscore_j,  &amp;i=1,2,\ldots,n;j=1,2,\ldots,m  &amp;\text{(d.) 资方$j$承接订单的平均逾期率不能超过设定值}\\
     &amp;pscore_i,dscore_j&amp;\geq 0&amp;i=1,2,\ldots,n;j=1,2,\ldots,m  &amp;\text{用户信用评分及资方接受的信用评分}\\
     &amp;\frac{\sum\limits_{i=1}^{n}x_{ij}\cdot pd_i}{n}\cdot\lambda&amp;+\frac{\alpha}{\alpha+\beta}\cdot (1-\lambda) \leq dr_j,  &amp;i=1,2,\ldots,n;j=1,2,\ldots,m  &amp;\text{(e.) 资方$j$承接订单的平均逾期率(基于Beta-Binomial)不能超过设定值}\\
     &amp;\lambda&amp;=\frac{\sum\limits_{i=1}^{n}x_{ij}}{\sum\limits_{i=1}^{n}x_{ij}+\alpha+\beta}&amp;i=1,2,\ldots,n;j=1,2,\ldots,m&amp;\text{平滑资方$j$承接订单逾期率的系数}\\
     &amp;\alpha,\beta&amp;\geq 0&amp;&amp;\text{资方$j$逾期率服从Beta-Binomial分布的超参数}\\
     &amp;\sum\limits_{k=1}^{s} td_k &amp;\leq 1&amp;k=1,2,\ldots,q &amp;\text{(f.) 所有业务类型承接订单占比之和≤1}\\
     &amp;\sum\limits_{j=1}^{m} d_j &amp;\leq 1&amp;j=1,2,\ldots,m &amp;\text{(g.) 所有资方承接订单占比之和≤1}\\
     &amp;\Gamma({t\leq v_j})&amp;\neq \emptyset,  &amp;j=1,2,\ldots,m  &amp;\text{截止当前时点$t$且在资方$j$授信有效期内，其承接订单的集合} \\
     &amp;x_{ij}&amp;\in \{0,1\}  &amp;i=1,2,\ldots,n;j=1,2,\ldots,m  &amp;\text{用户$i$定向到资方$j$则取值为1，反之为0}\\
     &amp;\sum\limits_{j=1}^{m}x_{ij}&amp;=1 &amp;i=1,2,\ldots,n;j=1,2,\ldots,m  &amp;\text{(h.) 用户$i$最终只能选择一家资方}\\
     &amp;e(i)&amp;=\left\{
           \begin{array}{rcl}
              \frac{\frac{r_i}{12}\cdot (\frac{r_i}{12}+1)^{w_i}}{(1+\frac{r_i}{12})^{w_i}-1}\cdot w_i-1 &amp; &amp; {等额本息}\\
              (w_i+1)*\frac{1}{2}*\frac{r_i}{12}  &amp; &amp; {等额本金}
           \end{array} \right. ,&amp;i=1,2,\ldots,n&amp;\text{针对用户$i$的预期收益，有等额本息和等额本金两种方式}\\
     &amp;v_j&amp;\geq0,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$授信有效期} \\
     &amp;s_j&amp;\geq0,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$授信额度} \\
     &amp;m_i&amp;\geq0,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$融资额为正整数，约看做EAD风险敞口} \\
     &amp;w_i&amp;\geq0,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$融资期限，单位为月} \\
     &amp;t(i)&amp;\geq0,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$所属业务类型} \\
     &amp;d_j&amp;\geq0,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$承接订单占比为正浮点数} \\
     &amp;0\leq r_i&amp;\leq1,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$匹配的金融产品方案对客年化利率} \\
     &amp;0\leq dr_j&amp;\leq1,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$的可接受逾期率} \\
     &amp;0\leq p_j&amp;\leq1,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$的通过率} \\
     &amp;c_j&amp;\geq0,  &amp;j=1,2,\ldots,m  &amp;\text{资方$j$的资金成本} \\
     &amp;0\leq pd_i&amp;\leq1,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$的预测违约概率} \\
     &amp;0\leq lgd_i&amp;\leq1,  &amp;i=1,2,\ldots,n  &amp;\text{用户$i$融资资产的违约损失率，和车型处置损失有关} \\
     &amp;i&amp;\geq0,  &amp;i=1,2,\ldots,n  &amp;\text{用户编号，截止目前一共有$n$位用户}\\
     &amp;j&amp;\geq0,  &amp;j=1,2,\ldots,m  &amp;\text{资方编号，截止目前一共有$m$个资方}\\
     &amp;k&amp;\geq0,  &amp;k=1,2,\ldots,q  &amp;\text{业务类型编号，截止目前一共有$q$个类型}\\
\end{array}
\end{align*}
\]</span></p>
<p><strong>要点说明</strong></p>
<p>1、每个用户的预期逾期率pd、预期损失率lgd需要实时拿到，背后要有风险模型、车辆处置回收模型支持，当然可简单做也可复杂做；</p>
2、所有资方额度消耗采用基于当前时消耗实时计算的平滑消耗方式，平滑函数可设定，借鉴计算广告，可采用下面的累积指数函数；
<center>
<img data-src="https://vivounicorn.github.io/images/op/exp.png" width="450"/>
</center>
<p>3、每家资方的额度有限，可以设定通过率高的资方优先被分配到订单；</p>
<p>4、可以对每种业务、每家资方做额度和单量的运营限制；</p>
<p>5、最优化目标函数需要包含以下项：做某个用户的精确或大致收益、做某个用户的pd（类似信用分）和lgd（基于资产残值的风险敞口或最坏情况下基于车辆融资额的风险敞口计算得到），做某个用户的资金成本、非预期损失如果可以获得那么也能加入；</p>
<p>6、由于不同资源方数据充分度不同，为了能算法出稳定的逾期率，采取平滑方式，引入<span class="math inline">\(beta\)</span>分布，<span class="math inline">\(\alpha、\beta\)</span>值的计算方法：</p>
<p>1）、假设1：用户信贷行为服从二项分布，其中参数<span class="math inline">\(I\)</span>为信审通过，<span class="math inline">\(C\)</span>为是否违约，<span class="math inline">\(pd\)</span>为违约概率： <span class="math display">\[ p(C_i|I_i,pd_i)=\begin{pmatrix} I_i \\ C_i \end{pmatrix}pd_i^{C_i}(1-pd_i)^{I_i-C_i} \]</span></p>
<p>2）、假设2：用户违约概率服从$ beta $分布： <span class="math display">\[ \begin{align*}
p(pd_i|\alpha,\beta)&amp;=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}pd_i^{\alpha-1}(1-pd_i)^{\beta-1}\\
&amp;=\frac{1}{B(\alpha,\beta)}pd_i^{\alpha-1}(1-pd_i)^{\beta-1}
\end{align*}
\]</span></p>
<p>3）、将用户违约概率视作隐含变量，则用户违约和它的联合概率分布为： <span class="math display">\[ p(C_i,pd_i|I_i,\alpha,\beta)=p(C_i|pd_i,I_i)\cdot p(pd_i|\alpha,\beta) \]</span></p>
<p>4）、采用MLE去估计相关参数，假设有<span class="math inline">\(n\)</span>个样本，则有： $ p(C,pd|I,,)=_{i=1}^np(C_i,pd_i|I_i,,) $</p>
<p>取<span class="math inline">\(ln\)</span>后得完全数据的$  $： <span class="math display">\[ \begin{align*}
ln\text{ }p(C,pd|I,\alpha,\beta)&amp;=\sum\limits_{i=1}^nln\text{ }p(C_i,pd_i|I_i,\alpha,\beta)\\
&amp;=\sum\limits_{i=1}^nln\text{ }p(C_i|pd_i,I_i)+ln\text{ }p(pd_i|\alpha,\beta)\\
&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}pd_i^{C_i}(1-pd_i)^{I_i-C_i}+ln\text{ }\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}pd_i^{\alpha-1}(1-pd_i)^{\beta-1}\\
&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+C_iln\text{ }pd_i+(I_i-C_i)ln\text{ }(1-pd_i)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)+(\alpha-1)ln\text{ }pd_i+(\beta-1)ln\text{ }(1-pd_i)
\end{align*}
\]</span></p>
<p>5）、如采用EM算法求解，需要计算完全数据的$  $的数学期望： <span class="math display">\[ \begin{align*}
E_{pd}ln\text{ }p(C,pd|I,\alpha,\beta)
&amp;=\sum\limits_{i=1}^nE_{pd}(ln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+C_iln\text{ }pd_i+(I_i-C_i)ln\text{ }(1-pd_i)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)+(\alpha-1)ln\text{ }pd_i+(\beta-1)ln\text{ }(1-pd_i))\\
&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+(C_i+\alpha-1)E_{pd}(ln\text{ }pd_i)+(I_i-C_i+\beta-1)E_{pd}(ln\text{ }(1-pd_i))\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)
\end{align*}
\]</span></p>
<p>从式中可见，期望求解在于求得：$ E_{pd}(lnpd_i)) $ 以及 $ E_{pd}(ln(1-pd_i)) $ <span class="math display">\[ \begin{align*}
E_{pd}(ln\text{ }pd_i))&amp;=\int_0^1ln\text{ }pd_i\cdot \frac{pd_i^{\alpha-1}(1-pd_i)^{\beta-1}}{B(\alpha,\beta)}d(pd_i)\\
&amp;=\frac{1}{B(\alpha,\beta)}\int_0^1\frac{\partial pd_i^{\alpha-1}(1-pd_i)^{\beta-1}}{\partial \alpha}d(pd_i)\\
&amp;=\frac{1}{B(\alpha,\beta)}\frac{\partial}{\partial \alpha}\int_0^1 pd_i^{\alpha-1}(1-pd_i)^{\beta-1}d(pd_i)\\
&amp;=\frac{1}{B(\alpha,\beta)}\frac{\partial B(\alpha,\beta)}{\partial \alpha}\\
&amp;=\frac{\partial ln \text{ }B(\alpha,\beta)}{\partial \alpha}\\
&amp;=\frac{\partial ln\text{ }\Gamma(\alpha)}{\partial \alpha}-\frac{\partial ln\text{ }\Gamma(\alpha+\beta)}{\partial \alpha}\\
&amp;=\psi(\alpha)-\psi(\alpha+\beta)
\end{align*}
\]</span></p>
<p>同理： $ E_{pd}(ln(1-pd_i))=()-(+) $ 因此，完全数据的$  $的数学期望最终为：</p>
<p>E-step： <span class="math display">\[ \begin{align*}
E_{pd}(ln\text{ }p(C,pd|I,\alpha,\beta))&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+(C_i+\alpha-1)E_{pd}(ln\text{ }pd_i)+(I_i-C_i+\beta-1)E_{pd}(ln\text{ }(1-pd_i))\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)\\
&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+(C_i+\alpha-1)(\psi(\alpha)-\psi(\alpha+\beta)))+(I_i-C_i+\beta-1)(\psi(\beta)-\psi(\alpha+\beta)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)
\end{align*}
\]</span></p>
<p>M-step： 求以上函数的极值，采用数学公式: $ NewtonRaphson $迭代法，得到： <span class="math display">\[ \begin{align*}
E_{pd}(ln\text{ }p(C,pd|I,\alpha,\beta))&amp;=f(\alpha,\beta)\\
&amp;=\sum\limits_{i=1}^nln\text{ }\begin{pmatrix} I_i \\ C_i \end{pmatrix}+(C_i+\alpha-1)(\psi(\alpha)-\psi(\alpha+\beta)))+(I_i-C_i+\beta-1)(\psi(\beta)-\psi(\alpha+\beta)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)
\end{align*}
\]</span></p>
<p>于是： <span class="math display">\[ \begin{align*}
\frac{\partial f(\alpha,\beta)}{\partial \alpha}
&amp;=\frac{\partial}{\partial \alpha}\sum\limits_{i=1}^n(C_i+\alpha-1)\psi(\alpha)+(I_i-C_i+\beta-1)\psi(\beta)-(I_i+\alpha+\beta-2)\psi(\alpha+\beta)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)\\
&amp;=\sum\limits_{i=1}^n\psi(\alpha)+(C_i+\alpha-1)\psi_1(\alpha)-\psi(\alpha+\beta)-(I_i+\alpha+\beta-2)\psi_1(\alpha+\beta)+\psi(\alpha+\beta)-\psi(\alpha)\\
&amp;=\sum\limits_{i=1}^n(C_i+\alpha-1)\psi_1(\alpha)-(I_i+\alpha+\beta-2)\psi_1(\alpha+\beta)
\end{align*}
\]</span> <span class="math display">\[ \begin{align*}
\frac{\partial f(\alpha,\beta)}{\partial \beta}
&amp;=\frac{\partial}{\partial \beta}\sum\limits_{i=1}^n(C_i+\alpha-1)\psi(\alpha)+(I_i-C_i+\beta-1)\psi(\beta)-(I_i+\alpha+\beta-2)\psi(\alpha+\beta)\\
&amp;+ln\text{ }\Gamma(\alpha+\beta)-ln\text{ }\Gamma(\alpha)-ln\text{ }\Gamma(\beta)\\
&amp;=\sum\limits_{i=1}^n\psi(\beta)+(I_i-C_i+\beta-1)\psi_1(\beta)-\psi(\alpha+\beta)-(I_i+\alpha+\beta-2)\psi_1(\alpha+\beta)+\psi(\alpha+\beta)-\psi(\beta)\\
&amp;=\sum\limits_{i=1}^n(I_i-C_i+\beta-1)\psi_1(\beta)-(I_i+\alpha+\beta-2)\psi_1(\alpha+\beta)
\end{align*}
\]</span> 令： <span class="math display">\[ \begin{align*}
\frac{\partial f(\alpha,\beta)}{\partial \alpha}=0\\
\frac{\partial f(\alpha,\beta)}{\partial \beta}=0
\end{align*}
\]</span> 利用迭代式：$ x_{n+1}=x_n- $ 得到： <span class="math display">\[ \alpha_{n+1}=\alpha_n-\frac{\sum\limits_{i=1}^n(C_i+\alpha_n-1)\psi_1(\alpha_n)-(I_i+\alpha_n+\beta_n-2)\psi_1(\alpha_n+\beta_n)}{\sum\limits_{i=1}^n\psi_1(\alpha_n)+(C_i+\alpha_n-1)\psi_2(\alpha_n)-\psi_1(\alpha_n+\beta_n)-(I_i+\alpha_n+\beta_n-2)\psi_2(\alpha_n+\beta_n)} \]</span> <span class="math display">\[ \beta_{n+1}=\beta_n-\frac{\sum\limits_{i=1}^n(I_i-C_i+\beta_n-1)\psi_1(\beta_n)-(I_i+\alpha_n+\beta_n-2)\psi_1(\alpha_n+\beta_n)}{\sum\limits_{i=1}^n\psi_1(\beta_n)+(I_i-C_i+\beta_n-1)\psi_2(\beta_n)-\psi_1(\alpha_n+\beta_n)-(I_i+\alpha_n+\beta_n-2)\psi_2(\alpha_n+\beta_n)} \]</span></p>
<p>例如：假设某资源方在某时间窗口做了6w单，其中100单发生逾期，则，平均逾期率为：0.17%，利用以上方法做平滑后，逾期率调整为0.23%， 其中: <span class="math inline">\(\alpha=1.61,\beta=682.85\)</span>，若今天线上来了该资源方的50个用户，他们的预测平均逾期率为：1.5%，则资源方当前逾期率为： <span class="math inline">\(r=1.58\%\cdot \lambda+0.23\%\cdot(1-\lambda)=0.3218\%\)</span>，其中: <span class="math inline">\(\lambda=\frac{50}{50+1.61+682.85}=0.068\)</span>。</p>
<h2 id="代码实践">代码实践</h2>
<p>完整代码可在<a href="https://github.com/vivounicorn/smart_allocation.git">这里</a>获得，优化求解器采用Google的OR-Tools，关键代码如下：</p>
<p>1、构建二部图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> bitarray <span class="keyword">import</span> bitarray</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> basic.customer <span class="keyword">import</span> Customer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BipartiteGraph</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, customer_list, num_funder</span>):</span></span><br><span class="line">        self.customer_list = customer_list</span><br><span class="line">        self.num_rows = <span class="built_in">len</span>(customer_list)</span><br><span class="line">        self.num_columns = num_funder</span><br><span class="line">        self.customer_map = &#123;&#125;  <span class="comment"># 用户id与用户变量编码的对应关系</span></span><br><span class="line">        self.reverse_customer_map = &#123;&#125;  <span class="comment"># 用户变量编码与用户结构体关系</span></span><br><span class="line">        self.funder_map = &#123;&#125;  <span class="comment"># 资源方id与资源方变量编码的对应关系</span></span><br><span class="line">        self.reverse_funder_map = &#123;&#125;  <span class="comment"># 资源方变量编码和资源方结构体的对应关系</span></span><br><span class="line">        self.last_idx = self.num_rows</span><br><span class="line"></span><br><span class="line">        size = self.num_rows * self.num_columns</span><br><span class="line">        <span class="keyword">if</span> size &gt; <span class="number">0</span>:</span><br><span class="line">            self.bitmap = bitarray(size)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.bitmap = bitarray()</span><br><span class="line"></span><br><span class="line">        self.bitmap.setall(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> customer_list <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;initialize failed.&quot;</span>)</span><br><span class="line">        self._build_map()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_build_map</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.customer_list <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        c_coder = <span class="number">0</span></span><br><span class="line">        f_coder = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> customer <span class="keyword">in</span> self.customer_list:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(customer, Customer):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> customer.<span class="built_in">id</span> <span class="keyword">not</span> <span class="keyword">in</span> self.customer_map:</span><br><span class="line">                self.customer_map[customer.<span class="built_in">id</span>] = c_coder  <span class="comment"># 用户id -&gt; 变量编码</span></span><br><span class="line">                self.reverse_customer_map[c_coder] = customer  <span class="comment"># 变量编码 -&gt; 用户结构体</span></span><br><span class="line">                c_coder += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> funder <span class="keyword">in</span> customer.funders:</span><br><span class="line">                <span class="keyword">if</span> funder.<span class="built_in">id</span> <span class="keyword">not</span> <span class="keyword">in</span> self.funder_map:</span><br><span class="line">                    self.funder_map[funder.<span class="built_in">id</span>] = f_coder  <span class="comment"># 资源方id -&gt; 变量编码</span></span><br><span class="line">                    self.reverse_funder_map[f_coder] = funder  <span class="comment"># 变量编码 -&gt; 资源方结构体</span></span><br><span class="line">                    f_coder += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                self.bitmap[self.num_columns * self.customer_map[customer.<span class="built_in">id</span>] + self.funder_map[funder.<span class="built_in">id</span>]] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> c_coder != self.num_rows - <span class="number">1</span> <span class="keyword">or</span> f_coder != self.num_columns - <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前提条件：每日无新增资方</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_customer</span>(<span class="params">self, customer</span>):</span></span><br><span class="line">        self.bitmap.extend([<span class="number">0</span>] * self.num_columns)</span><br><span class="line">        <span class="keyword">if</span> customer.<span class="built_in">id</span> <span class="keyword">not</span> <span class="keyword">in</span> self.customer_map:</span><br><span class="line">            self.customer_map[customer.<span class="built_in">id</span>] = self.num_rows  <span class="comment"># 用户id -&gt; 变量编码</span></span><br><span class="line">            self.reverse_customer_map[self.num_rows] = customer  <span class="comment"># 变量编码 -&gt; 用户id</span></span><br><span class="line">            self.num_rows += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> funder <span class="keyword">in</span> customer.funders:</span><br><span class="line">            <span class="keyword">if</span> funder.<span class="built_in">id</span> <span class="keyword">not</span> <span class="keyword">in</span> self.funder_map:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            self.bitmap[self.num_columns * self.customer_map[customer.<span class="built_in">id</span>] + self.funder_map[funder.<span class="built_in">id</span>]] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_graph</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.print_graph_base(<span class="keyword">lambda</span> i, j: self.bitmap[self.num_columns * i + j])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_graph_base</span>(<span class="params">self, _condition, node_size=<span class="number">5000</span>, font_size=<span class="number">30</span></span>):</span></span><br><span class="line">        plt.figure(figsize=(<span class="number">66</span>, <span class="number">66</span>))</span><br><span class="line">        bi_map = nx.Graph()</span><br><span class="line"></span><br><span class="line">        bi_map.add_nodes_from(<span class="built_in">list</span>(<span class="built_in">range</span>(self.num_rows)), bipartite=<span class="number">0</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        bi_map.add_nodes_from([<span class="built_in">str</span>(item) <span class="keyword">for</span> item <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">range</span>(self.num_columns))], bipartite=<span class="number">1</span>)</span><br><span class="line">        eds = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_rows):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.num_columns):</span><br><span class="line">                <span class="keyword">if</span> _condition(i, j):</span><br><span class="line">                    eds.append((i, <span class="built_in">str</span>(j)))</span><br><span class="line">        bi_map.add_edges_from(eds)</span><br><span class="line">        <span class="comment"># Separate by group</span></span><br><span class="line">        l, r = nx.bipartite.sets(bi_map)</span><br><span class="line">        pos = &#123;&#125;</span><br><span class="line">        <span class="comment"># Update position for node from each group</span></span><br><span class="line">        pos.update((node, (<span class="number">1</span>, index)) <span class="keyword">for</span> index, node <span class="keyword">in</span> <span class="built_in">enumerate</span>(l))</span><br><span class="line">        pos.update((node, (<span class="number">2</span>, index)) <span class="keyword">for</span> index, node <span class="keyword">in</span> <span class="built_in">enumerate</span>(r))</span><br><span class="line">        nx.draw(bi_map, pos=pos, nodelist=<span class="built_in">list</span>(<span class="built_in">range</span>(self.num_rows)), node_color=<span class="string">&#x27;r&#x27;</span>, node_size=node_size,</span><br><span class="line">                with_labels=<span class="literal">True</span>, font_size=font_size, font_color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">        nx.draw(bi_map, pos=pos, nodelist=[<span class="built_in">str</span>(item) <span class="keyword">for</span> item <span class="keyword">in</span> <span class="built_in">list</span>(<span class="built_in">range</span>(self.num_columns))], node_color=<span class="string">&#x27;b&#x27;</span>,</span><br><span class="line">                node_size=node_size, with_labels=<span class="literal">True</span>, font_size=font_size, font_color=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        plt.show()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> eds</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>2、构建最优化问题 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> ortools.sat.python <span class="keyword">import</span> cp_model</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> basic.bipartite_graph <span class="keyword">import</span> BipartiteGraph</span><br><span class="line"><span class="keyword">from</span> basic.db_op <span class="keyword">import</span> build_funders_data, build_customers_data</span><br><span class="line"></span><br><span class="line">PRECISION = <span class="number">10000</span>  <span class="comment"># 所有小数转换为整数，转换精度为保留小数点后5位</span></span><br><span class="line">UNIT = <span class="number">10000</span>  <span class="comment"># 所有涉及钱的都换算到单位：万</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CpModelOptimizer</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, cfg</span>):</span></span><br><span class="line">        self.config = cfg</span><br><span class="line">        self.funders_map = build_funders_data(cfg)</span><br><span class="line">        self.customer_list, self.funders_customers_map = build_customers_data(self.funders_map, cfg)</span><br><span class="line"></span><br><span class="line">        self.bp = BipartiteGraph(self.customer_list, <span class="built_in">len</span>(self.funders_map))</span><br><span class="line">        self.model = cp_model.CpModel()</span><br><span class="line">        self.xi, self.xj, self.bt, self.variables, _ = self.__build_variables()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__build_variables</span>(<span class="params">self</span>):</span></span><br><span class="line">        variables = []</span><br><span class="line">        xi = &#123;&#125;</span><br><span class="line">        xj = &#123;&#125;</span><br><span class="line">        bt = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.bp.num_rows):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.bp.num_columns):</span><br><span class="line">                <span class="keyword">if</span> self.bp.bitmap[self.bp.num_columns * i + j]:</span><br><span class="line">                    v = (self.model.NewIntVar(<span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;x&#123;0&#125;&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(i, j)), i, j)</span><br><span class="line">                    variables.append(v)</span><br><span class="line">                    <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> xi:</span><br><span class="line">                        xi[i] = [v]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        xi[i].append(v)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> xj:</span><br><span class="line">                        xj[j] = [v]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        xj[j].append(v)</span><br><span class="line"></span><br><span class="line">                    bus_t = self.bp.reverse_customer_map[i].t</span><br><span class="line">                    <span class="keyword">if</span> bus_t <span class="keyword">not</span> <span class="keyword">in</span> bt:</span><br><span class="line">                        bt[bus_t] = [v]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        bt[bus_t].append(v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> xi, xj, bt, variables, <span class="built_in">len</span>(variables)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_objective_function</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Create the objection function.</span></span><br><span class="line">        obj = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.xi:</span><br><span class="line">            <span class="keyword">for</span> xij <span class="keyword">in</span> self.xi[i]:</span><br><span class="line">                cus = self.bp.reverse_customer_map[xij[<span class="number">1</span>]]</span><br><span class="line">                fun = self.bp.reverse_funder_map[xij[<span class="number">2</span>]]</span><br><span class="line">                obj.append(xij[<span class="number">0</span>] * cus.m * (cus.e() - cus.pd * cus.lgd - fun.c))</span><br><span class="line"></span><br><span class="line">        self.model.Maximize(<span class="built_in">sum</span>(item <span class="keyword">for</span> item <span class="keyword">in</span> obj))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;The definition of optimization problem:&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;--------------------------------------&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;max &#x27;</span>, <span class="built_in">sum</span>(item <span class="keyword">for</span> item <span class="keyword">in</span> obj))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;s.t.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_a</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># Creates the constraints.</span></span><br><span class="line">        <span class="comment"># 构造约束条件:a.</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> self.xj:</span><br><span class="line">            a_xij = self.xj[j]</span><br><span class="line">            a_sumj = <span class="built_in">sum</span>(x[<span class="number">0</span>] * math.floor(self.bp.reverse_customer_map[x[<span class="number">1</span>]].m / UNIT * PRECISION) <span class="keyword">for</span> x <span class="keyword">in</span> a_xij)</span><br><span class="line">            smooth = <span class="built_in">sum</span>(self.bp.reverse_customer_map[x[<span class="number">1</span>]].m <span class="keyword">for</span> x <span class="keyword">in</span> a_xij) / UNIT</span><br><span class="line">            smooth = smooth / self.bp.reverse_funder_map[j].s / UNIT - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            smooth = math.floor((<span class="number">1</span> - math.exp(smooth)) * self.bp.reverse_funder_map[j].s * UNIT * PRECISION)</span><br><span class="line"></span><br><span class="line">            self.model.AddLinearConstraint(a_sumj, <span class="number">0</span>, smooth)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;    0≤&#x27;</span>, a_sumj, <span class="string">&#x27;≤&#x27;</span>, smooth, <span class="string">&#x27;      (a.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_b</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 构造约束条件:b.</span></span><br><span class="line">        b_sumij = <span class="built_in">sum</span>(v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> self.variables)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> self.xj:</span><br><span class="line">            b_xij = self.xj[j]</span><br><span class="line">            b_sumj = <span class="built_in">sum</span>(x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> b_xij)</span><br><span class="line">            d = self.bp.reverse_funder_map[j].d * self.bp.reverse_funder_map[j].p / <span class="built_in">sum</span>(</span><br><span class="line">                self.bp.reverse_funder_map[i].p <span class="keyword">for</span> i <span class="keyword">in</span> self.bp.reverse_funder_map)</span><br><span class="line">            dsum = <span class="built_in">sum</span>(</span><br><span class="line">                self.bp.reverse_funder_map[i].d * self.bp.reverse_funder_map[i].p / <span class="built_in">sum</span>(</span><br><span class="line">                    self.bp.reverse_funder_map[j].p <span class="keyword">for</span> j <span class="keyword">in</span> self.bp.reverse_funder_map) <span class="keyword">for</span> i <span class="keyword">in</span></span><br><span class="line">                self.bp.reverse_funder_map)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 托底资方不受限制，其他资源方尽量按照通过率及比例要求分配.</span></span><br><span class="line">            <span class="keyword">if</span> self.bp.reverse_funder_map[j].is_base:</span><br><span class="line">                ex = (b_sumj - b_sumij) * PRECISION</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                ex = b_sumj * PRECISION - b_sumij * math.floor(d / dsum * PRECISION + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            self.model.AddLinearConstraint(ex, cp_model.INT_MIN, <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;   &#x27;</span>, ex, <span class="string">&#x27;≤&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;      (b.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_c</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 构造约束条件:c.</span></span><br><span class="line">        t_sumij = <span class="built_in">sum</span>(v[<span class="number">0</span>] * math.floor(self.bp.reverse_customer_map[v[<span class="number">1</span>]].m / UNIT) <span class="keyword">for</span> v <span class="keyword">in</span> self.variables)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.bt:</span><br><span class="line">            t_xij = self.bt[i]  <span class="comment"># 某个业务类型对应的变量列表.</span></span><br><span class="line">            td = self.config.biz_items[i]  <span class="comment"># 该业务类型订单量占比.</span></span><br><span class="line">            t_sum = <span class="built_in">sum</span>(x[<span class="number">0</span>] * math.floor(self.bp.reverse_customer_map[x[<span class="number">1</span>]].m / UNIT) <span class="keyword">for</span> x <span class="keyword">in</span> t_xij)</span><br><span class="line">            td_ex = (t_sum * PRECISION - t_sumij * math.floor(td * PRECISION))</span><br><span class="line">            self.model.AddLinearConstraint(td_ex, cp_model.INT_MIN, <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;   &#x27;</span>, td_ex, <span class="string">&#x27;≤&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;      (c.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_d</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 构造约束条件:funders.</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> self.xj:</span><br><span class="line">            d_xij = self.xj[j]</span><br><span class="line">            d_sum = <span class="built_in">sum</span>(x[<span class="number">0</span>] * math.floor(self.bp.reverse_customer_map[x[<span class="number">1</span>]].p_score) <span class="keyword">for</span> x <span class="keyword">in</span> d_xij)</span><br><span class="line">            d_ex = d_sum - <span class="built_in">len</span>(d_xij) * math.floor(self.bp.reverse_funder_map[j].d_score)</span><br><span class="line">            self.model.AddLinearConstraint(d_ex, cp_model.INT_MIN, <span class="number">0</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;   &#x27;</span>, d_ex, <span class="string">&#x27;≤&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;      (funders.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_e</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 构造约束条件:funders.</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> self.xj:</span><br><span class="line">            d_xij = self.xj[j]</span><br><span class="line">            pctr = self.bp.reverse_funder_map[j].alpha / (self.bp.reverse_funder_map[j].alpha +</span><br><span class="line">                                                          self.bp.reverse_funder_map[j].beta)</span><br><span class="line">            n = <span class="built_in">len</span>(d_xij)</span><br><span class="line">            lamb = n / (n + self.bp.reverse_funder_map[j].alpha + self.bp.reverse_funder_map[j].beta)</span><br><span class="line">            d_sum = <span class="built_in">sum</span>(x[<span class="number">0</span>] * math.floor(self.bp.reverse_customer_map[x[<span class="number">1</span>]].pd * lamb * PRECISION) <span class="keyword">for</span> x <span class="keyword">in</span> d_xij) + \</span><br><span class="line">                    math.floor(pctr * n * (<span class="number">1</span> - lamb) * PRECISION) - math.floor(</span><br><span class="line">                self.bp.reverse_funder_map[j].dr * n * PRECISION)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># self.model.AddLinearConstraint(d_sum, cp_model.INT_MIN, 0)</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;   &#x27;</span>, d_sum, <span class="string">&#x27;≤&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;      (e.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__make_constraint_h</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 构造约束条件:h.</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.xi:</span><br><span class="line">            h_xij = self.xi[i]</span><br><span class="line">            h_sum = <span class="built_in">sum</span>(x[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> h_xij)</span><br><span class="line">            self.model.AddLinearConstraint(h_sum, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;   &#x27;</span>, h_sum, <span class="string">&quot;= 1&quot;</span>, <span class="string">&#x27;      (h.)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_problem</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.__make_objective_function()</span><br><span class="line">        self.__make_constraint_a()</span><br><span class="line">        self.__make_constraint_b()</span><br><span class="line">        self.__make_constraint_c()</span><br><span class="line">        self.__make_constraint_d()</span><br><span class="line">        self.__make_constraint_e()</span><br><span class="line">        self.__make_constraint_h()</span><br><span class="line"></span><br><span class="line">        solver = cp_model.CpSolver()</span><br><span class="line">        status = solver.Solve(self.model)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> status == cp_model.OPTIMAL <span class="keyword">or</span> status == cp_model.FEASIBLE:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;--------------------------------------&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Maximum of objective function: <span class="subst">&#123;solver.ObjectiveValue()&#125;</span>\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> self.variables:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;v[<span class="number">0</span>].Name&#125;</span>=<span class="subst">&#123;solver.Value(v[<span class="number">0</span>])&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;No solution found.&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Statistics.</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\nStatistics&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;  status   : <span class="subst">&#123;solver.StatusName(status)&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;  conflicts: <span class="subst">&#123;solver.NumConflicts()&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;  branches : <span class="subst">&#123;solver.NumBranches()&#125;</span>&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;  wall time: <span class="subst">&#123;solver.WallTime()&#125;</span> s&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        ij_map = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> self.variables:</span><br><span class="line">            <span class="keyword">if</span> solver.Value(v[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">                ij_map[(v[<span class="number">1</span>], v[<span class="number">2</span>])] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.bp.print_graph()</span><br><span class="line">        self.bp.print_graph_base(<span class="keyword">lambda</span> i, j: (i, j) <span class="keyword">in</span> ij_map)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> solver</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p>3、模拟实验</p>
<p><strong>用户数据</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">用户10,融资额:76000,融资期限:36,业务类型:0,还款类型:0,融资利率:0.1188,违约概率率:0.0101,违约损失率:0.8,易鑫分:490.0,首付比例:0.1,已还款期数:0,匹配资方列表:[100, 200]</span><br><span class="line">用户20,融资额:68500,融资期限:36,业务类型:0,还款类型:0,融资利率:0.1088,违约概率率:0.011,违约损失率:0.88,易鑫分:480.0,首付比例:0.1,已还款期数:0,匹配资方列表:[100, 300]</span><br><span class="line">用户30,融资额:73800,融资期限:36,业务类型:0,还款类型:0,融资利率:0.1188,违约概率率:0.0156,违约损失率:0.89,易鑫分:410.0,首付比例:0.1,已还款期数:0,匹配资方列表:[200, 300]</span><br><span class="line">用户40,融资额:59000,融资期限:36,业务类型:0,还款类型:0,融资利率:0.1088,违约概率率:0.0153,违约损失率:0.89,易鑫分:400.0,首付比例:0.1,已还款期数:0,匹配资方列表:[100, 200, 300]</span><br><span class="line">用户50,融资额:83500,融资期限:64,业务类型:1,还款类型:0,融资利率:0.1188,违约概率率:0.0122,违约损失率:0.88,易鑫分:390.0,首付比例:0.3,已还款期数:0,匹配资方列表:[100, 300]</span><br><span class="line">用户60,融资额:96200,融资期限:36,业务类型:1,还款类型:0,融资利率:0.1088,违约概率率:0.01035,违约损失率:0.87,易鑫分:485.0,首付比例:0.2,已还款期数:0,匹配资方列表:[100, 200]</span><br><span class="line">用户70,融资额:71100,融资期限:36,业务类型:1,还款类型:0,融资利率:0.1188,违约概率率:0.0112,违约损失率:0.98,易鑫分:460.0,首付比例:0.3,已还款期数:0,匹配资方列表:[100, 200, 300]</span><br><span class="line">用户80,融资额:69600,融资期限:36,业务类型:1,还款类型:0,融资利率:0.1088,违约概率率:0.0123,违约损失率:0.89,易鑫分:380.0,首付比例:0.2,已还款期数:0,匹配资方列表:[200, 300]</span><br><span class="line">用户90,融资额:57300,融资期限:36,业务类型:2,还款类型:0,融资利率:0.1288,违约概率率:0.035,违约损失率:0.99,易鑫分:350.0,首付比例:0.5,已还款期数:0,匹配资方列表:[100, 200, 300]</span><br><span class="line">用户100,融资额:42000,融资期限:36,业务类型:2,还款类型:0,融资利率:0.1288,违约概率率:0.025,违约损失率:0.99,易鑫分:355.0,首付比例:0.6,已还款期数:0,匹配资方列表:[100, 300]</span><br></pre></td></tr></table></figure>
<p><strong>资源方数据</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">资方100,授信额度:10.0,授信有效期:365,是否为循环额度:True,是否为托底资方:False,资方接受易鑫分下限:450.0,资方接受逾期率:0.012,预期资方单量占比:0.3,资方通过率:0.88,资金成本:0.103,alpha:50.0,beta:6500.0</span><br><span class="line">资方200,授信额度:15.0,授信有效期:365,是否为循环额度:True,是否为托底资方:True,资方接受易鑫分下限:480.0,资方接受逾期率:0.013,预期资方单量占比:0.2,资方通过率:0.95,资金成本:0.106,alpha:60.0,beta:8000.0</span><br><span class="line">资方300,授信额度:20.0,授信有效期:365,是否为循环额度:False,是否为托底资方:False,资方接受易鑫分下限:390.0,资方接受逾期率:0.015,预期资方单量占比:0.5,资方通过率:0.9,资金成本:0.0932,alpha:60.0,beta:6000.0</span><br></pre></td></tr></table></figure>
<p><strong>初始二部图</strong></p>
<center>
<img data-src="https://vivounicorn.github.io/images/op/1.png" width="600"/>
</center>
<p><strong>优化问题生成</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">max</span>  (((((((((((((((((((((((<span class="number">6275.5393280828075</span> * x00) + (<span class="number">6047.5393280828075</span> * x01)) + (<span class="number">4375.031654669008</span> * x10)) + (<span class="number">5046.331654669008</span> * x12)) + (<span class="number">5444.143779111989</span> * x21)) + (<span class="number">6388.783779111988</span> * x22)) + (<span class="number">3535.9924397879054</span> * x30)) + (<span class="number">3358.9924397879054</span> * x31)) + (<span class="number">4114.192439787905</span> * x32)) + (<span class="number">20129.925959620494</span> * x40)) + (<span class="number">20948.225959620493</span> * x42)) + (<span class="number">6209.188139111804</span> * x50)) + (<span class="number">5920.588139111805</span> * x51)) + (<span class="number">5665.026587193259</span> * x60)) + (<span class="number">5451.726587193259</span> * x61)) + (<span class="number">6361.806587193259</span> * x62)) + (<span class="number">4148.304437444714</span> * x71)) + (<span class="number">5039.184437444714</span> * x72)) + (<span class="number">4197.370367470781</span> * x80)) + (<span class="number">4025.4703674707816</span> * x81)) + (<span class="number">4758.910367470781</span> * x82)) + (<span class="number">3492.406552072825</span> * x90)) + (<span class="number">3904.0065520728244</span> * x92))</span><br><span class="line">s.t.</span><br><span class="line">    <span class="number">0</span>≤ ((((((((<span class="number">76000</span> * x00) + (<span class="number">68500</span> * x10)) + (<span class="number">59000</span> * x30)) + (<span class="number">83500</span> * x40)) + (<span class="number">96199</span> * x50)) + (<span class="number">71100</span> * x60)) + (<span class="number">57300</span> * x80)) + (<span class="number">42000</span> * x90)) ≤ <span class="number">631916844</span>       (a.)</span><br><span class="line">    <span class="number">0</span>≤ (((((((<span class="number">76000</span> * x01) + (<span class="number">73800</span> * x21)) + (<span class="number">59000</span> * x31)) + (<span class="number">96199</span> * x51)) + (<span class="number">71100</span> * x61)) + (<span class="number">69600</span> * x71)) + (<span class="number">57300</span> * x81)) ≤ <span class="number">947995763</span>       (a.)</span><br><span class="line">    <span class="number">0</span>≤ ((((((((<span class="number">68500</span> * x12) + (<span class="number">73800</span> * x22)) + (<span class="number">59000</span> * x32)) + (<span class="number">83500</span> * x42)) + (<span class="number">71100</span> * x62)) + (<span class="number">69600</span> * x72)) + (<span class="number">57300</span> * x82)) + (<span class="number">42000</span> * x92)) ≤ <span class="number">1264048029</span>       (a.)</span><br><span class="line">    ((<span class="number">10000</span> * (((((((x00 + x10) + x30) + x40) + x50) + x60) + x80) + x90)) + (-<span class="number">2921</span> * ((((((((((((((((((((((x00 + x01) + x10) + x12) + x21) + x22) + x30) + x31) + x32) + x40) + x42) + x50) + x51) + x60) + x61) + x62) + x71) + x72) + x80) + x81) + x82) + x90) + x92))) ≤ <span class="number">0</span>       (b.)</span><br><span class="line">    (<span class="number">10000</span> * (((((((x01 + x21) + x31) + x51) + x61) + x71) + x81) + -((((((((((((((((((((((x00 + x01) + x10) + x12) + x21) + x22) + x30) + x31) + x32) + x40) + x42) + x50) + x51) + x60) + x61) + x62) + x71) + x72) + x80) + x81) + x82) + x90) + x92))) ≤ <span class="number">0</span>       (b.)</span><br><span class="line">    ((<span class="number">10000</span> * (((((((x12 + x22) + x32) + x42) + x62) + x72) + x82) + x92)) + (-<span class="number">4978</span> * ((((((((((((((((((((((x00 + x01) + x10) + x12) + x21) + x22) + x30) + x31) + x32) + x40) + x42) + x50) + x51) + x60) + x61) + x62) + x71) + x72) + x80) + x81) + x82) + x90) + x92))) ≤ <span class="number">0</span>       (b.)</span><br><span class="line">    ((<span class="number">10000</span> * (((((((((<span class="number">7</span> * x00) + (<span class="number">7</span> * x01)) + (<span class="number">6</span> * x10)) + (<span class="number">6</span> * x12)) + (<span class="number">7</span> * x21)) + (<span class="number">7</span> * x22)) + (<span class="number">5</span> * x30)) + (<span class="number">5</span> * x31)) + (<span class="number">5</span> * x32))) + (-<span class="number">8000</span> * (((((((((((((((((((((((<span class="number">7</span> * x00) + (<span class="number">7</span> * x01)) + (<span class="number">6</span> * x10)) + (<span class="number">6</span> * x12)) + (<span class="number">7</span> * x21)) + (<span class="number">7</span> * x22)) + (<span class="number">5</span> * x30)) + (<span class="number">5</span> * x31)) + (<span class="number">5</span> * x32)) + (<span class="number">8</span> * x40)) + (<span class="number">8</span> * x42)) + (<span class="number">9</span> * x50)) + (<span class="number">9</span> * x51)) + (<span class="number">7</span> * x60)) + (<span class="number">7</span> * x61)) + (<span class="number">7</span> * x62)) + (<span class="number">6</span> * x71)) + (<span class="number">6</span> * x72)) + (<span class="number">5</span> * x80)) + (<span class="number">5</span> * x81)) + (<span class="number">5</span> * x82)) + (<span class="number">4</span> * x90)) + (<span class="number">4</span> * x92)))) ≤ <span class="number">0</span>       (c.)</span><br><span class="line">    ((<span class="number">10000</span> * (((((((((<span class="number">8</span> * x40) + (<span class="number">8</span> * x42)) + (<span class="number">9</span> * x50)) + (<span class="number">9</span> * x51)) + (<span class="number">7</span> * x60)) + (<span class="number">7</span> * x61)) + (<span class="number">7</span> * x62)) + (<span class="number">6</span> * x71)) + (<span class="number">6</span> * x72))) + (-<span class="number">9000</span> * (((((((((((((((((((((((<span class="number">7</span> * x00) + (<span class="number">7</span> * x01)) + (<span class="number">6</span> * x10)) + (<span class="number">6</span> * x12)) + (<span class="number">7</span> * x21)) + (<span class="number">7</span> * x22)) + (<span class="number">5</span> * x30)) + (<span class="number">5</span> * x31)) + (<span class="number">5</span> * x32)) + (<span class="number">8</span> * x40)) + (<span class="number">8</span> * x42)) + (<span class="number">9</span> * x50)) + (<span class="number">9</span> * x51)) + (<span class="number">7</span> * x60)) + (<span class="number">7</span> * x61)) + (<span class="number">7</span> * x62)) + (<span class="number">6</span> * x71)) + (<span class="number">6</span> * x72)) + (<span class="number">5</span> * x80)) + (<span class="number">5</span> * x81)) + (<span class="number">5</span> * x82)) + (<span class="number">4</span> * x90)) + (<span class="number">4</span> * x92)))) ≤ <span class="number">0</span>       (c.)</span><br><span class="line">    ((<span class="number">10000</span> * (((((<span class="number">5</span> * x80) + (<span class="number">5</span> * x81)) + (<span class="number">5</span> * x82)) + (<span class="number">4</span> * x90)) + (<span class="number">4</span> * x92))) + (-<span class="number">9000</span> * (((((((((((((((((((((((<span class="number">7</span> * x00) + (<span class="number">7</span> * x01)) + (<span class="number">6</span> * x10)) + (<span class="number">6</span> * x12)) + (<span class="number">7</span> * x21)) + (<span class="number">7</span> * x22)) + (<span class="number">5</span> * x30)) + (<span class="number">5</span> * x31)) + (<span class="number">5</span> * x32)) + (<span class="number">8</span> * x40)) + (<span class="number">8</span> * x42)) + (<span class="number">9</span> * x50)) + (<span class="number">9</span> * x51)) + (<span class="number">7</span> * x60)) + (<span class="number">7</span> * x61)) + (<span class="number">7</span> * x62)) + (<span class="number">6</span> * x71)) + (<span class="number">6</span> * x72)) + (<span class="number">5</span> * x80)) + (<span class="number">5</span> * x81)) + (<span class="number">5</span> * x82)) + (<span class="number">4</span> * x90)) + (<span class="number">4</span> * x92)))) ≤ <span class="number">0</span>       (c.)</span><br><span class="line">    (((((((((<span class="number">490</span> * x00) + (<span class="number">480</span> * x10)) + (<span class="number">400</span> * x30)) + (<span class="number">390</span> * x40)) + (<span class="number">485</span> * x50)) + (<span class="number">460</span> * x60)) + (<span class="number">350</span> * x80)) + (<span class="number">355</span> * x90)) + -<span class="number">3600</span>) ≤ <span class="number">0</span>       (d.)</span><br><span class="line">    ((((((((<span class="number">490</span> * x01) + (<span class="number">410</span> * x21)) + (<span class="number">400</span> * x31)) + (<span class="number">485</span> * x51)) + (<span class="number">460</span> * x61)) + (<span class="number">380</span> * x71)) + (<span class="number">350</span> * x81)) + -<span class="number">3360</span>) ≤ <span class="number">0</span>       (d.)</span><br><span class="line">    (((((((((<span class="number">480</span> * x12) + (<span class="number">410</span> * x22)) + (<span class="number">400</span> * x32)) + (<span class="number">390</span> * x42)) + (<span class="number">460</span> * x62)) + (<span class="number">380</span> * x72)) + (<span class="number">350</span> * x82)) + (<span class="number">355</span> * x92)) + -<span class="number">3120</span>) ≤ <span class="number">0</span>       (d.)</span><br><span class="line">    ((((((((((<span class="number">1232</span> * x00) + (<span class="number">1341</span> * x10)) + (<span class="number">1866</span> * x30)) + (<span class="number">1488</span> * x40)) + (<span class="number">1262</span> * x50)) + (<span class="number">1366</span> * x60)) + (<span class="number">4269</span> * x80)) + (<span class="number">3049</span> * x90)) + <span class="number">6099420</span>) + -<span class="number">9600000</span>) ≤ <span class="number">0</span>       (e.)</span><br><span class="line">    (((((((((<span class="number">876</span> * x01) + (<span class="number">1353</span> * x21)) + (<span class="number">1327</span> * x31)) + (<span class="number">898</span> * x51)) + (<span class="number">971</span> * x61)) + (<span class="number">1067</span> * x71)) + (<span class="number">3037</span> * x81)) + <span class="number">5206396</span>) + -<span class="number">9100000</span>) ≤ <span class="number">0</span>       (e.)</span><br><span class="line">    ((((((((((<span class="number">1450</span> * x12) + (<span class="number">2056</span> * x22)) + (<span class="number">2017</span> * x32)) + (<span class="number">1608</span> * x42)) + (<span class="number">1476</span> * x62)) + (<span class="number">1621</span> * x72)) + (<span class="number">4614</span> * x82)) + (<span class="number">3295</span> * x92)) + <span class="number">7910349</span>) + -<span class="number">12000000</span>) ≤ <span class="number">0</span>       (e.)</span><br><span class="line">    (x00 + x01) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x10 + x12) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x21 + x22) = <span class="number">1</span>       (h.)</span><br><span class="line">    ((x30 + x31) + x32) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x40 + x42) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x50 + x51) = <span class="number">1</span>       (h.)</span><br><span class="line">    ((x60 + x61) + x62) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x71 + x72) = <span class="number">1</span>       (h.)</span><br><span class="line">    ((x80 + x81) + x82) = <span class="number">1</span>       (h.)</span><br><span class="line">    (x90 + x92) = <span class="number">1</span>       (h.)</span><br></pre></td></tr></table></figure>
<p><strong>优化求解结果</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">Maximum of objective function: 66027.0492445656（预期EVA，单位：元）</span><br><span class="line"></span><br><span class="line">&lt;bound method IntVar.Name of x00(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x01(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x10(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x12(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x21(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x22(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x30(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x31(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x32(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x40(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x42(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x50(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x51(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x60(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x61(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x62(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x71(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x72(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x80(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x81(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x82(0..1)&gt;=0</span><br><span class="line">&lt;bound method IntVar.Name of x90(0..1)&gt;=1</span><br><span class="line">&lt;bound method IntVar.Name of x92(0..1)&gt;=0</span><br><span class="line"></span><br><span class="line">Statistics</span><br><span class="line">  status   : OPTIMAL</span><br><span class="line">  conflicts: 1</span><br><span class="line">  branches : 43</span><br><span class="line">wall time: 0.0031439560000000003 s</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<center>
<img data-src="https://vivounicorn.github.io/images/op/2.png" width="600"/>
</center>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>线性规划</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习与人工智能技术分享-第八章 目标检测与识别</title>
    <url>/article/8deb4264.html</url>
    <content><![CDATA[<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/cm_mask.jpg" width=266 /> 本章对机器学习在计算机视觉尤其是目标检测与识别方面的各种代表性模型和算法做了原理介绍和效果展示。 <span id="more"></span></p>
<h1 id="目标检测与识别">8. 目标检测与识别</h1>
目标检测的发展历程大致如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bg86igedlru9801vgh8f913g4m.png" width="800"  />
</center>
<h2 id="selective-search">8.1 Selective Search</h2>
对于目标识别任务，比如判断一张图片中有没有车、是什么车，一般需要解决两个问题：目标检测、目标识别。而目标检测任务中通常需要先通过某种方法做图像分割，事先得到候选框；直观的做法是：给定窗口，对整张图片滑动扫描，结束后改变窗口大小重复上面步骤，缺点很明显：重复劳动耗费资源、精度和质量不高等等。 针对上面的问题，一种解决方案是借鉴启发式搜索的方法，充分利用人类的先验知识。J.R.R. Uijlings在《<a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf">Selective Search for Object Recoginition</a>》提出一种方法：基于数据驱动，与具体类别无关的多种策略融合的启发式生成方法。图片包含各种丰富信息，例如：大小、形状、颜色、纹理、物体重叠关系等，如果只使用一种信息往往不能解决大部分问题，例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga5pfj1d621rq7i851vvprc19.png" width="500"/>
</center>
<p>左边的两只猫可以通过颜色区别而不是通过纹理，右面的变色龙却只能通过纹理区别而不是颜色。</p>
<h3 id="启发式生成设计准则">8.1.1 启发式生成设计准则</h3>
<p>所以概括来说：</p>
<ul>
<li>能够捕捉到各种尺度物体，大的、小的、边界清楚的、边界模糊的等等； 多尺度的例子： <img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga9sm381ben1hhu167411ng1h9f13.png" alt="多尺度例子" /></li>
<li>策略多样性，采用多样的策略集合共同作用；</li>
<li>计算快速，由于生成候选框只是检测第一步，所以计算上它决不能成为瓶颈。</li>
</ul>
<h3 id="selective-search-1">8.1.2 Selective Search</h3>
<p>基于以上准则设计Selective Search算法：</p>
<ul>
<li><p>采用层次分组算法解决尺度问题</p>
<p>引入图像分割中的自下而上分组思想，由于整个过程是层次的，在将整个图合并成一个大的区域的过程中会输出不同尺度的多个子区域。整个过程如下：</p>
<p>1、利用《<a href="https://cs.brown.edu/~pff/papers/seg-ijcv.pdf">Efficient Graph-Based Image Segmentation</a>》（基本思想：将图像中每个像素表示为图上的一个节点，用于连接不同节点的无向边都有一个权重，这个权重表示两个节点之间的不相似度，通过贪心算法利用最小生成树做图像分割）生成初始候选区域；</p>
2、采用贪心算法合并区域，计算任意两个领域的相似度，把达到阈值的合并，再计算新区域和其所有领域的相似度，循环迭代，直到整个图变成了一个区域，算法如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga9fgjm5ei1r9ks661milsvpm.png" width="800"/>
</center></li>
<li><p>多样化策略</p>
<p>三个方面：使用多种颜色空间、使用多种相似度计算方法、搜索起始区域不固定。</p>
<p>1、颜色空间有很多种：RGB、HSV、Lab等等，不是论文重点；</p>
2、相似度衡量算法，结合了4重策略：
<ul>
<li><p>颜色相似度</p>
<p>以RGB为例，使用L1-norm归一化每个图像通道的色彩直方图（bins=25），每个区域被表示为25×3维向量:<span class="math inline">\(C_i=\{c_i^1,...,c_i^n\}\)</span>; 颜色相似度定义为： <span class="math display">\[S_{color}(r_i,r_j)=\sum_{k=1}^nmin(c_i^k,c_j^k)\]</span> 区域合并后对新的区域计算其色彩直方图： <span class="math display">\[C_t=\frac{size(r_i)×C_i+size(r_j)×C_j}{size(r_i)+size(r_j)}\]</span> 新区域的大小为：<span class="math inline">\(size(r_t)=size(r_i)+size(r_j)\)</span></p></li>
<li><p>纹理相似度</p>
<p>使用快速生成的类SIFT特征，对每个颜色通道在8个方向上应用方差为1的高斯滤波器，对每个颜色通道的每个方向提取bins=10的直方图，所以整个纹理向量维度为：3×8×10=240，表示为：<span class="math inline">\(T_i=\{t_i^1,...,t_i^n\}\)</span>; 纹理相似度定义为： <span class="math display">\[S_{texture}(r_i,r_j)=\sum_{k=1}^nmin(t_i^k,t_j^k)\]</span></p></li>
<li><p>大小相似度</p>
<p>该策略希望小的区域能尽早合并，让合并操作比较平滑，防止出现某个大区域逐步吞并其他小区域的情况。相似度定义为： <span class="math display">\[S_{size}=1-\frac{size(r_i)+size(r_j)}{size(im)}\]</span> 其中<span class="math inline">\(size(im)\)</span>为图像包含像素点数目。</p></li>
<li><p>区域规则度相似度</p>
<p>能够框住合并后的两个区域的矩形大小越小说明两个区域的合并越规则，如： 区域规则度相似度定义为： <span class="math display">\[S_{fill}=1-\frac{size(BB_{i,j})-size(r_i)-size(r_j)}{size(im)}\]</span></p></li>
</ul>
<p>最终相似度为所有策略加权和，文中采用等权方式： <span class="math display">\[S_{r_i,r_j}=\alpha_1\cdot S_{color}(r_i,r_j)+\alpha_2\cdot S_{texture}(r_i,r_j)+\alpha_3\cdot S_{size}(r_i,r_j)+\alpha_4\cdot S_{fill}(r_i,r_j)\]</span></p></li>
</ul>
<h3 id="使用selective-search做目标识别">8.1.3 使用Selective Search做目标识别</h3>
训练过程包含：提取候选框、提取特征、生成正负样本、训练模型，图示如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgaclat41i5iddrrsg198m4h529.png" width="800" />
</center>
<p>早期图像特征提取往往是各种HOG特征或BoW特征，现在CNN特征几乎一统天下。 检测定位效果评价采用Average Best Overlap（ABO）和Mean Average Best Overlap（MABO）： <span class="math display">\[
ABO=\frac{1}{|G^c|}\sum_{g_i^c\in G^c}max_{I_j\in L} Overlap(g_i^c,l_j)
\]</span> 其中：<span class="math inline">\(c\)</span>为类别标注、<span class="math inline">\(g_i^c\)</span>为类别<span class="math inline">\(c\)</span>下的ground truth，<span class="math inline">\(L\)</span>为通过Selective Search生成的候选框。 <span class="math display">\[
MABO=\frac{1}{|C|}\sum_{i=1}^n ABO(C_i)
\]</span></p>
<h3 id="代码实践">8.1.4 代码实践</h3>
<p>参见<a href="https://github.com/vivounicorn/selectivesearch">AlpacaDB</a>。</p>
<ul>
<li>selectivesearch.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"><span class="keyword">import</span> skimage.feature</span><br><span class="line"><span class="keyword">import</span> skimage.color</span><br><span class="line"><span class="keyword">import</span> skimage.transform</span><br><span class="line"><span class="keyword">import</span> skimage.util</span><br><span class="line"><span class="keyword">import</span> skimage.segmentation</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># &quot;Selective Search for Object Recognition&quot; by J.R.R. Uijlings et al.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  - Modified version with LBP extractor for texture vectorization</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_generate_segments</span>(<span class="params">im_orig, scale, sigma, min_size</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        segment smallest regions by the algorithm of Felzenswalb and</span></span><br><span class="line"><span class="string">        Huttenlocher</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># open the Image</span></span><br><span class="line">    im_mask = skimage.segmentation.felzenszwalb(</span><br><span class="line">        skimage.util.img_as_float(im_orig), scale=scale, sigma=sigma,</span><br><span class="line">        min_size=min_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># merge mask channel to the image as a 4th channel</span></span><br><span class="line">    im_orig = numpy.append(</span><br><span class="line">        im_orig, numpy.zeros(im_orig.shape[:<span class="number">2</span>])[:, :, numpy.newaxis], axis=<span class="number">2</span>)</span><br><span class="line">    im_orig[:, :, <span class="number">3</span>] = im_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> im_orig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_colour</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the sum of histogram intersection of colour</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="built_in">min</span>(a, b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(r1[<span class="string">&quot;hist_c&quot;</span>], r2[<span class="string">&quot;hist_c&quot;</span>])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_texture</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the sum of histogram intersection of texture</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="built_in">min</span>(a, b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(r1[<span class="string">&quot;hist_t&quot;</span>], r2[<span class="string">&quot;hist_t&quot;</span>])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_size</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the size similarity over the image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - (r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;size&quot;</span>]) / imsize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_fill</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the fill similarity over the image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    bbsize = (</span><br><span class="line">        (<span class="built_in">max</span>(r1[<span class="string">&quot;max_x&quot;</span>], r2[<span class="string">&quot;max_x&quot;</span>]) - <span class="built_in">min</span>(r1[<span class="string">&quot;min_x&quot;</span>], r2[<span class="string">&quot;min_x&quot;</span>]))</span><br><span class="line">        * (<span class="built_in">max</span>(r1[<span class="string">&quot;max_y&quot;</span>], r2[<span class="string">&quot;max_y&quot;</span>]) - <span class="built_in">min</span>(r1[<span class="string">&quot;min_y&quot;</span>], r2[<span class="string">&quot;min_y&quot;</span>]))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - (bbsize - r1[<span class="string">&quot;size&quot;</span>] - r2[<span class="string">&quot;size&quot;</span>]) / imsize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_sim</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (_sim_colour(r1, r2) + _sim_texture(r1, r2)</span><br><span class="line">            + _sim_size(r1, r2, imsize) + _sim_fill(r1, r2, imsize))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_colour_hist</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate colour histogram for each region</span></span><br><span class="line"><span class="string">        the size of output histogram will be BINS * COLOUR_CHANNELS(3)</span></span><br><span class="line"><span class="string">        number of bins is 25 as same as [uijlings_ijcv2013_draft.pdf]</span></span><br><span class="line"><span class="string">        extract HSV</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    BINS = <span class="number">25</span></span><br><span class="line">    hist = numpy.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># extracting one colour channel</span></span><br><span class="line">        c = img[:, colour_channel]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate histogram for each colour and join to the result</span></span><br><span class="line">        hist = numpy.concatenate(</span><br><span class="line">            [hist] + [numpy.histogram(c, BINS, (<span class="number">0.0</span>, <span class="number">255.0</span>))[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L1 normalize</span></span><br><span class="line">    hist = hist / <span class="built_in">len</span>(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_texture_gradient</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate texture gradient for entire image</span></span><br><span class="line"><span class="string">        The original SelectiveSearch algorithm proposed Gaussian derivative</span></span><br><span class="line"><span class="string">        for 8 orientations, but we use LBP instead.</span></span><br><span class="line"><span class="string">        output will be [height(*)][width(*)]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ret = numpy.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], img.shape[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        ret[:, :, colour_channel] = skimage.feature.local_binary_pattern(</span><br><span class="line">            img[:, :, colour_channel], <span class="number">8</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_texture_hist</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate texture histogram for each region</span></span><br><span class="line"><span class="string">        calculate the histogram of gradient for each colours</span></span><br><span class="line"><span class="string">        the size of output histogram will be</span></span><br><span class="line"><span class="string">            BINS * ORIENTATIONS * COLOUR_CHANNELS(3)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    BINS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    hist = numpy.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mask by the colour channel</span></span><br><span class="line">        fd = img[:, colour_channel]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate histogram for each orientation and concatenate them all</span></span><br><span class="line">        <span class="comment"># and join to the result</span></span><br><span class="line">        hist = numpy.concatenate(</span><br><span class="line">            [hist] + [numpy.histogram(fd, BINS, (<span class="number">0.0</span>, <span class="number">1.0</span>))[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L1 Normalize</span></span><br><span class="line">    hist = hist / <span class="built_in">len</span>(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_regions</span>(<span class="params">img</span>):</span></span><br><span class="line"></span><br><span class="line">    R = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get hsv image</span></span><br><span class="line">    hsv = skimage.color.rgb2hsv(img[:, :, :<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 1: count pixel positions</span></span><br><span class="line">    <span class="keyword">for</span> y, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(img):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, (r, g, b, l) <span class="keyword">in</span> <span class="built_in">enumerate</span>(i):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># initialize a new region</span></span><br><span class="line">            <span class="keyword">if</span> l <span class="keyword">not</span> <span class="keyword">in</span> R:</span><br><span class="line">                R[l] = &#123;</span><br><span class="line">                    <span class="string">&quot;min_x&quot;</span>: <span class="number">0xffff</span>, <span class="string">&quot;min_y&quot;</span>: <span class="number">0xffff</span>,</span><br><span class="line">                    <span class="string">&quot;max_x&quot;</span>: <span class="number">0</span>, <span class="string">&quot;max_y&quot;</span>: <span class="number">0</span>, <span class="string">&quot;labels&quot;</span>: [l]&#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># bounding box</span></span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;min_x&quot;</span>] &gt; x:</span><br><span class="line">                R[l][<span class="string">&quot;min_x&quot;</span>] = x</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;min_y&quot;</span>] &gt; y:</span><br><span class="line">                R[l][<span class="string">&quot;min_y&quot;</span>] = y</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;max_x&quot;</span>] &lt; x:</span><br><span class="line">                R[l][<span class="string">&quot;max_x&quot;</span>] = x</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;max_y&quot;</span>] &lt; y:</span><br><span class="line">                R[l][<span class="string">&quot;max_y&quot;</span>] = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 2: calculate texture gradient</span></span><br><span class="line">    tex_grad = _calc_texture_gradient(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 3: calculate colour histogram of each region</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> R.items():</span><br><span class="line"></span><br><span class="line">        <span class="comment"># colour histogram</span></span><br><span class="line">        masked_pixels = hsv[:, :, :][img[:, :, <span class="number">3</span>] == k]</span><br><span class="line">        R[k][<span class="string">&quot;size&quot;</span>] = <span class="built_in">len</span>(masked_pixels / <span class="number">4</span>)</span><br><span class="line">        R[k][<span class="string">&quot;hist_c&quot;</span>] = _calc_colour_hist(masked_pixels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># texture histogram</span></span><br><span class="line">        R[k][<span class="string">&quot;hist_t&quot;</span>] = _calc_texture_hist(tex_grad[:, :][img[:, :, <span class="number">3</span>] == k])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_neighbours</span>(<span class="params">regions</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">a, b</span>):</span></span><br><span class="line">        <span class="keyword">if</span> (a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;min_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;min_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;max_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;max_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;min_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;max_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;max_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;min_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    R = regions.items()</span><br><span class="line">    neighbours = []</span><br><span class="line">    <span class="keyword">for</span> cur, a <span class="keyword">in</span> <span class="built_in">enumerate</span>(R[:-<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> R[cur + <span class="number">1</span>:]:</span><br><span class="line">            <span class="keyword">if</span> intersect(a[<span class="number">1</span>], b[<span class="number">1</span>]):</span><br><span class="line">                neighbours.append((a, b))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> neighbours</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_merge_regions</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    new_size = r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;size&quot;</span>]</span><br><span class="line">    rt = &#123;</span><br><span class="line">        <span class="string">&quot;min_x&quot;</span>: <span class="built_in">min</span>(r1[<span class="string">&quot;min_x&quot;</span>], r2[<span class="string">&quot;min_x&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;min_y&quot;</span>: <span class="built_in">min</span>(r1[<span class="string">&quot;min_y&quot;</span>], r2[<span class="string">&quot;min_y&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;max_x&quot;</span>: <span class="built_in">max</span>(r1[<span class="string">&quot;max_x&quot;</span>], r2[<span class="string">&quot;max_x&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;max_y&quot;</span>: <span class="built_in">max</span>(r1[<span class="string">&quot;max_y&quot;</span>], r2[<span class="string">&quot;max_y&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: new_size,</span><br><span class="line">        <span class="string">&quot;hist_c&quot;</span>: (</span><br><span class="line">            r1[<span class="string">&quot;hist_c&quot;</span>] * r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;hist_c&quot;</span>] * r2[<span class="string">&quot;size&quot;</span>]) / new_size,</span><br><span class="line">        <span class="string">&quot;hist_t&quot;</span>: (</span><br><span class="line">            r1[<span class="string">&quot;hist_t&quot;</span>] * r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;hist_t&quot;</span>] * r2[<span class="string">&quot;size&quot;</span>]) / new_size,</span><br><span class="line">        <span class="string">&quot;labels&quot;</span>: r1[<span class="string">&quot;labels&quot;</span>] + r2[<span class="string">&quot;labels&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selective_search</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        im_orig, scale=<span class="number">1.0</span>, sigma=<span class="number">0.8</span>, min_size=<span class="number">50</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Selective Search</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        im_orig : ndarray</span></span><br><span class="line"><span class="string">            Input image</span></span><br><span class="line"><span class="string">        scale : int</span></span><br><span class="line"><span class="string">            Free parameter. Higher means larger clusters in felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">        sigma : float</span></span><br><span class="line"><span class="string">            Width of Gaussian kernel for felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">        min_size : int</span></span><br><span class="line"><span class="string">            Minimum component size for felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">        img : ndarray</span></span><br><span class="line"><span class="string">            image with region label</span></span><br><span class="line"><span class="string">            region label is stored in the 4th value of each pixel [r,g,b,(region)]</span></span><br><span class="line"><span class="string">        regions : array of dict</span></span><br><span class="line"><span class="string">            [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                    &#x27;rect&#x27;: (left, top, right, bottom),</span></span><br><span class="line"><span class="string">                    &#x27;labels&#x27;: [...]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> im_orig.shape[<span class="number">2</span>] == <span class="number">3</span>, <span class="string">&quot;3ch image is expected&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image and get smallest regions</span></span><br><span class="line">    <span class="comment"># region label is stored in the 4th value of each pixel [r,g,b,(region)]</span></span><br><span class="line">    img = _generate_segments(im_orig, scale, sigma, min_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, &#123;&#125;</span><br><span class="line"></span><br><span class="line">    imsize = img.shape[<span class="number">0</span>] * img.shape[<span class="number">1</span>]</span><br><span class="line">    R = _extract_regions(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># extract neighbouring information</span></span><br><span class="line">    neighbours = _extract_neighbours(R)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate initial similarities</span></span><br><span class="line">    S = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> (ai, ar), (bi, br) <span class="keyword">in</span> neighbours:</span><br><span class="line">        S[(ai, bi)] = _calc_sim(ar, br, imsize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hierarchal search</span></span><br><span class="line">    <span class="keyword">while</span> S != &#123;&#125;:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get highest similarity</span></span><br><span class="line">        i, j = <span class="built_in">sorted</span>(S.items(), cmp=<span class="keyword">lambda</span> a, b: cmp(a[<span class="number">1</span>], b[<span class="number">1</span>]))[-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># merge corresponding regions</span></span><br><span class="line">        t = <span class="built_in">max</span>(R.keys()) + <span class="number">1.0</span></span><br><span class="line">        R[t] = _merge_regions(R[i], R[j])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mark similarities for regions to be removed</span></span><br><span class="line">        key_to_delete = []</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> S.items():</span><br><span class="line">            <span class="keyword">if</span> (i <span class="keyword">in</span> k) <span class="keyword">or</span> (j <span class="keyword">in</span> k):</span><br><span class="line">                key_to_delete.append(k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># remove old similarities of related regions</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> key_to_delete:</span><br><span class="line">            <span class="keyword">del</span> S[k]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate similarity set with the new region</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">filter</span>(<span class="keyword">lambda</span> a: a != (i, j), key_to_delete):</span><br><span class="line">            n = k[<span class="number">1</span>] <span class="keyword">if</span> k[<span class="number">0</span>] <span class="keyword">in</span> (i, j) <span class="keyword">else</span> k[<span class="number">0</span>]</span><br><span class="line">            S[(t, n)] = _calc_sim(R[t], R[n], imsize)</span><br><span class="line"></span><br><span class="line">    regions = []</span><br><span class="line">    <span class="keyword">for</span> k, r <span class="keyword">in</span> R.items():</span><br><span class="line">        regions.append(&#123;</span><br><span class="line">            <span class="string">&#x27;rect&#x27;</span>: (</span><br><span class="line">                r[<span class="string">&#x27;min_x&#x27;</span>], r[<span class="string">&#x27;min_y&#x27;</span>],</span><br><span class="line">                r[<span class="string">&#x27;max_x&#x27;</span>] - r[<span class="string">&#x27;min_x&#x27;</span>], r[<span class="string">&#x27;max_y&#x27;</span>] - r[<span class="string">&#x27;min_y&#x27;</span>]),</span><br><span class="line">            <span class="string">&#x27;size&#x27;</span>: r[<span class="string">&#x27;size&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: r[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img, regions</span><br></pre></td></tr></table></figure></li>
<li>example.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> skimage.data</span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> use_plugin,imread</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> mpatches</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> savefig</span><br><span class="line"><span class="keyword">import</span> selectivesearch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># loading astronaut image</span></span><br><span class="line">    <span class="comment">#img = skimage.data.astronaut()</span></span><br><span class="line">    use_plugin(<span class="string">&#x27;pil&#x27;</span>)</span><br><span class="line">    img = imread(<span class="string">&#x27;car.jpg&#x27;</span>, as_grey=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform selective search</span></span><br><span class="line">    img_lbl, regions = selectivesearch.selective_search(</span><br><span class="line">        img, scale=<span class="number">500</span>, sigma=<span class="number">0.9</span>, min_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    candidates = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> regions:</span><br><span class="line">        <span class="comment"># excluding same rectangle (with different segments)</span></span><br><span class="line">        <span class="keyword">if</span> r[<span class="string">&#x27;rect&#x27;</span>] <span class="keyword">in</span> candidates:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># excluding regions smaller than 2000 pixels</span></span><br><span class="line">        <span class="keyword">if</span> r[<span class="string">&#x27;size&#x27;</span>] &lt; <span class="number">2000</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># distorted rects</span></span><br><span class="line">        x, y, w, h = r[<span class="string">&#x27;rect&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> w / h &gt; <span class="number">1.2</span> <span class="keyword">or</span> h / w &gt; <span class="number">1.2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        candidates.add(r[<span class="string">&#x27;rect&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># draw rectangles on the original image</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots(ncols=<span class="number">1</span>, nrows=<span class="number">1</span>, figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">    ax.imshow(img)</span><br><span class="line">    <span class="keyword">for</span> x, y, w, h <span class="keyword">in</span> candidates:</span><br><span class="line">        <span class="built_in">print</span> x, y, w, h</span><br><span class="line">        rect = mpatches.Rectangle(</span><br><span class="line">            (x, y), w, h, fill=<span class="literal">False</span>, edgecolor=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line">    savefig(<span class="string">&#x27;MyFig.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li>
</ul>
<a href="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagj3gmmo21cu5v0tsvacou2m.png">car.jpg原图</a>如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagj3gmmo21cu5v0tsvacou2m.png" width="500"/>
</center>
结果图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagloviabk1f61cm2ldoco733.png" width="500"/>
</center>
<h2 id="overfeat">8.2 OverFeat</h2>
<p>计算机视觉有三大任务：分类(识别)、定位、检测，从左到右每个任务是下个任务的子任务，所以难度递增。OverFeat是2014年《<a href="https://arxiv.org/abs/1312.6229">OverFeat:Integrated Recognition, Localization and Detection using Convolutional Networks</a>》中提出的一个基于卷积神经网络的特征提取框架，论文的最大亮点在于通过一个统一的框架去解决图像分类、定位、检测问题，并提出<strong>feature map上的一个点可以还原并对应到原图的一个区域</strong>，于是一些在原图上的操作可以转到在feature map上做，这点对以后的检测算法有较深远的影响。它在ImageNet 2013的task 3定位任务中获得第一，在检测和分类任务中也有不错的表现。</p>
<h3 id="overfeat分类任务">8.2.1 OverFeat分类任务</h3>
文中借鉴了AlexNet的结构，并做了些结构改进和提高了线上inference效率，结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgcn7re5ia8isa12v2gih4do9.png" width="800"/>
</center>
<p>相对AlexNet，网络结构几乎一样，区别在于：</p>
<blockquote>
<p>去掉了LRN层，不做额外归一化操作</p>
</blockquote>
<blockquote>
<p>使用区域非重叠pooling</p>
</blockquote>
<blockquote>
<p>前两层使用较小的stride，从而产生较大的feature map，提高了模型精度</p>
</blockquote>
<ul>
<li>Offset Pooling 分类任务中一大亮点是提出利用Offset Pooling做多尺度分类的概念，在一维情况的解释如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgdcp5041m4g1ftk6aq1db91tk4m.png" width="600" />
</center></li>
</ul>
<p>a图代表经过第5个卷积层后的feature map有20个神经元，选取stride=3做非重叠pooling，有以下3种方式：（通常我们只使用第一种）</p>
<pre><code>&gt; △=0分组:[1,2,3]，[4,5,6],[7,8,9],...,[16,17,18]
&gt; △=1分组:[2,3,4]，[5,6,7],[8,9,10],...,[17,18,19]
&gt; △=2分组:[3,4,5]，[6,7,8],[9,10,11],...,[18,19,20]</code></pre>
<p>在二维情况下，输入图像在经过FCN及第5个卷积层后得到若干个feature map，使用3x3 filter在feature map上做滑动窗口（注意此时不在原图上做，节省大量计算消耗）。按上图的原理，滑动窗口总共要做9次，从(0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,0), (2,1), (2,2)处分别滑动。得到的feature map分别经过后面的3个FC层，得到多组特征，最后拼接起来得到最终特征向量并用于分类。</p>
<ul>
<li>Inference自适应输入图片大小</li>
</ul>
训练模型时往往采用的是固定大小图片(后面的SPP-net、Fast R-CNN等模型通过SPP或ROI pooling可以允许输入大小可变)，当inference阶段遇到比规定大小更大的图片时怎么办？可以利用Fully Convolutional Networks（《<a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Fully Convolutional Networks for Semantic Segmentation</a>》）的思想：把卷积层到全连接层映射看成对整张图的卷积操作，把全连接层到全连接层的映射可以看成采用1x1卷积核的卷积操作。以下图说明：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgdefki817bkpp61od4bq61ch713.png" width="600" />
</center>
<p>绿色代表卷积核，蓝色代表feature map，当输入大于规定尺寸时，在黄色区域会有额外计算，最终的输出也不是一个值而是一个矩阵，可以用各种策略输出最终结果，比如一种简单做法是用矩阵平均值作为最终分类结果。</p>
<h3 id="overfeat定位任务">8.2.2 OverFeat定位任务</h3>
<ul>
<li><p>回归训练</p>
相对于分类问题，定位问题可以与其共享前1~5层网络结构，这种方式也被后面的模型所借鉴，区别是增加了一个<span class="math inline">\(l_2\)</span>的回归损失函数，基本思路是对同一张图缩放产生多尺度图片做输入，用回归网络预测Bounding Box（后面简写为BB）后再做融合，需要注意回归层是与类别相关的，如果有1000个类则有1000个版本，每类一个。回归示意图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgf6dah21ok1hj71cl1h1h1p1j9.png" width="400" />
</center>
<p>第5层pooling结果作为输入，共256个通道，以FCN的思想理解，先走一个4096通道的全连接层再走一个1024通道的全连接层，与前面类似使用Offet Pooing和滑动窗口对每类生成一个4通道矩阵，4个通道分别代表BB的四条边的坐标。</p></li>
<li><p>网络输出</p>
回归网络的输出例子如下，单图下生成多个BB的预测，这些BB倾向于收敛到一个固定位置并且可以定位物体姿势多样化的情况，当然计算复杂度不小，所以没法用到实时检测中。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgf7av4q1fasqp1uimn2c1uvkm.png" width="500"/>
</center></li>
<li><p>预测融合策略</p>
<ol type="a">
<li>同一幅图在6种不同缩放尺度下分别输入<strong>分类</strong>网络，每种尺度下选top k类别作为标定，用<span class="math inline">\(C_s\)</span>表示；</li>
<li>对任意尺度<span class="math inline">\(s\)</span>分别输入BB <strong>回归</strong>网络，用<span class="math inline">\(B_s\)</span>表示每个类别对应的BB集合；</li>
<li>将所有<span class="math inline">\(B_s\)</span>合并为大集合<span class="math inline">\(B\)</span>；</li>
<li>重复以下过程直到结束： <span class="math display">\[
  \begin{array}{l}
  (b_1^*,b_2^*)=argmin_{b_1\neq b_2 \in B}\text{match_score}(b_1,b_2)\\
  if \quad \text{match_score}(b_1^*,b_2^*)&gt;t \quad \\
  then \quad stop.\\
  Otherwise \quad set \quad B=B-\{b_1^*,b_2^*\}\cup \text{box_merge}(b_1^*,b_2^*)
  \end{array}
  \]</span> 其中match_score为两个BB的中心点之间的距离及BB重合区域面积之和，box_merge为两个BB坐标均值，过程很好理解：所有分类（如可能有熊、鲸鱼等）的BB被放在一个大集合，多尺度得到的分类集合中，正确分类会占有优势（置信度、匹配度、BB连续度等），随着迭代的过程正确分类的BB被加强，错误分类的BB被减弱直到消失，不过这个方法确实复杂，可以看到在后来的算法有各种改进和替换。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgfb34cc7i713lcnhr3881oqs1g.png" width="600" />
</center></li>
</ol></li>
</ul>
<h3 id="overfeat检测任务">8.2.3 OverFeat检测任务</h3>
<p>与分类类似但需要考虑位置信息，同样采用网络结构共享特征提取，在预测分类中还需要加“背景”这一类。</p>
<h3 id="代码实践-1">8.2.4 代码实践</h3>
<p>可参见：<a href="https://github.com/sermanet/OverFeat">OverFeat</a></p>
<h2 id="r-cnn">8.3 R-CNN</h2>
<p>过去若干年，目标检测使用的都是滑动窗口的方式，这种方式计算效率较差，另外以往CNN在ImageNet比赛分类问题的表现更加突出，如何利用这些成果以及ImageNet的大量训练数据去借力打力也是一个值得研究的课题。R-CNN由Ross Girshick等人在《<a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a>》中提出，OverFeat从某种程度可以看做R-CNN的特例，R-CNN在图像检测领域有很大的影响力，该算法的亮点在于：使用Selective Search代替传统滑动窗口方式生成候选框并使用CNN提取特征；把分类和回归方法同时应用在检测中；当训练数据不足时，通过预训练利用领域数据（知识）做transfer learning，在对象数据集上再应用fine-tuning继续训练。</p>
<h3 id="iou">8.3.1 IoU</h3>
IoU（intersection over union），是用来衡量Bounding Box定位精度的指标，它的定义类似Jaccard距离，假设A为人工标定的BB，B为预测的BB则： <span class="math display">\[IOU=\frac{area(A \cap B)}{area(A \cup B)}\]</span>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbntg01g031n4o1l4ge7uasv3u.png" width="500" />
</center>
<h3 id="nms">8.3.2 NMS</h3>
NMS（non-maximum suppression）在目标检测中用来依据置信度消除重叠度过高的重复候选框，从而提高检测算法效率。 例如，<a href="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbfv0e1i8n4as1l6qn70ome2n.png">原图</a>为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbfv0e1i8n4as1l6qn70ome2n.png" width="500" />
</center>
原图+候选框为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbl582ucc3981voe1dgg1o8b3h.png" width="500"/>
</center>
执行NMS后为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbj2es9mh1m4tkkgmv6tsb34.png" width="500"/>
</center>
<p>代码可参考：<a href="http://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/">Non-Maximum Suppression for Object Detection in Python</a> <strong>nms.py</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#  Felzenszwalb et al.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">non_max_suppression_slow</span>(<span class="params">boxes, overlapThresh</span>):</span></span><br><span class="line">	<span class="comment"># if there are no boxes, return an empty list</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(boxes) == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">	<span class="comment"># initialize the list of picked indexes</span></span><br><span class="line">	pick = []</span><br><span class="line"></span><br><span class="line">	<span class="comment"># grab the coordinates of the bounding boxes</span></span><br><span class="line">	x1 = boxes[:,<span class="number">0</span>]</span><br><span class="line">	y1 = boxes[:,<span class="number">1</span>]</span><br><span class="line">	x2 = boxes[:,<span class="number">2</span>]</span><br><span class="line">	y2 = boxes[:,<span class="number">3</span>]</span><br><span class="line">	scores = boxes[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># compute the area of the bounding boxes and sort the bounding</span></span><br><span class="line">	<span class="comment"># boxes by the bottom-right y-coordinate of the bounding box</span></span><br><span class="line">	area = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">	idxs = np.argsort(scores)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># keep looping while some indexes still remain in the indexes</span></span><br><span class="line">	<span class="comment"># list</span></span><br><span class="line">	<span class="keyword">while</span> <span class="built_in">len</span>(idxs) &gt; <span class="number">0</span>:</span><br><span class="line">		<span class="comment"># grab the last index in the indexes list, add the index</span></span><br><span class="line">		<span class="comment"># value to the list of picked indexes, then initialize</span></span><br><span class="line">		<span class="comment"># the suppression list (i.e. indexes that will be deleted)</span></span><br><span class="line">		<span class="comment"># using the last index</span></span><br><span class="line">		last = <span class="built_in">len</span>(idxs) - <span class="number">1</span></span><br><span class="line">		i = idxs[last]</span><br><span class="line">		pick.append(i)</span><br><span class="line">		suppress = [last]</span><br><span class="line"></span><br><span class="line">		<span class="comment"># loop over all indexes in the indexes list</span></span><br><span class="line">		<span class="keyword">for</span> pos <span class="keyword">in</span> xrange(<span class="number">0</span>, last):</span><br><span class="line">			<span class="comment"># grab the current index</span></span><br><span class="line">			j = idxs[pos]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># find the largest (x, y) coordinates for the start of</span></span><br><span class="line">			<span class="comment"># the bounding box and the smallest (x, y) coordinates</span></span><br><span class="line">			<span class="comment"># for the end of the bounding box</span></span><br><span class="line">			xx1 = <span class="built_in">max</span>(x1[i], x1[j])</span><br><span class="line">			yy1 = <span class="built_in">max</span>(y1[i], y1[j])</span><br><span class="line">			xx2 = <span class="built_in">min</span>(x2[i], x2[j])</span><br><span class="line">			yy2 = <span class="built_in">min</span>(y2[i], y2[j])</span><br><span class="line"></span><br><span class="line">			<span class="comment"># compute the width and height of the bounding box</span></span><br><span class="line">			w = <span class="built_in">max</span>(<span class="number">0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">			h = <span class="built_in">max</span>(<span class="number">0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">			<span class="comment"># compute the ratio of overlap between the computed</span></span><br><span class="line">			<span class="comment"># bounding box and the bounding box in the area list</span></span><br><span class="line">			overlap = <span class="built_in">float</span>(w * h) / area[j]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># if there is sufficient overlap, suppress the</span></span><br><span class="line">			<span class="comment"># current bounding box</span></span><br><span class="line">			<span class="keyword">if</span> overlap &gt; overlapThresh:</span><br><span class="line">				suppress.append(pos)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># delete all indexes from the index list that are in the</span></span><br><span class="line">		<span class="comment"># suppression list</span></span><br><span class="line">		idxs = np.delete(idxs, suppress)</span><br><span class="line">	<span class="comment"># return only the bounding boxes that were picked</span></span><br><span class="line">	<span class="keyword">return</span> boxes[pick]</span><br></pre></td></tr></table></figure> <strong>nms_slow.py</strong> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nms <span class="keyword">import</span> non_max_suppression_slow</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct a list containing the images that will be examined</span></span><br><span class="line"><span class="comment"># along with their respective bounding boxes</span></span><br><span class="line"><span class="comment"># 最后一位为：分类置信度*100</span></span><br><span class="line">images = [</span><br><span class="line">        (<span class="string">&quot;images/333.jpg&quot;</span>, np.array([</span><br><span class="line">        (<span class="number">285</span>,<span class="number">293</span>,<span class="number">713</span>,<span class="number">679</span>,<span class="number">96</span>),</span><br><span class="line">        (<span class="number">9</span>,<span class="number">309</span>,<span class="number">161</span>,<span class="number">719</span>,<span class="number">90</span>),</span><br><span class="line">        (<span class="number">703</span>,<span class="number">259</span>,<span class="number">959</span>,<span class="number">659</span>,<span class="number">93</span>),</span><br><span class="line">	    (<span class="number">291</span>,<span class="number">309</span>,<span class="number">693</span>,<span class="number">663</span>,<span class="number">90</span>),</span><br><span class="line">        (<span class="number">1</span>,<span class="number">371</span>,<span class="number">155</span>,<span class="number">621</span>,<span class="number">80</span>),</span><br><span class="line">        (<span class="number">511</span>,<span class="number">347</span>,<span class="number">681</span>,<span class="number">637</span>,<span class="number">89</span>),</span><br><span class="line">        (<span class="number">293</span>,<span class="number">587</span>,<span class="number">721</span>,<span class="number">671</span>,<span class="number">70</span>),</span><br><span class="line">        (<span class="number">757</span>,<span class="number">469</span>,<span class="number">957</span>,<span class="number">641</span>,<span class="number">60</span>)]))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the images</span></span><br><span class="line"><span class="keyword">for</span> (imagePath, boundingBoxes) <span class="keyword">in</span> images:</span><br><span class="line">	<span class="comment"># load the image and clone it</span></span><br><span class="line">	<span class="built_in">print</span> <span class="string">&quot;[x] %d initial bounding boxes&quot;</span> % (<span class="built_in">len</span>(boundingBoxes))</span><br><span class="line">	image = cv2.imread(imagePath)</span><br><span class="line">	orig = image.copy()</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over the bounding boxes for each image and draw them</span></span><br><span class="line">	<span class="keyword">for</span> (startX, startY, endX, endY, c) <span class="keyword">in</span> boundingBoxes:</span><br><span class="line">		cv2.rectangle(orig, (startX, startY), (endX, endY), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># perform non-maximum suppression on the bounding boxes</span></span><br><span class="line">	pick = non_max_suppression_slow(boundingBoxes, <span class="number">0.3</span>)</span><br><span class="line">	<span class="built_in">print</span> <span class="string">&quot;[x] after applying non-maximum, %d bounding boxes&quot;</span> % (<span class="built_in">len</span>(pick))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over the picked bounding boxes and draw them</span></span><br><span class="line">	<span class="keyword">for</span> (startX, startY, endX, endY,c) <span class="keyword">in</span> pick:</span><br><span class="line">		cv2.rectangle(image, (startX, startY), (endX, endY), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># display the images</span></span><br><span class="line">	cv2.imshow(<span class="string">&quot;Original&quot;</span>, orig)</span><br><span class="line">	cv2.imshow(<span class="string">&quot;After NMS&quot;</span>, image)</span><br><span class="line">	cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="map">8.3.3 mAP</h3>
<p>先介绍什么是AP，以PASCAL VOC CHALLENGE 2010以后的定义做说明。 假设<span class="math inline">\(m\)</span>个样本中有<span class="math inline">\(p\)</span>个正例，依据包含正例的个数，可以得到<span class="math inline">\(p\)</span>个recall值，分别为：<span class="math inline">\(1/p，2/p，3/p，...，p/p\)</span>，对于每个recall值<span class="math inline">\(r\)</span>可以计算出对应<span class="math inline">\(r^{&#39;} \geq r\)</span>的最大precision，然后对这<span class="math inline">\(p\)</span>个precision值取平均即得到AP值。 举个例子，假设是否为车的分类，一共有30个测试样本，预测结果及标注如下：</p>
<table>
<thead>
<tr class="header">
<th>编号</th>
<th>预测值</th>
<th>实际值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.88</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.76</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.92</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.10</td>
<td>1</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.23</td>
<td>0</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.34</td>
<td>0</td>
</tr>
<tr class="odd">
<td>9</td>
<td>0.35</td>
<td>0</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.66</td>
<td>1</td>
</tr>
<tr class="odd">
<td>11</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>12</td>
<td>0.45</td>
<td>1</td>
</tr>
<tr class="odd">
<td>13</td>
<td>0.93</td>
<td>1</td>
</tr>
<tr class="even">
<td>14</td>
<td>0.97</td>
<td>0</td>
</tr>
<tr class="odd">
<td>15</td>
<td>0.81</td>
<td>1</td>
</tr>
<tr class="even">
<td>16</td>
<td>0.78</td>
<td>0</td>
</tr>
<tr class="odd">
<td>17</td>
<td>0.66</td>
<td>0</td>
</tr>
<tr class="even">
<td>18</td>
<td>0.54</td>
<td>0</td>
</tr>
<tr class="odd">
<td>19</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>20</td>
<td>0.31</td>
<td>0</td>
</tr>
<tr class="odd">
<td>21</td>
<td>0.22</td>
<td>0</td>
</tr>
<tr class="even">
<td>22</td>
<td>0.12</td>
<td>0</td>
</tr>
<tr class="odd">
<td>23</td>
<td>0.02</td>
<td>0</td>
</tr>
<tr class="even">
<td>24</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td>25</td>
<td>0.15</td>
<td>0</td>
</tr>
<tr class="even">
<td>26</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="odd">
<td>27</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="even">
<td>28</td>
<td>0.37</td>
<td>0</td>
</tr>
<tr class="odd">
<td>29</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>30</td>
<td>0.99</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>按照预测得分降序排列后如下：</p>
<table>
<thead>
<tr class="header">
<th>编号</th>
<th>预测值</th>
<th>实际值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>30</td>
<td>0.99</td>
<td>1</td>
</tr>
<tr class="even">
<td>14</td>
<td>0.97</td>
<td>0</td>
</tr>
<tr class="odd">
<td>13</td>
<td>0.93</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.92</td>
<td>0</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0.88</td>
<td>1</td>
</tr>
<tr class="even">
<td>15</td>
<td>0.81</td>
<td>1</td>
</tr>
<tr class="odd">
<td>16</td>
<td>0.78</td>
<td>0</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="odd">
<td>27</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.76</td>
<td>0</td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.66</td>
<td>1</td>
</tr>
<tr class="even">
<td>17</td>
<td>0.66</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>11</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="odd">
<td>18</td>
<td>0.54</td>
<td>0</td>
</tr>
<tr class="even">
<td>12</td>
<td>0.45</td>
<td>1</td>
</tr>
<tr class="odd">
<td>19</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>29</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="odd">
<td>28</td>
<td>0.37</td>
<td>0</td>
</tr>
<tr class="even">
<td>9</td>
<td>0.35</td>
<td>0</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.34</td>
<td>0</td>
</tr>
<tr class="even">
<td>20</td>
<td>0.31</td>
<td>0</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.23</td>
<td>0</td>
</tr>
<tr class="even">
<td>21</td>
<td>0.22</td>
<td>0</td>
</tr>
<tr class="odd">
<td>25</td>
<td>0.15</td>
<td>0</td>
</tr>
<tr class="even">
<td>22</td>
<td>0.12</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.10</td>
<td>1</td>
</tr>
<tr class="even">
<td>24</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td>23</td>
<td>0.02</td>
<td>0</td>
</tr>
<tr class="even">
<td>26</td>
<td>0.01</td>
<td>0</td>
</tr>
</tbody>
</table>
AP计算过程如下(注意与AUC之间的异同)：
<table>
<tr>
<td>
编号
</td>
<td>
预测值
</td>
<td>
实际值
</td>
<td>
Precision
</td>
<td>
Recall（r）
</td>
<td>
Max Precision with Recall（r'≥r）
</td>
<td>
AP
</td>
</tr>
<tr>
<td>
30
</td>
<td>
0.99
</td>
<td>
1
</td>
<td>
1/1=1
</td>
<td>
1/12=0.08
</td>
<td rowspan="2">
1
</td>
<td rowspan="30">
0.609
</td>
</tr>
<tr>
<td>
14
</td>
<td>
0.97
</td>
<td>
0
</td>
<td>
1/2=0.5
</td>
<td>
1/12=0.08
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
13
</td>
<td>
0.93
</td>
<td>
1
</td>
<td>
2/3=0.67
</td>
<td>
2/12=0.17
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
4
</td>
<td>
0.92
</td>
<td>
0
</td>
<td>
2/4=0.5
</td>
<td>
2/12=0.17
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0.88
</td>
<td>
1
</td>
<td>
3/5=0.6
</td>
<td>
3/12=0.25
</td>
<td>
0.6
</td>
<td>
</td>
</tr>
<tr>
<td>
15
</td>
<td>
0.81
</td>
<td>
1
</td>
<td>
4/6=0.67
</td>
<td>
4/12=0.33
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
16
</td>
<td>
0.78
</td>
<td>
0
</td>
<td>
4/7=0.57
</td>
<td>
4/12=0.33
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
6
</td>
<td>
0.77
</td>
<td>
1
</td>
<td>
5/8=0.63
</td>
<td>
5/12=0.42
</td>
<td>
0.63
</td>
<td>
</td>
</tr>
<tr>
<td>
27
</td>
<td>
0.77
</td>
<td>
1
</td>
<td>
6/9=0.67
</td>
<td>
6/12=0.5
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
2
</td>
<td>
0.76
</td>
<td>
0
</td>
<td>
6/10=0.6
</td>
<td>
6/12=0.5
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
10
</td>
<td>
0.66
</td>
<td>
1
</td>
<td>
7/11=0.64
</td>
<td>
7/12=0.58
</td>
<td rowspan="5">
0.64
</td>
<td>
</td>
</tr>
<tr>
<td>
17
</td>
<td>
0.66
</td>
<td>
0
</td>
<td>
7/12=0.58
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
3
</td>
<td>
0.56
</td>
<td>
0
</td>
<td>
7/13=0.54
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
11
</td>
<td>
0.56
</td>
<td>
0
</td>
<td>
7/14=0.5
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
18
</td>
<td>
0.54
</td>
<td>
0
</td>
<td>
7/15=0.47
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
12
</td>
<td>
0.45
</td>
<td>
1
</td>
<td>
8/16=0.5
</td>
<td>
8/12=0.67
</td>
<td>
0.5
</td>
<td>
</td>
</tr>
<tr>
<td>
19
</td>
<td>
0.43
</td>
<td>
1
</td>
<td>
9/17=0.53
</td>
<td>
9/12=0.75
</td>
<td>
0.53
</td>
<td>
</td>
</tr>
<tr>
<td>
29
</td>
<td>
0.43
</td>
<td>
1
</td>
<td>
10/18=0.56
</td>
<td>
10/12=0.83
</td>
<td rowspan="9">
0.56
</td>
<td>
</td>
</tr>
<tr>
<td>
28
</td>
<td>
0.37
</td>
<td>
0
</td>
<td>
10/19=0.53
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
9
</td>
<td>
0.35
</td>
<td>
0
</td>
<td>
10/20=0.5
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
8
</td>
<td>
0.34
</td>
<td>
0
</td>
<td>
10/21=0.48
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
20
</td>
<td>
0.31
</td>
<td>
0
</td>
<td>
10/22=0.45
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
7
</td>
<td>
0.23
</td>
<td>
0
</td>
<td>
10/23=0.43
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
21
</td>
<td>
0.22
</td>
<td>
0
</td>
<td>
10/24=0.42
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
25
</td>
<td>
0.15
</td>
<td>
0
</td>
<td>
10/25=0.4
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
22
</td>
<td>
0.12
</td>
<td>
0
</td>
<td>
10/26=0.38
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
5
</td>
<td>
0.1
</td>
<td>
1
</td>
<td>
11/27=0.41
</td>
<td>
11/12=0.92
</td>
<td>
0.41
</td>
<td>
</td>
</tr>
<tr>
<td>
24
</td>
<td>
0.05
</td>
<td>
1
</td>
<td>
12/28=0.43
</td>
<td>
12/12=1
</td>
<td rowspan="3">
0.43
</td>
<td>
</td>
</tr>
<tr>
<td>
23
</td>
<td>
0.02
</td>
<td>
0
</td>
<td>
12/29=0.41
</td>
<td>
12/12=1
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
26
</td>
<td>
0.01
</td>
<td>
0
</td>
<td>
12/30=0.4
</td>
<td>
12/12=1
</td>
<td>
</td>
<td>
</td>
</tr>
</table>
<p>mAP是所有类别下的AP求算数平均值的结果。</p>
<h3 id="r-cnn原理">8.3.4 R-CNN原理</h3>
<strong>训练阶段</strong> 整个过程分4步：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgfh5oqq50153t9n15a4fr1t.png" width="500"/>
</center>
<ul>
<li>候选框生成阶段 利用Selective Search生成2000个候选框（BB），之前很多年人们用的都是滑动窗口方式。需要注意的是，由于候选框图片大小不一，而后续用于提特征的CNN对输入要求是固定大小的(227×227)，所以需要做预处理，文中实验效果最好的方法是：不论长宽比例直接将图片缩放到227×227大小，并做padding=16的处理以保留上下文信息。</li>
<li>特征提取阶段 利用CNN提取图片特征，文中大部分实验结果采用AlexNet网络结构，小部分采用VGG16，前者训练速度快但精度相对低，后者反之，AlexNet结构如下。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1baou2biq9uhumh1tm1d95du99.png" width="600"/>
</center>
<ul>
<li>有监督预训练 使用ImageNet ILSVRC2012分类任务的1000类训练数据训练一个AlexNet模型，由于CNN主要作用体现在特征提取中，同样是猫狗，在不同数据集上特征是一样的，所以可以在不同问题间共享特征，区别无非在最终任务目标和特征如何组合上；</li>
<li>基于领域知识的fine-tuning 以上述模型做权重初始化，将softmax层1000类输出改为随机初始化权重的N+1类输出（1为背景类，对VOC，N=20），在目标训练集上继续训练，其中正样本为：与ground truth框IoU≥0.5的样本，其余的为负样本。训练时优化器采用学习率为0.001的SGD，样本采用mini-batch方式学习，大小为128，其中每个batch由采用均匀分布随机抽取的针对所有分类的32个正样本和96个负样本（背景）组成。</li>
</ul></li>
<li>训练分类器阶段 每一类做一个线性SVM分类器（为配合候选框特征向量的维度，每个SVM分类器为4096个权重），正样本为：每一类的ground truth，负样本为：与ground truth的IoU≤0.3的候选框（0.3这个阈值是通过在{0，0.1，0.2，0.3，0.4，0.5}集合上做grid search后观察验证集效果得到的）。 例如，对于VOC：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgpup10fl1g1he71goo1o9617jem.png" width="500"/>
</center></li>
<li>训练回归器阶段 主要目的是修正BB减少定位错误，借鉴DPM的方法，使用ridge regression修正BB位置，具体方法为： 假设输入为：候选框与ground truth框对集合，用<span class="math inline">\(\{(P^i,G^i)\}_{i=1,...,N}\)</span>，其中<span class="math inline">\(P_i=(P_x^i,P_y^i,P_w^i,P_h^i)\)</span>，括号中分别为候选框中心点的坐标及候选框宽与高，选取靠近（IoU≥0.6）ground truth的候选框，目标是学习一个映射使得候选框能被修正到ground truth框。利用SIT（scale-invariant translation）和LST（log-space translation）思想去学习这个变换（这里大家可以想想为什么？）： <span class="math display">\[
\begin{array}{l}
\hat{G_x}=P_w\cdot d_x(P)+P_x\\
\hat{G_y}=P_h\cdot d_y(P)+P_y \\
\hat{G_w}=P_w\cdot e^{d_w(P)}\\
\hat{G_h}=P_h\cdot e^{d_h(P)}
\end{array}
 \]</span> 变换函数<span class="math inline">\(d_*(P)\)</span>与AlexNet最后一个pooling层（4096个特征）的输出<span class="math inline">\(\phi_5(P)\)</span>关系为: <span class="math display">\[d_*(P)=w^T_*\phi_5(P)\]</span> 优化目标函数为： <span class="math display">\[w_*=argmin_{\hat{w_*}}\sum_i^N(t_*^i-\hat{w}_*^T\phi_5(P^i))^2+\lambda||\hat{w_*}||^2\]</span> 其中： <span class="math display">\[
\begin{array}{l}
t_x=(G_x-P_x)/P_w\\
t_y=(G_y-P_y)/P_h \\
t_w=log(G_w/P_w)\\
t_h=log(G_h/P_h)
\end{array}
 \]</span></li>
</ul>
<p>以上四个步骤是相互独立的，后验（马后炮）的来看，可以做这些改进：</p>
<p>1、把分类和回归放在一个网络做共享特征；</p>
<p>2、网络结构对输入图片大小自适应；</p>
<p>3、把候选框生成算法也放在同一个网络来做共享特征；</p>
<p>4、分类器抛弃SVM直接融合在神经网络中；</p>
<p>5、不用每个候选框都做一次特征提取。</p>
<p><strong>测试阶段</strong>过程如下：</p>
<ul>
<li>使用SS提取2000个候选框</li>
<li>将候选框大小缩放到227×227</li>
<li>每个候选框输入CNN，产生特征后对每一类做SVM分类输出置信度</li>
<li>对候选框做基于贪心的NMS</li>
<li>每个候选框的BB只做一次预测</li>
</ul>
<h3 id="代码实践-2">8.3.5 代码实践</h3>
<p>作者代码能力极强，具体可见：<a href="https://github.com/rbgirshick/rcnn">R-CNN: Region-based Convolutional Neural Networks</a>。</p>
<h2 id="spp-net">8.4 SPP-Net</h2>
<p>SPP-Net是何凯明等人在《<a href="https://arxiv.org/abs/1406.4729">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a>》一文中提出，文章亮点是主要解决了两个问题：</p>
<p>1、允许CNN网络的输入图片大小不固定（后面的FCN也可以解决这个问题）；</p>
<p>2、借鉴OverFeat只对整张图做一次特征提取，一些操作只在feature map上做而不用在原图进行且feature map上的点可以还原到原图上。</p>
<h3 id="问题回顾">8.4.1 问题回顾</h3>
之前的CNN网络的输入都是固定大小的，好处是网络结构相对简单和计算量低，坏处是所有图片都需要做预处理，这个会损失原图信息或引入噪声。训练和预测的一般流程是：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsbrok31sh917c5ju5jvrn1qm.png" width="600" />
</center>
常用的缩放方式有裁剪和缩放，例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgs6vv3j1uqh179e1aalshh1r0h9.png" width="600" />
</center>
分析CNN网络结构可以发现，卷积层和pooling层对图片输入大小都没有要求，唯独全连接层需要其输入是固定大小的，所以改进主要针对全连接层的输入，另外通过特征可视化观察到feature map包含了图片的空间信息，所以新方法同样需要包含空间信息，于是文中提出了通过增加SPP层解决问题，新的算法流程变为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgscko9j1q99uf5fkaq31ifv13.png" width="600" />
</center>
<h3 id="spp详解">8.4.2 SPP详解</h3>
可以把这个问题看做如何找到输入可变，输出固定且能保留空间信息的映射问题，问题三个相关变量：feature map的大小、bin的个数（借鉴BoW《<a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf">Video Google: A Text Retrieval Approach to Object Matching in Videos</a>》的思想，表示固定特征的维度数）、pooling步长。现在feature map的大小不固定但bin的个数固定，于是唯一能自适应可变的就是pooling步长了。 假设：最后一个卷积层产生的feature map大小为<span class="math inline">\(a×a\)</span>，希望产生<span class="math inline">\(n×n\)</span>个bins，则窗口大小为<span class="math inline">\(\lceil\frac{a}{n}\rceil\)</span>，步长为<span class="math inline">\(\lfloor\frac{a}{n}\rfloor\)</span>，例如：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsg5gtkprvdbthhf4793bd1g.png" width="500"/>
</center>
<p>每个bin的pooling方式可以是max pooling或其他pooling。</p>
SPP同样支持多尺度特征，例如4×4、2×2、1×1三种尺度最后拼成21×256维特征向量：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsg8da2e9abus1i219c61ulb1t.png" width="500"  />
</center>
<h3 id="感受野receptive-field">8.4.3 感受野(Receptive Field)</h3>
感受野来源于生物学，Levine and Shefner在《<a href="https://www.amazon.co.uk/d/Books/Fundamentals-Sensation-Perception-Michael-Levine/0198524668">Fundamentals of sensation and perception</a>》中将感受野定义为：由于受到刺激导致特定神经元发生反应的区域。比如人在观察某个物体的某个部分时由于受到刺激，物体会投影到视网膜，之后传到给大脑并激活某个区域（橘色的框框住的区域）。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgunun1usbfjgt1p0o1rhq1fgq9.png" width="500"  />
</center>
CNN的任何一个卷积层或pooling层产生的任何一个feature map上的任何一点都会对应到原始图像上的某个区域，那个区域就是该点的感受野。例如，红、绿、橙三个点的感受野不同：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgur286f1vmo1f71uau8jh1tp8m.png" width="500"  />
</center>
<p>感受野的大小与以下两个因素有关但<strong>与是否padding无关</strong>： 1、filter的大小； 2、stride的大小。</p>
<h3 id="feature-map与原图对应关系转换">8.4.4 feature map与原图对应关系转换</h3>
<p>由于SPP只对原图做一次特征提取，省去了大量重复劳动，另外由于特征点的可还原性，使得后续对所有对候选框做SPP特征映射操作时只需要在最后一个卷积层产生的feature map上进行即可（否则需要考虑感受野上的所有特征映射将会产生巨大的计算量）。 详情可参考《<a href="https://arxiv.org/pdf/1506.06981.pdf">R-CNN minus R</a>》. 简单的转换方法为： 需要对CNN网络的<strong>所有卷积层和pooling层</strong>做padding，使得原图中的任何一点与卷积或pooling后的图上的点一一对应（边缘信息也没有丢失）。</p>
<p>假设：</p>
<p>1、任何一层的核大小为<span class="math inline">\(p\)</span>；</p>
<p>2、每层padding值为<span class="math inline">\(\lfloor\frac{p}{2}\rfloor\)</span>；</p>
<p>3、原图中任何一点坐标为<span class="math inline">\((x,y)\)</span>，该点在任何一个feature map上的位置为<span class="math inline">\((x,^{&#39;},y^{&#39;})\)</span>；</p>
<p>4、从原图到该feature map感受野范围内的所有stride乘积为<span class="math inline">\(S\)</span>。</p>
<p>则： 原图候选框<strong>左上点</strong>的坐标与其在任意feature map上的坐标关系为： <span class="math display">\[
\begin{array}{l}
x^{&#39;}=\lfloor\frac{x}{S}\rfloor+1\\
y^{&#39;}=\lfloor\frac{y}{S}\rfloor+1
\end{array}
\]</span> 原图候选框<strong>右下点</strong>的坐标与其在任意feature map上的坐标关系为： <span class="math display">\[
\begin{array}{l}
x^{&#39;}=\lceil\frac{x}{S}\rceil-1\\
y^{&#39;}=\lceil\frac{y}{S}\rceil-1
\end{array}
\]</span></p>
<p><strong>通用</strong>的转换方法为： <span class="math display">\[
\begin{array}{l}
i_0=\alpha_L(i_L-1)+\beta_L\\
\alpha_L=\prod_{p=1}^L S_p\\
\beta_L=1+\sum_{p=1}^L(\prod_{q=1}^{p-1}S_q)(\frac{F_p-1}{2}-P_p)
\end{array}
\]</span> 其中： <span class="math inline">\(i_0\)</span>是feature map上的特征点<span class="math inline">\(i_L\)</span>在<strong>感受野的中心位置</strong>坐标； <span class="math inline">\(L\)</span>是当前特征点处于由CNN的第几层产生的feature map中； <span class="math inline">\(S_p\)</span>第<span class="math inline">\(p\)</span>层的stride大小； <span class="math inline">\(F_p\)</span>第<span class="math inline">\(p\)</span>层的filter大小； <span class="math inline">\(P_p\)</span>第<span class="math inline">\(p\)</span>层的padding大小。 反过来可以知道原图任何一个候选框在任何一个feature map上的位置。</p>
<p>感受野大小的计算采用Top to Down的方式，从当前层往靠近输入层的方式逐层传递，具体方法为： 假设：待计算感受野的特征点所在feature map所处层为<span class="math inline">\(L\)</span>，<span class="math inline">\(r_0\)</span>为特征点在原图的感受野大小。 则： <span class="math display">\[
\begin{array}{l}
r_L=1;\\
for \quad t=L;t&lt;=1;t--\\
\quad \quad \quad r_{t-1}=(r_{t}-1)*S_{t}+F_{t};\\
return \quad r_0;
\end{array}
\]</span></p>
<p>以下面两幅图为例：</p>
<ul>
<li>图一 无padding。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bh4i570957619rpopqks14r4p.png" width="600" />
</center>
<p>绿色点为第2层feature map上坐标为(1,1)的点，则它在原图的中心点为： <span class="math display">\[
\begin{array}{l}
\alpha_2=1*2=2\\
\beta_2=1+(2-1)/2+1*(3-1)/2=2.5\\
i_0=2*(i_2-1)+2.5
\end{array}
\]</span> 中心点坐标为图中<strong>红点</strong>：(2.5,2.5) 感受野大小为4： <span class="math display">\[
\begin{array}{l}
r_2=1\\
r_1=(r_2-1)*2+3=3\\
r_0=(r_1-1)*1+2=4
\end{array}
\]</span></p></li>
<li>图二 第一层有padding。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bh4kt6mh1vhbm2b1e161oob2eh16.png" width="600" />
</center>
<p>绿色点为第2层feature map上坐标为(1,1)的点，则它在原图的中心点为： <span class="math display">\[
\begin{array}{l}
\alpha_2=1*3=3\\
\beta_2=1+(2-1)/2+1*((3-1)/2-1)=1.5\\
i_0=3*(i_2-1)+1.5
\end{array}
\]</span> 中心点坐标为图中<strong>红点</strong>：(1.5,1.5) 感受野大小为4： <span class="math display">\[
\begin{array}{l}
r_2=1\\
r_1=(r_2-1)*3+3=3\\
r_0=(r_1-1)*1+2=4
\end{array}
\]</span></p></li>
</ul>
<h3 id="代码实践-3">8.4.5 代码实践</h3>
<ul>
<li>receptivefield.py <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#一层表示为一个三元组： [filter size, stride, padding]</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forword</span>(<span class="params">conv, layerIn</span>):</span></span><br><span class="line">  n_in = layerIn</span><br><span class="line">  k = conv[<span class="number">0</span>]</span><br><span class="line">  s = conv[<span class="number">1</span>]</span><br><span class="line">  p = conv[<span class="number">2</span>]</span><br><span class="line">  <span class="keyword">return</span> math.floor((n_in - k + <span class="number">2</span>*p)/s) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alexnet</span>():</span></span><br><span class="line">  convnet = [[],[<span class="number">11</span>,<span class="number">4</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">6</span>,<span class="number">1</span>,<span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]]</span><br><span class="line">  layer_names = [[<span class="string">&#x27;input&#x27;</span>],<span class="string">&#x27;conv1&#x27;</span>,<span class="string">&#x27;pool1&#x27;</span>,<span class="string">&#x27;conv2&#x27;</span>,<span class="string">&#x27;pool2&#x27;</span>,<span class="string">&#x27;conv3&#x27;</span>,<span class="string">&#x27;conv4&#x27;</span>,<span class="string">&#x27;conv5&#x27;</span>,<span class="string">&#x27;pool5&#x27;</span>,<span class="string">&#x27;fc6-conv&#x27;</span>, <span class="string">&#x27;fc7-conv&#x27;</span>]</span><br><span class="line">  <span class="keyword">return</span> [convnet, layer_names]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testnet</span>():</span></span><br><span class="line">  convnet = [[],[<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>]]</span><br><span class="line">  layer_names = [[<span class="string">&#x27;input&#x27;</span>],<span class="string">&#x27;conv1&#x27;</span>,<span class="string">&#x27;conv2&#x27;</span>]</span><br><span class="line">  <span class="keyword">return</span> [convnet, layer_names]</span><br><span class="line"></span><br><span class="line"><span class="comment"># layerid &gt;= 1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receptivefield</span>(<span class="params">net, layerid</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] receptivefield:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  rf = <span class="number">1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(layerid)):</span><br><span class="line">    filtersize, stride, padding = net[<span class="number">0</span>][i+<span class="number">1</span>]</span><br><span class="line">    rf = (rf - <span class="number">1</span>)*stride + filtersize</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;                感受野大小为:%d.&#x27;</span> % (<span class="built_in">int</span>(rf))</span><br><span class="line">  <span class="keyword">return</span> rf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">anylayerout</span>(<span class="params">net, layerin, layerid</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] anylayerout:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layerid):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">      fout = forword(net[<span class="number">0</span>][i+<span class="number">1</span>], layerin)</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    fout = forword(net[<span class="number">0</span>][i+<span class="number">1</span>], fout)</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;当前层为:%s, 输出节点维度为:%d.&#x27;</span> % (net[<span class="number">1</span>][layerid], <span class="built_in">int</span>(fout))</span><br><span class="line"></span><br><span class="line"><span class="comment">#x,y&gt;=1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receptivefieldcenter</span>(<span class="params">net, layerid, x, y</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] receptivefieldcenter:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  al = <span class="number">1</span></span><br><span class="line">  bl = <span class="number">1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layerid):</span><br><span class="line">    filtersize, stride, padding = net[<span class="number">0</span>][i+<span class="number">1</span>]</span><br><span class="line">    al = al * stride</span><br><span class="line">    ss = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">      fsize, std, pad = net[<span class="number">0</span>][j+<span class="number">1</span>]</span><br><span class="line">      ss = ss * std</span><br><span class="line"></span><br><span class="line">    bl = bl + ss * (<span class="built_in">float</span>(filtersize-<span class="number">1</span>)/<span class="number">2</span> - padding)</span><br><span class="line"></span><br><span class="line">  xi0 = al * (x - <span class="number">1</span>) + <span class="built_in">float</span>(bl)</span><br><span class="line">  yi0 = al * (y - <span class="number">1</span>) + bl</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;                该层上的特征点(%d,%d)在原图的感受野中心坐标为:(%.1f,%.1f).&#x27;</span> % (<span class="built_in">int</span>(x), <span class="built_in">int</span>(y), <span class="built_in">float</span>(xi0), <span class="built_in">float</span>(yi0))</span><br><span class="line">  <span class="keyword">return</span> (xi0, yi0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># net:为某个CNN网络</span></span><br><span class="line"><span class="comment"># insize:为输入层大小</span></span><br><span class="line"><span class="comment"># totallayers：为除了输入层外的所有层个数</span></span><br><span class="line"><span class="comment"># x,y为某层特征点坐标</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printlayer</span>(<span class="params">net, insize, totallayers, x, y</span>):</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(totallayers):</span><br><span class="line">    <span class="comment"># 计算每一层的输出大小</span></span><br><span class="line">    anylayerout(net, insize, i+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算每层的感受野大小</span></span><br><span class="line">    receptivefield(net, i+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算feature map上(x,y)点在原图感受野的中心位置坐标</span></span><br><span class="line">    receptivefieldcenter(net, i+<span class="number">1</span>, x, y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  <span class="comment">#net = testnet()</span></span><br><span class="line">  <span class="comment">#printlayer(net, insize=6, totallayers=2, x=1, y=1)</span></span><br><span class="line">  net = alexnet()</span><br><span class="line">  printlayer(net, insize=<span class="number">227</span>, totallayers=<span class="number">8</span>, x=<span class="number">2</span>, y=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></li>
<li>输出
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhehjb06nst2511lbr19d64jt39.png" width="600" />
</center></li>
</ul>
<h2 id="fast-r-cnn">8.5 Fast R-CNN</h2>
<p>《<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">Fast R-CNN</a>》的出现解决了R-CNN+SPP中的以下问题：</p>
<ul>
<li>把分类和回归放在一个网络做共享特征，提取的特征向量不用落地</li>
<li>借鉴SPP，网络结构对输入图片大小自适应</li>
<li>抛弃SVM分类器，利用softmax直接融合在神经网络中</li>
<li>借鉴SPP，只做一次全图的特征提取，不用每个候选框都做</li>
</ul>
<h3 id="算法概述">8.5.1 算法概述</h3>
算法基本步骤为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhes1rl71nh81e9ljv41nnbpr23m.png" width="500" />
</center>
<ul>
<li>候选框生成阶段 方法同R-CNN。</li>
<li>特征提取阶段 注意整个网络的输入为两部分：整个图和候选框信息。特征提取会对整张图进行，利用输入的候选框坐标及大小信息可以方便低成本的在任何一个feature map上找到任何一个原图点的特征映射点(方法回看SPP-net)，大大提高了特征提取效率。</li>
<li>RoI pooling阶段 借鉴SPP的思想，对每个候选框生成一个自适应候选框大小的固定长度的ROI（region of interest）特征向量，除此之外，大家还可以想想RoI Pooling的更深层次作用。</li>
<li>多任务学习阶段 把得到的RoI特征向量用全连接层做组合后分别送入两个分支：一个做分类，一个做Bounding Box回归，并为此设计一个多任务损失函数。</li>
</ul>
直观对比R-CNN与Fast R-CNN的<a href="http://kaiminghe.com/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf">forward pipeline</a>：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhet2nk1per1nd3c3tg5f1u7m43.png" width="600"/>
</center>
<h3 id="训练阶段">8.5.2 训练阶段</h3>
<ul>
<li><p>RoI pooling层生成说明</p>
<p>RoI pooling是SPP的特殊形式（金字塔层数为1，pooling采用max pooling），具体原理类比SPP即可，feature map通过该层后会产生<span class="math inline">\(H × W\)</span>大小（例如7 × 7）的特征向量，例如： 某个RoI坐标表示为四元组<span class="math inline">\((r,c,h,w)\)</span>，其中<span class="math inline">\(r,c\)</span>为RoI最左上角坐标，<span class="math inline">\(h,w\)</span>为其高与宽，则RoI pooling会划分<span class="math inline">\(H × W\)</span>个大小<span class="math inline">\(为\frac{h}{H} × \frac{w}{W}\)</span>的小网格，之后对每个小网格做max pooling即可。</p></li>
<li><p>RoI pooling层反向传播</p>
RoI pooling的反向传播比较简单，输入feature map上的任意特征元素的梯度信息为：所有由它产生的roi pooling feature map的特征元素所带梯度信息的累加和。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivqa5cb1hbeksa7gbdm123o1g.png" width="500"/>
</center>
<p>假设：</p>
<p>1、<span class="math inline">\(x_i \in R\)</span>是 RoI pooling层输入feature map的第<span class="math inline">\(i\)</span>个特征元素；</p>
<p>2、<span class="math inline">\(y_{rj}\)</span>是第<span class="math inline">\(r\)</span>个RoI的roi pooling后得到feature map的第<span class="math inline">\(j\)</span>个特征元素；</p>
<p>3、<span class="math inline">\(R(r,j)\)</span>是第<span class="math inline">\(r\)</span>个RoI通过roi pooling得到的feature map上的第<span class="math inline">\(j\)</span>个输出特征元素对应原feature map上的子图；</p>
<p><span class="math inline">\(i^*_{r,j}=argmax_{i^{\text{&#39;}} \in R(r,j)}x_i^\text{&#39;}\)</span>为在上述子图中做max pooling后得到的原feature map元素索引号。</p>
<p>则反向传播得到的原feature map元素的梯度为： <span class="math display">\[
  \frac{\partial L}{\partial x_i}=\sum_r \sum_j[i=i^*_{r,j}]\frac{\partial L}{\partial y_{rj}}
  \]</span> <span class="math inline">\([x]\)</span>函数表示：如果<span class="math inline">\(x\)</span>为真则返回1，否则返回0。</p></li>
<li><p>多任务损失函数</p>
<p>使用smooth L1函数并融合分类和bounding box回归损失，损失函数如下： <span class="math display">\[
  L(p,u,t^u,v)=L_{cls}(p,u)+\lambda \cdot [u \geq 1]L_{loc}(t^u,v)
  \]</span> 其中: <span class="math display">\[L_{cls}(p,u)=-log \text{ }p_u\]</span> <span class="math display">\[L_{loc}(t^u,v)=\sum_{i \in \{x,y,w,h\}}smooth_{L_1}(t_i^u-v_i)\]</span></p>
<span class="math display">\[ smooth_{L_1}(x)=
  \begin{cases}
  0.5x^2&amp; \text{if |x|&lt;1}\\
  |x|-0.5&amp; \text{otherwise}
  \end{cases}
  \]</span> smooth L1函数对异常点不敏感（在|x|值较大时使用线性分段函数而不是二次函数），如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivr14vrusab6vouf12a9la11t.png" width="400" />
</center></li>
</ul>
<h3 id="代码实践-4">8.5.3 代码实践</h3>
<p>fast r-cnn完整代码请参考<a href="https://github.com/rbgirshick/fast-rcnn">rbgirshick/fast-rcnn</a>。</p>
<ul>
<li>RoI Pooling层实现解析 <figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">// Fast R-CNN</span></span><br><span class="line"><span class="comment">// Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment">// Licensed under The MIT License [see fast-rcnn/LICENSE for details]</span></span><br><span class="line"><span class="comment">// Written by Ross Girshick</span></span><br><span class="line"><span class="comment">// ------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cfloat&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;caffe/fast_rcnn_layers.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::max;</span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::min;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下参数解释以VGG16为例，即进入roi pooling前的网络结构采用经典VGG16.</span></span><br><span class="line"><span class="comment">// 在Layer类中输入数据用bottom表示, 输出数据用top表示</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">ROIPoolForward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> nthreads,			<span class="comment">// 任务数，对应通过roi pooling后的输出feature map的神经元节点总数，</span></span></span></span><br><span class="line"><span class="params"><span class="function">	                            <span class="comment">// 具体为：RoI的个数(m) × channel个数(VGG16的conv5_3的输出为512个) × roi pooling输出宽(配置为7) × roi pooling输出高(配置为7) = 25088×m个</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype* bottom_data,	<span class="comment">// 输入的feature map，原图经过各种卷积、pooling等前向传播后得到（VGG16的conv5_3卷积产生的feature map，大小为：512×14×14）</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype spatial_scale,	<span class="comment">// 由之前所有卷积层的strides相乘得到，在fast rcnn中为1/16，注：从原图往conv5_3的feature map上映射为缩小过程，所以乘以1/16，反之需要乘以16</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> channels,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的channel个数(512)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> height,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的高(14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> width,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的宽(14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_height,	<span class="comment">// roi pooling输出feature map的高，fast rcnn中配置为h=7</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_width,		<span class="comment">// roi pooling输出feature map的宽，fast rcnn中配置为w=7</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype* bottom_rois,	<span class="comment">// 输入的roi信息，存储所有rois或一个batch的rois，数据结构为[batch_ind,x1,y1,x2,y2]，包含roi的：索引、左上角坐标及右下角坐标</span></span></span></span><br><span class="line"><span class="params"><span class="function">	Dtype* top_data,			<span class="comment">// 存储roi pooling后得到的feature map</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">int</span>* argmax_data)</span> </span>&#123;         <span class="comment">// 为每个roi pooling后的feature map元素存储max pooling后对应conv5_3 feature map元素的索引信息，长度等于nthreads</span></span><br><span class="line">    <span class="comment">// index为线程索引，个数为roi pooling后的feature map上所有值的个数，索引范围为：[0,nthreads-1]</span></span><br><span class="line">	CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的W,输出roi pooling后feature map的中的宽的坐标，即feature map的第i=[0,k-1]列</span></span><br><span class="line">    <span class="keyword">int</span> pw = index % pooled_width;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的H,输出roi pooling后feature map的中的高的坐标，即feature map的第j=[0,k-1]行</span></span><br><span class="line">    <span class="keyword">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的C,即第c个channel，channel数最大值为输入feature map的channel数（VGG16中为512）.</span></span><br><span class="line">    <span class="keyword">int</span> c = (index / pooled_width / pooled_height) % channels;</span><br><span class="line">    <span class="comment">// 该线程对应的是第几个RoI,一共m个.</span></span><br><span class="line">    <span class="keyword">int</span> n = index / pooled_width / pooled_height / channels;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// [start, end)，指定RoI信息的存储范围，指针每次移动5的倍数是因为包含信息的数据结构大小为5，包含信息为：[batch_ind,x1,y1,x2,y2]，含义同上</span></span><br><span class="line">    bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">    <span class="comment">// 将每个原图的RoI区域映射到feature map(VGG16为conv5_3产生的feature mao)上的坐标,bottom_rois第0个位置存放的是roi索引.</span></span><br><span class="line">    <span class="keyword">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">	<span class="comment">// 原图到feature map的映射为乘以1/16，这里采用粗映射而不是上文讲的精确映射，原因你懂的.</span></span><br><span class="line">    <span class="keyword">int</span> roi_start_w = round(bottom_rois[<span class="number">1</span>] * spatial_scale);</span><br><span class="line">    <span class="keyword">int</span> roi_start_h = round(bottom_rois[<span class="number">2</span>] * spatial_scale);</span><br><span class="line">    <span class="keyword">int</span> roi_end_w = round(bottom_rois[<span class="number">3</span>] * spatial_scale);</span><br><span class="line">    <span class="keyword">int</span> roi_end_h = round(bottom_rois[<span class="number">4</span>] * spatial_scale);</span><br><span class="line">    <span class="comment">// 强制把RoI的宽和高限制在1x1，防止出现映射后的RoI大小为0的情况</span></span><br><span class="line">    <span class="keyword">int</span> roi_width = max(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> roi_height = max(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 根据原图映射得到的roi的高和配置的roi pooling的高(这里大小配置为7)自适应计算bin桶的高度</span></span><br><span class="line">    Dtype bin_size_h = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                       / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_height);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 根据原图映射得到的roi的宽和配置的roi pooling的宽(这里大小配置为7)自适应计算bin桶的宽度</span></span><br><span class="line">    Dtype bin_size_w = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                       / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算第(i,j)个bin桶在feature map上的坐标范围，需要依据它们确定后续max pooling的范围</span></span><br><span class="line">    <span class="keyword">int</span> hstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph)</span><br><span class="line">                                        * bin_size_h));</span><br><span class="line">    <span class="keyword">int</span> wstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw)</span><br><span class="line">                                        * bin_size_w));</span><br><span class="line">    <span class="keyword">int</span> hend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph + <span class="number">1</span>)</span><br><span class="line">                                     * bin_size_h));</span><br><span class="line">    <span class="keyword">int</span> wend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw + <span class="number">1</span>)</span><br><span class="line">                                     * bin_size_w));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 确定max pooling具体范围，注意由于RoI取自原图，其左上角不是从(0,0)开始，</span></span><br><span class="line">	<span class="comment">// 所以需要加上 roi_start_h 或 roi_start_w作为偏移量，并且超出feature map尺寸范围的部分会被舍弃</span></span><br><span class="line">    hstart = min(max(hstart + roi_start_h, <span class="number">0</span>), height);</span><br><span class="line">    hend = min(max(hend + roi_start_h, <span class="number">0</span>), height);</span><br><span class="line">    wstart = min(max(wstart + roi_start_w, <span class="number">0</span>), width);</span><br><span class="line">    wend = min(max(wend + roi_start_w, <span class="number">0</span>), width);</span><br><span class="line">    <span class="keyword">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line">    <span class="comment">// 如果区域为0返回错误代码</span></span><br><span class="line">    Dtype maxval = is_empty ? <span class="number">0</span> : -FLT_MAX;</span><br><span class="line">    <span class="comment">// If nothing is pooled, argmax = -1 causes nothing to be backprop&#x27;d</span></span><br><span class="line">    <span class="keyword">int</span> maxidx = <span class="number">-1</span>;</span><br><span class="line">    bottom_data += (roi_batch_ind * channels + c) * height * width;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 在给定bin桶的区域中做max pooling</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> h = hstart; h &lt; hend; ++h) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> w = wstart; w &lt; wend; ++w) &#123;</span><br><span class="line">        <span class="keyword">int</span> bottom_index = h * width + w;</span><br><span class="line">        <span class="keyword">if</span> (bottom_data[bottom_index] &gt; maxval) &#123;</span><br><span class="line">          maxval = bottom_data[bottom_index];</span><br><span class="line">          maxidx = bottom_index;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 为某个roi pooling的feature map元素记录其由对conv5_3(VGG16)的feature map做max pooling后产生元素的索引号及值</span></span><br><span class="line">    top_data[index] = maxval;</span><br><span class="line">    argmax_data[index] = maxidx;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Forward_gpu(</span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,	<span class="comment">// 以VGG16为例，bottom[0]为最后一个卷积层conv5_3产生的feature map，shape[1, 512, 14, 14],</span></span><br><span class="line">	                                    <span class="comment">//              bottom[1]为rois数据，shape[roi个数m, 5]</span></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;	<span class="comment">// top为输出层结构， top-&gt;count() = top.n（RoI的个数) × top.channel(channel数)</span></span><br><span class="line">		                                <span class="comment">//                               × top.w(输出feature map的宽) × top.h(输出feature map的高)</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_gpu_data();</span><br><span class="line">  <span class="keyword">int</span>* argmax_data = max_idx_.mutable_gpu_data();</span><br><span class="line">  <span class="keyword">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   参照caffe-fast-rcnn/src/caffe/layers/roi_pooling_layer.cpp中的代码：</span></span><br><span class="line"><span class="comment">   template &lt;typename Dtype&gt;</span></span><br><span class="line"><span class="comment">   void ROIPoolingLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span><br><span class="line"><span class="comment">      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span></span><br><span class="line"><span class="comment">     channels_ = bottom[0]-&gt;channels();</span></span><br><span class="line"><span class="comment">     height_ = bottom[0]-&gt;height();</span></span><br><span class="line"><span class="comment">     width_ = bottom[0]-&gt;width();</span></span><br><span class="line"><span class="comment">     top[0]-&gt;Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_);</span></span><br><span class="line"><span class="comment">     max_idx_.Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_);</span></span><br><span class="line"><span class="comment">   &#125;*/</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  参照caffe-fast-rcnn/include/caffe/util/device_alternate.hpp中的代码：</span></span><br><span class="line"><span class="comment">  // CUDA_KERNEL_LOOP</span></span><br><span class="line"><span class="comment">  #define CUDA_KERNEL_LOOP(i, n) \</span></span><br><span class="line"><span class="comment">  for (int i = blockIdx.x * blockDim.x + threadIdx.x; \</span></span><br><span class="line"><span class="comment">       i &lt; (n); \</span></span><br><span class="line"><span class="comment">       i += blockDim.x * gridDim.x)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  // CAFFE_GET_BLOCKS</span></span><br><span class="line"><span class="comment">  // CUDA: number of blocks for threads.</span></span><br><span class="line"><span class="comment">  inline int CAFFE_GET_BLOCKS(const int N) &#123;</span></span><br><span class="line"><span class="comment">       return (N + CAFFE_CUDA_NUM_THREADS - 1) / CAFFE_CUDA_NUM_THREADS;</span></span><br><span class="line"><span class="comment">  &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  // CAFFE_CUDA_NUM_THREADS</span></span><br><span class="line"><span class="comment">  // CUDA: thread number configuration.</span></span><br><span class="line"><span class="comment">  // Use 1024 threads per block, which requires cuda sm_2x or above,</span></span><br><span class="line"><span class="comment">  // or fall back to attempt compatibility (best of luck to you).</span></span><br><span class="line"><span class="comment">  #if __CUDA_ARCH__ &gt;= 200</span></span><br><span class="line"><span class="comment">      const int CAFFE_CUDA_NUM_THREADS = 1024;</span></span><br><span class="line"><span class="comment">  #else</span></span><br><span class="line"><span class="comment">      const int CAFFE_CUDA_NUM_THREADS = 512;</span></span><br><span class="line"><span class="comment">  #endif</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"></span><br><span class="line">  ROIPoolForward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">      count, bottom_data, spatial_scale_, channels_, height_, width_,</span><br><span class="line">      pooled_height_, pooled_width_, bottom_rois, top_data, argmax_data);</span><br><span class="line">  CUDA_POST_KERNEL_CHECK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="comment">// 反向传播的过程与论文中&quot;Back-propagation through RoI pooling layers&quot;这一小节的公式完全一致</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">ROIPoolBackward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> nthreads,			<span class="comment">// 输入feature map的元素数(VGG16为：512×14×14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype* top_diff,		<span class="comment">// roi pooling输出feature map所带的梯度信息∂L/∂y(r,j)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span>* argmax_data,		<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> num_rois,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype spatial_scale,  <span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> channels,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> height,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> width,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> pooled_height,	<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_width,		<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	Dtype* bottom_diff,			<span class="comment">// 保留输入feature map每个元素通过梯度反向传播得到的梯度信息</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype* bottom_rois)</span> </span>&#123;	<span class="comment">// 同前向，不解释</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 含义同前向，需要注意的是这里表示的是输入feature map的元素数(反向传播嘛)</span></span><br><span class="line">  CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">    <span class="comment">// 同前向，不解释</span></span><br><span class="line">    <span class="keyword">int</span> w = index % width;</span><br><span class="line">    <span class="keyword">int</span> h = (index / width) % height;</span><br><span class="line">    <span class="keyword">int</span> c = (index / width / height) % channels;</span><br><span class="line">    <span class="keyword">int</span> n = index / width / height / channels;</span><br><span class="line">    Dtype gradient = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 同论文中公式，任何一个输入feature map的元素的梯度信息为：</span></span><br><span class="line">	<span class="comment">// 所有max pooling时被该元素落入且该元素值被选中(最大值)的</span></span><br><span class="line">	<span class="comment">// roi pooling feature map元素的梯度信息累加和</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 遍历所有RoI，以判断是否满足上述条件</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> roi_n = <span class="number">0</span>; roi_n &lt; num_rois; ++roi_n) &#123;</span><br><span class="line">      <span class="keyword">const</span> Dtype* offset_bottom_rois = bottom_rois + roi_n * <span class="number">5</span>;</span><br><span class="line">      <span class="keyword">int</span> roi_batch_ind = offset_bottom_rois[<span class="number">0</span>];</span><br><span class="line">      <span class="comment">// 如果RoI的索引号不满足条件则跳过</span></span><br><span class="line">      <span class="keyword">if</span> (n != roi_batch_ind) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 找原图RoI在feature map上的映射位置，解释同前向传播</span></span><br><span class="line">      <span class="keyword">int</span> roi_start_w = round(offset_bottom_rois[<span class="number">1</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_start_h = round(offset_bottom_rois[<span class="number">2</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_end_w = round(offset_bottom_rois[<span class="number">3</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_end_h = round(offset_bottom_rois[<span class="number">4</span>] * spatial_scale);</span><br><span class="line">      <span class="comment">// (h,w)不在RoI范围则跳过</span></span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">bool</span> in_roi = (w &gt;= roi_start_w &amp;&amp; w &lt;= roi_end_w &amp;&amp;</span><br><span class="line">                           h &gt;= roi_start_h &amp;&amp; h &lt;= roi_end_h);</span><br><span class="line">      <span class="keyword">if</span> (!in_roi) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> offset = (roi_n * channels + c) * pooled_height * pooled_width;</span><br><span class="line">      <span class="keyword">const</span> Dtype* offset_top_diff = top_diff + offset;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">int</span>* offset_argmax_data = argmax_data + offset;</span><br><span class="line">      <span class="comment">// 同前向</span></span><br><span class="line">      <span class="keyword">int</span> roi_width = max(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">int</span> roi_height = max(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 同前向</span></span><br><span class="line">      Dtype bin_size_h = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                         / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_height);</span><br><span class="line">      Dtype bin_size_w = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                         / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 类比前向，看做一个逆过程</span></span><br><span class="line">      <span class="keyword">int</span> phstart = <span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(h - roi_start_h) / bin_size_h);</span><br><span class="line">      <span class="keyword">int</span> phend = <span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(h - roi_start_h + <span class="number">1</span>) / bin_size_h);</span><br><span class="line">      <span class="keyword">int</span> pwstart = <span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(w - roi_start_w) / bin_size_w);</span><br><span class="line">      <span class="keyword">int</span> pwend = <span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(w - roi_start_w + <span class="number">1</span>) / bin_size_w);</span><br><span class="line">      phstart = min(max(phstart, <span class="number">0</span>), pooled_height);</span><br><span class="line">      phend = min(max(phend, <span class="number">0</span>), pooled_height);</span><br><span class="line">      pwstart = min(max(pwstart, <span class="number">0</span>), pooled_width);</span><br><span class="line">      pwend = min(max(pwend, <span class="number">0</span>), pooled_width);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 累积所有与当前输入feature map上的元素相关的roi pooling元素的梯度信息</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> ph = phstart; ph &lt; phend; ++ph) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> pw = pwstart; pw &lt; pwend; ++pw) &#123;</span><br><span class="line">          <span class="keyword">if</span> (offset_argmax_data[ph * pooled_width + pw] == (h * width + w)) &#123;</span><br><span class="line">            gradient += offset_top_diff[ph * pooled_width + pw];</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 存储当前输入feature map上元素的反向传播梯度信息</span></span><br><span class="line">    bottom_diff[index] = gradient;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Backward_gpu(</span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,		<span class="comment">// roi pooling输出feature map</span></span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,	<span class="comment">// 是否做反向传播，回忆前向传播时的那个bool值</span></span><br><span class="line">	  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;	<span class="comment">// roi pooling输入feature map(VGG16中的conv5_3产生的feature map)</span></span><br><span class="line">  <span class="keyword">if</span> (!propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();		<span class="comment">// 原始RoI信息</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* top_diff = top[<span class="number">0</span>]-&gt;gpu_diff();			<span class="comment">// roi pooling feature map梯度信息</span></span><br><span class="line">  Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();	<span class="comment">// 待写入的输入feature map梯度信息</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();					<span class="comment">// 输入feature map元素总数</span></span><br><span class="line">  caffe_gpu_set(count, Dtype(<span class="number">0.</span>), bottom_diff);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span>* argmax_data = max_idx_.gpu_data();</span><br><span class="line">  <span class="comment">// NOLINT_NEXT_LINE(whitespace/operators)</span></span><br><span class="line">  ROIPoolBackward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">      count, top_diff, argmax_data, top[<span class="number">0</span>]-&gt;num(), spatial_scale_, channels_,</span><br><span class="line">      height_, width_, pooled_height_, pooled_width_, bottom_diff, bottom_rois);</span><br><span class="line">  CUDA_POST_KERNEL_CHECK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_LAYER_GPU_FUNCS(ROIPoolingLayer);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>实现代码参考，GPU版本：<a href="https://github.com/rbgirshick/caffe-fast-rcnn/blob/bcd9b4eadc7d8fbc433aeefd564e82ec63aaf69c/src/caffe/layers/roi_pooling_layer.cu">roi_pooling_layer.cu</a>和CPU版本：<a href="https://github.com/rbgirshick/caffe-fast-rcnn/blob/bcd9b4eadc7d8fbc433aeefd564e82ec63aaf69c/src/caffe/layers/roi_pooling_layer.cpp">roi_pooling_layer.cpp</a>。</p>
<p>conv5_3及roi相关层配置： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_2&quot;</span></span><br><span class="line">  top: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">512</span></span><br><span class="line">    pad: <span class="number">1</span></span><br><span class="line">    kernel_size: <span class="number">3</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;relu5_3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  top: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;roi_pool5&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ROIPooling&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rois&quot;</span></span><br><span class="line">  top: <span class="string">&quot;pool5&quot;</span></span><br><span class="line">  roi_pooling_param &#123;</span><br><span class="line">    pooled_w: <span class="number">7</span></span><br><span class="line">    pooled_h: <span class="number">7</span></span><br><span class="line">    spatial_scale: <span class="number">0.0625</span> <span class="comment"># 1/16</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>一些直观解释
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivq6gre1al81aqq1cgcflq78m.png" width="800"/>
</center></li>
</ul>
<h2 id="faster-r-cnn">8.6 Faster R-CNN</h2>
<p>《<a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>》提出了Region Proposal Network(RPN)，解决了基于Region的检测算法需要事先通过Selective Search生成候选框的问题，让候选框生成、分类、bounding box回归公用同一套特征提取网络，从而使这类检测算法真正意义上实现End to End。</p>
<h3 id="算法概述-1">8.6.1 算法概述</h3>
如上所述，Faster R-CNN设计了RPN使得候选框生成可以共用特征提取网络，算法流程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bj1mie6rheb17fo2hh1sk3js59.png" width="800" />
</center>
<p>RPN负责生成Proposal候选框，其他过程类似Fast R-CNN，同样，生成候选框的扫描过程发生在最后一个卷积层产生的feature map上（而不是扫描原图），通过之前讲的坐标换算关系可以将feature map任意一点映射回原图。</p>
<h3 id="rpn">8.6.2 RPN</h3>
RPN的结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjht1v6fjkca6cpa49jh11j926.png" width="450"/>
</center>
<p>1、RPN的输入是特征提取器最后一个卷积(pooling)产生的feature map，例如VGG16为conv5_3产生的512维（channel数）的feature map（图中例子是256维）；</p>
<p>2、之后以m×m大小的滑动窗口扫描feature map，如果feature map大小为h×w，则扫描h×w次（即以每个像素点为中心做一次），文中m的取值为3，取值与具体网络结构有关，感受野的不同导致候选框的初始大小不同；</p>
<p>3、每做一次滑动窗口会生成k个初始候选框，初始候选框的大小与anchor（<strong>原理8.6.3解释</strong>）有关，中心点为滑动窗口中心点，即对一次滑动窗口行为，所有利用anchor生成的候选框都有相同的中心点（图中蓝点），一定注意：这里的anchor及利用它生成的候选框都是<strong>相对于原图的位置</strong>；</p>
<p>4、定义两个分支，第一个分支（左边）是一个二分类器，用来区分当前候选框是否为物体，如果有k个由anchor生成的候选框，则输出2<em>k个值（2维向量为:[是物体的概率，是背景的概率]）；第二个分支（右边）为回归器，用来回归候选框的中心点坐标和宽与高（4维向量[x,y,w,h]），如果有k个由anchor生成的候选框，则输出4</em>k个值，显然这里候选框的生成要短、平、快，精调细选由后续网络来做。</p>
<h3 id="anchor">8.6.3 Anchor</h3>
<p>RPN里很重要的一个概念是anchor，可以把它理解为生成候选框的模板，在RPN里只生成一次，anchor是用原图为参照物，以(0,0,指定宽,指定高)四元组采用不同缩放比例和尺度后产生的候选框模板集合，而候选框由滑动窗口(中心点x，中心点y)利用anchor生成。也可以从逆SPP角度去理解，SPP可以把一个feature map通过多尺度变换为金字塔式的多个feature map，反过来任何一个feature map也可利用多尺度变成多个feature map，这么做的好处是压根儿不用在原图上做各种尺度缩放而只用在feature map上做就好，并且这种变换具有不变性(Translation-Invariant Anchor)：候选框生成及其预测函数具有可复现性，例如通过k-means聚类得到800个anchor，如果重复做一次实验不一定还是原来那800个，这个性质可以降低模型大小以及过拟合的风险。</p>
<p>以16×16大小为，base anchor[0,0,15,15]为例：</p>
1、只使用_ratio_enum生成候选框如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjjioarcna9g52sdk98v1ko72j.png" width="800"/>
</center>
2、只使用_scale_enum生成候选框如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjjiq26o181l1m5r1d6r1ktq1td30.png" width="800"/>
</center>
3、混合使用生成候选框如下： 这种模板生成只需要做一次，之后大家以此为基准做中心点漂移即可。(所有其他像素点横纵坐标总是大于0的)
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjhhinlo1b97tjeralm8r1iddv.png" width="800" />
</center>
<p>代码可参考<a href="https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/generate_anchors.py">generate_anchors.py</a>: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Faster R-CNN</span></span><br><span class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Ross Girshick and Sean Bell</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify that we compute the same anchors as Shaoqing&#x27;s matlab implementation:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    &gt;&gt; load output/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat</span></span><br><span class="line"><span class="comment">#    &gt;&gt; anchors</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    anchors =</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#       -83   -39   100    56</span></span><br><span class="line"><span class="comment">#      -175   -87   192   104</span></span><br><span class="line"><span class="comment">#      -359  -183   376   200</span></span><br><span class="line"><span class="comment">#       -55   -55    72    72</span></span><br><span class="line"><span class="comment">#      -119  -119   136   136</span></span><br><span class="line"><span class="comment">#      -247  -247   264   264</span></span><br><span class="line"><span class="comment">#       -35   -79    52    96</span></span><br><span class="line"><span class="comment">#       -79  -167    96   184</span></span><br><span class="line"><span class="comment">#      -167  -343   184   360</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#array([[ -83.,  -39.,  100.,   56.],</span></span><br><span class="line"><span class="comment">#       [-175.,  -87.,  192.,  104.],</span></span><br><span class="line"><span class="comment">#       [-359., -183.,  376.,  200.],</span></span><br><span class="line"><span class="comment">#       [ -55.,  -55.,   72.,   72.],</span></span><br><span class="line"><span class="comment">#       [-119., -119.,  136.,  136.],</span></span><br><span class="line"><span class="comment">#       [-247., -247.,  264.,  264.],</span></span><br><span class="line"><span class="comment">#       [ -35.,  -79.,   52.,   96.],</span></span><br><span class="line"><span class="comment">#       [ -79., -167.,   96.,  184.],</span></span><br><span class="line"><span class="comment">#       [-167., -343.,  184.,  360.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成多尺度anchors，默认实现是大小为16，起始anchor位置是(0, 0, 15, 15)[左下角和右上角坐标]，宽高比例为1/2,1,2，尺度缩放倍数为8,16,32。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_anchors</span>(<span class="params">base_size=<span class="number">16</span>, ratios=[<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">                     scales=<span class="number">2</span>**np.arange(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>)</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate anchor (reference) windows by enumerating aspect ratios X</span></span><br><span class="line"><span class="string">    scales wrt a reference (0, 0, 15, 15) window.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 生成起始anchor位置是(0, 0, 15, 15)</span></span><br><span class="line">    base_anchor = np.array([<span class="number">1</span>, <span class="number">1</span>, base_size, base_size]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 枚举1/2,1,2三种宽高缩放比例</span></span><br><span class="line">    ratio_anchors = _ratio_enum(base_anchor, ratios)</span><br><span class="line">    <span class="comment"># 在以上比例的基础上做8,16,32三类尺度缩放，最终生成9个anchor。</span></span><br><span class="line">    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales)</span><br><span class="line">                         <span class="keyword">for</span> i <span class="keyword">in</span> xrange(ratio_anchors.shape[<span class="number">0</span>])])</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"><span class="comment"># 对给定anchor返回宽、高和中心点坐标（anchor存储的是左下角和右上角）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_whctrs</span>(<span class="params">anchor</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return width, height, x center, and y center for an anchor (window).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w = anchor[<span class="number">2</span>] - anchor[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">    h = anchor[<span class="number">3</span>] - anchor[<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    x_ctr = anchor[<span class="number">0</span>] + <span class="number">0.5</span> * (w - <span class="number">1</span>)</span><br><span class="line">    y_ctr = anchor[<span class="number">1</span>] + <span class="number">0.5</span> * (h - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> w, h, x_ctr, y_ctr</span><br><span class="line"><span class="comment"># 给定宽、高和中心点，输出anchor的左下角和右上角坐标</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_mkanchors</span>(<span class="params">ws, hs, x_ctr, y_ctr</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Given a vector of widths (ws) and heights (hs) around a center</span></span><br><span class="line"><span class="string">    (x_ctr, y_ctr), output a set of anchors (windows).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    ws = ws[:, np.newaxis]</span><br><span class="line">    hs = hs[:, np.newaxis]</span><br><span class="line">    anchors = np.hstack((x_ctr - <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr - <span class="number">0.5</span> * (hs - <span class="number">1</span>),</span><br><span class="line">                         x_ctr + <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr + <span class="number">0.5</span> * (hs - <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"></span><br><span class="line"><span class="comment"># 枚举anchor的三种宽高比 1:2,1:1,2:1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_ratio_enum</span>(<span class="params">anchor, ratios</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each aspect ratio wrt an anchor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    size = w * h</span><br><span class="line">    size_ratios = size / ratios</span><br><span class="line">    ws = np.<span class="built_in">round</span>(np.sqrt(size_ratios))</span><br><span class="line">    hs = np.<span class="built_in">round</span>(ws * ratios)</span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"></span><br><span class="line"><span class="comment"># 枚举anchor的各种尺度，如：anchor为[0 0 15 15],尺度为[8 16 32]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scale_enum</span>(<span class="params">anchor, scales</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each scale wrt an anchor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    ws = w * scales</span><br><span class="line">    hs = h * scales</span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    t = time.time()</span><br><span class="line">    a = generate_anchors()</span><br><span class="line">    <span class="built_in">print</span> time.time() - t</span><br><span class="line">    <span class="built_in">print</span> a</span><br><span class="line">    <span class="keyword">from</span> IPython <span class="keyword">import</span> embed; embed()</span><br></pre></td></tr></table></figure></p>
<h3 id="代码实践-5">8.6.4 代码实践</h3>
<p>集中介绍RPN中proposal层的实现，以特征提取网络采用VGG16在poscal_voc数据集上为例。</p>
<ul>
<li>网络结构
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/VGG16-fasterrcnn.png" width="800"/>
</center></li>
<li><p>RPN配置 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_conv/3x3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">512</span></span><br><span class="line">    kernel_size: <span class="number">3</span> pad: <span class="number">1</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_relu/3x3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">18</span>   <span class="comment"># 2(bg/fg) * 9(anchors)</span></span><br><span class="line">    kernel_size: <span class="number">1</span> pad: <span class="number">0</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">36</span>   <span class="comment"># 4 * 9(anchors)</span></span><br><span class="line">    kernel_size: <span class="number">1</span> pad: <span class="number">0</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">   bottom: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">   top: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">   name: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">   <span class="built_in">type</span>: <span class="string">&quot;Reshape&quot;</span></span><br><span class="line">   reshape_param &#123; shape &#123; dim: <span class="number">0</span> dim: <span class="number">2</span> dim: -<span class="number">1</span> dim: <span class="number">0</span> &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&#x27;rpn-data&#x27;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&#x27;Python&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_cls_score&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;gt_boxes&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;im_info&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;data&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_labels&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_targets&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_inside_weights&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_outside_weights&#x27;</span></span><br><span class="line">  python_param &#123;</span><br><span class="line">    module: <span class="string">&#x27;rpn.anchor_target_layer&#x27;</span></span><br><span class="line">    layer: <span class="string">&#x27;AnchorTargetLayer&#x27;</span></span><br><span class="line">    param_str: <span class="string">&quot;&#x27;feat_stride&#x27;: 16&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_loss_cls&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;SoftmaxWithLoss&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_labels&quot;</span></span><br><span class="line">  propagate_down: <span class="number">1</span></span><br><span class="line">  propagate_down: <span class="number">0</span></span><br><span class="line">  top: <span class="string">&quot;rpn_cls_loss&quot;</span></span><br><span class="line">  loss_weight: <span class="number">1</span></span><br><span class="line">  loss_param &#123;</span><br><span class="line">    ignore_label: -<span class="number">1</span></span><br><span class="line">    normalize: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_loss_bbox&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;SmoothL1Loss&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_bbox_targets&quot;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_bbox_inside_weights&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_bbox_outside_weights&#x27;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_loss_bbox&quot;</span></span><br><span class="line">  loss_weight: <span class="number">1</span></span><br><span class="line">  smooth_l1_loss_param &#123; sigma: <span class="number">3.0</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>准备阶段 配置参数和生成anchor模板： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup</span>(<span class="params">self, bottom, top</span>):</span></span><br><span class="line">        <span class="comment"># parse the layer parameter string, which must be valid YAML</span></span><br><span class="line">        layer_params = yaml.load(self.param_str_)</span><br><span class="line">        <span class="comment"># 获取所有特征提取层stride的乘积。（例如VGG为16）</span></span><br><span class="line">        self._feat_stride = layer_params[<span class="string">&#x27;feat_stride&#x27;</span>]</span><br><span class="line">        <span class="comment"># 设置初始尺度变换比例为8、16、32。</span></span><br><span class="line">        anchor_scales = layer_params.get(<span class="string">&#x27;scales&#x27;</span>, (<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>))</span><br><span class="line">        <span class="comment"># 使用上面介绍的方法生成anchor模板。</span></span><br><span class="line">        self._anchors = generate_anchors(scales=np.array(anchor_scales))</span><br><span class="line">        <span class="comment"># anchor数量。（例如：9）</span></span><br><span class="line">        self._num_anchors = self._anchors.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> DEBUG:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;feat_stride: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self._feat_stride)</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;anchors:&#x27;</span></span><br><span class="line">            <span class="built_in">print</span> self._anchors</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rois blob: holds R regions of interest, each is a 5-tuple</span></span><br><span class="line">        <span class="comment"># (n, x1, y1, x2, y2) specifying an image batch index n and a</span></span><br><span class="line">        <span class="comment"># rectangle (x1, y1, x2, y2)</span></span><br><span class="line">        top[<span class="number">0</span>].reshape(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scores blob: holds scores for R regions of interest</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(top) &gt; <span class="number">1</span>:</span><br><span class="line">            top[<span class="number">1</span>].reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li>
<li>前向传播
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjk8ruf11p2rkalrqph4u1jk53p.png" width="300" />
</center></li>
</ul>
以i为中心利用anchor模板生成anchor过程如下(蓝色为模板，用红色为i中心点生成)：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjhi2u9n1aahsa712s5s2gi621c.png" width="800"  />
</center>
<p>实现上就是中心点i的各个坐标直接加到anchor模板的各个坐标即可（anchor模板是以0为中心点的），代码类似： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = self._num_anchors</span><br><span class="line">K = shifts.shape[<span class="number">0</span>]</span><br><span class="line">anchors = self._anchors.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">          shifts.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">anchors = anchors.reshape((K * A, <span class="number">4</span>))</span><br></pre></td></tr></table></figure></p>
<h3 id="faster-r-cnn训练流程">8.6.5 Faster R-CNN训练流程</h3>
<p>采用四阶段交替方式训练(4-Step Alternating Training)</p>
<p>1、使用ImageNet预训练模型权重初始化并fine-tuned训练一个RPN；</p>
<p>2、使用ImageNet预训练模型权重初始化并将上一步产生的候选框(proposal)作为输入训练独立的Faster R-CNN检测模型（此时没有卷积网络共享）；</p>
<p>3、生成新的RPN并使用上一步Fast-RCNN模型参数初始化，设置RPN、Fast-RCNN共享的那部分网络权重不做更新，只fine-tuned训练RPN独有的网络层，达到两者共享用于提取特征的卷积层的目的；</p>
<p>4、固定共享的那些卷积层权重，只训练Fast-RCNN独有的网络层。</p>
<p>Faster R-CNN是效果最好的目标检测与分类模型之一，但如果想用于实时监测和前置到客户端则需要做大量模型裁剪、压缩和优化工作，具体做法我以后介绍，目前我们做的比较初步，模型大小压缩到10m左右，准确率损失小于1.5%，线上inference响应时间在500k左右大小图片、k80单机单卡单次请求下为20ms左右（在高并发情况下会通过打batch的方式及其他方法提高并发量）。</p>
<strong>未做优化</strong>的汽车检测demo：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjmrl00f1l1f8pnpg2qkbb1o9.png" width="600" height="400" />
</center>
<div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"loop":"yes","screenshot":"yes","video":{"url":"https://vivounicorn.github.io/images/ai_chapter_8/output.mp4"},"danmaku":{"api":"https://api.prprpr.me/dplayer/"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>
<h3 id="faster-r-cnn-with-caffe">8.6.6 Faster R-CNN with Caffe</h3>
源码地址：<a href="https://github.com/rbgirshick/py-faster-rcnn">Faster R-CNN</a>（rbgirshick版）。 一定注意，caffe有个问题（我认为是架构上的设计缺陷，这个问题tensorflow就没有）：由于要支持自定义的网络层之类的需求，每个人的caffe版本可能是不一样的，所以在编译时需要注意，比如这里的caffe必须使用0dcd397这个branch，否则编译不通过，因为这里有自定义的proposal层以及相关参数。 目录结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjka01lv1t6k184g1pt81r69ek746.png" width="600" height="400" />
</center>
<hr />
<p><strong>Centos 7上编译运行caffe及Faster R-CNN</strong></p>
<ul>
<li><p>编译准备 1、 为你的账号添加sudo权限 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gpasswd -a user_name wheel</span><br></pre></td></tr></table></figure> 2、安装编译器 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install gcc gcc-c++</span><br></pre></td></tr></table></figure> 3、安装 git <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install git</span><br></pre></td></tr></table></figure> 4、clone代码 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/rbgirshick/py-faster-rcnn.git</span><br></pre></td></tr></table></figure> 5、安装依赖项 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install snappy-devel opencv-devel atlas-devel boost-devel protobuf-devel</span><br></pre></td></tr></table></figure> 6、安装cmake <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install cmake</span><br></pre></td></tr></table></figure> 7、安装automake <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> wget http://ftp.gnu.org/gnu/automake/automake-1.14.tar.gz</span><br><span class="line">tar -xvf automake-1.14.tar.gz</span><br><span class="line">cd automake-1.14</span><br><span class="line">./configure</span><br><span class="line">make -j</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure> 8、安装gflags <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/gflags/gflags</span><br><span class="line"></span><br><span class="line">cd gflags</span><br><span class="line"></span><br><span class="line">mkdir build &amp;&amp; cd build</span><br><span class="line"></span><br><span class="line">export CXXFLAGS=&quot;-fPIC&quot; &amp;&amp; cmake ..</span><br><span class="line"></span><br><span class="line">make VERBOSE=1 -j</span><br><span class="line"></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure> 9、安装glog <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/google/glog</span><br><span class="line"></span><br><span class="line">cd glog</span><br><span class="line"></span><br><span class="line">./autogen.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure> 10、安装 lmdb <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/LMDB/lmdb</span><br><span class="line"></span><br><span class="line">cd lmdb/libraries/liblmdb</span><br><span class="line"></span><br><span class="line">make -j</span><br><span class="line"></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure> 11、安装 hdf5 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://support.hdfgroup.org/ftp/HDF5/current18/src/hdf5-1.8.19.tar.gz</span><br><span class="line"></span><br><span class="line"> tar -xvf hdf5-1.8.19.tar.gz</span><br><span class="line"></span><br><span class="line">cd hdf5-1.8.19</span><br><span class="line"></span><br><span class="line">./configure --prefix=/usr/local</span><br><span class="line"></span><br><span class="line">make -j</span><br><span class="line"></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure></p>
12、安装 leveldb <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/google/leveldb</span><br><span class="line"></span><br><span class="line">cd leveldb</span><br><span class="line"></span><br><span class="line">make -j</span><br><span class="line"></span><br><span class="line">sudo cp out-shared/libleveldb.so* /usr/local/lib</span><br><span class="line"></span><br><span class="line">sudo cp out-static/*.a /usr/local/lib</span><br><span class="line"></span><br><span class="line">sudo cp -r include/* /usr/local/include</span><br></pre></td></tr></table></figure></li>
<li><p>编译caffe</p>
<p>1、下载源码 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd py-faster-rcnn</span><br><span class="line">git clone  https://github.com/rbgirshick/caffe-fast-rcnn.git</span><br></pre></td></tr></table></figure></p>
<p>检查文件/src/caffe/proto/caffe.proto是否与下面文件一致： <a href="https://vivounicorn.github.io/images/ai_chapter_8/caffe.proto">点击下载 caffe.proto 文件</a></p>
<p>2、修改配置 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd caffe-fast-rcnn</span><br><span class="line"></span><br><span class="line">cp Makefile.config.example Makefile.config</span><br><span class="line"></span><br><span class="line">vim Makefile.config</span><br></pre></td></tr></table></figure> 修改它的几个地方：</p>
<pre><code>  1)、指定CUDA_DIR，如：CUDA_DIR := /usr/local/cuda

  2)、BLAS := open

  3)、WITH_PYTHON_LAYER := 1</code></pre>
3、编译caffe-fast-rcnn <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">make clean</span><br><span class="line"></span><br><span class="line">make all -j</span><br><span class="line"></span><br><span class="line">make test -j</span><br><span class="line"></span><br><span class="line">make runtest -j</span><br><span class="line"></span><br><span class="line">make pycaffe -j</span><br></pre></td></tr></table></figure> 4、编译py-faster-rcnn的lib <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd py-faster-rcnn/lib/</span><br><span class="line"></span><br><span class="line">make</span><br></pre></td></tr></table></figure> 5、配置环境变量 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line"></span><br><span class="line">export PYTHONPATH=/data/liyiran/py-R-FCN/tools/python:$PYTHONPATH</span><br><span class="line"></span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></li>
<li><p>运行示例</p>
<p>1、下载pascal_voc数据集 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd py-faster-rcnn/data</span><br><span class="line"></span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar</span><br><span class="line"></span><br><span class="line">tar -xvf VOCtrainval_06-Nov-2007.tar</span><br><span class="line"></span><br><span class="line">mv VOCtrainval_06-Nov-2007 VOCdevkit2007</span><br></pre></td></tr></table></figure> 2、下载预训练模型 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd py-faster-rcnn/model</span><br><span class="line"></span><br><span class="line">wget https://dl.dropboxusercontent.com/s/gstw7122padlf0l/imagenet_models.tgz?dl=0</span><br></pre></td></tr></table></figure></p>
<p>3、使用VGG16，应用于pascal_voc 2007数据集 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sh experiments/scripts/faster_rcnn_end2end.sh 1 VGG16 pascal_voc</span><br></pre></td></tr></table></figure></p></li>
</ul>
<h2 id="r-fcn">8.7 R-FCN</h2>
<p>回想之前所有基于Region的检测算法，有一个共同点是：整个网络被分成两部分：共享计算的、与Region无关的全卷积子网络和RoI Pooling之后不共享计算的、与Region相关的子网络(如RPN和BBox Regression网络)。再回想之前所有的分类网络，尤其到残差和GoogLeNet系列，都可以看做是全卷积网络，且在分类问题上的效果已经非常赞了，但当把这些网络直接用于检测问题时，效果往往特别差，甚至不如VGG-16，原因也是明确的：分类问题往往会忽略位置信息，只需要判断是否为某个物体，所以要求提取出来的特征具有平移不变性，不管图片特征放大、缩小还是位移都能很好的适应，而卷积操作、pooling操作都能较好的保持这个性质，并且网络越深模型越对位置不敏感；但在检测问题中，提取的特征还需要能敏锐的捕捉到位置信息，即具备平移变化性，这就尴尬了。为此，大家插入类似RoI Pooling这样的层结构，一方面是的任意大小图片都可以输入，更重要的是一定程度上弥补了位置信息的缺失，所以检测效果也就嗖嗖的上来了。但带来一个副作用是：RoI后每个Region都需要跑一遍后续子网络，计算不共享就导致训练和Inference的速度慢，为此代季峰、何凯明几位提出《<a href="https://arxiv.org/pdf/1605.06409.pdf">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a>》检测框架，用Position-Sensitive RoI Pooling代替原来的RoI Pooling，共享了所有计算，很好的tradeoff了平移不变性和平移变化性，并且由于是全卷积，训练和Inference的速度更快。</p>
以ResNet-101为例，图片<a href="https://www.robots.ox.ac.uk/~vgg/rg/slides/vgg_rg_16_feb_2017_rfcn.pdf">来源</a>：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bord2chg3k91e1918ga1lb4dcb9.png" width="500"/>
</center>
<h3 id="算法概述-2">8.7.1 算法概述</h3>
<p>1、核心思想</p>
如上所述，算法核心就是position-sentitive RoI pooling的加入，核心思想是这样的：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bordnnep1lfsh8h13hdu2lo0h1m.png" width="600"/>
</center>
<p>这里的feature map是过去RoI Pooling前的全卷积特征提取子网络，之后接着的（彩色立方体）是position-sensitive feature map，它其实是一个<strong>普通的卷积层</strong>，权重通过position-sensitive RoI Pooling层反向传播时修正。假设position-sensitive feature map（后面简写为ps feature map）的大小为k×k，检测分类数为C+1（1为背景类），则ps feature map的通道数为：k×k×(C+1)，假如K=3，则每一类的 ps feature map会有k×k=9个，每个feature map含有一类位置特征（如：左上、左中、左右、......，下右，图中用不同颜色代表）；接着，通过ps RoI Pooling后，每个RoI Region在C+1的每一类上都会得到一个k×k网格，对每个网格做分类判断，之后所有网格一起投票。最终得到C+1维向量，然后接个softmax做分类。</p>
<p>2、整体结构</p>
考虑RPN子网络，整体结构是这样的：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borduslh1ghka2p1odb2o1fk323.png" width="600" />
</center>
<p>对RPN来说也是类似，每个Bounding Box候选框的位置为一类（左上角坐标、长和宽），ps feature map的通道数为k×k×4。</p>
<p>3、position-sensitive feature map</p>
<p>以ResNet-101作为基础网络结构为例，做以下结构上的更改：</p>
<ul>
<li>去掉GAP层和所有fc层</li>
<li>保留前100层，最后一个卷积层后接一个(1×1)×1024卷积层做降维</li>
</ul>
<p>为了显示编码位置信息，假如ps feature map网格大小k×k，RoI大小为：<span class="math inline">\(w×h\)</span>，则每个bin大小约为：<span class="math inline">\(\frac{w}{k} ×\frac{h}{k}\)</span>，对于第(i,j)个bin（<span class="math inline">\(0\leq i,j\leq k-1\)</span>）做ps RoI Pooling为：</p>
<p><span class="math display">\[
r_c(i,j|\Theta)=\sum_{(x,y)\in bin(i,j)}z_{i,j,c}(x+x_0,y+y_0|\Theta)/n.
\]</span></p>
<p>其中：</p>
<p><span class="math inline">\(r_c(i,j)\)</span>为第c类在第(i,j)个bin的pooling响应值；</p>
<p><span class="math inline">\(z_{i,j,c}\)</span>为是k×k×(C+1)个feature map中的一个；</p>
<p><span class="math inline">\((x_0,y_0)\)</span>为RoI的左上角坐标；</p>
<p><span class="math inline">\(n\)</span>是当前bin中的像素数；</p>
<p><span class="math inline">\(\Theta\)</span>是网络所有可学习参数；</p>
<p>x、y的取值范围为：<span class="math inline">\(\lfloor i\frac{w}{k}\rfloor \leq x \leq \lceil(i+1)\frac{w}{k}\rceil\)</span>，<span class="math inline">\(\lfloor j\frac{h}{k}\rfloor \leq y \leq \lceil(j+1)\frac{h}{k}\rceil\)</span>；</p>
<p>pooling采用average、max甚至其他自定义的操作。</p>
<p>4、损失函数定义</p>
<p>由分类部分和回归部分损失组成：</p>
<p><span class="math display">\[
L(s,t_{x,y,w,h})=L_{cls}(s_{c^*})+\lambda [c^*&gt;0]L_{reg}(t,t^*)
\]</span> 其中：</p>
<p><span class="math inline">\(c^*\)</span>是每一类的label，<span class="math inline">\(c^*=0\)</span>代表背景类；</p>
<p><span class="math inline">\(L_{cls}(s_{c^*})=-log(s_{c^*})=-log(\frac{e^{r_{c^*}(\Theta)}}{\sum_{c=0}^{C}e^{r_{c(\Theta)}}})\)</span>，是交叉熵损失函数；</p>
<p><span class="math inline">\(L_{reg}(t,t^*)=\sum_{i \in \{x,y,w,h\}}smooth_{L_1}(t-t^*)\)</span>，与Fast R-CNN的定义一致；</p>
<p><span class="math inline">\([c^*&gt;0] = \begin{cases}1&amp; \text{if }c^*&gt;0\\0&amp; \text{otherwise}\end{cases}\)</span></p>
<p>5、可视化效果</p>
预测正例：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borjgjtc16vu1od1qk619t61k8f30.png" width="600"/>
</center>
预测负例：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borjid0t1m1qeeaj281ja31o1j3d.png" width="600" />
</center>
<h3 id="position-sentitive-roi-pooling">8.7.2 position-sentitive RoI pooling</h3>
<ul>
<li>原图及检测图</li>
</ul>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnq3ig3p88edhnnlq17ml1ng2v.png" width="600"/>
</center>
<ul>
<li>所有分类下的位置敏感特征图
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnq32c2323o12giggg1q6ri5k9.png" width="600" />
</center></li>
</ul>
<h3 id="模型训练">8.7.3 模型训练</h3>
<p>1、训练使用<a href="https://arxiv.org/pdf/1604.03540.pdf">Online Hard Example Mining</a></p>
<p>OHEM是一种boosting策略，目的是使得训练更加高效，简单说，它不是使用简单的抽样策略，而是对容易判断的样本做抑制，对模型不容易判断的样本重复添加。 在检测中，正样本定义为：与ground-truth的<span class="math inline">\(IoU\geq0.5\)</span>，反之为负样本，应用过程为：</p>
<ul>
<li>前向传播：所有候选框在Inference后做损失排序，选取B(一共N个)个损失最高的候选框，当然，由于临近位置的候选框的损失相近，所以还需要对其做NMS(如取IoU=0.7)，然后再选出这B个样本；</li>
<li>反向传播：仅用这B个样本做反向传播更新权重。</li>
</ul>
<p>2、训练参数</p>
<ul>
<li>权重衰减系数：0.0005</li>
<li>动量项取值：0.9</li>
<li>图像被缩放为600像素</li>
<li>每个GPU使用一张图像，选择B=128个候选框做反向传播</li>
<li>利用VOC数据做fine-tune</li>
<li>采用 Faster R-CNN的四步交替法训练</li>
</ul>
<h3 id="代码实践-6">8.7.4 代码实践</h3>
源码可在<a href="https://github.com/YuwenXiong/py-R-FCN">py-R-FCN</a>下载，需要把下载<a href="https://github.com/daijifeng001/caffe-rfcn">R-FCN版本caffe</a>，编译方式类似Faster RCNN，目录类似：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnmv6i6n181gsds1ea7r1q13v49.png" width="600"/>
</center>
<ul>
<li>PSROIPooling</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// ------------------------------------------------------------------</span><br><span class="line">// R-FCN</span><br><span class="line">// Copyright (c) <span class="number">2016</span> Microsoft</span><br><span class="line">// Licensed under The MIT License [see r-fcn/LICENSE <span class="keyword">for</span> details]</span><br><span class="line">// Written by Yi Li</span><br><span class="line">// ------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment">#include &lt;cfloat&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &quot;caffe/rfcn_layers.hpp&quot;</span></span><br><span class="line"><span class="comment">#include &quot;caffe/util/gpu_util.cuh&quot;</span></span><br><span class="line"></span><br><span class="line">using std::<span class="built_in">max</span>;</span><br><span class="line">using std::<span class="built_in">min</span>;</span><br><span class="line"></span><br><span class="line">namespace caffe &#123;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  __global__ void PSROIPoolingForward(</span><br><span class="line">    const <span class="built_in">int</span> nthreads,			// 任务数，对应通过roi pooling后的输出feature <span class="built_in">map</span>的神经元节点总数，RoI的个数(m) × channel个数(<span class="number">21</span>类) × psroi pooling输出宽(配置为<span class="number">7</span>) × psroi pooling输出高(配置为<span class="number">7</span>) = <span class="number">1029</span>×m个</span><br><span class="line">    const Dtype* bottom_data,	// 输入的feature <span class="built_in">map</span>，原图经过各种卷积、pooling等前向传播后得到（ResNet50的rfcn_cls卷积产生的position sensitive feature <span class="built_in">map</span>，大小为：<span class="number">1029</span>×<span class="number">14</span>×<span class="number">14</span>）</span><br><span class="line">    const Dtype spatial_scale,	// 由之前所有卷积层的strides相乘得到，在rfcn中为<span class="number">1</span>/<span class="number">16</span>，注：从原图往rfcn_cls的feature <span class="built_in">map</span>上映射为缩小过程，所以乘以<span class="number">1</span>/<span class="number">16</span>，反之需要乘以<span class="number">16</span></span><br><span class="line">    const <span class="built_in">int</span> channels,			// 输入层（ResNet50为卷积层rfcn_cls）feature <span class="built_in">map</span>的channel个数(k×k×(C+<span class="number">1</span>)=<span class="number">7</span>×<span class="number">7</span>×<span class="number">21</span>=<span class="number">1029</span>)</span><br><span class="line">    const <span class="built_in">int</span> height,			// feature <span class="built_in">map</span>的宽度(<span class="number">14</span>)</span><br><span class="line">	const <span class="built_in">int</span> width,			// feature <span class="built_in">map</span>的高度(<span class="number">14</span>)</span><br><span class="line">    const <span class="built_in">int</span> pooled_height,	// psroi pooling输出feature <span class="built_in">map</span>的高，fast rcnn中配置为h=<span class="number">7</span></span><br><span class="line">	const <span class="built_in">int</span> pooled_width,		// psroi pooling输出feature <span class="built_in">map</span>的宽，fast rcnn中配置为w=<span class="number">7</span></span><br><span class="line">    const Dtype* bottom_rois,	// 输入的roi信息，存储所有rois或一个batch的rois，数据结构为[batch_ind,x1,y1,x2,y2]，包含roi的：索引、左上角坐标及右下角坐标</span><br><span class="line">    const <span class="built_in">int</span> output_dim,		// 输出feature <span class="built_in">map</span>的维度，psroipooled_cls_rois为<span class="number">21</span>（<span class="number">21</span>个类别），psroipooled_loc_rois为<span class="number">8</span></span><br><span class="line">    const <span class="built_in">int</span> group_size,		// k=<span class="number">7</span></span><br><span class="line">    Dtype* top_data,			// 存储psroi pooling后得到的feature <span class="built_in">map</span></span><br><span class="line">    <span class="built_in">int</span>* mapping_channel) &#123;</span><br><span class="line">								// index为线程索引，个数为psroi pooling后的feature <span class="built_in">map</span>上所有值的个数，索引范围为：[<span class="number">0</span>,nthreads-<span class="number">1</span>]</span><br><span class="line">    CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">      // 该线程对应的top blob（N,C,H,W）中的W,输出roi pooling后feature <span class="built_in">map</span>的中的宽的坐标，即feature <span class="built_in">map</span>的第i=[<span class="number">0</span>,k-<span class="number">1</span>]列</span><br><span class="line">      <span class="built_in">int</span> pw = index % pooled_width;</span><br><span class="line">	  // 该线程对应的top blob（N,C,H,W）中的H,输出roi pooling后feature <span class="built_in">map</span>的中的高的坐标，即feature <span class="built_in">map</span>的第j=[<span class="number">0</span>,k-<span class="number">1</span>]行</span><br><span class="line">      <span class="built_in">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">	  // 该线程对应的top blob（N,C,H,W）中的C,即第c个channel，channel数最大值为<span class="number">21</span>（包含背景类的类别数）</span><br><span class="line">      <span class="built_in">int</span> ctop = (index / pooled_width / pooled_height) % output_dim;</span><br><span class="line">	  // 该线程对应的是第几个RoI,一共m个.</span><br><span class="line">      <span class="built_in">int</span> n = index / pooled_width / pooled_height / output_dim;</span><br><span class="line"></span><br><span class="line">      // [start, end)，指定RoI信息的存储范围，指针每次移动<span class="number">5</span>的倍数是因为包含信息的数据结构大小为<span class="number">5</span>，包含信息为：[batch_ind,x1,y1,x2,y2]，含义同上</span><br><span class="line">      bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">	  // 将每个原图的RoI区域映射到feature <span class="built_in">map</span>(VGG16为conv5_3产生的feature mao)上的坐标,bottom_rois第<span class="number">0</span>个位置存放的是roi索引.</span><br><span class="line">      <span class="built_in">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">	  // 原图到feature <span class="built_in">map</span>的映射为乘以<span class="number">1</span>/<span class="number">16</span>，这里采用粗映射而不是上文讲的精确映射，原因你懂的.</span><br><span class="line">      Dtype roi_start_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">1</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_start_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">2</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_end_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">3</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line">      Dtype roi_end_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">4</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line"></span><br><span class="line">      // 强制把RoI的宽和高限制在1x1，防止出现映射后的RoI大小为<span class="number">0</span>的情况</span><br><span class="line">      Dtype roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w, <span class="number">0.1</span>);</span><br><span class="line">      Dtype roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line">      // 根据原图映射得到的roi的高和配置的psroi pooling的高(这里大小配置为<span class="number">7</span>)自适应计算<span class="built_in">bin</span>桶的高度</span><br><span class="line">      Dtype bin_size_h = roi_height / static_cast&lt;Dtype&gt;(pooled_height);</span><br><span class="line">	  // 根据原图映射得到的roi的宽和配置的psroi pooling的宽(这里大小配置为<span class="number">7</span>)自适应计算<span class="built_in">bin</span>桶的宽度</span><br><span class="line">      Dtype bin_size_w = roi_width / static_cast&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	  // 计算第(i,j)个<span class="built_in">bin</span>桶在feature <span class="built_in">map</span>上的坐标范围，需要依据它们确定后续pooling的范围</span><br><span class="line">      <span class="built_in">int</span> hstart = floor(static_cast&lt;Dtype&gt;(ph) * bin_size_h</span><br><span class="line">                          + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wstart = floor(static_cast&lt;Dtype&gt;(pw)* bin_size_w</span><br><span class="line">                          + roi_start_w);</span><br><span class="line">      <span class="built_in">int</span> hend = ceil(static_cast&lt;Dtype&gt;(ph + <span class="number">1</span>) * bin_size_h</span><br><span class="line">                        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wend = ceil(static_cast&lt;Dtype&gt;(pw + <span class="number">1</span>) * bin_size_w</span><br><span class="line">                        + roi_start_w);</span><br><span class="line">      // 确定<span class="built_in">max</span> pooling具体范围，注意由于RoI取自原图，其左上角不是从(<span class="number">0</span>,<span class="number">0</span>)开始，</span><br><span class="line">	  // 所以需要加上 roi_start_h 或 roi_start_w作为偏移量，并且超出feature <span class="built_in">map</span>尺寸范围的部分会被舍弃</span><br><span class="line">      hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart, <span class="number">0</span>), height);</span><br><span class="line">      hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend, <span class="number">0</span>), height);</span><br><span class="line">      wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart, <span class="number">0</span>),width);</span><br><span class="line">      wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend, <span class="number">0</span>), width);</span><br><span class="line">      <span class="built_in">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line"></span><br><span class="line">      <span class="built_in">int</span> gw = pw;</span><br><span class="line">      <span class="built_in">int</span> gh = ph;</span><br><span class="line">	  // 计算第C类的(ph,pw)位置索引 = ctop×group_size×group_size + gh×gh×group_size + gw</span><br><span class="line">      // 例如: ps feature <span class="built_in">map</span>上第C[=<span class="number">1</span>]类的第(i,j)[=(<span class="number">1</span>,<span class="number">1</span>)]位置，c=<span class="number">1</span>×<span class="number">7</span>×<span class="number">7</span> + <span class="number">1</span>×<span class="number">1</span>×<span class="number">7</span>+<span class="number">1</span>=<span class="number">57</span></span><br><span class="line">      <span class="built_in">int</span> c = (ctop*group_size + gh)*group_size + gw;</span><br><span class="line"></span><br><span class="line">	  // 逐层做average pooling</span><br><span class="line">      bottom_data += (roi_batch_ind * channels + c) * height * width;</span><br><span class="line">      Dtype out_sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="built_in">int</span> h = hstart; h &lt; hend; ++h)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> w = wstart; w &lt; wend; ++w)&#123;</span><br><span class="line">          <span class="built_in">int</span> bottom_index = h*width + w;</span><br><span class="line">          out_sum += bottom_data[bottom_index];</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">	  // 计算第(i,j)<span class="built_in">bin</span>桶在feature <span class="built_in">map</span>上的面积</span><br><span class="line">      Dtype bin_area = (hend - hstart)*(wend - wstart);</span><br><span class="line">	  // 若第(i,j)<span class="built_in">bin</span>桶宽高非法则设置为<span class="number">0</span>，否则为平均值</span><br><span class="line">      top_data[index] = is_empty? <span class="number">0.</span> : out_sum/bin_area;</span><br><span class="line">	  // 记录此次迭代计算ps feature <span class="built_in">map</span>上的索引位置</span><br><span class="line">      mapping_channel[index] = c;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  void PSROIPoolingLayer&lt;Dtype&gt;::Forward_gpu(</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,		// 以ResNet50为例，bottom[<span class="number">0</span>]为最后一个卷积层rfcn_cls产生的feature <span class="built_in">map</span>，shape[<span class="number">1</span>, <span class="number">1029</span>, <span class="number">14</span>, <span class="number">14</span>],</span><br><span class="line">	                                            //                 bottom[<span class="number">1</span>]为rois数据，shape[roi个数m, <span class="number">5</span>]</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;		// top为输出层结构， top-&gt;count() = top.n（RoI的个数) × top.channel(channel数)</span><br><span class="line">												//                               × top.w(输出feature <span class="built_in">map</span>的宽) × top.h(输出feature <span class="built_in">map</span>的高)</span><br><span class="line">    const Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">    const Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();</span><br><span class="line">    Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_gpu_data();</span><br><span class="line">    <span class="built_in">int</span>* mapping_channel_ptr = mapping_channel_.mutable_gpu_data();</span><br><span class="line">    <span class="built_in">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">    caffe_gpu_set(count, Dtype(<span class="number">0</span>), top_data);</span><br><span class="line">    caffe_gpu_set(count, -<span class="number">1</span>, mapping_channel_ptr);</span><br><span class="line">    // NOLINT_NEXT_LINE(whitespace/operators)</span><br><span class="line">    PSROIPoolingForward&lt;Dtype&gt; &lt;&lt; &lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS &gt;&gt; &gt;(</span><br><span class="line">      count, bottom_data, spatial_scale_, channels_, height_, width_, pooled_height_,</span><br><span class="line">      pooled_width_, bottom_rois, output_dim_, group_size_, top_data, mapping_channel_ptr);</span><br><span class="line">    CUDA_POST_KERNEL_CHECK;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  __global__ void PSROIPoolingBackwardAtomic(</span><br><span class="line">    const <span class="built_in">int</span> nthreads,						// 输入feature <span class="built_in">map</span>的元素数</span><br><span class="line">    const Dtype* top_diff,					// psroi pooling输出feature <span class="built_in">map</span>所带的梯度信息∂L/∂y(r,j)</span><br><span class="line">    const <span class="built_in">int</span>* mapping_channel,				// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> num_rois,						// 同前向，不解释</span><br><span class="line">    const Dtype spatial_scale,				// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> channels,						// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> height,						// 同前向，不解释</span><br><span class="line">	const <span class="built_in">int</span> width,						// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> pooled_height,				// 同前向，不解释</span><br><span class="line">	const <span class="built_in">int</span> pooled_width,					// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> output_dim,					// 同前向，不解释</span><br><span class="line">    Dtype* bottom_diff,						// 保留输入feature <span class="built_in">map</span>每个元素通过梯度反向传播得到的梯度信息</span><br><span class="line">    const Dtype* bottom_rois) &#123;				// 同前向，不解释</span><br><span class="line">	// 含义同前向，需要注意的是这里表示的是输入feature <span class="built_in">map</span>的元素数(反向传播嘛)</span><br><span class="line">    CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">      // 同前向，不解释</span><br><span class="line">      <span class="built_in">int</span> pw = index % pooled_width;</span><br><span class="line">      <span class="built_in">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">      <span class="built_in">int</span> n = index / pooled_width / pooled_height / output_dim;</span><br><span class="line"></span><br><span class="line">      // 找原图RoI在feature <span class="built_in">map</span>上的映射位置，解释同前向传播</span><br><span class="line">      bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">      <span class="built_in">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">      Dtype roi_start_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">1</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_start_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">2</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_end_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">3</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line">      Dtype roi_end_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">4</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line"></span><br><span class="line">      // 同前向</span><br><span class="line">      Dtype roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w, <span class="number">0.1</span>); //avoid <span class="number">0</span></span><br><span class="line">      Dtype roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line">      // 同前向</span><br><span class="line">      Dtype bin_size_h = roi_height / static_cast&lt;Dtype&gt;(pooled_height);</span><br><span class="line">      Dtype bin_size_w = roi_width / static_cast&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">      <span class="built_in">int</span> hstart = floor(static_cast&lt;Dtype&gt;(ph)* bin_size_h</span><br><span class="line">        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wstart = floor(static_cast&lt;Dtype&gt;(pw)* bin_size_w</span><br><span class="line">        + roi_start_w);</span><br><span class="line">      <span class="built_in">int</span> hend = ceil(static_cast&lt;Dtype&gt;(ph + <span class="number">1</span>) * bin_size_h</span><br><span class="line">        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wend = ceil(static_cast&lt;Dtype&gt;(pw + <span class="number">1</span>) * bin_size_w</span><br><span class="line">        + roi_start_w);</span><br><span class="line">      // 同前向</span><br><span class="line">      hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart, <span class="number">0</span>), height);</span><br><span class="line">      hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend, <span class="number">0</span>), height);</span><br><span class="line">      wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart, <span class="number">0</span>), width);</span><br><span class="line">      wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend, <span class="number">0</span>), width);</span><br><span class="line">      <span class="built_in">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line"></span><br><span class="line">      // 计算第C类ps feature <span class="built_in">map</span>权重值，梯度信息会被平均分配</span><br><span class="line">      <span class="built_in">int</span> c = mapping_channel[index];</span><br><span class="line">      Dtype* offset_bottom_diff = bottom_diff + (roi_batch_ind * channels + c) * height * width;</span><br><span class="line">      Dtype bin_area = (hend - hstart)*(wend - wstart);</span><br><span class="line">      Dtype diff_val = is_empty ? <span class="number">0.</span> : top_diff[index] / bin_area;</span><br><span class="line">      <span class="keyword">for</span> (<span class="built_in">int</span> h = hstart; h &lt; hend; ++h)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> w = wstart; w &lt; wend; ++w)&#123;</span><br><span class="line">          <span class="built_in">int</span> bottom_index = h*width + w;</span><br><span class="line">          caffe_gpu_atomic_add(diff_val, offset_bottom_diff + bottom_index);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  void PSROIPoolingLayer&lt;Dtype&gt;::Backward_gpu(</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,			// psroi pooling输出feature <span class="built_in">map</span></span><br><span class="line">	  const vector&lt;<span class="built_in">bool</span>&gt;&amp; propagate_down,		// 是否做反向传播，回忆前向传播时的那个<span class="built_in">bool</span>值</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;		// psroi pooling输入feature <span class="built_in">map</span>(ResNet中的rfcn_cls产生的feature <span class="built_in">map</span>)</span><br><span class="line">    <span class="keyword">if</span> (!propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    const Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();	// 原始RoI信息</span><br><span class="line">    const Dtype* top_diff = top[<span class="number">0</span>]-&gt;gpu_diff();			// psroi pooling feature <span class="built_in">map</span>梯度信息</span><br><span class="line">    Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();	// 待写入的输入feature <span class="built_in">map</span>梯度信息</span><br><span class="line">    const <span class="built_in">int</span> bottom_count = bottom[<span class="number">0</span>]-&gt;count();		// 输入feature <span class="built_in">map</span>元素总数</span><br><span class="line">    const <span class="built_in">int</span>* mapping_channel_ptr = mapping_channel_.gpu_data();</span><br><span class="line">    caffe_gpu_set(bottom[<span class="number">1</span>]-&gt;count(), Dtype(<span class="number">0</span>), bottom[<span class="number">1</span>]-&gt;mutable_gpu_diff());</span><br><span class="line">    caffe_gpu_set(bottom_count, Dtype(<span class="number">0</span>), bottom_diff);</span><br><span class="line">    const <span class="built_in">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">    // NOLINT_NEXT_LINE(whitespace/operators)</span><br><span class="line">    PSROIPoolingBackwardAtomic&lt;Dtype&gt; &lt;&lt; &lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS &gt;&gt; &gt;(</span><br><span class="line">      count, top_diff, mapping_channel_ptr, top[<span class="number">0</span>]-&gt;num(), spatial_scale_,</span><br><span class="line">      channels_, height_, width_, pooled_height_, pooled_width_, output_dim_,</span><br><span class="line">      bottom_diff, bottom_rois);</span><br><span class="line">    CUDA_POST_KERNEL_CHECK;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  INSTANTIATE_LAYER_GPU_FUNCS(PSROIPoolingLayer);</span><br><span class="line"></span><br><span class="line">&#125;  // namespace caffe</span><br></pre></td></tr></table></figure>
<ul>
<li>PS feature map可视化</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*- 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Demo script showing detections in sample images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">See README.md for installation instructions before running.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;Agg&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> _init_paths</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.config <span class="keyword">import</span> cfg</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.test <span class="keyword">import</span> im_detect</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.nms_wrapper <span class="keyword">import</span> nms</span><br><span class="line"><span class="keyword">from</span> utils.timer <span class="keyword">import</span> Timer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> caffe, os, sys, cv2</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">CLASSES = (<span class="string">&#x27;__background__&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;pottedplant&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tvmonitor&#x27;</span>)</span><br><span class="line"></span><br><span class="line">NETS = &#123;<span class="string">&#x27;ResNet-101&#x27;</span>: (<span class="string">&#x27;ResNet-101&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;resnet101_rfcn_final.caffemodel&#x27;</span>),</span><br><span class="line">        <span class="string">&#x27;ResNet-50&#x27;</span>: (<span class="string">&#x27;ResNet-50&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;resnet50_rfcn_final.caffemodel&#x27;</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parse input arguments.&quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;Faster R-CNN demo&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gpu&#x27;</span>, dest=<span class="string">&#x27;gpu_id&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;GPU device id to use [0]&#x27;</span>,</span><br><span class="line">                        default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cpu&#x27;</span>, dest=<span class="string">&#x27;cpu_mode&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Use CPU mode (overrides --gpu)&#x27;</span>,</span><br><span class="line">                        action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--net&#x27;</span>, dest=<span class="string">&#x27;demo_net&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Network to use [ResNet-101]&#x27;</span>,</span><br><span class="line">                        choices=NETS.keys(), default=<span class="string">&#x27;ResNet-101&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span>(<span class="params">data, i</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Take an array of shape (n, height, width) or (n, height, width, 3)</span></span><br><span class="line"><span class="string">       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># normalize data for display</span></span><br><span class="line">    data = (data - data.<span class="built_in">min</span>()) / (data.<span class="built_in">max</span>() - data.<span class="built_in">min</span>())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># force the number of filters to be square</span></span><br><span class="line">    n = <span class="built_in">int</span>(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</span><br><span class="line">    padding = (((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]),</span><br><span class="line">               (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>))                 <span class="comment"># add some space between filters</span></span><br><span class="line">               + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>))  <span class="comment"># don&#x27;t pad the last dimension (if there is one)</span></span><br><span class="line">    data = np.pad(data, padding, mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">1</span>)  <span class="comment"># pad with ones (white)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># tile the filters into an image</span></span><br><span class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</span><br><span class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</span><br><span class="line"></span><br><span class="line">    plt.imshow(data); plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;feature-&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_demo</span>(<span class="params">net, image_name</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;可视化位置敏感特征图.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the demo image</span></span><br><span class="line">    im_file = os.path.join(cfg.DATA_DIR, <span class="string">&#x27;demo&#x27;</span>, image_name)</span><br><span class="line">    im = cv2.imread(im_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Detect all object classes and regress object bounds</span></span><br><span class="line">    timer = Timer()</span><br><span class="line">    timer.tic()</span><br><span class="line">    scores, boxes = im_detect(net, im)</span><br><span class="line">    timer.toc()</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Detection took &#123;:.3f&#125;s for &#x27;</span></span><br><span class="line">           <span class="string">&#x27;&#123;:d&#125; object proposals&#x27;</span>).<span class="built_in">format</span>(timer.total_time, boxes.shape[<span class="number">0</span>])</span><br><span class="line">    conv = net.blobs[<span class="string">&#x27;data&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">    ave = np.average(conv.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">    plt.imshow(ave); plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;featurex.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Visualize detections for each class</span></span><br><span class="line">    CONF_THRESH = <span class="number">0.8</span></span><br><span class="line">    NMS_THRESH = <span class="number">0.3</span></span><br><span class="line">    <span class="keyword">for</span> cls_ind, cls <span class="keyword">in</span> <span class="built_in">enumerate</span>(CLASSES[<span class="number">1</span>:]):</span><br><span class="line">        cls_ind += <span class="number">1</span> <span class="comment"># because we skipped background</span></span><br><span class="line">        cls_boxes = boxes[:, <span class="number">4</span>:<span class="number">8</span>]</span><br><span class="line">        cls_scores = scores[:, cls_ind]</span><br><span class="line">        dets = np.hstack((cls_boxes,</span><br><span class="line">                          cls_scores[:, np.newaxis])).astype(np.float32)</span><br><span class="line">        keep = nms(dets, NMS_THRESH)</span><br><span class="line">        dets = dets[keep, :]</span><br><span class="line">        <span class="built_in">print</span> cls_ind, <span class="string">&#x27; &#x27;</span>, cls</span><br><span class="line">        <span class="comment"># rfcn_cls[0, 0:49] 是第0类的7×7map，rfcn_cls[0, 49:98] 是第1类的7×7map，以此类推。</span></span><br><span class="line">        feat = net.blobs[<span class="string">&#x27;rfcn_cls&#x27;</span>].data[<span class="number">0</span>, cls_ind*<span class="number">49</span>:(cls_ind+<span class="number">1</span>)*<span class="number">49</span>]</span><br><span class="line">        vis_square(feat, cls)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cfg.TEST.HAS_RPN = <span class="literal">True</span>  <span class="comment"># Use RPN for proposals</span></span><br><span class="line"></span><br><span class="line">    args = parse_args()</span><br><span class="line"></span><br><span class="line">    prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][<span class="number">0</span>],</span><br><span class="line">                            <span class="string">&#x27;rfcn_end2end&#x27;</span>, <span class="string">&#x27;test_agnostic.prototxt&#x27;</span>)</span><br><span class="line">    caffemodel = os.path.join(cfg.DATA_DIR, <span class="string">&#x27;rfcn_models&#x27;</span>,</span><br><span class="line">                              NETS[args.demo_net][<span class="number">33</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(caffemodel):</span><br><span class="line">        <span class="keyword">raise</span> IOError((<span class="string">&#x27;&#123;:s&#125; not found.\n&#x27;</span>).<span class="built_in">format</span>(caffemodel))</span><br><span class="line">    <span class="keyword">if</span> args.cpu_mode:</span><br><span class="line">        caffe.set_mode_cpu()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        caffe.set_mode_gpu()</span><br><span class="line">        caffe.set_device(args.gpu_id)</span><br><span class="line">        cfg.GPU_ID = args.gpu_id</span><br><span class="line">    net = caffe.Net(prototxt, caffemodel, caffe.TEST)</span><br><span class="line">    <span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">        <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(blob.data.shape)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n\nLoaded network &#123;:s&#125;&#x27;</span>.<span class="built_in">format</span>(caffemodel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Warmup on a dummy image</span></span><br><span class="line">    im = <span class="number">128</span> * np.ones((<span class="number">300</span>, <span class="number">500</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>):</span><br><span class="line">        _, _= im_detect(net, im)</span><br><span class="line">    im_names = [<span class="string">&#x27;car.jpg&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> im_name <span class="keyword">in</span> im_names:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#x27;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Demo for data/demo/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(im_name)</span><br><span class="line">        vis_demo(net, im_name)</span><br><span class="line">    <span class="comment"># obtain the output probabilities</span></span><br><span class="line">    output_prob = net.blobs[<span class="string">&#x27;cls_prob&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;probabilities:&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> output_prob</span><br></pre></td></tr></table></figure>
<h2 id="densenet">8.8 DenseNet</h2>
<h3 id="关于神经网络的深度">8.8.1 关于神经网络的深度</h3>
<p>理论上，当我们有足够大量的数据，能够完全体现当前问题的数据分布的时候，我们仅需要一个简单线性模型或最多用个有单隐层的RBF神经网络就可以完美建模。但实际情况是没有那么多数据，那就自然需要一个高复杂度的模型来拟合样本，但如果模型复杂度过高而样本数没有与其达到某种关系，又会造成其泛化性低下，所谓过拟合的问题。实际上，假设未来做testing的数据分布和training的数据分布是一致的，一个有<span class="math inline">\(N\)</span>个神经网络节点、<span class="math inline">\(W\)</span>个权重、线性阈值函数的前馈神经网络在泛化误差<span class="math inline">\(0&lt;\epsilon \le0.125\)</span>的前提下，训练数据规模的下界是：<span class="math inline">\(m\ge O(\frac{W}{\epsilon}log\frac{N}{\epsilon})\)</span>，详情可见论文《<a href="https://papers.nips.cc/paper/154-what-size-net-gives-valid-generalization.pdf">What Size Net Gives Valid Generalization</a>》。</p>
<p>网络的深度则反映了模型的复杂度，深度直接决定了层数而间接影响了节点数和权重数，网络深度的增加意味着能得到更多的抽象特征，但原始输入信号和梯度信息会随着网络深度的增加而消失或无用，所以这又是一个折中权衡，像之前讲的Highway Network、ResNet及其衍生等等模型的思路是通过一个short path的连接让前一层的信号能够传递到后一层，我认为这个思路是开创性的。</p>
<h3 id="densenet思路">8.8.2 DenseNet思路</h3>
《<a href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a>》（CVPR 2017的最佳论文之一）提出的DenseNet则把ResNet的思路做的更加彻底：在一个Dense Block中，任意一个当前层都会与其后面的所有层直接连接，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9b0b69pfu15spn1q1r8e3ug9.png" width="500" />
</center>
<p>假如包括当前层在内后面还有<span class="math inline">\(L\)</span>层，那么从当前层往后产生的直接连接数为：<span class="math inline">\(\frac{L(L+1)}{2}\)</span>。</p>
<p>回顾之前对ResNet的分析以及《<a href="https://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a>》这篇论文的实验，可以得到以下信息：</p>
<p>神经网络不一定非得是逐层递进的，任意一层可以接收它前面任意一层的输入而扔掉它前面的其它层，也就是说当前层feature map的提取可以只依赖更前面层的feature map； 传统前馈神经网络架构可以被看做是有个状态维护机制，在层与层之间传递这个状态，后一层在接收前一层的状态后又加入自己的信息，修改状态后传给下一层； ResNet网络在路径选择的思想下展开（见ResNet一章的分析）后，其实也说明它有一定的冗余性，适当的随机Dropout一些层相当于扔掉了一些路径，实际实验看还会提高网络Inference的泛化性。</p>
<p>基于以上认知，作者设计了DenseNet：让每一层都与后面所有层直接连接，达到特征复用的目的；同时这些连接也可以看做网络的全局状态，大家共同维护，不用传来传去；降低每一层feature map数，让网络结构变“窄”，达到去除冗余的目的。</p>
<p>与ResNet比较：</p>
<ul>
<li><p>ResNet采用按照向量每个维度的Element-wise做加和的方式处理连接，而DenseNet采用按照每个通道的Channel-wise做直接向量拼接的方式处理连接。</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9idtee10si1p1d1gvm1djp1uikm.png" width="800"/>
</center>
<p><strong>PS：注意图中C操作符的位置</strong></p>
<p>DenseNet的前向传播过程可以像这样展开：</p>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9ksjj1pmb1sa6cm92lv1pga52.png" width="800"/>
</center>
<p>每一层的输入都包含所有前面层的feature map。</p>
<p>形式化的对比如下：</p>
<p>ResNet：第<span class="math inline">\(l\)</span>层的输出是<span class="math inline">\(x_l=H_l(x_{l-1})+x_{l-1}\)</span></p>
<p>DenseNet：第<span class="math inline">\(l\)</span>层的输出是<span class="math inline">\(x_l=H_l([x_0,x_1,...,x_{l-1}])\)</span></p>
其中：<span class="math inline">\([]\)</span>为向量拼接操作，<span class="math inline">\(H_l\)</span>是一个复合函数，文中是batch normalization (BN)+rectified linear unit (ReLU)+3×3 convolution (Conv)的复合——BN(ReLU(Conv(x)))。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9l3s1j1ogm198q14ed1oc116fo5f.png" width="600" />
</center></li>
<li><p>dense blocks与transition layer DenseNet的拼接操作要求保证feature map大小具有一致性，但由于pooling下采样操作的存在一定会改变feature map的，所以作者用dense blocks+transition layers的方式解决问题：</p>
<p>1、dense blocks内部feature map大小都一致，借鉴Inception结构，利用bottleneck中的1×1卷积降低通道数，即 <strong>BN+ReLU+Conv(1x1)+BN+ReLU+Conv(3x3)</strong> 操作；</p>
2、dense blocks之间增加transition layer，同样借鉴Inception结构，利用1×1卷积降低通道数，即<strong>BN+ReLU+Conv(1×1)+AvgPooling(2x2)</strong> 操作：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9m0fcunr3ou4143msh6160h5s.png" width="800" />
</center>
<p>transition layer可以起到压缩模型的作用：假设dense block有<span class="math inline">\(m\)</span>个feature map，我们让紧接着的transition layer产生<span class="math inline">\(\lfloor \theta m\rfloor\)</span>，这里<span class="math inline">\(0&lt;\theta\le1\)</span>为压缩系数。</p>
宏观来看，整个DenseNet如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9mgbktmq3qm6tt17bd1g746p.png" width="800" />
</center></li>
<li>利用Growth Rate和复合函数，DenseNet可以做的很“窄”：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/k-growth.png" width="600" />
</center>
假设每个<span class="math inline">\(H_l\)</span>复合函数产生<span class="math inline">\(k\)</span>个feature map，那么第<span class="math inline">\(l\)</span>层的输入feature map数为：<span class="math inline">\(k_0+k\times(l-1)\)</span> ，可见越往后的dense block输入feature map越多，当然由于全局feature map的存在，每层只有 <span class="math inline">\(k\)</span> 个feature map是独有的，其余的都共享。 显然，“窄”的好处是参数少、计算效率高，比较如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9ne9qt9661umllgh1pif1rgc76.png" width="800"/>
</center></li>
<li>DenseNet结构使得特征更加具有多样性 显然，由于从高到低引入了不同复杂度的特征，使得最终做预测的特征具有很强的多样性，提高模型的泛化性和鲁棒性。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9q7n3n1mrnnh555lvddl087j.png" width="800"/>
</center></li>
</ul>
<h3 id="代码实践-7">8.8.3 代码实践</h3>
看一个基于keras的简单例子，比较好重现了DenseNet的构建，看的时候对照着DenseNet的前向展开图更好理解原理： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Activation, Dropout, Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.pooling <span class="keyword">import</span> AveragePooling2D, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment">#增加一层并使用复合函数BN+ReLU+Conv(3x3)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span>(<span class="params">x, nb_channels, kernel_size=<span class="number">3</span>, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    out = BatchNormalization(gamma_regularizer=l2(l2_reg),</span><br><span class="line">                             beta_regularizer=l2(l2_reg))(x)</span><br><span class="line">    out = Activation(<span class="string">&#x27;relu&#x27;</span>)(out)</span><br><span class="line">    out = Convolution2D(nb_channels, kernel_size, kernel_size,</span><br><span class="line">                        border_mode=<span class="string">&#x27;same&#x27;</span>, init=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        W_regularizer=l2(l2_reg), bias=<span class="literal">False</span>)(out)</span><br><span class="line">    <span class="keyword">if</span> dropout &gt; <span class="number">0</span>:</span><br><span class="line">        out = Dropout(dropout)(out)</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定层数和增长率，增加一个dense block</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dense_block</span>(<span class="params">x, nb_layers, growth_rate, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_layers):</span><br><span class="line">        <span class="comment"># Get layer output</span></span><br><span class="line">        out = add_layer(x, growth_rate, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">        <span class="keyword">if</span> K.image_dim_ordering() == <span class="string">&#x27;tf&#x27;</span>:</span><br><span class="line">            merge_axis = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> K.image_dim_ordering() == <span class="string">&#x27;th&#x27;</span>:</span><br><span class="line">            merge_axis = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&#x27;Invalid dim_ordering: &#x27;</span> + K.image_dim_ordering())</span><br><span class="line">        <span class="comment"># Concatenate input with layer ouput</span></span><br><span class="line">        x = merge([x, out], mode=<span class="string">&#x27;concat&#x27;</span>, concat_axis=merge_axis)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#增加一个transition layer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span>(<span class="params">x, nb_channels, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    x = add_layer(x, nb_channels, kernel_size=<span class="number">1</span>, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">    x = AveragePooling2D()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定dense block数量、层数、增长率，构建DenseNet</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">densenet_model</span>(<span class="params">nb_blocks, nb_layers, growth_rate, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                   init_channels=<span class="number">16</span></span>):</span></span><br><span class="line">    n_channels = init_channels</span><br><span class="line">    inputs = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">    x = Convolution2D(init_channels, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                      init=<span class="string">&#x27;he_normal&#x27;</span>, W_regularizer=l2(l2_reg),</span><br><span class="line">                      bias=<span class="literal">False</span>)(inputs)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_blocks - <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># Create a dense block</span></span><br><span class="line">        x = dense_block(x, nb_layers, growth_rate,</span><br><span class="line">                        dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">        <span class="comment"># Update the number of channels</span></span><br><span class="line">        n_channels += nb_layers*growth_rate</span><br><span class="line">        <span class="comment"># Transition layer</span></span><br><span class="line">        x = transition_block(x, n_channels, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add last dense_block</span></span><br><span class="line">    x = dense_block(x, nb_layers, growth_rate, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">    <span class="comment"># Add final BN-Relu</span></span><br><span class="line">    x = BatchNormalization(gamma_regularizer=l2(l2_reg),</span><br><span class="line">                             beta_regularizer=l2(l2_reg))(x)</span><br><span class="line">    x = Activation(<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    <span class="comment"># Global average pooling</span></span><br><span class="line">    x = GlobalAveragePooling2D()(x)</span><br><span class="line">    x = Dense(<span class="number">10</span>, W_regularizer=l2(l2_reg))(x)</span><br><span class="line">    x = Activation(<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    model = Model(<span class="built_in">input</span>=inputs, output=x)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#1个dense block，里面共2层，feature map数为3</span></span><br><span class="line">    model = densenet_model(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line">    plot_model(model, to_file=<span class="string">&quot;DenseNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure> 生成网络结构为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ckcktrsoqnj16k0103c1o78vbi80.png" width="600"/>
</center>
对应的前向展开为：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ckckvl6c1jofn1i10ji1666cr58d.png" width="500" />
</center>
<h2 id="mask-r-cnn">8.9 Mask R-CNN</h2>
<h3 id="算法概述-3">8.9.1 算法概述</h3>
Mask R-CNN是何恺明等人在《<a href="https://arxiv.org/pdf/1703.06870.pdf">Mask R-CNN</a>》一文中提出的一个简单的、扩展性较强的用于目标检测、识别、实例和语义分割的通用框架，可以看做是Faster R-CNN的升级加强版，结构上也可以理解为：把原有Faster R-CNN的RoIPooling层替换为RoIAlign层，并加了第三个用来预测Mask的分支，以支持pixel2pixel像素粒度的分类预测（语义分割）。 演化过程如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/a07ym-aobhi.png" width="800" />
</center>
换个角度看整体结构如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/mask-rcnn.png" width="800" />
</center>
<h3 id="mask">8.9.2 Mask</h3>
<p>需要注意的是，在Mask任务分枝下，假设有<span class="math inline">\(K\)</span>个分类，则对每个RoI会针对所有<span class="math inline">\(K\)</span>个分类产生一个<span class="math inline">\(m×m\)</span>的binary masks（0或非0）预测图（即mask任务分支对每个RoI产生一个维度为<span class="math inline">\(Km^2\)</span>的输出）。</p>
<p>由于这种像素级的分割对空间位置信息很敏感，而原有的RoI Pooling大量使用了取整操作（文中叫做harsh quantization），从而使得RoI Pooling的输出产生位移，会和原图像上的RoI对不上（ps：分类操作本就对位置不敏感，所以不受这种位移影响），所以文中采用了RoI Align来改进，使得提高了mask预测精度提高了10%到50%。 查看8.5 Fast R-CNN的代码介绍也可以发现，做原图到feature map的映射时用了round四舍五入以及计算bin在feature map上的坐标范围时用了floor取整操作。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// rbgirshick/fast-rcnn对ROIPoolForward的实现：</span><br><span class="line">......</span><br><span class="line">// 原图到feature <span class="built_in">map</span>的映射为乘以<span class="number">1</span>/<span class="number">16</span>，这里采用粗映射.</span><br><span class="line"><span class="built_in">int</span> roi_start_w = <span class="built_in">round</span>(bottom_rois[<span class="number">1</span>] * spatial_scale);</span><br><span class="line"><span class="built_in">int</span> roi_start_h = <span class="built_in">round</span>(bottom_rois[<span class="number">2</span>] * spatial_scale);</span><br><span class="line"><span class="built_in">int</span> roi_end_w = <span class="built_in">round</span>(bottom_rois[<span class="number">3</span>] * spatial_scale);</span><br><span class="line"><span class="built_in">int</span> roi_end_h = <span class="built_in">round</span>(bottom_rois[<span class="number">4</span>] * spatial_scale);</span><br><span class="line">......</span><br><span class="line">// 计算第(i,j)个<span class="built_in">bin</span>桶在feature <span class="built_in">map</span>上的坐标范围，需要依据它们确定后续<span class="built_in">max</span> pooling的范围</span><br><span class="line"><span class="built_in">int</span> hstart = static_cast&lt;<span class="built_in">int</span>&gt;(floor(static_cast&lt;Dtype&gt;(ph) * bin_size_h));</span><br><span class="line"><span class="built_in">int</span> wstart = static_cast&lt;<span class="built_in">int</span>&gt;(floor(static_cast&lt;Dtype&gt;(pw) * bin_size_w));</span><br><span class="line"><span class="built_in">int</span> hend = static_cast&lt;<span class="built_in">int</span>&gt;(ceil(static_cast&lt;Dtype&gt;(ph + <span class="number">1</span>) * bin_size_h));</span><br><span class="line"><span class="built_in">int</span> wend = static_cast&lt;<span class="built_in">int</span>&gt;(ceil(static_cast&lt;Dtype&gt;(pw + <span class="number">1</span>) * bin_size_w));</span><br></pre></td></tr></table></figure></p>
<h3 id="roialign">8.9.3 RoIAlign</h3>
<ul>
<li>图像的仿射变换 在图像处理中经常会用仿射变换去做各种图像处理，用数学表达为 ： 假设，<span class="math inline">\(x,y\)</span>是原始图像中某一点的位置，<span class="math inline">\(x^*,y^*\)</span>是做了图像变换后该点的位置，则这个变换过程表示为： <span class="math display">\[
\begin{bmatrix}
x^* \\
y^*
\end{bmatrix}
=\begin{bmatrix}
v_{11} &amp; v_{12} &amp; v_{13} \\
v_{21} &amp; v_{22} &amp; v_{23}
\end{bmatrix}
\cdot
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}
\]</span> 假设有以下500×500图片：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/me.jpeg" width="300">
</center>
<p>以opencv中的仿射变换为例，常用的变换有：</p>
<table>
<colgroup>
<col style="width: 30%" />
<col style="width: 26%" />
<col style="width: 23%" />
<col style="width: 19%" />
</colgroup>
<thead>
<tr class="header">
<th>变换</th>
<th style="text-align: center;">变换矩阵</th>
<th style="text-align: center;">例子</th>
<th style="text-align: right;">效果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>恒等(Identity)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Identity.png" width="300" /></td>
</tr>
<tr class="even">
<td>平移(Translation)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; 0 &amp; v_{13}\geq 0 \\0 &amp; 1 &amp; v_{23}\geq 0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; 0 &amp; 30 \\ 0 &amp; 1 &amp; 30 \end{bmatrix}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Translation.png" width="300" /></td>
</tr>
<tr class="odd">
<td>镜像(Reflection)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} -1 &amp; 0 &amp; v_{13}\geq 0 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} -1 &amp; 0 &amp; 500 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Translation.png" width="300" /></td>
</tr>
<tr class="even">
<td>缩放(Scale)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} v_{11} &amp; 0 &amp; 0 \\ 0 &amp; v_{22} &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1.5 &amp; 0 &amp; 0 \\ 0 &amp; 1.5 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Translation.png" width="300" /></td>
</tr>
<tr class="odd">
<td>旋转(Rotate)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} v_{11}=cos(\theta) &amp; v_{12}=-sin(\theta) &amp; 0 \\ v_{21}=sin(\theta) &amp; v_{22}=cos(\theta) &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 0.866 &amp; -0.5 &amp; 0 \\ 0.5 &amp; 0.866 &amp; 0 \end{bmatrix}_{\theta=\frac{\pi}{6}=30^\circ}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Rotate.png" width="500" /></td>
</tr>
<tr class="even">
<td>剪切(Shear)</td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; v_{12} &amp; 0 \\ v_{21} &amp;1 &amp;0 \end{bmatrix}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\begin{bmatrix} 1 &amp; 0.5 &amp; 0 \\ 0.5 &amp; 1 &amp; 0 \end{bmatrix}\)</span></td>
<td style="text-align: right;"><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Translation.png" width="300" /></td>
</tr>
</tbody>
</table>
<p>代码如下： <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_transformation</span>(<span class="params">file_name, T</span>):</span></span><br><span class="line">    img = cv2.imread(file_name)</span><br><span class="line">    new_img = cv2.warpAffine(img, T, img.shape[:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">50</span>,<span class="number">50</span>))</span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line">    plt.imshow(new_img)</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像</span></span><br><span class="line">T1 = np.float32([[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">500</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="comment"># 恒等</span></span><br><span class="line">T2 = np.float32([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># x和y同时平移平移</span></span><br><span class="line">T3 = np.float32([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">30</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">1</span>, <span class="number">30</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缩放</span></span><br><span class="line">T4 = np.float32([[<span class="number">1.5</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0</span>, <span class="number">1.5</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="comment"># 旋转</span></span><br><span class="line">T5 = np.float32([[<span class="number">0.866</span>, -<span class="number">0.5</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0.5</span>, <span class="number">0.866</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="comment"># 剪切</span></span><br><span class="line">T6 = np.float32([[<span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0</span>],</span><br><span class="line">                [<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T1)</span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T2)</span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T3)</span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T4)</span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T5)</span><br><span class="line">image_transformation(<span class="string">&#x27;me.jpeg&#x27;</span>, T6)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li>
<li>线性插值 在要求没那么高的场景中，为了弥补相近两个数据中间缺失的数据，常常采用线性插值法，即假设两点之间的数据分布为线性分布，显然如果曲线曲率越大，线性插值的误差越大。 形式化表示如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Linear_interpolation.png" width="300">
</center>
<center>
<p><a href="https://zh.wikipedia.org/wiki/%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC">wikipedia</a></p>
</center>
<p>假设：已知坐标 <span class="math inline">\((x_0, y_0)\)</span> 和 <span class="math inline">\((x_1, y_1)\)</span>，要在两点间插入一点<span class="math inline">\((x,y)\)</span>作为补充数据，其中<span class="math inline">\(x\)</span>的值已指定，则<span class="math inline">\(y\)</span>的值为： <span class="math display">\[
\frac{y-y_0}{x-x_0}=\frac{y_1-y_0}{x_1-x_0}
\]</span> 得到： <span class="math display">\[
\begin{align*}
y&amp;=y_0+\frac{x-x_0}{x_1-x_0}y_1-\frac{x-x_0}{x_1-x_0}y_0\\
&amp;=\frac{x-x_0}{x_1-x_0}y_1+\frac{x_1-x}{x_1-x_0}y_0
\end{align*}
\]</span></p></li>
<li>双线性插值 双线性插值是对线性插值在二维上的扩展，基本思想是利用某点周围的四个点估计出该点的值，形式化表示如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/Bilinear_interpolation.png" width="300">
</center>
<center>
<p><a href="https://zh.wikipedia.org/wiki/%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC">wikipedia</a></p>
</center>
<p>问题：想得到未知函数<span class="math inline">\(f\)</span>在点<span class="math inline">\(P(x,y)\)</span>的值。（以图像为例：已知图像上某个位置，想得到在这个位置的灰度值）</p>
<p>假设：已知函数<span class="math inline">\(f\)</span>在<span class="math inline">\(P\)</span>点 <strong><em>周围</em></strong> 四个点的函数值：<span class="math inline">\(Q_{11}=(x_1,y_1)\)</span>、<span class="math inline">\(Q_{12}=(x_1,y_2)\)</span>、<span class="math inline">\(Q_{21}=(x_2,y_1)\)</span>、<span class="math inline">\(Q_{22}=(x_2,y_2)\)</span>。（以图像为例：“周围隐含<span class="math inline">\(x_2-x_1=1\)</span>且<span class="math inline">\(y_2-y_1=1\)</span>）</p>
<p>则：双线性插值会先在<span class="math inline">\(x\)</span>轴方向做线性插值2次，后在<span class="math inline">\(y\)</span>轴方向做线性插值1次，从而得到目标值。（ps：效果等同于在<span class="math inline">\(y\)</span>轴方向插值2次，后在<span class="math inline">\(x\)</span>轴方向插值1次） 即:在<span class="math inline">\(x\)</span>轴方向做线性插值2次得到， <span class="math display">\[
\begin{align*}
f(R_1)=f(x,y_1)&amp;=\frac{x_2-x}{x_2-x_1}f(Q_{11})+\frac{x-x_1}{x_2-x_1}f(Q_{21})\\
f(R_2)=f(x,y_2)&amp;=\frac{x_2-x}{x_2-x_1}f(Q_{12})+\frac{x-x_1}{x_2-x_1}f(Q_{22})
\end{align*}
\]</span> 在<span class="math inline">\(y\)</span>轴方向做线性插值1次得到， <span class="math display">\[
\begin{align*}
f(P)=f(x,y)&amp;=\frac{y_2-y}{y_2-y_1}f(R_{1})+\frac{y-y_1}{y_2-y_1}f(R_{2})\\
&amp;=\frac{y_2-y}{y_2-y_1}(\frac{x_2-x}{x_2-x_1}f(Q_{11})+\frac{x-x_1}{x_2-x_1}f(Q_{21}))+\frac{y-y_1}{y_2-y_1}(\frac{x_2-x}{x_2-x_1}f(Q_{12})+\frac{x-x_1}{x_2-x_1}f(Q_{22}))\\
&amp;=\frac{1}{(x_2-x_1)(y_2-y_1)}(f(Q_{11})\underbrace{(x_2-x)(y_2-y)}_{w_{11}}+f(Q_{21})\underbrace{(x-x_1)(y_2-y)}_{w_{21}}+f(Q_{12})\underbrace{(x_2-x)(y-y_1)}_{w_{12}}+f(Q_{22})\underbrace{(x-x_1)(y-y_1)}_{w_{22}})\\
\end{align*}
\]</span></p>
<p>细心的读者一定已经发现：插值后的<span class="math inline">\(P\)</span>点取值也可以看做是周围4个点取值的线性加权之和，且权重：<span class="math inline">\(w_{11}+w_{21}+w_{12}+w_{22}=1\)</span> 上式表达为矩阵形式为： <span class="math display">\[
f(x,y)=\frac{1}{(x_2-x_1)(y_2-y_1)}\begin{bmatrix} x_2-x &amp; x-x_1 \end{bmatrix}\cdot \begin{bmatrix} f(Q_{11}) &amp; f(Q_{12}) \\ f(Q_{21}) &amp; f(Q_{22}) \end{bmatrix} \cdot \begin{bmatrix} y_2-y  \\ y-y_1  \end{bmatrix}
\]</span></p>
<p>在图像矩阵上利用某点周围四个点的灰度值估计该点灰度值时，上式简化为矩阵形式： <span class="math display">\[
f(P)=f(x,y)=\begin{bmatrix} x_1+1-x &amp; x-x_1 \end{bmatrix}\cdot \begin{bmatrix} f(Q_{11}) &amp; f(Q_{12}) \\ f(Q_{21}) &amp; f(Q_{22}) \end{bmatrix} \cdot \begin{bmatrix} y_1+1-y  \\ y-y_1  \end{bmatrix}
\]</span> 或等式： <span class="math display">\[
f(x,y)=\sum_{i=1}^{2}\sum_{j=1}^{2}f(x_i,y_j)max(0,1-|x-x_i|)max(0,1-|y-y_i|)\tag{1}
\]</span></p></li>
<li>RoIAlign 不管RoI Pooling还是RoI Align，都是为了把任意大小的RoI（注意这里不是bounding box）区域映射为相同固定大小的输出，前者由于量化误差的存在（四舍五入或取整），导致边界上的数据丢失，从而会使得RoI的边界从原图映射到Feature Map后出现偏离，如下图：
<center>
<p><img data-src="https://vivounicorn.github.io/images/ai_chapter_8/RoiPooling.png" width="600"></p>
绿色为RoI映射后的理论边界，蓝色为实际边界
</center>
这种偏离对分类问题无影响（忽略精确的边界信息反而会提高分类准确率），但对语义分割确影响比较大（因为每个像素都要分类，所以精确的空间位置信息很重要），作者使用RoIAlign后可以使mask的精度提高10%~50%。 具体做法使用了:《<a href="https://arxiv.org/pdf/1506.02025.pdf">Spatial Transformer Networks</a>》一文介绍的双线性插值方法，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/STN.png" width="600">
</center>
<p>基本过程如下：</p>
<strong>1、保留边界</strong>，对边界不做量化操作，保持浮点数边界，并将RoI分为<span class="math inline">\(H×W\)</span>(如3×3)的个子网格（Bin），每个子网格的边界也保留浮点数边界，即：我们不需要处理位置“坐标”，只需要处理“值”（相比较，RoIPooling做了两次量化：一次是原图映射到Feature Map时，一次是划分bin做Pooling时）：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/RoiAligngrid.png" width="600">
</center>
<strong>2、采样与插值</strong>，整体示意图如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/RoiAlignsimple.png" width="800">
</center>
<p>每个Bin取4个规则的采样点，采样方法如下： <span class="math display">\[
\begin{align*}
x&amp;=x_l+(i + 0.5)\frac{x_h-x_l}{n}\tag{2.1}\\
y&amp;=y_l+(j + 0.5)\frac{y_h-y_l}{n}\tag{2.2}\\
n&amp;=number \quad of \quad samples.\\
i,j&amp;=0,...,n
\end{align*}
\]</span> 对应上图中：<span class="math inline">\(x_l=min(x_1,x_2)\)</span>、<span class="math inline">\(x_h=max(x_1,x_2)\)</span>、<span class="math inline">\(y_l=min(y_1,y_2)\)</span>、<span class="math inline">\(y_h=max(y_1,y_2)\)</span>，当<span class="math inline">\(n=2\)</span>时，每个Bin采样后得到图中4个采样点(绿点)。</p>
然后对每个采样点(以红点标注的那个采样点<span class="math inline">\(P\)</span>点为例)取周围4个点得到2×2个子区域，取每个子区域的中点（途中黑色的<span class="math inline">\(Q_{11}、Q_{12}、Q_{21}、Q_{22}\)</span>点）做双线性插值，得到该采样点<span class="math inline">\(P\)</span>处的值。
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/RoiAlignmax.png" width="800">
</center></li>
<li>原理及细节说明 上面的描述比较抽象，现在我们看个例子帮助大家理解： 1、假设输入原图为<strong>512×512</strong>，以<strong>stride=32</strong>，产生的feature map为<strong>16×16</strong>，每个RoI会被处理输出为一个固定大小的<strong>3×3</strong>的feature map:
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_org.png" width="800">
</center>
2、以图中最下方的RoI为示例对象，假设其最左上角坐标为：<span class="math inline">\((5.26, 9.33)\)</span>，<span class="math inline">\(width=\frac{200}{32}=6.25\)</span>，<span class="math inline">\(height=\frac{185}{32}=5.78\)</span>，如下图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_roi.png" width="800">
</center>
3、显然边界坐标都不是整数，传统的RoI Pooling会做量化，把边界信息丢失，而使用RoIAlign不需要做这种量化。根据输出feature map 3× 3的大小要求，RoI会被划分为9个bin，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_fm.png" width="800">
</center>
4、每个bin会做<span class="math inline">\(n\)</span>个点的抽样（文中<span class="math inline">\(n=2\)</span>），具体抽样方法为<strong><em>公式：2.1-2.2</em></strong>，抽样后如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_sample.png" width="800">
</center>
5、以图中标红抽样点为例，在feature map上获取距离其最近的4个近邻点，使用双线性插值得到该点的值，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_ex.png" width="800">
</center>
6、对所有bin里的所有抽样点做上述估计，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_all.png" width="800">
</center>
7、使用max或avg pooling得到输出feature map，如图：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/roialign_out.png" width="800">
</center>
<p>以上为RoIAlign整个过程的过程模拟，完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bin</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x_low, y_low, x_high, y_high, sample_num</span>):</span></span><br><span class="line">        self.x_low = x_low</span><br><span class="line">        self.y_low = y_low</span><br><span class="line">        self.x_high = x_high</span><br><span class="line">        self.y_high = y_high</span><br><span class="line">        self.sample_num = sample_num</span><br><span class="line">        <span class="comment"># sample_list的index和nearest_four的index一一对应，代表每个采样点附近最近的4个点</span></span><br><span class="line">        self.sample_list = []</span><br><span class="line">        self.nearest_four = []</span><br><span class="line">        self._generate_sample_point()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对某个bin做数据采样</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_generate_sample_point</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.sample_num):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.sample_num):</span><br><span class="line">                x = self.x_low + (i + <span class="number">0.5</span>) * (self.x_high - self.x_low) / self.sample_num</span><br><span class="line">                y = self.y_low + (j + <span class="number">0.5</span>) * (self.y_high - self.y_low) / self.sample_num</span><br><span class="line">                self.sample_list.append((x, y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印某个bin里的所有采样点的位置坐标</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_sample_points</span>(<span class="params">self, idx=<span class="number">0</span>, is_print_position=<span class="literal">True</span>, is_difference_marker=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.sample_list)):</span><br><span class="line">            (x, y) = self.sample_list[i]</span><br><span class="line">            <span class="keyword">if</span> i == idx:</span><br><span class="line">                clr = <span class="string">&#x27;red&#x27;</span></span><br><span class="line">                mkr = <span class="string">&#x27;o&#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                clr = <span class="string">&#x27;yellow&#x27;</span></span><br><span class="line">                mkr = <span class="string">&#x27;v&#x27;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> is_difference_marker:</span><br><span class="line">                clr = <span class="string">&#x27;red&#x27;</span></span><br><span class="line">                mkr = <span class="string">&#x27;o&#x27;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> is_print_position:</span><br><span class="line">                plt.text(x, y, <span class="string">&quot;(%.2f,%.2f)&quot;</span> % (x, y), fontsize=<span class="number">15</span>, color=clr)</span><br><span class="line"></span><br><span class="line">            plt.plot(x, y, marker=mkr, color=clr, markersize=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RoiAlign</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, left_top, width_height, matrix, sample_num=<span class="number">2</span>, feature_map_size=(<span class="params"><span class="number">3</span>, <span class="number">3</span></span>)</span>):</span></span><br><span class="line">        self.fig = plt.figure(figsize=(<span class="number">50</span>, <span class="number">50</span>))</span><br><span class="line">        self.ax = self.fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.ax.xaxis.set_ticks_position(<span class="string">&#x27;top&#x27;</span>)</span><br><span class="line">        self.ax.invert_yaxis()</span><br><span class="line"></span><br><span class="line">        self.sample_num = sample_num</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(matrix.shape) == <span class="number">2</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(feature_map_size) == <span class="number">2</span></span><br><span class="line">        self.matrix = matrix</span><br><span class="line">        self.in_shape = matrix.shape</span><br><span class="line">        self.out_shape = feature_map_size</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(left_top) == <span class="number">2</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(width_height) == <span class="number">2</span></span><br><span class="line">        self.x_low = left_top[<span class="number">0</span>]</span><br><span class="line">        self.y_low = left_top[<span class="number">1</span>]</span><br><span class="line">        self.width = width_height[<span class="number">0</span>]</span><br><span class="line">        self.height = width_height[<span class="number">1</span>]</span><br><span class="line">        self.width = width_height[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        self.bins = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印整个feature map</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_matrix</span>(<span class="params">self</span>):</span></span><br><span class="line">        plt.pcolormesh(self.matrix, cmap=<span class="string">&#x27;PuBu_r&#x27;</span>, shading=<span class="string">&#x27;flat&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">        w = self.in_shape[<span class="number">0</span>]</span><br><span class="line">        h = self.in_shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">                plt.text((j + <span class="number">0.5</span>), (i + <span class="number">0.5</span>), self.matrix[i][j], fontsize=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 找到某个bin的某个采样点周围的所有4个最近邻点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_all_nearest_points</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.bins) &gt; <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.bins)):</span><br><span class="line">            <span class="keyword">assert</span> <span class="built_in">len</span>(self.bins[i].sample_list) &gt; <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> x, y <span class="keyword">in</span> self.bins[i].sample_list:</span><br><span class="line">                self.bins[i].nearest_four.append(self.find_nearest_point(x, y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在输入feature map上找到某个bin中的采样点(x,y)的4个最近邻点，并对该点做双线性插值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_nearest_point</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        y_l, y_h = np.floor(y).astype(<span class="string">&#x27;int32&#x27;</span>), np.ceil(y).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">        x_l, x_h = np.floor(x).astype(<span class="string">&#x27;int32&#x27;</span>), np.ceil(x).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        a = self.matrix[y_l, x_l]</span><br><span class="line">        b = self.matrix[y_l, x_h]</span><br><span class="line">        c = self.matrix[y_h, x_l]</span><br><span class="line">        d = self.matrix[y_h, x_h]</span><br><span class="line"></span><br><span class="line">        y_weight = y - y_l</span><br><span class="line">        x_weight = x - x_l</span><br><span class="line"></span><br><span class="line">        val = a * (<span class="number">1</span> - x_weight) * (<span class="number">1</span> - y_weight) + \</span><br><span class="line">              b * x_weight * (<span class="number">1</span> - y_weight) + \</span><br><span class="line">              c * y_weight * (<span class="number">1</span> - x_weight) + \</span><br><span class="line">              d * x_weight * y_weight</span><br><span class="line">        <span class="keyword">return</span> [(x_l, y_l), (x_h, y_l), (x_l, y_h), (x_h, y_h), val]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印RoI及其宽度、高度、和最左上角位置坐标</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_roi</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        x_l = self.x_low</span><br><span class="line">        y_l = self.y_low</span><br><span class="line">        width = self.width</span><br><span class="line">        height = self.height</span><br><span class="line">        self.ax.add_patch(plt.Rectangle((x_l, y_l), width, height, fill=<span class="literal">False</span>, edgecolor=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">5</span>))</span><br><span class="line">        plt.plot(x_l, y_l, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">        plt.text(x_l - <span class="number">0.5</span>, y_l - <span class="number">0.1</span>, <span class="string">&quot;(&#123;&#125;,&#123;&#125;)&quot;</span>.<span class="built_in">format</span>(x_l, y_l), fontsize=<span class="number">30</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        plt.text(x_l + width / <span class="number">2</span>, y_l - <span class="number">0.2</span>, <span class="string">&quot;width=%.2f&quot;</span> % width, fontsize=<span class="number">30</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        plt.text(x_l - <span class="number">0.25</span>, y_l + height / <span class="number">2</span> + <span class="number">1</span>, <span class="string">&quot;height=%.2f&quot;</span> % height, rotation=<span class="string">&#x27;vertical&#x27;</span>, fontsize=<span class="number">30</span>,</span><br><span class="line">                 color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        x_split = width / self.out_shape[<span class="number">0</span>]</span><br><span class="line">        y_split = height / self.out_shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.out_shape[<span class="number">0</span>]):</span><br><span class="line">            plt.plot([x_l + i * x_split, x_l + i * x_split], [y_l, y_l + height], color=<span class="string">&#x27;yellow&#x27;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.out_shape[<span class="number">1</span>]):</span><br><span class="line">            plt.plot([x_l, x_l + width], [y_l + j * y_split, y_l + j * y_split], color=<span class="string">&#x27;yellow&#x27;</span>, linewidth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.out_shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.out_shape[<span class="number">1</span>]):</span><br><span class="line">                bin_split = Bin(self.x_low + i * x_split, self.y_low + j * y_split,</span><br><span class="line">                                self.x_low + (i + <span class="number">1</span>) * x_split, self.y_low + (j + <span class="number">1</span>) * y_split,</span><br><span class="line">                                self.sample_num)</span><br><span class="line"></span><br><span class="line">                self.bins.append(bin_split)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印某个bin或者RoI内所有bin的采样点，并对第j（从上到下、从左到右编号）个采样点涂抹不同颜色</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_bins</span>(<span class="params">self, i=<span class="number">0</span>, j=<span class="number">0</span>, is_print_all=<span class="literal">True</span>, is_print_position=<span class="literal">True</span>, is_difference_marker=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> is_print_all:</span><br><span class="line">            self.bins[i].print_sample_points(idx=j, is_print_position=is_print_position,</span><br><span class="line">                                             is_difference_marker=is_difference_marker)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">bin</span> <span class="keyword">in</span> self.bins:</span><br><span class="line">                <span class="built_in">bin</span>.print_sample_points(idx=j, is_print_position=is_print_position,</span><br><span class="line">                                        is_difference_marker=is_difference_marker)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印所有bin里的每个采样点的4个最近邻点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_all_bins_nearest_four</span>(<span class="params">self, is_print_4sample=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="keyword">for</span> s_bin <span class="keyword">in</span> self.bins:</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s_bin.nearest_four)):</span><br><span class="line">                tuple_five = s_bin.nearest_four[i]</span><br><span class="line">                cur = s_bin.sample_list[i]</span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">len</span>(tuple_five) == <span class="number">5</span></span><br><span class="line">                q11 = tuple_five[<span class="number">0</span>]</span><br><span class="line">                q21 = tuple_five[<span class="number">1</span>]</span><br><span class="line">                q12 = tuple_five[<span class="number">2</span>]</span><br><span class="line">                q22 = tuple_five[<span class="number">3</span>]</span><br><span class="line">                val = tuple_five[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> is_print_4sample:</span><br><span class="line">                    plt.plot(q11[<span class="number">0</span>] + <span class="number">0.5</span>, q11[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">                    plt.plot(q21[<span class="number">0</span>] + <span class="number">0.5</span>, q21[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;yellow&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">                    plt.plot(q12[<span class="number">0</span>] + <span class="number">0.5</span>, q12[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">                    plt.plot(q22[<span class="number">0</span>] + <span class="number">0.5</span>, q22[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">                plt.text(cur[<span class="number">0</span>] + <span class="number">0.1</span>, cur[<span class="number">1</span>] + <span class="number">0.2</span>, <span class="string">&quot;%.2f&quot;</span> % val, fontsize=<span class="number">20</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印第i（从上到下、从左到右编号）个bin，第j（从上到下、从左到右编号）个采样点的4个最近邻点</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_single_bin_sample</span>(<span class="params">self, is_print_4sample=<span class="literal">True</span>, i=<span class="number">0</span>, j=<span class="number">0</span></span>):</span></span><br><span class="line">        tuple_five = self.bins[i].nearest_four[j]</span><br><span class="line">        cur = self.bins[i].sample_list[j]</span><br><span class="line"></span><br><span class="line">        q11 = tuple_five[<span class="number">0</span>]</span><br><span class="line">        q21 = tuple_five[<span class="number">1</span>]</span><br><span class="line">        q12 = tuple_five[<span class="number">2</span>]</span><br><span class="line">        q22 = tuple_five[<span class="number">3</span>]</span><br><span class="line">        val = tuple_five[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> is_print_4sample:</span><br><span class="line">            plt.plot(q11[<span class="number">0</span>] + <span class="number">0.5</span>, q11[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;red&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">            plt.plot(q21[<span class="number">0</span>] + <span class="number">0.5</span>, q21[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;yellow&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">            plt.plot(q12[<span class="number">0</span>] + <span class="number">0.5</span>, q12[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line">            plt.plot(q22[<span class="number">0</span>] + <span class="number">0.5</span>, q22[<span class="number">1</span>] + <span class="number">0.5</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>, markersize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">        plt.text(cur[<span class="number">0</span>] + <span class="number">0.1</span>, cur[<span class="number">1</span>] + <span class="number">0.2</span>, <span class="string">&quot;%.2f&quot;</span> % val, fontsize=<span class="number">20</span>, color=<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 执行max pooling或者average pooling.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">do_pooling</span>(<span class="params">self, max_or_avg=<span class="string">&#x27;max&#x27;</span></span>):</span></span><br><span class="line">        out_feature_map = np.zeros(self.out_shape)</span><br><span class="line">        w = self.out_shape[<span class="number">0</span>]</span><br><span class="line">        h = self.out_shape[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(self.bins) == w * h</span><br><span class="line"></span><br><span class="line">        bin_pooling = []</span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">bin</span> <span class="keyword">in</span> self.bins:</span><br><span class="line">            res = []</span><br><span class="line">            <span class="keyword">for</span> tuple_five <span class="keyword">in</span> <span class="built_in">bin</span>.nearest_four:</span><br><span class="line">                res.append(tuple_five[<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> max_or_avg == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                bin_pooling.append(np.<span class="built_in">max</span>(res))</span><br><span class="line">            <span class="keyword">elif</span> max_or_avg == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                bin_pooling.append(np.around(np.mean(res).astype(<span class="string">&#x27;float&#x27;</span>), <span class="number">2</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">                out_feature_map[j, i] = np.around(bin_pooling[i * w + j], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        fig = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">        ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        ax.xaxis.set_ticks_position(<span class="string">&#x27;top&#x27;</span>)</span><br><span class="line">        ax.invert_yaxis()</span><br><span class="line">        plt.pcolormesh(out_feature_map, cmap=<span class="string">&#x27;PuBu_r&#x27;</span>, shading=<span class="string">&#x27;flat&#x27;</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">                plt.text((i + <span class="number">0.5</span>), (j + <span class="number">0.5</span>), out_feature_map[j][i], fontsize=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    fm = np.array([[<span class="number">28</span>, <span class="number">148</span>, <span class="number">175</span>, <span class="number">42</span>, <span class="number">71</span>, <span class="number">121</span>, <span class="number">68</span>, <span class="number">52</span>, <span class="number">157</span>, <span class="number">65</span>, <span class="number">62</span>, <span class="number">15</span>, <span class="number">182</span>, <span class="number">210</span>, <span class="number">39</span>, <span class="number">1</span>],</span><br><span class="line">                   [<span class="number">81</span>, <span class="number">209</span>, <span class="number">97</span>, <span class="number">200</span>, <span class="number">194</span>, <span class="number">11</span>, <span class="number">37</span>, <span class="number">103</span>, <span class="number">107</span>, <span class="number">200</span>, <span class="number">104</span>, <span class="number">244</span>, <span class="number">43</span>, <span class="number">225</span>, <span class="number">192</span>, <span class="number">25</span>],</span><br><span class="line">                   [<span class="number">42</span>, <span class="number">189</span>, <span class="number">120</span>, <span class="number">52</span>, <span class="number">198</span>, <span class="number">180</span>, <span class="number">88</span>, <span class="number">23</span>, <span class="number">60</span>, <span class="number">178</span>, <span class="number">103</span>, <span class="number">2</span>, <span class="number">90</span>, <span class="number">32</span>, <span class="number">215</span>, <span class="number">86</span>],</span><br><span class="line">                   [<span class="number">60</span>, <span class="number">47</span>, <span class="number">211</span>, <span class="number">106</span>, <span class="number">118</span>, <span class="number">99</span>, <span class="number">28</span>, <span class="number">230</span>, <span class="number">99</span>, <span class="number">94</span>, <span class="number">237</span>, <span class="number">116</span>, <span class="number">172</span>, <span class="number">135</span>, <span class="number">201</span>, <span class="number">175</span>],</span><br><span class="line">                   [<span class="number">105</span>, <span class="number">250</span>, <span class="number">226</span>, <span class="number">142</span>, <span class="number">39</span>, <span class="number">148</span>, <span class="number">137</span>, <span class="number">43</span>, <span class="number">133</span>, <span class="number">254</span>, <span class="number">59</span>, <span class="number">180</span>, <span class="number">72</span>, <span class="number">79</span>, <span class="number">112</span>, <span class="number">187</span>],</span><br><span class="line">                   [<span class="number">153</span>, <span class="number">177</span>, <span class="number">48</span>, <span class="number">76</span>, <span class="number">198</span>, <span class="number">237</span>, <span class="number">133</span>, <span class="number">97</span>, <span class="number">137</span>, <span class="number">60</span>, <span class="number">78</span>, <span class="number">62</span>, <span class="number">83</span>, <span class="number">101</span>, <span class="number">169</span>, <span class="number">5</span>],</span><br><span class="line">                   [<span class="number">252</span>, <span class="number">167</span>, <span class="number">27</span>, <span class="number">8</span>, <span class="number">200</span>, <span class="number">72</span>, <span class="number">132</span>, <span class="number">171</span>, <span class="number">111</span>, <span class="number">137</span>, <span class="number">150</span>, <span class="number">116</span>, <span class="number">74</span>, <span class="number">3</span>, <span class="number">124</span>, <span class="number">238</span>],</span><br><span class="line">                   [<span class="number">252</span>, <span class="number">184</span>, <span class="number">146</span>, <span class="number">93</span>, <span class="number">95</span>, <span class="number">194</span>, <span class="number">61</span>, <span class="number">53</span>, <span class="number">117</span>, <span class="number">78</span>, <span class="number">0</span>, <span class="number">116</span>, <span class="number">182</span>, <span class="number">254</span>, <span class="number">106</span>, <span class="number">197</span>],</span><br><span class="line">                   [<span class="number">43</span>, <span class="number">6</span>, <span class="number">123</span>, <span class="number">73</span>, <span class="number">68</span>, <span class="number">39</span>, <span class="number">57</span>, <span class="number">189</span>, <span class="number">222</span>, <span class="number">122</span>, <span class="number">210</span>, <span class="number">18</span>, <span class="number">24</span>, <span class="number">60</span>, <span class="number">77</span>, <span class="number">118</span>],</span><br><span class="line">                   [<span class="number">67</span>, <span class="number">68</span>, <span class="number">27</span>, <span class="number">216</span>, <span class="number">175</span>, <span class="number">122</span>, <span class="number">34</span>, <span class="number">122</span>, <span class="number">115</span>, <span class="number">131</span>, <span class="number">72</span>, <span class="number">121</span>, <span class="number">134</span>, <span class="number">252</span>, <span class="number">55</span>, <span class="number">115</span>],</span><br><span class="line">                   [<span class="number">55</span>, <span class="number">182</span>, <span class="number">125</span>, <span class="number">188</span>, <span class="number">157</span>, <span class="number">42</span>, <span class="number">194</span>, <span class="number">218</span>, <span class="number">82</span>, <span class="number">35</span>, <span class="number">129</span>, <span class="number">69</span>, <span class="number">186</span>, <span class="number">168</span>, <span class="number">217</span>, <span class="number">164</span>],</span><br><span class="line">                   [<span class="number">193</span>, <span class="number">76</span>, <span class="number">12</span>, <span class="number">201</span>, <span class="number">78</span>, <span class="number">106</span>, <span class="number">68</span>, <span class="number">36</span>, <span class="number">159</span>, <span class="number">246</span>, <span class="number">228</span>, <span class="number">24</span>, <span class="number">103</span>, <span class="number">141</span>, <span class="number">18</span>, <span class="number">137</span>],</span><br><span class="line">                   [<span class="number">191</span>, <span class="number">66</span>, <span class="number">94</span>, <span class="number">18</span>, <span class="number">26</span>, <span class="number">149</span>, <span class="number">28</span>, <span class="number">15</span>, <span class="number">115</span>, <span class="number">182</span>, <span class="number">87</span>, <span class="number">14</span>, <span class="number">223</span>, <span class="number">236</span>, <span class="number">122</span>, <span class="number">168</span>],</span><br><span class="line">                   [<span class="number">216</span>, <span class="number">49</span>, <span class="number">214</span>, <span class="number">157</span>, <span class="number">208</span>, <span class="number">117</span>, <span class="number">68</span>, <span class="number">38</span>, <span class="number">70</span>, <span class="number">12</span>, <span class="number">145</span>, <span class="number">80</span>, <span class="number">215</span>, <span class="number">70</span>, <span class="number">36</span>, <span class="number">130</span>],</span><br><span class="line">                   [<span class="number">201</span>, <span class="number">148</span>, <span class="number">125</span>, <span class="number">191</span>, <span class="number">41</span>, <span class="number">107</span>, <span class="number">29</span>, <span class="number">247</span>, <span class="number">211</span>, <span class="number">140</span>, <span class="number">56</span>, <span class="number">28</span>, <span class="number">203</span>, <span class="number">250</span>, <span class="number">48</span>, <span class="number">60</span>],</span><br><span class="line">                   [<span class="number">3</span>, <span class="number">184</span>, <span class="number">98</span>, <span class="number">221</span>, <span class="number">24</span>, <span class="number">56</span>, <span class="number">237</span>, <span class="number">79</span>, <span class="number">23</span>, <span class="number">225</span>, <span class="number">120</span>, <span class="number">137</span>, <span class="number">215</span>, <span class="number">190</span>, <span class="number">46</span>, <span class="number">226</span>]])</span><br><span class="line"></span><br><span class="line">    out_shape = (<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    roi = RoiAlign((<span class="number">5.26</span>, <span class="number">9.33</span>),  <span class="comment"># left top point</span></span><br><span class="line">                   (<span class="number">200</span> / <span class="number">32</span>, <span class="number">185</span> / <span class="number">32</span>),  <span class="comment"># width and height</span></span><br><span class="line">                   fm, <span class="number">2</span>, out_shape)</span><br><span class="line"></span><br><span class="line">    bin_idx = <span class="number">6</span></span><br><span class="line">    sample_idx = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    roi.print_matrix()</span><br><span class="line">    roi.print_roi()</span><br><span class="line">    roi.find_all_nearest_points()</span><br><span class="line">    roi.print_bins(i=bin_idx, j=sample_idx, is_print_all=<span class="literal">True</span>, is_print_position=<span class="literal">True</span>, is_difference_marker=<span class="literal">True</span>)</span><br><span class="line">    roi.print_single_bin_sample(<span class="literal">True</span>, bin_idx, sample_idx)</span><br><span class="line">    roi.print_all_bins_nearest_four(is_print_4sample=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    roi.do_pooling(<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="网络结构及目标函数">8.9.4 网络结构及目标函数</h3>
<ul>
<li><p>网络结构</p>
下图左右两图分别为：ResNet骨干网络+Head和FPN骨干网络+Head：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/maskrcnn_head.png" width="800">
</center></li>
<li><p>目标函数</p>
<p>对Faster R-CNN做了些许扩展： <span class="math display">\[
L=\underbrace{L_{cls}+L_{box}}_{Faster R-CNN}+\underbrace{L_{mask}}_{MaskR-CNN}
\]</span></p>
<p>Faster R-CNN部分：</p>
<p><span class="math display">\[
\underbrace{L(p,u,t^u,v)}_{\begin {align} p&amp;:预测分类\\u&amp;:分类标注\\t^u&amp;:分类u的预测bbox\\v&amp;:bbox标注 \end{align}}=\underbrace{L_{cls}(p,u)}_{log\text{ }loss}+\underbrace{\lambda[u\geq 1]}_{[u\geq 1]=\left\{\begin{matrix}1 &amp;若 u \geq 1\\0&amp;其他\end{matrix}\right.} \cdot \underbrace{L_{box}(t^u,v)}_{smooth\text{ }L1\text{ }loss}
\]</span> 其中： <span class="math display">\[
\begin {align} log\text{ }loss&amp;:-logp_u=-ulog (p)-(1-u)log(1-p)\\ smooth\text{ }L1\text{ }loss&amp;:\sum_{i \in \{x,y,w,h\}}smooth_{L_i}(t_i^u-v_i)\\ smooth_{L_i}(x)&amp;=\left\{\begin{matrix}0.5x^2 \quad &amp;若 |x|&lt;1\\|x|-0.5&amp;其他\end{matrix}\right.\end{align}
\]</span></p>
Mask部分: <span class="math display">\[
\begin {align}
L_{mask}&amp;= - \frac{1}{m×m} \sum_{i=1}^m \sum_{j=1}^m \big[ u_{ij} \log y^k_{ij} + (1-u_{ij}) \log (1- y^k_{ij}) \big]\\
y_{ij}&amp;:位置(i,j)处像素针对分类k的预测mask值\\
u_{ij}&amp;:位置(i,j)处像素的标注mask值\\
m&amp;:mask \text{ } feature \text{ } map矩阵维度(m×m)\\
\end{align}
\]</span> 注意，对每个像素都会有一个二分类结果，以及每个类都会有一个mask矩阵(m×m)输出，所以总共会有<span class="math inline">\(K\cdot(m×m)\)</span>个sigmoid输出，而如果RoI判定为第<span class="math inline">\(k\)</span>个分类，则损失函数<span class="math inline">\(L_{mask}\)</span>为第<span class="math inline">\(k\)</span>个分类下的平均二分类交叉熵损失（average binary cross-entropy loss），也就是说所有分类之间不会产生竞争，文中这部分效果如下：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/bce.png" width="390">
</center>
分割效果：
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/cm.jpg" width="390"> <img data-src="https://vivounicorn.github.io/images/ai_chapter_8/cm_mask.jpg" width="390">
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/street1.png" width="390"> <img data-src="https://vivounicorn.github.io/images/ai_chapter_8/street1_mask.jpg" width="390">
</center>
<center>
<img data-src="https://vivounicorn.github.io/images/ai_chapter_8/street2.png" width="390"> <img data-src="https://vivounicorn.github.io/images/ai_chapter_8/street2_mask.jpg" width="390">
</center></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>第八章</tag>
        <tag>目标检测</tag>
        <tag>目标识别</tag>
      </tags>
  </entry>
</search>
