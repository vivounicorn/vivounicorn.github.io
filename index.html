<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"vivounicorn.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="学习和思考，以心力提升认知">
<meta property="og:url" content="https://vivounicorn.github.io/index.html">
<meta property="og:site_name" content="学习和思考，以心力提升认知">
<meta property="og:locale">
<meta property="article:author" content="张磊">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://vivounicorn.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>学习和思考，以心力提升认知</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">学习和思考，以心力提升认知</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/page/2021/09/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BB%9F%E4%B8%80%E6%A1%86%E6%9E%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="张磊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习和思考，以心力提升认知">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/page/2021/09/14/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%B8%89%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%BB%9F%E4%B8%80%E6%A1%86%E6%9E%B6/" class="post-title-link" itemprop="url">机器学习与人工智能技术分享-第三章 机器学习中的统一框架</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-09-14 14:03:49 / Modified: 14:27:27" itemprop="dateCreated datePublished" datetime="2021-09-14T14:03:49+08:00">2021-09-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div style="float:left;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4gmqc1l38cpd11e61b97uvs9.png"  width="200" height="260" >
</div>
<div style="float:right;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4qcc01pn16mp7m3149c1dubm.png" width="200" height="260" >
</div>
<div style="float:none;clear:both;">

</div>
<h1 id="机器学习中的统一框架">3. 机器学习中的统一框架</h1>
<p>很多机器学习问题都可以放在一个统一框架下讨论，这样大家在理解各种模型时就是相互联系的。</p>
<h2 id="目标函数">3.1 目标函数</h2>
<p>回忆一下目标函数的定义：</p>
<p><span class="math display">\[w^*=\operatorname*{argmin}\limits_{w} \sum_{i=1}^N\underbrace{L(m_i(w))}_{Bias}+\underbrace{\lambda Reg(w)}_{Variance}\]</span></p>
<p>很多模型可以用这种形式框起来，比如linear regression、logistic regression、SVM、additive models、k-means，neural networks 等等。其中损失函数部分用来控制模型的拟合能力，期望降低偏差，正则项部分用来提升模型泛化能力，期望降低方差，最优模型是对偏差和方差的最优折中。</p>
<h3 id="损失函数">3.1.1 损失函数</h3>
损失函数反应了模型对历史数据的学习程度，我们期望模型能尽可能学到历史经验，得到一个低偏差模型。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1ap8fa5ue1egnr91dlm19n1r7hm.png" width="400" />
</center>
<p>Q：大家想想横坐标是什么？</p>
<p><span class="math display">\[
\begin{array}{l}
\text{0-1 loss: }&amp;L_{01}(m_i(w))=\amalg(m_{i}(w) \le 0)\\
\text{squared loss: }&amp;L_{2}(m_i(w))=\frac{1}{2}(m_{i}(w) -1)^2\\
\text{hinge loss: }&amp;L_{hinge}(m_i(w))=max(0,1-m_{i}(w))\\
\text{log loss: }&amp;L_{log}(m_i(w))=log(1+e^{-m_{i}(w)})\\
&amp;\text{where $m$ is called &#39;margin&#39;.}
\end{array}
\]</span></p>
<p>实践当中很少直接使用0-1损失做优化（当然也有这么用的如：<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/5214-direct-0-1-loss-minimization-and-margin-maximization-with-boosting.pdf">Direct 0-1 Loss Minimization and Margin Maximization with Boosting</a> 和 <a target="_blank" rel="noopener" href="http://www.jmlr.org/proceedings/papers/v28/nguyen13a.pdf">Algorithms for Direct 0–1 Loss Optimization in Binary Classification</a>，但总的来说应用有限），原因如下：</p>
<blockquote>
<ul>
<li>0-1损失的优化是组合优化问题且为NP-hard，无法在多项式时间内求得；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>损失函数非凸非光滑，很多优化方法无法使用；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>对权重的更新可能会导致损失函数大的变化，即变化不光滑；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>只能使用<span class="math inline">\(L_0\)</span>正则，其他正则形式都不起作用；</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>即使使用<span class="math inline">\(L_0\)</span>正则，依然是非凸非光滑，优化求解困难。</li>
</ul>
</blockquote>
<p>由于0-1损失的问题，所以以上损失函数都是对它的近似。原理细节可以参考：<a target="_blank" rel="noopener" href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding Machine Learning: From Theory to Algorithms</a></p>
不同损失函数在相同数据集下的直观表现如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1ap8g4c7s17bs1ffh1taedhjvr61g.png" width="400"/>
</center>
<h3 id="正则化项">3.1.2 正则化项</h3>
<p>正则化项影响的是模型在未知样本上的表现，我们希望通过它能降低模型方差提高泛化性。</p>
<p>如果有数据集:</p>
<p><span class="math display">\[D=\{(x_i,y_i)|i=1,2,3,...N\}\]</span> 在给定假设下，通常采用极大似然估计(MLE)求解参数：</p>
<p><span class="math display">\[w^*=\operatorname*{argmin}\limits_{w} \prod_{i=1}^N{-p(y_i|x_i;w)}=\operatorname*{argmin}\limits_{w} \sum_{i=1}^N{-log~p(y_i|x_i;w)}\]</span></p>
<p>假设模型参数也服从某种概率分布： <span class="math inline">\(w \sim p(w)\)</span>， 可以采用极大后验概率估计(MAP)求解参数。 <span class="math display">\[
\begin{array}{l}
 w^*=\operatorname*{argmin}\limits_{w} \prod_{i=1}^N{-p(w|x_i,y_i)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(w|x_i,y_i)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(x_i,y_i|w)p(w)}\\
 ~~~~=\operatorname*{argmin}\limits_{w}\sum_{i=1}^N{-log~p(x_i,y_i|w)-log~p(w)}\\
  ~~~~= \left\{ \begin{array}{1}
     \text{generative model} &amp; \operatorname*{argmin}\limits_{w}\sum_{i=1}^N[{\underbrace{-log~p(x_i,y_i|w)}_{Bias}-\underbrace{log~p(w)}_{Variance}}] \\
      \text{discriminative model} &amp; \operatorname*{argmin}\limits_{w}\sum_{i=1}^N[{\underbrace{-log~p(y_i|x_i;w)}_{Bias}-\underbrace{log~p(w)}_{Variance}}]
      \end{array} \right.
\end{array}
\]</span></p>
<h3 id="l2-正则">3.1.3 L2 正则</h3>
<p>假设 <span class="math inline">\(w_j \sim N(0,\delta_j^2)\)</span> <span class="math display">\[
\begin{array}{l}
\because p(w_j)=\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{w^2}{2\delta^2}}\\
\therefore Reg(w)=\sum_{i=1}^mw_i^2,\text{ m is the number of weights.}
\end{array}
\]</span></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa4p07h1h51j2aiv91klv8r21g.png" width="400"/>
</center>
<h3 id="l1-正则">3.1.4 L1 正则</h3>
<p>假设 <span class="math inline">\(w_j \sim Laplace(0,b_j)\)</span></p>
<p><span class="math display">\[
\begin{array}{l}
\because p(w_j)=\frac{1}{2b}e^{-\frac{|w_j|}{b}}\\
\therefore Reg(w)=\sum_{i=1}^m|w_i|,\text{ m is the number of weights.}
\end{array}
\]</span></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa4gt6gce5vqn1lc19jm1bhm.png" width="400"/>
</center>
<h3 id="正则化的几何解释">3.1.5 正则化的几何解释</h3>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apa5eiaehd01u531gcv1s5oem21t.png" width="400" />
</center>
<center>
L1 and L2 Regularization
</center>
<p>给定向量<span class="math inline">\(w = (w_1,..., w_n)\)</span>, 定义 <span class="math inline">\(L_q\)</span>正则，其中 <span class="math inline">\(n &gt; 0\)</span>：</p>
<p><span class="math display">\[
\begin{array}{l}
\parallel w \parallel_q=\sqrt[q]{\sum_{i=1}^n|w_i|^q}\\
\text{when $q=0$ we define $l_0$-norm to be the number of non-zero elements of the vector:}\\
\parallel w \parallel_0=\#~(i|x_i \ne 0)\\
\end{array}
\]</span></p>
不同q的取值下正则项的几何表现如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/l.png" width="300" />
</center>
<center>
from <a target="_blank" rel="noopener" href="https://commons.wikimedia.org/wiki/File:Norm-vergleich.gif">wiki</a>
</center>
<h3 id="dropout正则化与数据扩充">3.1.6 Dropout正则化与数据扩充</h3>
<p>这两类方法在神经网络中比较常用，后面会专门介绍。</p>
<h2 id="神经网络框架">3.2 神经网络框架</h2>
<p>很多模型可以看做是神经网络，例如：感知机、线性回归、支持向量机、逻辑回归等</p>
<h3 id="linear-regression">3.2.1 Linear Regression</h3>
线性回归可以看做是激活函数为<span class="math inline">\(f(x)=x\)</span>的单层神经网络：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apae0i741rsj1a0r1ns22k9eis2n.png" width="400" />
</center>
<h3 id="logistic-regression">3.2.2 Logistic Regression</h3>
逻辑回归可以看做是激活函数为<span class="math inline">\(f(x)=\frac{1}{1+e^{-x}}\)</span>的单层神经网络：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apadm18v2cl4rf1dik16uu1nsc2a.png" width="500"/>
</center>
</center>
<h3 id="support-vector-machine">3.2.3 Support Vector Machine</h3>
采用核方法后的支持向量机可以看做是含有一个隐层的3层神经网络：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apag746u1qhdd1r1ku6tv01v423u.png" width="400" />
</center>
<h3 id="bootstrap-neural-networks">3.2.4 Bootstrap Neural Networks</h3>
采用bagging方式的组合神经网络：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apagfhml1hg719r15ukv7m7ro55.png" width="400" />
</center>
<h3 id="boosting-neural-network">3.2.5 Boosting Neural Network</h3>
采用boosting方式的组合神经网络：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_3/image_1apaghfqm75bu4l1n2m164e17d25i.png" width="400" />
</center>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/page/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%E5%9B%9E%E9%A1%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="张磊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习和思考，以心力提升认知">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/page/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%E5%9B%9E%E9%A1%BE/" class="post-title-link" itemprop="url">机器学习与人工智能技术分享-第二章 建模方法回顾</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-13 16:55:54" itemprop="dateCreated datePublished" datetime="2021-09-13T16:55:54+08:00">2021-09-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-09-14 14:00:57" itemprop="dateModified" datetime="2021-09-14T14:00:57+08:00">2021-09-14</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div style="float:left;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4gmqc1l38cpd11e61b97uvs9.png"  width="200" height="260" >
</div>
<div style="float:right;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4qcc01pn16mp7m3149c1dubm.png" width="200" height="260" >
</div>
<div style="float:none;clear:both;">

</div>
<h1 id="建模方法回顾">2. 建模方法回顾</h1>
<p>以通用的监督学习为例，基本包含4个部分:</p>
<p><span class="math display">\[
\begin{array}{l}
\text{1. Prediction:  }y_i=f(x_i|w),~i=1,2,.....\\
\text{2. Parameters:  }w=\{w_i|i=1,2,...,dim\}\\
\text{3. Objective function:  }obj(w)=loss(w)+reg(w)\\
\text{4. Optimization:  }min~obj(w) \text{ with(out) constraint.}\\
\end{array}
\]</span></p>
<h2 id="偏差与方差">2.0 偏差与方差</h2>
<blockquote>
<ul>
<li>在机器学习算法中，偏差是由先验假设的不合理带来的模型误差，高偏差会导致<strong>欠拟合</strong>： 所谓欠拟合是指对特征和标注之间的因果关系学习不到位，导致模型本身没有较好的学到历史经验的现象；</li>
<li>方差表征的是模型误差对样本发生一定变化时的敏感度，高方差会导致<strong>过拟合</strong>：模型对训练样本中的随机噪声也做了拟合学习，导致在未知样本上应用时出现效果较差的现象；</li>
<li>机器学习模型的核心之一在于其推广能力，即在未知样本上的表现。</li>
</ul>
</blockquote>
对方差和偏差的一种直观解释:
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoqq68m81tb5rsd1k71llid5k13.png" width="400" />
</center>
<p>一个例子，假如我们有预测模型:</p>
<blockquote>
<p><span class="math display">\[
\begin{array}{l}
y=f(x)+\epsilon\\
\epsilon \sim N(0,\sigma)
\end{array}
\]</span></p>
</blockquote>
<p>我们希望用 <span class="math inline">\(f^{e}(x)\)</span> 估计 <span class="math inline">\(f(x)\)</span>，如果使用基于square loss 的线性回归，则误差分析如下: &gt; <span class="math display">\[
\begin{array}{l}
Err(x)=E[(y-f^{e}(x))^2]\\
~~~~~~~~~~~~=E[(f(x)-f^{e}(x))^2]+\sigma_e^2\\
~~~~~~~~~~~~=[f(x)]^2-2f(x)E[f^{e}(x)]+E[f^{e}(x)^2]+\sigma_e^2\\
~~~~~~~~~~~~=E[f^{e}(x)]^2-2f(x)E[f^{e}(x)]+[f(x)]^2\\
~~~~~~~~~~~~+E[f^{e}(x)^2]-2E[f^{e}(x)]^2+E[f^{e}(x)]^2+\sigma_e^2\\
~~~~~~~~~~~~=E[f^{e}(x)]^2-2f(x)E[f^{e}(x)]+[f(x)]^2\\
~~~~~~~~~~~~+E[f^{e}(x)^2-2f^{e}(x)E[f^{e}(x)]+E[f^{e}(x)]^2]+\sigma_e^2\\
~~~~~~~~~~~~=\underbrace{(E[f^{e}(x)]-f(x))^2}_{Bias^2}+\underbrace{E[(f^{e}(x)-E[f^{e}(x)])^2]}_{Variance}+\sigma_e^2\\
\end{array}
\]</span></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoqrsu9k1u936ff1gps16anac61g.png" width="400"/>
</center>
<p>所以大家可以清楚的看到模型学习过程其实就是对偏差和方差的折中过程。</p>
<h2 id="线性回归-linear-regression">2.1 线性回归-Linear Regression</h2>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aoif9nr11ft1j95hca71a1a9dm.png" width="400"  />
</center>
<center>
简单线性回归
</center>
<h3 id="模型原理">2.1.1 模型原理</h3>
<p>标准线性回归通过对自变量的线性组合来预测因变量，组合自变量的权重通过最小化训练集中所有样本的预测平方误差和来得到，原理如下。</p>
<blockquote>
<ul>
<li>预测函数</li>
</ul>
</blockquote>
<p><span class="math display">\[ \tilde y_i=\sum_{i=1}^N w^Tx_i\]</span></p>
<blockquote>
<ul>
<li>参数学习－采用最小二乘法</li>
</ul>
</blockquote>
<p><span class="math display">\[min~\frac{1}{2}\sum_{i=1}^N(y_i-\tilde y_i)^2\]</span></p>
<p>所有机器学习模型的成立都会有一定的先验假设，线性回归也不例外，它对数据做了以下强假设:</p>
<blockquote>
<ul>
<li>自变量相互独立，无多重共线性</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>因变量是自变量的线性加权组合：</li>
</ul>
</blockquote>
<p><span class="math display">\[y=w^Tx+\epsilon\]</span></p>
<blockquote>
<ul>
<li>所有样本独立同分布(iid)，且误差项服从以下分布：</li>
</ul>
</blockquote>
<p><span class="math display">\[\epsilon \sim N(0,\sigma^2)\]</span></p>
<p>最小二乘法与以上假设的关系推导如下: <span class="math display">\[
\begin{array}{l}
\because y=w^Tx+\epsilon,~~~~~\epsilon \sim N(0,\sigma^2)\\
\therefore p(y|x) = N(w^Tx,\sigma^2)\\
\Rightarrow p(y|x) = \frac{1}{\sqrt {2\pi}\sigma} e^{-\frac{(y-w^Tx)^2}{2\sigma^2}}
\end{array}
\]</span></p>
<p>使用MLE(极大似然法)估计参数如下: <span class="math display">\[
\begin{array}{l}
w=arg~max_w\sum_{i=1}^Nlog~p(y_i|x_i)\\
\Leftrightarrow w=arg~min_w\frac{1}{2}\sum_{i=1}^N{(y_i-w^Tx_i)^2}
\end{array}
\]</span></p>
<p>线性回归有两个重要变体：</p>
<ul>
<li>Lasso Regression:采用L1正则并使用MAP做参数估计</li>
<li>Ridge Regression:采用L2正则并使用MAP做参数估计</li>
</ul>
<p>关于正则化及最优化后续会做介绍。</p>
<h3 id="损失函数">2.1.2 损失函数</h3>
<p><strong>损失函数1 —— Least Square Loss</strong></p>
<p><span class="math display">\[loss(x)=\frac{1}{2}\sum_{i=1}^N(y_i-\tilde y_i)^2\]</span></p>
<p>进一步阅读可参考：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Least_squares">Least Squares</a></p>
<p>Q: 模型和损失的关系是什么?</p>
<h2 id="支持向量机-support-vector-machine">2.2 支持向量机-Support Vector Machine</h2>
<p>支持向量机通过寻找一个分类超平面使得(相对于其它超平面)它与训练集中任何一类样本中最接近于超平面的样本的距离最大。虽然从实用角度讲(尤其是针对大规模数据和使用核函数)并非最优选择，但它是大家理解机器学习的最好模型之一，涵盖了类似偏差和方差关系的泛化理论、最优化原理、核方法原理、正则化等方面知识。</p>
<h3 id="模型原理-1">2.2.1 模型原理</h3>
<p>SVM原理可以从最简单的解析几何问题中得到：</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aonhhgoo83ei2ca021k5vfc11j.png" width="400"  />
</center>
<p>超平面的定义如下: <span class="math display">\[
\begin{array}{l}
y=f(x)=w^Tx+b\\
f(x)=0
\end{array}
\]</span></p>
<p>从几何关系上来看，超平面与数据点的关系如下(以正样本点为例)： <span class="math display">\[
\begin{array}{l}
x_i=p_i+\gamma_i\frac{w}{\Arrowvert w\Arrowvert}\\
\text{where the p is point  x&#39;s projection on the hyperplane.}\\
\Leftrightarrow w^Tx_i+b=w^Tp_i+b+\gamma_i\frac{w^Tw}{\Arrowvert w\Arrowvert}\\
\because f(p_i)=0\\
\therefore f(x_i)=\gamma_i\Arrowvert w\Arrowvert\\
\Rightarrow \gamma_i=\frac{f(x_i)}{\Arrowvert w\Arrowvert}\\
\text{consider two cases(label=}\pm1\text{)}\\
\Rightarrow \gamma_i=\frac{y_if(x_i)}{\Arrowvert w\Arrowvert}\\
\text{set}~~\tilde{\gamma_i}=y_if(x_i)\\
\Rightarrow \gamma_i=\frac{\tilde{\gamma_i}}{\Arrowvert w\Arrowvert}
\end{array}
\]</span></p>
<p>定义几何距离和函数距离分别如下： <span class="math display">\[
\begin{array}{l}
\text{relative geometric margin:}~~~~\tilde{\gamma}=min_1^N\tilde{\gamma_i}\\
\text{relative functional margin:}~~~~\gamma=min_1^N\gamma_i
\end{array}
\]</span></p>
<p>由于超平面的大小对于SVM求解并不重要，重要的是其方向，所以根据SVM的定义,得到约束最优化问题： <span class="math display">\[
\begin{array}{l}
max~~\gamma\\
~~~st.~y_i\frac{f(x_i)}{\Arrowvert w\Arrowvert}\ge \gamma,~~i=1,2....N\\
\Leftrightarrow \\
max~\frac{\tilde{\gamma}}{\Arrowvert w\Arrowvert}\\
~~~st.~y_if(x_i)\ge \tilde{\gamma},~~i=1,2....N\\
\text{the value of } \tilde{\gamma}\text{ does not affect the solution of the problem.}\\
\text{to set } \tilde{\gamma}=1.\\
\Leftrightarrow \\
min~\frac{1}{2}\Arrowvert w\Arrowvert^2\\
~~~st.~y_if(x_i)-1\ge 0,~~i=1,2....N\\
\end{array}
\]</span></p>
现实当中我们无法保证数据是线性可分的，强制要求所有样本能正确分类是不太可能的，即使做了核变换也只是增加了这种可能性，因此我们又需要做折中，允许误分的情况出现，对误分的样本根据其严重性做惩罚，所以引入松弛变量，将上述问题变成软间隔优化问题。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1aont3ghm1g1e18qk18b492k1nd20.png" width="400" />
</center>
<p>新的优化问题： <span class="math display">\[
\begin{array}{l}
min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^Ng(\xi_i)\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
~~~~~~~~~~~g(\xi)=\xi \text{ or } g(\xi)=\xi^2.....\\
\end{array}
\]</span></p>
<p>如果选择： <span class="math display">\[g(\xi)=\xi\]</span></p>
<p>那么优化问题变成： <span class="math display">\[
\begin{array}{l}
min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\end{array}
\]</span></p>
<h3 id="损失函数-1">2.2.2 损失函数</h3>
<p><strong>损失函数2 —— Hinge Loss</strong></p>
<p><span class="math display">\[loss(x)=\sum_{i=1}^N[1-y_if(x_i)]_+\]</span></p>
<p>使用hinge loss将SVM套入机器学习框架，让它更容易理解。此时原始约束最优化问题变成损失函数是hinge loss且正则项是L2正则的无约束最优化问题：</p>
<p><span class="math display">\[
\begin{array}{l}
(1)min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\Leftrightarrow \\
(2)min~\sum_{i=1}^N[1-y_if(x_i)]_++\lambda \Arrowvert w\Arrowvert^2
\end{array}
\]</span></p>
<p>下面我证明以上问题(1)和问题(2)是等价的(反之亦然)：</p>
<p><span class="math display">\[
\begin{array}{l}
&amp;&amp; \because 1-y_if(x_i)\leq \xi_i \text{ and }0 \leq \xi_i\\
&amp;&amp; \text{if }1-y_if(x_i)\geq 0 \text{ then}\\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~~\Leftrightarrow \\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N1-y_if(x_i)\\
&amp;&amp; \text{if }1-y_if(x_i)&lt;0\text{ then}\\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~~\Leftrightarrow \\
&amp;&amp; ~~~~min~\frac{1}{2}\Arrowvert w\Arrowvert^2\\
&amp;&amp; \therefore\\
&amp;&amp; min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
&amp;&amp; ~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
&amp;&amp; ~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\Leftrightarrow \\
&amp;&amp; min~\sum_{i=1}^N[1-y_if(x_i)]_++\lambda \Arrowvert w\Arrowvert^2\\
\end{array}
\]</span></p>
<p>到此为止，SVM和普通的判别模型没什么两样，也没有support vector的概念，它之所以叫SVM就得说它的对偶形式了，通过拉格朗日乘数法对原始问题做对偶变换：</p>
<p><span class="math display">\[
\begin{array}{l}
min~\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum_{i=1}^N\xi_i\\
~~~st.~y_if(x_i)\ge 1-\xi_i,~~i=1,2....N\\
~~~~~~~~~\xi_i\ge 0,~~i=1,2....N\\
\Rightarrow \\
L(w,b,\xi,\alpha,\mu)=\frac{1}{2}\Arrowvert w\Arrowvert^2+C\sum\limits_{i=1}^{N}\xi_i\\
~~~~~~~~-\sum\limits_{i=1}^{N}\alpha_i(y_i(w^Tx_i+b)-1+\xi_i)-\sum\limits_{i=1}^{N}\mu_i\xi_i\\
\text{(KKT conditions)}\\
\frac{\partial{L}}{\partial{w}}=w-\sum\limits_{i=1}^{n}y_i\alpha_i x_i=0\\
\frac{\partial{L}}{\partial{b}}=\sum\limits_{i=1}^{n}y_i\alpha_i=0\\
\frac{\partial L}{\partial \xi}=C-\alpha-\mu=0\\
\text{(Complementary Slackness condition)}\\
\alpha_i(y_i(w^Tx_i+b)- 1+\xi_i)=0\\
\mu_i\xi_i=(\alpha_i-C)\xi_i=0\\
\alpha_i\geq 0\\
\xi_i\geq 0\\
\mu_i\geq 0\\
\text{(Replace inner product with the kernel function)}\\
\\
\Rightarrow \\
max~\sum\limits_{i=1}^{N}\alpha_i-\frac{1}{2}\sum\limits_{i,j=1}^{N}{y_iy_j\alpha_i\alpha_j(K(x_i,x_j))}\\
~~~st.~\sum\limits_{i=1}^{n}y_i\alpha_i=0\\
~~~~~~~~~~0 \leq \alpha_i \leq C\\
\end{array}
\]</span></p>
<p>从互补松弛条件可以得到以下信息：</p>
<p>当<span class="math inline">\(\alpha_i=C\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>不为零，此时其几何间隔小于<span class="math inline">\(1/\Arrowvert w\Arrowvert\)</span>，对应样本点就是误分点；当<span class="math inline">\(\alpha_i=0\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>为零，此时其几何间隔大于<span class="math inline">\(1\Arrowvert w\Arrowvert\)</span>，对应样本点就是内部点，即分类正确而又远离最大间隔分类超平面的那些样本点；而<span class="math inline">\(0 &lt; \alpha_i &lt;C\)</span>时，松弛变量<span class="math inline">\(\xi_i\)</span>为零，此时其几何间隔等于<span class="math inline">\(1/ \Arrowvert w\Arrowvert\)</span>，对应<strong>样本点</strong>就是<strong>支持向量</strong>。<span class="math inline">\(\alpha_i\)</span>的取值一定是<span class="math inline">\([0,C]\)</span>，这意味着向量<span class="math inline">\(\alpha\)</span>被限制在了一个边长为<span class="math inline">\(C\)</span>的盒子里。 详细说明可参考:<a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/22/1913538.html29le/image_1asr9qkai1mseu8n13i8ele1sf89.png">SVM学习——软间隔优化</a>。</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1asr9qkai1mseu8n13i8ele1sf89.png" width="500" />
</center>
<center>
<span class="math inline">\(C\)</span>越大表明你越不想放弃离群点，分类超平面越向离群点移动
</center>
<p>当以上问题求得最优解<span class="math inline">\(\alpha^*\)</span>后，几何间隔变成如下形式： <span class="math display">\[\gamma=(\sum\limits_{i,j \in \{support~vectors\}}y_iy_j\alpha_i^*\alpha_j^*K(x_i,x_j))^{-1/2}\]</span> 它只与有限个样本有关系，这些样本被称作支持向量，从这儿也能看出此时模型参数个数与样本个数有关系，这是典型的非参学习过程。</p>
<h3 id="核方法">2.2.3 核方法</h3>
<p>上面对将内积<span class="math inline">\(x_i^Tx_j\)</span>用一个核函数<span class="math inline">\(K(x_i,x_j)\)</span>做了代替，实际上这种替换不限于SVM，所有出现样本间内积的地方都可以考虑这种核变换，本质上它就是通过某种隐式的空间变换在新空间(有限维或无限维兼可)做样本相似度衡量，采用核方法后的模型都可以看做是无固定参数的基于样本的学习器，属于非参学习，核方法与SVM这类模型的发展是互相独立的。</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1astp4htfueu10v51ciq1ab32sr9.png" width="500" />
</center>
<center>
from <a target="_blank" rel="noopener" href="http://www.eric-kim.net/eric-kim-net/posts/1/kernel_trick.html">Kernel Trick</a>
</center>
<p>这里不对原理做展开，可参考：</p>
<p>1、<a target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0521813972/qid=1137139342/sr=11-1/ref=sr_11_1/002-7679689-7393625?n=283155">Kernel Methods for Pattern Analysis</a></p>
<p>2、<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/1862-the-kernel-trick-for-distances.pdf">the kernel trick for distances</a></p>
<p>一些可以应用核方法的模型：</p>
<blockquote>
<ul>
<li>SVM</li>
<li>Perceptron</li>
<li>PCA</li>
<li>Gaussian processes</li>
<li>Canonical correlation analysis</li>
<li>Ridge regression</li>
<li>Spectral clustering</li>
</ul>
</blockquote>
<p>在我看来核方法的意义在于： 1、对样本进行空间映射，以较低成本隐式的表达样本之间的相似度，改善样本线性可分的状况，但不能保证线性可分； 2、将线性模型变成非线性模型从而提升其表达能力，但这种升维的方式往往会造成计算复杂度的上升。</p>
<p>一些关于SVM的参考资料:</p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/02/1894311.html">SVM学习——线性学习器</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/06/1897702.html">SVM学习——求解二次规划问题</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/13/1904720.html">SVM学习——核函数</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/18/1909709.html">SVM学习——统计学习理论</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2010/12/22/1913538.html">SVM学习——软间隔优化</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2011/01/13/1934296.html">SVM学习——Coordinate Desent Method</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2011/06/01/2067496.html">SVM学习——Sequential Minimal Optimization</a></p>
<p><a target="_blank" rel="noopener" href="http://www.cnblogs.com/vivounicorn/archive/2011/08/25/2152824.html">SVM学习——Improvements to Platt’s SMO Algorithm</a></p>
<h2 id="逻辑回归-logistic-regression">2.3 逻辑回归-Logistic Regression</h2>
<p>逻辑回归恐怕是互联网领域用的最多的模型之一了，很多公司做算法的同学都会拿它做为算法系统进入模型阶段的baseline。</p>
<h3 id="模型原理-2">2.3.1 模型原理</h3>
<p>逻辑回归是一种判别模型，与线性回归类似，它有比较强的先验假设 :</p>
<ul>
<li>假设因变量服从贝努利分布</li>
</ul>
<p><span class="math display">\[
 \begin{array}{l}
 p(y|x)=Bernoulli(\pi)\\
 ~~~~~~~=p(y=1|x)^y(1-p(y=1|x))^{1-y},y\in\{0,1\}
 \end{array}
 \]</span></p>
<ul>
<li>假设训练样本服从<strong>钟形分布</strong>，例如高斯分布：</li>
</ul>
<p><span class="math display">\[p(x_i|y=y_k)=Gaussian(\mu_{ik},\sigma_i)\]</span></p>
<ul>
<li><p><span class="math inline">\(y\)</span> 是样本标注，布尔类型，取值为0或1；</p></li>
<li><p><span class="math inline">\(x\)</span> 是样本的特征向量。</p></li>
</ul>
<p>逻辑回归是判别模型，所以我们直接学习<span class="math inline">\(p(y|x)\)</span>，以高斯分布为例:</p>
<p><span class="math display">\[p(y=1|x)=\frac{1}{1+e^{-(w^Tx+b)}}\]</span></p>
<p><span class="math display">\[p(y=0|x)=\frac{1}{1+e^{(w^Tx+b)}}\]</span></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap1pq34s184n18stpt413bq12at9.png" width="400"  />
</center>
<p>整个原理部分的推导过程如下：</p>
<span class="math display">\[\begin{array}{l}
p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}\\
~~~~~~~~~~~~~~~~~~=\frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1)+p(x|y=0)p(y=0)}\\
~~~~~~~~~~~~~~~~~~=\frac{1}{1+\frac{p(x|y=0)p(y=0)}{p(x|y=1)p(y=1)}}\\
~~~~~~~~~~~~~~~~~~=\frac{1}{1+\frac{p(x|y=0)(1-p(y=1))}{p(x|y=1)p(y=1)}}~~\text {to set p(y=1)=}\pi\\
~~~~~~~~~~~~~~~~~~=\frac{1}{1+\frac{p(x|y=0)(1-\pi)}{p(x|y=1)\pi}}\\
~~~~~~~~~~~~~~~~~~=\frac{1}{1+e^{ln\frac{1-\pi}{\pi}+ln\frac{p(x|y=0)}{p(x|y=1)}}}\\
~~~~~~~~~~~~~~~~~~=\frac{1}{1+e^{ln\frac{1-\pi}{\pi}+\sum_iln\frac{p(x_i|y=0)}{p(x_i|y=1)}}}\\
\because p(x_i|y_k)=\frac{1}{\sigma_{ik}\sqrt{2\pi}}e^{-\frac{(x_i-\mu_{ik})^2}{2\sigma_{ik}^2}}\\
\therefore p(y=1|x)=\frac{1}{1+e^{-(ln\frac{\pi-1}{\pi}+\sum_i(\frac{\mu_{i1}-\mu_{i0}}{\sigma_i^2}x_i+\frac{\mu_{i0}^2-\mu_{i1}^2}{2\sigma_i^2}))}}\\
~~~~~~~~~~~~~~~~~~~~~~=\frac{1}{1+e^{-(\sum_iw_ix_i+b)}},i=1,2,...,dim\\
~~~~~~~~~~~~~~~~~~~~~~\text{where}\\
~~~~~~~~~~~~~~~~~~~~~~b=\sum_i\frac{\mu_{i0}^2-\mu_{i1}^2}{2\sigma_i^2}+ln\frac{\pi-1}{\pi}\\
~~~~~~~~~~~~~~~~~~~~~~w_i=\frac{\mu_{i1}-\mu_{i0}}{\sigma_i^2}
\end{array}\]</span>
<p>采用 MLE 或者 MAP 做参数求解:</p>
<p><span class="math display">\[
\begin{array}{l}
w=arg~max_w\sum_{i=1}^Nln~p(y_i|x_i)\\
\Leftrightarrow \\
w=arg~min_w\sum_{i=1}^N{y_iln~p(y_i=1|x_i)+(1-y_i)ln~p(y_i=0|x_i)}
\end{array}
\]</span></p>
<h3 id="损失函数-2">2.3.2 损失函数</h3>
<p><strong>损失函数3 —— Cross Entropy Loss</strong></p>
<p><span class="math display">\[
\begin{array}{l}
loss(x)=H_p(q)=\sum_{i=1}^N\sum_y(\int_y) p(y|x_i)ln\frac{1}{q(y|x_i)}\\
\text{especially for bernoulli distribution:}\\
loss(x)=\sum_{i=1}^Ny_i ln ~p(y_i|x_i)+(1-y_i)(1-ln~p(y_i|x_i))
\end{array}
\]</span></p>
<p>简单理解，从概率角度：Cross Entropy损失函数衡量的是两个概率分布<span class="math inline">\(p\)</span>与<span class="math inline">\(q\)</span>之间的相似性，对真实分布估计的越准损失越小；从信息论角度：用编码方式<span class="math inline">\(q\)</span>对由编码方式<span class="math inline">\(p\)</span>产生的信息做编码，如果两种编码方式越接近，产生的信息损失越小。与Cross Entropy相关的一个概念是Kullback–Leibler divergence，后者是衡量两个概率分布接近程度的标量值，定义如下： <span class="math display">\[D_q(p) = \sum_x(\int_x) p(x)\log_2\left(\frac{p(x)}{q(x)} \right)\]</span> 当两个分布完全一致时其值为0，显然Cross Entropy与Kullback–Leibler divergence的关系是： <span class="math display">\[H_p(q)=H(p)+D_q(p)\]</span></p>
<p>关于交叉熵及其周边原理，有一篇文章写得特别好：<strong><a target="_blank" rel="noopener" href="http://colah.github.io/posts/2015-09-Visual-Information/">Visual Information Theory</a></strong>。</p>
<h2 id="bagging-and-boosting框架">2.4 Bagging and Boosting框架</h2>
<p>Bagging和Boosting是两类最常用以及好用的模型融合框架，殊途而同归。</p>
<h3 id="bagging框架">2.4.1 Bagging框架</h3>
Bagging(Breiman, 1996) 方法是通过对训练样本和特征做有放回的抽样，并拟合若干个基础模型进而通过投票方式做最终分类决策的框架。每个基础分类器（可以是树形结构、神经网络等等任何分类模型）的特点是<strong>低偏差、高方差</strong>，框架通过(加权)投票方式降低方差，使得整体趋于<strong>低偏差、低方差</strong>。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2hfjae8q6nta1ppd10l1fkv1g.png" width="600" />
</center>
<p>分析如下：</p>
<p>假设任务是学习一个模型 <span class="math inline">\(y=f(x)\)</span> ，我们通过抽样生成生成<span class="math inline">\(N\)</span> 个数据集，并训练得到<span class="math inline">\(N\)</span>个基础分类器<span class="math inline">\(c_i......c_N\)</span>。</p>
<p><span class="math display">\[
\begin{array}{l}
\text{define}:\\
~~~~~~~~(1). y=f(x), \text{prediction function}\\
~~~~~~~~(2). o_i(x)=c_i(x), \text{ $c_i$ is the i-th classifier}\\
~~~~~~~~(3). \overline{o}(x)=\sum_{i=1}^Nw_io_i(x), \text{ where } \sum_{i=1}^Nw_i=1\\
~~~~~~~~(4). v_i(x)=[o_i(x)-\overline{o}(x)]^2\\
~~~~~~~~(5). \overline{v}(x)=\sum_{i=1}^Nw_iv_i(x)=\sum_{i=1}^Nw_i[o_i(x)-\overline{o}(x)]^2\\
~~~~~~~~(6). \overline{\epsilon}(x)=\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2]\\
~~~~~~~~(7). e(x)=(f(x)-\overline{o}(x))^2 \\
\because \overline{v}(x)=\sum_{i=1}^Nw_i[o_i(x)-\overline{o}(x)]^2\\
~~~~~~~~~~~=\sum_{i=1}^Nw_i[(f(x)-o_i(x))-(f(x)-\overline{o}(x))]^2\\
~~~~~~~~~~~=\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2+(f(x)-\overline{o}(x))^2\\
~~~~~~~~~~~~~~~~~~~-2(f(x)-o_i(x))(f(x)-\overline{o}(x))]\\
~~~~~~~~~~~=\sum_{i=1}^Nw_i[(f(x)-o_i(x))^2]-(f(x)-\overline{o}(x))^2\\
\therefore e(x)=\overline{\epsilon}(x)-\overline{v}(x)
\end{array}
\]</span></p>
<p>从结论可以发现多分类器投票机制的引入可以降低模型方差从而降低分类错误率，大家可以多理解理解这一系列推导。</p>
<h3 id="boosting框架">2.4.2 Boosting框架</h3>
Boosting(Freund &amp; Shapire, 1996) 通过迭代方式训练若干基础分类器，每个分类器依据上一轮分类器产生的残差做权重调整，每轮的分类器需要够“简单”，具有<strong>高偏差、低方差</strong>的特点，框架再辅以(加权)投票方式降低偏差，使得整体趋于<strong>低偏差、低方差</strong>。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2e2geqo3a11ur18od2b413ek13.png" width="600" />
</center>
<p>一个简单的总结: <span class="math display">\[
\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
\text{where }f_i\text{ is the base classier }i\\
~~~~~~~~~~~w_i \text{ is the weight of classier }i\\
~~~~~~~~~~~x \text{ is the feature vector of example}\\
\text{define:}\\
~~~~~~~\text{(1). margin of an example(x,y) with respect to the classier is yF(x)}\\
~~~~~~~\text{(2). cost function of $N$ examples is $C(F)=\frac{1}{N}\sum_{i=1}^NC(y_iF(x_i))$}\\
\text{Now we wish to find a new $f$ to add to F so that $C(F+\alpha f)$ can be decreased}\\
\because C(F+\alpha f)=C(F)+\alpha\langle\nabla{C(F)},f\rangle\\
\therefore \text{the greatest reduction of $C$ will satisfied: }\\
~~~~f=Max~-\langle\nabla{C(F)},f\rangle
\end{array}
\]</span></p>
<p>AnyBoost Algorithm</p>
<p>Boost算法是个框架，很多模型都能往进来套。 <span class="math display">\[
\begin{array}{l}
F_0(x)=0\\
\text{for $i$=0 to T:}\\
~~~~~~f_{t+1}=classifier(F_t)\\
~~~~~~if~~-\langle\nabla{C(F)},f_{t+1}\rangle \le0:\\
~~~~~~~~~~~~return~F_t\\
~~~~~~choose~w_{t+1}\\
~~~~~~F_{t+1}=F_t+w_{t+1}f_{t+1}\\
return~F_{T+1}
\end{array}
\]</span></p>
<p>Q: boosting 和 margin的关系是什么（机器学习中margin的定义为<span class="math inline">\(yf(x)\)</span>）？</p>
<p>Q: 类似bagging，为什么boosting能够通过reweight及投票方式降低整体偏差？</p>
<h2 id="additive-tree-模型">2.5 Additive Tree 模型</h2>
<p>Additive tree models (ATMs)是指基础模型是树形结构的一类融合模型，可做分类、回归，很多经典的模型可以被看做ATM模型，比如Random forest 、Adaboost with trees、GBDT等。</p>
<p>ATM 对N棵决策树做加权融合，其判别函数为：</p>
<p><span class="math display">\[
\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
\text{where }f_i\text{ is the output of tree }i\\
~~~~~~~~~~~w_i \text{ is the weight of tree }i\\
~~~~~~~~~~~x \text{ is the feature vector of instance}
\end{array}
\]</span></p>
<h3 id="random-forests">2.5.1 Random Forests</h3>
Random Forest 属于bagging类模型，每棵树会使用各自随机抽样样本和特征被独立的训练。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2m8teo1kqg1up8mtvccpfns2a.png" width="400" />
</center>
<p><span class="math display">\[
\begin{array}{l}
\text{for $t$ = 1 to $T$:}\\
~~~~~~~\text{(1). Sample $n$ instances from the dataset with replacement}\\
~~~~~~~\text{(2). Randomization:}\\
~~~~~~~~~~~~~~\text{$\bullet$ Bootstrap samples.}\\
~~~~~~~~~~~~~~\text{$\bullet$ Random selection of $K\le p$ split variables.}\\
~~~~~~~~~~~~~~\text{$\bullet$ Random selection of threshold.}\\
~~~~~~~\text{(2). Train an low-bias unpruned decision or regression tree $f_t$ on the sampled instances }\\
\\
\text{The final is the average of the outputs from all the trees:}\\
F(x)=\sum_{i=1}^Tw_if_i(x)\\
~~~where~\sum_{i=1}^Tw_i=1,~(such~ as ~w_i=\frac{1}{T})
\end{array}
\]</span></p>
<h3 id="adaboost-with-trees">2.5.2 AdaBoost with trees</h3>
<p>AdaBoost with trees通过训练多个弱分类器来组合得到一个强分类器，每次迭代会生成一棵<strong>高偏差、低方差</strong>的树形弱分类器，每一轮的训练会更关注上一轮被分类器分错的样本，为其加大权重，训练过程如下：</p>
<p><span class="math display">\[
\begin{array}{l}
f_0(x)=0\\
\text{for $i$=1 to $T$:}\\
~~~~~~~~~~~minimize~\sum_{i=1}^NL(y_i,F_t(x_i)+\alpha_tf_t(x_i))\\
~~~~~~~~~~~F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\\
\\
\text{The final is weighted average of the outputs from all the weak classifiers:}\\
F(x)=\sum_{i=1}^T\alpha_if_i(x)\\
\end{array}
\]</span></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap2oflv078q1h631peataq13ih2n.png" width="500" />
</center>
<center>
From Bishop(2006)
</center>
<h3 id="gradient-boosting-decision-tree">2.5.3 Gradient Boosting Decision Tree</h3>
<p>Gradient boosted 是一类boosting的技术，不同于Adaboost加大误分样本权重的策略，它每次迭代加的是上一轮梯度更新值： <span class="math display">\[\sum_{i=1}^NL(y_i,F_t(x_i)+\alpha_tf_t(x_i))\]</span></p>
<p>其训练过程如下:</p>
<p><span class="math display">\[
\begin{array}{l}
F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\\
f_t(x_i)\thickapprox -\frac{\partial L(y_i,F_t(x_i))}{\partial F_t(x_i)}\\
~~~~~~~~~~~~~~~\text{where $\alpha_t$ is the learning rate.}
\end{array}
\]</span></p>
GBDT是基础分类器为决策树的可做分类和回归的模型。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/gbdt.png" width="400" />
</center>
目前我认为最好的GBDT的实现是XGBoost: 其回归过程的示例图如下，通过对样本落到每棵树的叶子节点的权重值做累加来实现回归(或分类)：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap5297q1nte1tkpb3u1lfr1pk45c.png" width="500"  />
</center>
<center>
Regression Tree Ensemble from chentianqi
</center>
<p>其原理推导如下：</p>
<p><span class="math display">\[
\begin{array}{l}
\text{Prediction model: }F(x)=\sum_{i=1}^Tw_if_i(x)\\
\text{Objective: }obj^t=\sum_{i=1}^NL(y_i,F_i^t(x_i))+\Omega(f_t)\\
~~~~~~~~~~~~~~~~~\text{where N is instance numbers and t is current trees.}\\
\because obj^t=\sum_{i=1}^NL(y_i,F_i^t(x_i))+\Omega(f_t)\\
~~~~~~~~~=\sum_{i=1}^NL(y_i,F_i^{t-1}(x_i)+w_tf_t(x_i))+\Omega(f_t)\\
\text{Recall: }f(x+\Delta x)\thickapprox f(x)+\nabla f(x)\Delta x+\frac{1}{2}\nabla^2 f(x)\Delta x^2\\
\therefore obj^t\thickapprox\sum_{i=1}^N[L(y_i,F_i^{t-1}(x_i))+\nabla _{F_{t-1}}L(y_i,F_i^{t-1}(x_i))w_tf_t(x_i)\\
~~~~~~~~~~~~~~~\frac{1}{2}\nabla _{F_{t-1}}^2L(y_i,F_i^{t-1}(x_i))w_t^2f_t^2(x_i)]+\Omega(f_t)\\
\text{set $g_i=\nabla _{F_{t-1}}L(y_i,F_i^{t-1}(x_i))$}\\
~~~~~~h_i=\nabla _{F_{t-1}}^2L(y_i,F_i^{t-1}(x_i))\\
~~~obj^t\thickapprox \sum_{i=1}^N[L(y_i,F_i^{t-1}(x_i))+g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)\\
\because L(y_i,F_i^{t-1}(x_i)) \text{ is constant.}\\
\therefore \text{Our objective function is:}\\
~~~obj^t=\sum_{i=1}^N[g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)+C\\
\text{Define tree by a vector of scores in leafs,any instance will be mapped to a leaf:}\\ 
f_t(x)=m_q(x),~~m\in R^T,~~q:R^d\rightarrow\{1,2,3,...,T\}\\
\Omega(f_t)=\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2,\\
\text{where $T$ is total number of leaf nodes of $t$ trees}\\
~~~~~~~~~~~\text{$m_j$ is the weight of j-th leaf node.}\\
\text{Define the instance set in leaf $j$ as $I_j=\{i|j=q(x_i)\}$}\\
\text{Our new objective function is:}\\
obj^t=\sum_{i=1}^N[g_iw_tf_t(x_i)+\frac{1}{2}h_iw_t^2f_t^2(x_i)]+\Omega(f_t)\\
~~~~~~~=\sum_{i=1}^N[g_iw_tm_q(x_i)+\frac{1}{2}h_iw_t^2m_q^2(x_i)]+\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2\\
~~~~~~~=\sum_{j=1}^T[(\sum_{i \in I_j}g_i)w_tm_j+\frac{1}{2}(\sum_{i \in I_j}h_iw_t^2+\lambda )m_j^2]+\gamma T\\
\text{Define $G_j=\sum_{i \in I_j}g_i$ and $H_j=\sum_{i \in I_j}h_i$ then}\\
obj^t=\sum_{j=1}^T[G_jw_tm_j+\frac{1}{2}(H_jw_t^2+\lambda)m_j^2]+\gamma T\\
\text{For a quadratic function optimization problems:}\\
m_j^*=-\frac{G_j^2w_t}{H_jw_t^2+\lambda}\\
obj^*=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2w_t^2}{H_jw_t^2+\lambda}+\gamma T\\
\text{If we set $w_t=1$ then}\\
m_j^*=-\frac{G_j}{H_j+\lambda}\\
obj^*=-\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{H_j+\lambda}+\gamma T\\
\text{So when we add a split, our obtained gain is:}\\
gain=\underbrace{\frac{G_L^2}{H_L+\lambda}}_{left ~child}+\underbrace{\frac{G_R^2}{H_R+\lambda}}_{right~child}-\underbrace{\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}}_{do~not~split}-\gamma~~~~(thinking~why?)
\end{array}
\]</span></p>
<p>对GBDT来说依然避免不了过拟合，所以与传统机器学习一样，通过正则化策略可以降低这种风险：</p>
<ul>
<li>提前终止（Early Stopping）</li>
</ul>
<p>通过观察模型在验证集上的错误率，如果它变化不大则可以提前结束训练，控制迭代轮数（即树的个数）；</p>
<ul>
<li>收缩（Shrinkage）</li>
</ul>
<p><span class="math inline">\(F_{t+1}(x)=F_t(x)+\alpha_tf_t(x)\)</span> 从迭代的角度可以看成是学习率（learning rate），从融合（ensemble）的角度可以看成每棵树的权重，<span class="math inline">\(\alpha\)</span>的大小经验上可以取0.1，它是对模型泛化性和训练时长的折中；</p>
<ul>
<li>抽样（Subsampling）</li>
</ul>
<p>借鉴Bagging的思想，GBDT可以在每一轮树的构建中使用训练集中无放回抽样的样本，也可以对特征做抽样，模拟真实场景下的样本分布波动；</p>
<ul>
<li>目标函数中显式的正则化项</li>
</ul>
<p><span class="math inline">\(\Omega(f_t)=\gamma T+ \frac{1}{2}\lambda \sum_{i=1}^Tm_j^2\)</span> 通过对树的叶子节点个数、叶子节点权重做显式的正则化达到缓解过拟合的效果；</p>
<ul>
<li>参数放弃（Dropout）</li>
</ul>
模拟深度学习里随机放弃更新权重的方法，可以在每新增一棵树的时候拟合随机抽取的一些树的残差，相关方法可以参考：<a target="_blank" rel="noopener" href="http://jmlr.org/proceedings/papers/v38/korlakaivinayak15.pdf">DART: Dropouts meet Multiple Additive Regression Trees</a>，文中对该方法和Shrinkage的方法做了比较：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1b0s1udkl1att1v8o1hfs11im1eepm.png" width="400" />
</center>
<p>XGBoost源码在: https://github.com/dmlc中，其包含非常棒的设计思想和实现，建议大家都去学习一下，一起添砖加瓦。原理部分我就不再多写了，看懂一篇论文即可，但特别需要注意的是文中提到的<strong>weighted quantile sketch</strong>算法，它用来解决当样本集权重分布不一致时如何选择分裂节点的问题：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.02754.pdf">XGBoost: A Scalable Tree Boosting System</a>。</p>
<h3 id="简单的例子">2.5.4 简单的例子</h3>
<p>下面是关于几个常用机器学习模型的对比，从中能直观地体会到不同模型的运作区别，数据集采用libsvm作者整理好的fourclass_scale数据集，机器学习工具采用sklearn，代码中模型未做任何调参，仅使用默认参数设置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line">import urllib</span><br><span class="line">import matplotlib</span><br><span class="line">import os</span><br><span class="line">matplotlib.use(&#x27;Agg&#x27;)</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">from mpl_toolkits.mplot3d import proj3d</span><br><span class="line">import numpy as np</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">from sklearn.externals.joblib import Memory</span><br><span class="line">from sklearn.datasets import load_svmlight_file</span><br><span class="line">from sklearn import metrics</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">from sklearn import svm</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.linear_model import Ridge</span><br><span class="line">from sklearn.ensemble import GradientBoostingClassifier</span><br><span class="line">from mpl_toolkits.mplot3d import Axes3D</span><br><span class="line">from matplotlib import cm</span><br><span class="line">from matplotlib.ticker import LinearLocator, FormatStrFormatter</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">import keras</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers.core import Dense,Dropout,Activation</span><br><span class="line"></span><br><span class="line">def download(outpath):</span><br><span class="line">  filename=outpath+&quot;/fourclass_scale&quot;</span><br><span class="line">  if os.path.exists(filename) == False:</span><br><span class="line">    urllib.urlretrieve(&quot;https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/fourclass_scale&quot;,filename)</span><br><span class="line"></span><br><span class="line">def data_building():</span><br><span class="line">  dtrain = load_svmlight_file(&#x27;fourclass_scale&#x27;)</span><br><span class="line">  train_d=dtrain[0].toarray()</span><br><span class="line">  train_l=dtrain[1]</span><br><span class="line">  x1 = train_d[:,0]</span><br><span class="line">  x2 = train_d[:,1]</span><br><span class="line">  y = train_l</span><br><span class="line">  px1 = []</span><br><span class="line">  px2 = []</span><br><span class="line">  pl = []</span><br><span class="line">  nx1 = []</span><br><span class="line">  nx2 = []</span><br><span class="line">  nl = []</span><br><span class="line">  idx = 0</span><br><span class="line">  for i in y:</span><br><span class="line">    if i == 1:</span><br><span class="line">      px1.append(x1[idx]-0.5)</span><br><span class="line">      px2.append(x2[idx]+0.5)</span><br><span class="line">      pl.append(i)</span><br><span class="line">    else:</span><br><span class="line">      nx1.append(x1[idx]+0.8)</span><br><span class="line">      nx2.append(x2[idx]-0.8)</span><br><span class="line">      nl.append(i)</span><br><span class="line">    idx = idx + 1</span><br><span class="line"></span><br><span class="line">  x_axis, y_axis = np.meshgrid(np.linspace(x1.min(), x1.max(), 100), np.linspace(x2.min(), x2.max(), 100))</span><br><span class="line">  return x_axis, y_axis, px1, px2, nx1, nx2, train_d, train_l</span><br><span class="line"></span><br><span class="line">def paint(name, x_axis, y_axis, px1, px2, nx1, nx2, z):</span><br><span class="line">  fig = plt.figure()</span><br><span class="line">  ax = Axes3D(fig)</span><br><span class="line">  ax=plt.subplot(projection=&#x27;3d&#x27;)</span><br><span class="line">  ax.scatter(px1,px2,c=&#x27;r&#x27;)</span><br><span class="line">  ax.scatter(nx1,nx2,c=&#x27;g&#x27;)</span><br><span class="line">  ax.plot_surface(x_axis, y_axis,z.reshape(x_axis.shape), rstride=8, cstride=8, alpha=0.3)</span><br><span class="line">  ax.contourf(x_axis, y_axis, z.reshape(x_axis.shape), zdir=&#x27;z&#x27;, offset=-100, cmap=cm.coolwarm)</span><br><span class="line">  ax.contourf(x_axis, y_axis, z.reshape(x_axis.shape), levels=[0,max(z)], cmap=cm.hot)</span><br><span class="line">  ax.set_xlabel(&#x27;X&#x27;)</span><br><span class="line">  ax.set_ylabel(&#x27;Y&#x27;)</span><br><span class="line">  ax.set_zlabel(&#x27;Z&#x27;)</span><br><span class="line">  fig.savefig(name+&quot;.png&quot;, format=&#x27;png&#x27;)</span><br><span class="line"></span><br><span class="line">def svc(x_axis, y_axis, x,y):</span><br><span class="line">  clf = svm.SVC()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  return y</span><br><span class="line"></span><br><span class="line">def lr(x_axis, y_axis, x,y):</span><br><span class="line">  clf = LogisticRegression()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  return y</span><br><span class="line"></span><br><span class="line">def ridge(x_axis, y_axis, x,y):</span><br><span class="line">  clf = Ridge()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  return y</span><br><span class="line"></span><br><span class="line">def dt(x_axis, y_axis, x,y):</span><br><span class="line">  clf = GradientBoostingClassifier()</span><br><span class="line">  clf.fit(x, y)</span><br><span class="line">  y = clf.predict(np.c_[x_axis.ravel(), y_axis.ravel()])</span><br><span class="line">  return y</span><br><span class="line">  </span><br><span class="line">def nn(x_axis, y_axis, x,y):</span><br><span class="line">  model = Sequential()</span><br><span class="line">  model.add(Dense(20, input_dim=2))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line">  model.add(Dense(20))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line">  model.add(Dense(1, activation=&#x27;tanh&#x27;))</span><br><span class="line">  model.compile(loss=&#x27;mse&#x27;,</span><br><span class="line">                optimizer=&#x27;adam&#x27;,</span><br><span class="line">                metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">  model.fit(x,y,batch_size=20, nb_epoch=50, validation_split=0.2)</span><br><span class="line">  y = model.predict(np.c_[x_axis.ravel(), y_axis.ravel()],batch_size=20)</span><br><span class="line">  return y</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">  download(&quot;/root&quot;)</span><br><span class="line">  x_axis, y_axis, px1, px2, nx1, nx2, train_d, train_l = data_building()</span><br><span class="line">  z = svc(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(&quot;svc&quot;, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = lr(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(&quot;lr&quot;, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = ridge(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(&quot;ridge&quot;, x_axis, y_axis, px1, px2, nx1, nx2, z) </span><br><span class="line">  z = dt(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(&quot;gbdt&quot;, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line">  z = nn(x_axis, y_axis, train_d, train_l)</span><br><span class="line">  paint(&quot;nn&quot;, x_axis, y_axis, px1, px2, nx1, nx2, z)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1apkqel8gmtlervoud3k1ad2m.png" width="900" />
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1apme7kvi5klumr1cig181c2vm9.png" width="300" />
</center>
<h3 id="catboost">2.5.5 CatBoost</h3>
<p>基于不同的工程实现方式，目前常用的GBDT框架有3种，分别为：XGBoost（天奇）、LightGBM（微软）、CatBoost（Yandex）。三种实现在效果上并没有特别大的区别，区别主要在特征的处理尤其是类别特征上和建树过程上。</p>
<ul>
<li>类别特征</li>
</ul>
<p>在机器学习中有一大类特征叫类别特征，这类特征主要有两个特点：</p>
<blockquote>
<p>类别取值是离散的</p>
</blockquote>
<blockquote>
<p>每个类别取值非数值类型</p>
</blockquote>
<p>例如，“性别”这个特征，它一般有3个取值：“女”，“男”，“未知”，在特征处理阶段会被编码为离散的实数值或向量，然后进入模型。 - 类别特征编码 将类别取值编码为实数值有很多方法，大致如下：</p>
<p>1、 <strong>Label Encoding</strong></p>
<pre><code>每个类别赋值一个整数值。例如，性别“女”=0，“男”=1，“未知”=2，实践中这种编码方法用处有限。</code></pre>
<p>2、 <strong>One-Hot Encoding</strong></p>
<pre><code>创建一个维度与类别取值个数相同的向量，每个向量位置对应一个类别取值，当前类别取值为1，其他为0,这种编码最大问题是类别取值太多时，向量维度很高很稀疏，对模型学习效果和内存占用都是挑战（比如，NLP里几十万的词典表）。</code></pre>
<p>例如，性别特征编码：</p>
<table>
<thead>
<tr class="header">
<th>性别</th>
<th style="text-align: center;">编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>女</td>
<td style="text-align: center;">100</td>
</tr>
<tr class="even">
<td>男</td>
<td style="text-align: center;">010</td>
</tr>
<tr class="odd">
<td>未知</td>
<td style="text-align: center;">001</td>
</tr>
</tbody>
</table>
<p>3、 <strong>Distributed Representation</strong></p>
<pre><code>类别取值会被表示为一个实数向量，这个向量维度远小于取值个数。最经典的是NLP里常用的word2vec，一举三得：实现向量表示、实现降维、向量具有隐语义。</code></pre>
<p>4、<strong>Target Encoding</strong></p>
<pre><code>本质上它是一种反馈类特征，利用了标注数据，在实践中，要提升效果，反馈类特征一定是你要最优先考虑的。
但使用时需要特别注意**Target Leakage**，例如：

1)、在训练集使用标注信息生成特征的方式，在测试集上无法实现

2)、在训练集使用了未来的信息做特征，如，使用了测试集信息

3)、特征生成时样本的统计意义不足，如，广告曝光不足
......</code></pre>
<p><strong>Target Encoding</strong>有很多版本：</p>
<p>1)、<strong>Greedy Target Statistics</strong></p>
<p>编码方式为：</p>
<p><span class="math display">\[f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}\]</span> 其中:</p>
<p><span class="math inline">\((f_{i,j}^k,y_i)\quad \{ 0\leq i \leq N,0\leq j \leq M,0\leq k \leq L\}\)</span>：为训练数据集，如果<span class="math inline">\(f\)</span>是类别特征，则<span class="math inline">\(f_{i,j}^k\)</span>为第<span class="math inline">\(i\)</span>个样本第<span class="math inline">\(j\)</span>个特征的第<span class="math inline">\(k\)</span>种取值，<span class="math inline">\(y_i\)</span>为标注且<span class="math inline">\(y_i \in \{0,1\}\)</span>。</p>
<p><span class="math inline">\(N\)</span>：样本总量，<span class="math inline">\(M\)</span>：特征总量，<span class="math inline">\(L\)</span>：某类别特征下可取值总数</p>
<p><span class="math inline">\(f_{i,j}^{&#39;k}\)</span>：为第<span class="math inline">\(i\)</span>个样本第<span class="math inline">\(j\)</span>个特征的第<span class="math inline">\(k\)</span>种取值编码后的结果</p>
<p><span class="math inline">\(\mathrm{I}\{\cdot\}\)</span>：为指示函数</p>
<p>大白话是：以训练样本中的某一特征对样本GroupBy，计算每个Group（即当前类的所有取值）内标注的均值为新的特征。 例如，有以下广告曝光及点击样本：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>分组计算：</p>
<p>“女”：<span class="math inline">\(ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(ctr=\frac{2}{4}=0.5\)</span></p>
<p>“未知”：<span class="math inline">\(ctr=\frac{1}{3}=0.3\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.3</td>
</tr>
</tbody>
</table>
<p>2)、<strong>Greedy Target Statistics with Smoothes</strong></p>
<p>为了降低原始Greedy Target Statistics方法对处理低频特征值的劣势，通常会对它做平滑操作。 例如，有以下广告曝光及点击样本：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>分组计算：</p>
<p>“女”：<span class="math inline">\(ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(ctr=\frac{0}{4}=0\)</span></p>
<p>“未知”：<span class="math inline">\(ctr=\frac{0}{3}=0\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>显然，这种编码方式，将来做模型训练大概率会过拟合，可以加一个正则项来缓解，编码方式改为：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=
\lambda^k \frac{\sum_{i=0}^{N}y_i}{N} + (1-\lambda^k)\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}
 \]</span></p>
<p>其中，<span class="math inline">\(0\leq \lambda \leq 1\)</span></p>
<p>变换一种形式：</p>
<p><span class="math display">\[f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}+\alpha^k}\]</span> 其中，<span class="math inline">\(p^k=\frac{\sum_{i=0}^{N}y_i}{N}\)</span>，<span class="math inline">\(\alpha^k=\frac{\sum_{i=0}^{N}\lambda^k \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}{1-\lambda^k}\)</span>(显然<span class="math inline">\(0\leq\alpha\leq 1\)</span>)</p>
<p>大白话：用性别这个特征的平均ctr来平滑每个类别取值的ctr，假设，“女”的<span class="math inline">\(\lambda=0\)</span>，“男”的<span class="math inline">\(\lambda=0.5\)</span>，“未知”的<span class="math inline">\(\lambda=0.6\)</span>，则：</p>
<p>分组计算：</p>
<p>平均ctr：<span class="math inline">\(\overline{ctr} =\frac{3}{12}=0.25\)</span></p>
<p>“女”：<span class="math inline">\(0 \cdot \overline{ctr} + 1 \cdot ctr=\frac{3}{5}=0.6\)</span></p>
<p>“男”：<span class="math inline">\(0.5 \cdot \overline{ctr} + 0.5 \cdot ctr=0.5 \cdot 0.25+\frac{0}{4}=0.125\)</span></p>
<p>“未知”：<span class="math inline">\(0.6 \cdot \overline{ctr} + 0.4 \cdot ctr=0.6 \cdot 0.25+\frac{0}{3}=0.15\)</span></p>
<p>性别特征编码为：</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">性别特征编码</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>5</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>6</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr class="odd">
<td>7</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="even">
<td>8</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="odd">
<td>9</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
<tr class="even">
<td>10</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0.6</td>
</tr>
<tr class="odd">
<td>11</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0.125</td>
</tr>
<tr class="even">
<td>12</td>
<td style="text-align: center;">未知</td>
<td style="text-align: center;">0.15</td>
</tr>
</tbody>
</table>
<p>这种方法的特点是简单，适用于内置到Boosting框架中，但缺点是会出现<strong>Target Leakage</strong>现象，例如： 假设类别特征依然是“性别”，如果在训练集上</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>平均ctr：<span class="math inline">\(\overline{ctr} =\frac{2}{4}=0.5\)</span></p>
<p>“女”：<span class="math inline">\(p(y=1|女)=0.5\)</span></p>
<p>“男”：<span class="math inline">\(p(y=1|男)=0.5\)</span></p>
<p>编码：<span class="math inline">\(f_i^k=\frac{y_i+\alpha \overline{ctr}}{1+\alpha}\)</span></p>
<p>显然，在训练集上<span class="math inline">\(f_i^k=\frac{0.5+\alpha\overline{ctr}}{1+\alpha}\)</span>是最佳分割点，意味着在未来测试集上，不管特征分布是如何，“性别”这个类别特征所有取值下的编码一定是：</p>
<p><span class="math inline">\(f_i^k=\frac{0.5+\alpha\overline{ctr}}{1+\alpha}=\frac{0.5+\alpha0.5}{1+\alpha}=0.5\)</span>，显然模型过拟合了。</p>
<p>3)、<strong>Target Encoding with Beta Distribution</strong></p>
<p>通过加权平均方式，可以很好的平滑特征，但是缺点之一是超参数需要人工拍且不可解释，由于实际当中大部分分类问题是二分类（或可以转化为二分类），而二分类问题大多可以通过Bernoulli Distribution建模，而Bernoulli Distribution又有一个很好的正交分布Beta Distribution，因此利用贝叶斯MAP框架，可以假设参数服从Beta Distribution，即：</p>
<ul>
<li><p>点击率CTR：<span class="math inline">\(r \sim Beta (\alpha, \beta),P(r|\alpha,\beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}r^{\alpha-1}(1-r)^{\beta-1}\)</span></p></li>
<li><p>点击Clicks：<span class="math inline">\(C \sim Binomial(I,r),P(c|I,r)\propto{r^{C}}{(1-r)^{I-C}}\)</span></p></li>
</ul>
<p>其中<span class="math inline">\(C\)</span>为点击数，<span class="math inline">\(I\)</span>为曝光数，<span class="math inline">\(r\)</span>为点击率</p>
<p>则：</p>
<p><span class="math display">\[
 \begin{equation*}
 \begin{aligned}
 P(C_i,...C_N|I_i,...I_N,\alpha,\beta)&amp;=\prod_{i=1}^{N}P(C_i|I_i,\alpha,\beta) \\
 &amp;=\prod_{i=1}^{N}\int_{r_i} P(C_i,r_i|I_i,\alpha,\beta)dr_i \\
 &amp;=\prod_{i=1}^{N}\int_{r_i} P(C_i|I_i,r_i)\cdot P(r_i|\alpha,\beta)dr_i \\
 &amp;\propto \prod_{i=1}^{N}\int_{r_i}r_i^{C_i}(1-r_i)^{I_i-C_i}r_i^{\alpha-1}(1-r_i)^{\beta-1} \\
 &amp;=\propto \prod_{i=1}^{N}\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(C_i+\alpha)}{\Gamma(\alpha)}\frac{\Gamma(I_i-C_i+\beta)}{\Gamma(\beta)}
 \end{aligned}
 \end{equation*}
 \]</span></p>
<p>做参数估计，得到<span class="math inline">\(\alpha\)</span>和<span class="math inline">\(\beta\)</span>的估计<span class="math inline">\(\hat{\alpha}\)</span>和<span class="math inline">\(\hat{\beta}\)</span>，则平滑后的点击率<span class="math inline">\(\hat{r_i}\)</span>为：</p>
<p><span class="math display">\[
 \begin{equation*}
 \begin{aligned}
 \hat{r_i}&amp;=\frac{C_i+\hat{\alpha_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \\
 &amp;=\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \cdot \frac{\hat{\alpha_i}}{\hat{\alpha_i}+\hat{\beta_i}} +\frac{I_i}{I_i+\hat{\alpha_i}+\hat{\beta_i}} \cdot \frac{C_i}{I_i} \\
 &amp;=\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}}\cdot \frac{\hat{\alpha_i}}{\hat{\alpha_i}+\hat{\beta_i}} + (1-\frac{\hat{\alpha_i}+\hat{\beta_i}}{I_i+\hat{\alpha_i}+\hat{\beta_i}}) \cdot \frac{C_i}{I_i} \\
 &amp;=\lambda_i \cdot \overline{ctr}+(1-\lambda_i) \cdot ctr_i
 \end{aligned}
 \end{equation*}
 \]</span></p>
<blockquote>
<p>最终，新的编码方式如下：</p>
</blockquote>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=
\lambda^k \frac{\sum_{i=0}^{N}y_i}{N} + (1-\lambda^k)\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\} }{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}}
 \]</span></p>
<p>其中<span class="math inline">\(\lambda^k=\frac{\hat{\alpha}+\hat{\beta}}{\mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}+\hat{\alpha}+\hat{\beta}}\)</span></p>
<p>这种方法实践效果更好，尤其在特征工程阶段，但它计算复杂，相当于在用一个模型生成特征，且不适合内置在Boost类框架中。</p>
<p>4)、<strong>Handout Target Statistics</strong></p>
<p>针对Greedy Target Statistics with Smoothes遇到的问题，一种改进是将训练集分成两部分，一部分用来生成TS特征，一部分用来训练，但显然可用训练数据变少了，尤其在标注样本不是那么rich的场景下。</p>
<p>5)、<strong>Leave-one-out Target Statistics</strong></p>
<p>一般会和交叉验证配合使用，简单说就是训练集留1个样本做测试，其他样本做训练，假设<span class="math inline">\(f_{i,j}^k\)</span>为当前被“leave”的样本，则其编码后结果为：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-y_k +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-1+\alpha^k}
 \]</span></p>
<p>训练集最佳分裂点是：</p>
<p><span class="math display">\[
 f_{i,j}^{&#39;k}=\frac{\sum_{i=0}^{N}y_i  \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-0.5 +\alpha^k p^k}{\sum_{i=0}^{N} \mathrm{I}\{f_{i,j}=f_{i,j}^{k}\}-1+\alpha^k}
 \]</span> 显然，发生了“Target Leakage”导致模型过拟合。</p>
<p>假设类别特征依然是“性别”，如果在训练集上</p>
<table>
<thead>
<tr class="header">
<th>样本编号</th>
<th style="text-align: center;">性别特征</th>
<th style="text-align: center;">是否点击广告</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>1</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td>2</td>
<td style="text-align: center;">女</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td>3</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>4</td>
<td style="text-align: center;">男</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>“女”编码为：<span class="math inline">\(p(y=1|女)=\frac{1-1+ap}{4-1+a}=\frac{ap}{3+a}\)</span></p>
<p>“女”编码为：<span class="math inline">\(p(y=0|女)=\frac{1-0+ap}{4-1+a}=\frac{1+ap}{3+a}\)</span></p>
<p>显然“女”的最佳分割点是：<span class="math inline">\(\frac{0.5+ap}{3+a}\)</span></p>
<p>“男”编码为：<span class="math inline">\(p(y=1|男)=\frac{3-1+ap}{4-1+a}=\frac{2+ap}{3+a}\)</span></p>
<p>“男”编码为：<span class="math inline">\(p(y=0|男)=\frac{3-0+ap}{4-1+a}=\frac{3+ap}{3+a}\)</span></p>
<p>显然“男”的最佳分割点是：<span class="math inline">\(\frac{2.5+ap}{3+a}\)</span></p>
<p>出现过拟合！</p>
<p>6)、<strong>Ordered Target Statistics</strong></p>
<p>借鉴Online Learning的方式，所有样本的TS特征生成只依赖当前时间线之前的历史样本，如果样本没有时间属性，则利用某个分布生成随机数，为所有样本赋予"顺序"。为了降低模型方差，每步Gradient Boosting迭代会重新为样本赋予“顺序”。</p>
<ul>
<li>Oblivious Decision Trees</li>
</ul>
基于Oblivious Tree的决策树，Oblivious有人翻译为对称，有人翻译为遗忘，前者体现了结构上的特点，后者体现了行为上的特点。 从结构上讲，只有一个入度为0的节点且为根节点，所有叶子节点(出度为0)为分类节点，其他节点为中间节点，任意一条从根节点到叶子节点的路径，每个中间节点只出现一次，中间节点，即internal或test node为分类变量，每一层的中间节点变量一样，<strong>注意，每层的每个分类变量一样但判断条件可以不一样</strong>，所以结构上看是对称的，似乎叫Symmetric Tree更合适。 作者把它称为Oblivious，我认为是基于它行为上的特点，即每个分类变量(中间节点)的触发与整个路径上的所有变量的顺序及它们所处的层次决定，而不是由该变量节点本身决定，所以对比传统决策树，似乎“遗忘”了历史的判断行为，每次都要依着从根节点开始的路径对每个分类变量逐个做判断。典型的结构如下图：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e366blci7k512pq1vduq2v6519.png" width="600" />
</center>
注意看，在age这个属性上，不同的路径可以有不同的判断条件，这种结构在特征选择上比较高效。再一个，每个到达叶子节点的路径上的分类变量都是一样的，这些变量一定是所有输入变量的子集，从这个角度看，其实是在做<strong>维度缩减</strong>。此外Oblivious Tree也可以看做是Oblivious Oblivious Read-Once Decision Graphs的展开形式，如下图：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e364p1q9rkocvq1juo1cs96jq9.png" width="600" />
</center>
<p>详情可以看《<strong>Bottom-Up Induction of Oblivious Read-Once Decision Graphs</strong>》一文。</p>
<ul>
<li>Decision Table</li>
</ul>
<p>决策表是一种古老但是非常高效的规则匹配方法。用于基于规则的决策系统，如早期的专家系统，匹配模式形如：<strong>if A then B</strong>，最典型的有两类：</p>
<pre><code>* Condition-Action Rules

A为条件，B为动作，例如：if x发了工资 then x去银行还月供。

* Logical Rules

A和B为一阶逻辑表达式，例如：if x是男人 then x是哺乳动物。</code></pre>
<p>利用Decision Table可以做分类器，例如最常用的Decision Table Majority，它有两个组成部分：</p>
<pre><code>* Schema，所有决策表中要用到特征的集合。

* Body，依据训练数据得到的命中模式的集合。</code></pre>
<p>典型的例子如下：</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e36utda26u3k4712t5d8d10001g.png" width="600" />
</center>
<p>回顾Oblivious Decision Trees的结构，非常适合实现一个DTM，定义某个损失函数，构造ODT，最终保留下的中间分类节点集合为Schema，从根节点到叶子节点的所有路径组成的集合是Body。</p>
<ul>
<li>CatBoost简介</li>
</ul>
<p>CatBoost是Yandex在2017年推出的一个GBDT实现框架，论文见：《<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/7898-catboost-unbiased-boosting-with-categorical-features.pdf">CatBoost: unbiased boosting with categorical features</a>》，它的基础学习器是Oblivious Decision Trees，结构上平衡、不容易过拟合、Inference速度极快，支持自动将类别特征处理为数值特征并做特征交叉，为提高模型精度和泛化性能，在Prediction Shift和Gradient Bias上做了理论分析和解决。</p>
<p>1、<strong>Prediction Shift</strong></p>
简单回顾第二章Boosting相关内容：
<span class="math display">\[\begin{array}{l}
F(x)=\sum_{i=1}^Nw_if_i(x)\\
其中:\\
\quad \quad f_i是第i轮迭代得到的基础分类器\\
\quad \quad w_i是第i个分类器的权重\\
\quad \quad x是样本特征集\\
定义:\\
\quad \quad \text{(1). 样本总数为 $N$,损失函数定义为$C(F)$,例如： $C(F(x))=\frac{1}{N}\sum_{i=1}^NC(y_iF(x_i))$}\\
\quad \quad \text{(2). $g^t=g^t(x,y)=\frac{\partial C(y,s)}{\partial s}|_{s=F^{t-1}(x)}$,$h^t=h^t(x,y)=\frac{\partial ^2C(y,s)}{\partial s^2}|_{s=F^{t-1}(x)}$}\\
\text{现在我们希望当前轮迭代能够找到一个函数 $f(x)$ ,使得在新分类器$F^t(x)=F^{t-1}(x)+\alpha f(x)$下的损失函数值 $C(F^{t-1}(x)+\alpha f(x))$ 能够下降}\\
依据泰勒展开式:\\
\because C(F^t(x))=C(F^{t-1}(x)+\alpha f(x))=C(F^{t-1}(x))+\alpha {g^t} f+\frac{1}{2}h^t(\xi)f^2\\
\therefore 根据拉格朗日定理得到:\\
f=-\alpha g^t\\
由于f是个函数，所以通常用利用最小二乘法对其做拟合:\\
f^t=\mathop{argmin}\limits_{f \in F}~ \mathbb{E}(-f(x)-g^t(x,y))^2
\end{array}\]</span>
<p>这里会有三个问题，即所谓shift，导致最终模型泛化能力下降：</p>
<blockquote>
<p>1、训练样本和测试样本梯度值的分布可能不一致；</p>
</blockquote>
<blockquote>
<p>2、采用类似最小二乘法做函数拟合可能出现偏差，因为背后的假设是梯度值分布服从正态分布，可能与真实世界里的分布不一致；</p>
</blockquote>
<blockquote>
<p>3、如果每步迭代都使用相同数据集，则得到的模型是有偏的且偏差与数据集大小成反比；反之，如果每步迭代使用相互独立的数据集，则得到的训练模型是无偏的。</p>
</blockquote>
<p>以上shift最终造成预测时出现Prediction Shift，假设我们有无限大的标注数据集，那就简单了，每步迭代都独立的抽一个数据集出来，可以训练出无偏模型，但实际上不可能，所以这个问题只可以缓解不能解决，因为你永远不能准确知道真实样本的完美分布，只能摸着石头过河，广告、推荐和搜索里把这个方法叫做E&amp;E(Exploitation &amp; Exploration)，本质上Boostng Tree的生成过程就是通过E&amp;E方法迭代生成：使用某个样本集exploit得到当前“最优”的模型，即<span class="math inline">\(F^{t-1}(x)\)</span>，用这个模型explore另外一个样本集，根据结果和某种策略优化模型得到新的“最优”模型<span class="math inline">\(F^t(x)\)</span>，如此往复，直到找到Exploitation &amp; Exploration的最佳trade-off点。</p>
<p>2、 <strong>Ordered boosting</strong></p>
<p>为了缓解Prediction Shift，一个取巧的方法是：</p>
<p>• 用随机排序函数<span class="math inline">\(\sigma\)</span>对所有样本重排序</p>
<p>• 维护<span class="math inline">\(n\)</span>个独立的模型，每个模型<span class="math inline">\(M_i\)</span>由排序后的前<span class="math inline">\(i\)</span>个训练样本生成</p>
<p>• 对第<span class="math inline">\(j\)</span>个样本的残差用模型<span class="math inline">\(M_{j-1}\)</span>来估计</p>
<p>• 原来每个迭代使用由相同样本得到的模型F求梯度的方式改为用辅助模型M估计：</p>
<span class="math display">\[g^t:=\frac{\partial L(y,s)}{s}|_{s=F^{t-1}(x)}\Rightarrow g^t:=\frac{\partial L(y,s)}{s}|_{s=M^{t-1}(x)}\]</span>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3er90lfo882vu1v234415gu1j.png" width="400" />
</center>
<p><strong>Algorithm 1:</strong> <strong>Ordered Boosting</strong></p>
<blockquote>
<p><strong><em>input:</em></strong> <span class="math inline">\(\{(x_k,y_k)\}_{k=1}^n为所有样本,且由\sigma函数重新随机排序, T为树的个数\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(M_i \leftarrow 0 \quad for \quad i=1..n,n为模型个数\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(for \quad t\leftarrow1 \quad to \quad T \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad for \quad i\leftarrow1 \quad to \quad n \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad for \quad j\leftarrow1 \quad to \quad i \quad do\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad \quad\quad g_j\leftarrow\frac{\partial L(y_j,s)}{s}|_{s=M_{j-1}(x_j)}(采用最小二乘损失函数:g_j\leftarrow y_j-M_{j-1}(x_j)\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad \Delta M\leftarrow LearnModel(x_j,g_j)\quad for \quad j=1..i\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(\quad \quad M_i=M_i+\Delta M\)</span></p>
</blockquote>
<blockquote>
<p><span class="math inline">\(return \quad M_n\)</span></p>
</blockquote>
<p>由于要训练<span class="math inline">\(n\)</span>个模型，时间和空间复杂度都上升了<span class="math inline">\(n\)</span>倍，所以这个算法实操性较低。 CatBoost对建树算法做了改进，有对<strong>Algorithm 1</strong>算法效率改进的Ordered模式和类似于传统GBDT的Plain模式，其中Ordered模式在小数据集上优势明显。</p>
<p>建树的算法<strong>Algorithm 2</strong>说明如下：</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/a2.png" width="800"  />
</center>
<p>在Ordered模式下，计算梯度的时间复杂度是<span class="math inline">\(O(sn^2)\)</span>，包含选择排序函数的时间、扫描样本生成辅助函数的时间、扫描样本生成梯度的时间，CatBoost在实现时用了几个技巧：</p>
<p>1、不维护全部<span class="math inline">\(M_{r,j}(i)\)</span>，转而只维护<span class="math inline">\(M^{&#39;}_{r,j}(i)=M_{r,2^j}(i),j=1,...,\lceil log_2^n\rceil,\sigma_r(i)\leq2^{j+1}\)</span>，这样时间复杂度会降到<span class="math inline">\(O(sn)\)</span></p>
<p>2、每次迭代时对样本做抽样，这个方法能有效降低过拟合</p>
<p>3、由产生样本过程导致的bias，例如，排第一页的广告比第100页的广告更容易被用户看到、点到，那第100页的广告如果被点击了，这条样本的含金量明显更高，所以位置bias产生的样本可以通过给样本权重的方式或把位置作为特征等方法校正，相关论文可以看：</p>
<p>《<a target="_blank" rel="noopener" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/04/main-1.pdf">Model Ensemble for Click Prediction in Bing Search Ads</a>》</p>
<p>《<a target="_blank" rel="noopener" href="https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45286.pdf">Learning to Rank with Selection Bias in Personal Search</a>》</p>
<p>《<a target="_blank" rel="noopener" href="https://www.researchgate.net/publication/335771749_PAL_a_position-bias_aware_learning_framework_for_CTR_prediction_in_live_recommender_systems">PAL: a position-bias aware learning framework for CTR prediction in live recommender systems</a>》</p>
<p>《<a target="_blank" rel="noopener" href="https://projecteuclid.org/euclid.aos/1176345338">The bayesian bootstrap</a>》</p>
<p>3、<strong>完整算法描述</strong></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3jn8bq91vlofsk3tc1lb516h22c.png" width="800"  />
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1e3jnra3u19v71ec21djqff31mtt2p.png" width="800" />
</center>
<p>4、<strong>代码实践</strong></p>
<p>CatBoost官网上有大量教程，这里给个简单例子：</p>
<p>1、定义Model类 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    class CatBoostModel</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedShuffleSplit</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> catboost <span class="keyword">as</span> cb</span><br><span class="line"><span class="keyword">from</span> catboost <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CatBoostModel</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]       <span class="comment"># 定义模型参数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]            <span class="comment"># 定义训练集划分比例</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>] <span class="comment"># 缓解过拟合，提前结束迭代参数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]       <span class="comment"># 控制树的个数</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;cat_features&#x27;</span>]          <span class="comment"># 类别特征列表</span></span><br><span class="line">        <span class="keyword">assert</span> kwargs[<span class="string">&#x27;all_features&#x27;</span>]          <span class="comment"># 所有特征列表</span></span><br><span class="line"></span><br><span class="line">        self.catboost_params = kwargs[<span class="string">&#x27;catboost_params&#x27;</span>]</span><br><span class="line">        self.eval_ratio = kwargs[<span class="string">&#x27;eval_ratio&#x27;</span>]</span><br><span class="line">        self.early_stopping_rounds = kwargs[<span class="string">&#x27;early_stopping_rounds&#x27;</span>]</span><br><span class="line">        self.num_boost_round = kwargs[<span class="string">&#x27;num_boost_round&#x27;</span>]</span><br><span class="line">        self.cat_features = kwargs[<span class="string">&#x27;cat_features&#x27;</span>]</span><br><span class="line">        self.all_features = kwargs[<span class="string">&#x27;all_features&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.selected_features_ = <span class="literal">None</span></span><br><span class="line">        self.X = <span class="literal">None</span></span><br><span class="line">        self.y = <span class="literal">None</span></span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_selected_features</span>(<span class="params">self, topk</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Fit the training data to FeatureSelector</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns</span></span><br><span class="line"><span class="string">        -------</span></span><br><span class="line"><span class="string">        list :</span></span><br><span class="line"><span class="string">                Return the index of imprtant feature.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> topk &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        self.selected_features_ = self.feature_importance.argsort()[-topk:][::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.selected_features_</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X, num_iteration=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.model.predict(X, num_iteration)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_fea_importance</span>(<span class="params">self, clf, columns</span>):</span></span><br><span class="line">        importances = clf.feature_importances_</span><br><span class="line">        indices = np.argsort(importances)[::-<span class="number">1</span>]</span><br><span class="line">        importance_list = []</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(columns)):</span><br><span class="line">            importance_list.append((columns[indices[f]], importances[indices[f]]))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;%2d) %-*s %f&quot;</span> % (f + <span class="number">1</span>, <span class="number">30</span>, columns[indices[f]], importances[indices[f]]))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;another feature importances with prettified=True\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(clf.get_feature_importance(prettified=<span class="literal">True</span>))</span><br><span class="line">        importance_df = pd.DataFrame(importance_list, columns=[<span class="string">&#x27;Features&#x27;</span>, <span class="string">&#x27;Importance&#x27;</span>])</span><br><span class="line">        <span class="keyword">return</span> importance_df</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_test_split</span>(<span class="params">self, X, y, test_size, random_state=<span class="number">2020</span></span>):</span></span><br><span class="line">        sss = <span class="built_in">list</span>(StratifiedShuffleSplit(</span><br><span class="line">            n_splits=<span class="number">1</span>, test_size=test_size, random_state=random_state).split(X, y))</span><br><span class="line">        X_train = np.take(X, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        X_eval = np.take(X, sss[<span class="number">0</span>][<span class="number">1</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_train = np.take(y, sss[<span class="number">0</span>][<span class="number">0</span>], axis=<span class="number">0</span>)</span><br><span class="line">        y_eval = np.take(y, sss[<span class="number">0</span>][<span class="number">1</span>], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> [X_train, X_eval, y_train, y_eval]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">catboost_model_train</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">                        df, </span></span></span><br><span class="line"><span class="params"><span class="function">                        finetune=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        target_name=<span class="string">&#x27;Label&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                        id_index=<span class="string">&#x27;Id&#x27;</span></span>):</span></span><br><span class="line">        df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">        feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> self.cat_features:</span><br><span class="line">                <span class="comment">#df[i].fillna(-999, inplace=True)</span></span><br><span class="line">                <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                    df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line"></span><br><span class="line">        X_train, X_eval, y_train, y_eval = self.train_test_split(df[feature_name],</span><br><span class="line">                                                          df[target_name].values,</span><br><span class="line">                                                          self.eval_ratio,</span><br><span class="line">                                                          random.seed(<span class="number">41</span>))</span><br><span class="line">        <span class="keyword">del</span> df</span><br><span class="line">        gc.collect()</span><br><span class="line">      </span><br><span class="line">        catboost_train = Pool(data=X_train, label=y_train, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line">        catboost_eval = Pool(data=X_eval, label=y_eval, cat_features=self.cat_features, feature_names=self.all_features)</span><br><span class="line"></span><br><span class="line">        self.model = cb.train(params=self.catboost_params,</span><br><span class="line">                               init_model=finetune,</span><br><span class="line">                               pool=catboost_train,</span><br><span class="line">                               num_boost_round=self.num_boost_round,</span><br><span class="line">                               eval_set=catboost_eval,</span><br><span class="line">                               verbose_eval=<span class="number">50</span>,</span><br><span class="line">                               plot=<span class="literal">True</span>,</span><br><span class="line">                               early_stopping_rounds=self.early_stopping_rounds)</span><br><span class="line"></span><br><span class="line">        self.feature_importance  = self.get_fea_importance(self.model, self.all_features)</span><br><span class="line">        metrics = self.model.eval_metrics(data=catboost_eval,metrics=[<span class="string">&#x27;AUC&#x27;</span>],plot=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;AUC values:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(np.array(metrics[<span class="string">&#x27;AUC&#x27;</span>])))</span><br><span class="line">        <span class="keyword">return</span> self.feature_importance, metrics, self.model</span><br></pre></td></tr></table></figure> 2、定义catboost trainer（里面涉及nni的部分先忽略，后面再讲）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> bz2</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_svmlight_file</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> nni</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> CatBoostModel</span><br><span class="line"><span class="keyword">from</span> catboost.datasets <span class="keyword">import</span> adult</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;auto_gbdt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">TARGET_NAME = <span class="string">&#x27;income&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_default_parameters</span>():</span></span><br><span class="line">    params_cb = &#123;</span><br><span class="line">       <span class="string">&#x27;boosting_type&#x27;</span>: <span class="string">&#x27;Ordered&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;objective&#x27;</span>: <span class="string">&#x27;CrossEntropy&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;eval_metric&#x27;</span>: <span class="string">&#x27;AUC&#x27;</span>,</span><br><span class="line">       <span class="string">&#x27;custom_metric&#x27;</span>: [<span class="string">&#x27;AUC&#x27;</span>, <span class="string">&#x27;Accuracy&#x27;</span>],</span><br><span class="line">       <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.05</span>,</span><br><span class="line">       <span class="string">&#x27;random_seed&#x27;</span>: <span class="number">2020</span>,</span><br><span class="line">       <span class="string">&#x27;depth&#x27;</span>: <span class="number">2</span>,</span><br><span class="line">       <span class="string">&#x27;l2_leaf_reg&#x27;</span>: <span class="number">3.8</span>,</span><br><span class="line">       <span class="string">&#x27;thread_count&#x27;</span>: <span class="number">16</span>,</span><br><span class="line">       <span class="string">&#x27;use_best_model&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">       <span class="string">&#x27;verbose&#x27;</span>: <span class="number">0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> params_cb</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_features_name</span>():</span></span><br><span class="line">    alls = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>, <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>,  <span class="string">&#x27;capital-loss&#x27;</span>,  <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>]</span><br><span class="line">    cats = [<span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>, <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> alls, cats</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_prepare_cleaner</span>(<span class="params">target</span>):</span></span><br><span class="line">    train_df, test_df = adult()</span><br><span class="line">    le = LabelEncoder()</span><br><span class="line">    le.fit(train_df[target])</span><br><span class="line">    train_df[target] = le.transform(train_df[target])</span><br><span class="line"></span><br><span class="line">    le.fit(test_df[target])</span><br><span class="line">    test_df[target] = le.transform(test_df[target])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_df, test_df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cat_fea_cleaner</span>(<span class="params">df, target_name, id_index, cat_features</span>):</span></span><br><span class="line">    df = df.loc[df[target_name].isnull() == <span class="literal">False</span>]</span><br><span class="line">    feature_name = [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> [target_name, id_index]]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> feature_name:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cat_features:</span><br><span class="line">            <span class="keyword">if</span> df[i].fillna(<span class="string">&#x27;na&#x27;</span>).nunique() &lt; <span class="number">12</span>:</span><br><span class="line">                df.loc[:, i] = df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                df.loc[:, i] = LabelEncoder().fit_transform(df.loc[:, i].fillna(<span class="string">&#x27;na&#x27;</span>).astype(<span class="built_in">str</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">str</span> <span class="keyword">or</span> <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=<span class="built_in">int</span> <span class="keyword">or</span>  <span class="built_in">type</span>(df.loc[<span class="number">0</span>,i])!=long:</span><br><span class="line">                df.loc[:, i] = df.loc[:, i].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainer_and_tester_run</span>(<span class="params">train_df, test_df, all_features, cat_features</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># get parameters from tuner</span></span><br><span class="line">    RECEIVED_PARAMS = nni.get_next_parameter()</span><br><span class="line">    logger.debug(RECEIVED_PARAMS)</span><br><span class="line">    PARAMS = get_default_parameters()</span><br><span class="line">    PARAMS.update(RECEIVED_PARAMS)</span><br><span class="line">    logger.debug(PARAMS)</span><br><span class="line"></span><br><span class="line">    cb = CatBoostModel(catboost_params=PARAMS,</span><br><span class="line">                    eval_ratio=<span class="number">0.33</span>,</span><br><span class="line">                    early_stopping_rounds=<span class="number">20</span>,</span><br><span class="line">                    cat_features=cat_features,</span><br><span class="line">                    all_features=all_features,</span><br><span class="line">                    num_boost_round=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is starting...&quot;</span>)</span><br><span class="line">    train_df = cat_fea_cleaner(train_df, TARGET_NAME, <span class="string">&#x27;index&#x27;</span>, cat_features)</span><br><span class="line">    test_df = cat_fea_cleaner(test_df, TARGET_NAME, <span class="string">&#x27;index&#x27;</span>, cat_features)</span><br><span class="line">    feature_imp, val_score, clf = \</span><br><span class="line">    cb.catboost_model_train(df=train_df,</span><br><span class="line">                            target_name=TARGET_NAME,</span><br><span class="line">                            id_index=<span class="string">&#x27;id&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    logger.info(feature_imp)</span><br><span class="line">    logger.info(val_score)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">del</span> train_df</span><br><span class="line">    gc.collect()</span><br><span class="line">    logger.debug(<span class="string">&quot;The trainning process is ended.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    av_auc = inference(clf, test_df, all_features, cat_features)</span><br><span class="line">    nni.report_final_result(av_auc)</span><br><span class="line">    <span class="keyword">del</span> test_df</span><br><span class="line">    gc.collect()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference</span>(<span class="params">clf, test_df, fea, cat_fea</span>):</span></span><br><span class="line"></span><br><span class="line">    logger.debug(<span class="string">&quot;The testing process is starting...&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        y_pred = clf.predict(test_df[fea])</span><br><span class="line">        auc = roc_auc_score(test_df[TARGET_NAME].values, y_pred)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;auc of prediction:&#123;0&#125;&quot;</span>.<span class="built_in">format</span>(auc))</span><br><span class="line">        <span class="keyword">del</span> test_df</span><br><span class="line">        gc.collect()</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">&quot;The inference process is ended.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> auc</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_offline</span>():</span></span><br><span class="line">    alls, cats = get_features_name()</span><br><span class="line">    <span class="built_in">print</span>(alls, cats) </span><br><span class="line">    train_df, test_df = data_prepare_cleaner(TARGET_NAME)</span><br><span class="line">    <span class="built_in">print</span>(train_df)</span><br><span class="line">    <span class="built_in">print</span>(test_df)</span><br><span class="line">    trainer_and_tester_run(train_df, test_df, alls, cats)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run_offline()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br></pre></td><td class="code"><pre><span class="line">[root@GPU-AI01 cat_test]# python3 catboost_trainer.py </span><br><span class="line">[&#x27;age&#x27;, &#x27;workclass&#x27;, &#x27;fnlwgt&#x27;, &#x27;education&#x27;, &#x27;education-num&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;, &#x27;hours-per-week&#x27;, &#x27;native-country&#x27;] [&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;]</span><br><span class="line">        age         workclass    fnlwgt   education  education-num      marital-status         occupation  ...   race     sex capital-gain  capital-loss  hours-per-week  native-country income</span><br><span class="line">0      39.0         State-gov   77516.0   Bachelors           13.0       Never-married       Adm-clerical  ...  White    Male       2174.0           0.0            40.0   United-States      0</span><br><span class="line">1      50.0  Self-emp-not-inc   83311.0   Bachelors           13.0  Married-civ-spouse    Exec-managerial  ...  White    Male          0.0           0.0            13.0   United-States      0</span><br><span class="line">2      38.0           Private  215646.0     HS-grad            9.0            Divorced  Handlers-cleaners  ...  White    Male          0.0           0.0            40.0   United-States      0</span><br><span class="line">3      53.0           Private  234721.0        11th            7.0  Married-civ-spouse  Handlers-cleaners  ...  Black    Male          0.0           0.0            40.0   United-States      0</span><br><span class="line">4      28.0           Private  338409.0   Bachelors           13.0  Married-civ-spouse     Prof-specialty  ...  Black  Female          0.0           0.0            40.0            Cuba      0</span><br><span class="line">...     ...               ...       ...         ...            ...                 ...                ...  ...    ...     ...          ...           ...             ...             ...    ...</span><br><span class="line">32556  27.0           Private  257302.0  Assoc-acdm           12.0  Married-civ-spouse       Tech-support  ...  White  Female          0.0           0.0            38.0   United-States      0</span><br><span class="line">32557  40.0           Private  154374.0     HS-grad            9.0  Married-civ-spouse  Machine-op-inspct  ...  White    Male          0.0           0.0            40.0   United-States      1</span><br><span class="line">32558  58.0           Private  151910.0     HS-grad            9.0             Widowed       Adm-clerical  ...  White  Female          0.0           0.0            40.0   United-States      0</span><br><span class="line">32559  22.0           Private  201490.0     HS-grad            9.0       Never-married       Adm-clerical  ...  White    Male          0.0           0.0            20.0   United-States      0</span><br><span class="line">32560  52.0      Self-emp-inc  287927.0     HS-grad            9.0  Married-civ-spouse    Exec-managerial  ...  White  Female      15024.0           0.0            40.0   United-States      1</span><br><span class="line"></span><br><span class="line">[32561 rows x 15 columns]</span><br><span class="line">        age     workclass    fnlwgt     education  education-num      marital-status  ...     sex capital-gain capital-loss hours-per-week  native-country  income</span><br><span class="line">0      25.0       Private  226802.0          11th            7.0       Never-married  ...    Male          0.0          0.0           40.0   United-States       0</span><br><span class="line">1      38.0       Private   89814.0       HS-grad            9.0  Married-civ-spouse  ...    Male          0.0          0.0           50.0   United-States       0</span><br><span class="line">2      28.0     Local-gov  336951.0    Assoc-acdm           12.0  Married-civ-spouse  ...    Male          0.0          0.0           40.0   United-States       1</span><br><span class="line">3      44.0       Private  160323.0  Some-college           10.0  Married-civ-spouse  ...    Male       7688.0          0.0           40.0   United-States       1</span><br><span class="line">4      18.0           NaN  103497.0  Some-college           10.0       Never-married  ...  Female          0.0          0.0           30.0   United-States       0</span><br><span class="line">...     ...           ...       ...           ...            ...                 ...  ...     ...          ...          ...            ...             ...     ...</span><br><span class="line">16276  39.0       Private  215419.0     Bachelors           13.0            Divorced  ...  Female          0.0          0.0           36.0   United-States       0</span><br><span class="line">16277  64.0           NaN  321403.0       HS-grad            9.0             Widowed  ...    Male          0.0          0.0           40.0   United-States       0</span><br><span class="line">16278  38.0       Private  374983.0     Bachelors           13.0  Married-civ-spouse  ...    Male          0.0          0.0           50.0   United-States       0</span><br><span class="line">16279  44.0       Private   83891.0     Bachelors           13.0            Divorced  ...    Male       5455.0          0.0           40.0   United-States       0</span><br><span class="line">16280  35.0  Self-emp-inc  182148.0     Bachelors           13.0  Married-civ-spouse  ...    Male          0.0          0.0           60.0   United-States       1</span><br><span class="line"></span><br><span class="line">[16281 rows x 15 columns]</span><br><span class="line">[03/29/2020, 04:36:35 PM] WARNING (nni) Requesting parameter without NNI framework, returning empty dict</span><br><span class="line">[&#x27;workclass&#x27;, &#x27;education&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;native-country&#x27;] [&#x27;age&#x27;, &#x27;workclass&#x27;, &#x27;fnlwgt&#x27;, &#x27;education&#x27;, &#x27;education-num&#x27;, &#x27;marital-status&#x27;, &#x27;occupation&#x27;, &#x27;relationship&#x27;, &#x27;race&#x27;, &#x27;sex&#x27;, &#x27;capital-gain&#x27;, &#x27;capital-loss&#x27;, &#x27;hours-per-week&#x27;, &#x27;native-country&#x27;]</span><br><span class="line">&lt;IPython.core.display.HTML object&gt;</span><br><span class="line">MetricVisualizer(layout=Layout(align_self=&#x27;stretch&#x27;, height=&#x27;500px&#x27;))</span><br><span class="line">0:      test: 0.8316184 best: 0.8316184 (0)     total: 79ms     remaining: 1m 18s</span><br><span class="line">50:     test: 0.9020779 best: 0.9020779 (50)    total: 942ms    remaining: 17.5s</span><br><span class="line">100:    test: 0.9081992 best: 0.9081992 (100)   total: 1.71s    remaining: 15.2s</span><br><span class="line">150:    test: 0.9108707 best: 0.9108707 (150)   total: 2.48s    remaining: 13.9s</span><br><span class="line">200:    test: 0.9133666 best: 0.9133666 (200)   total: 3.27s    remaining: 13s</span><br><span class="line">250:    test: 0.9161119 best: 0.9161119 (250)   total: 4.05s    remaining: 12.1s</span><br><span class="line">300:    test: 0.9181722 best: 0.9181726 (299)   total: 4.8s     remaining: 11.2s</span><br><span class="line">350:    test: 0.9191926 best: 0.9191926 (350)   total: 5.56s    remaining: 10.3s</span><br><span class="line">400:    test: 0.9205207 best: 0.9205207 (400)   total: 6.3s     remaining: 9.41s</span><br><span class="line">450:    test: 0.9210106 best: 0.9210106 (450)   total: 7.05s    remaining: 8.59s</span><br><span class="line">500:    test: 0.9215160 best: 0.9215160 (500)   total: 7.81s    remaining: 7.78s</span><br><span class="line">550:    test: 0.9221193 best: 0.9221193 (550)   total: 8.59s    remaining: 7s</span><br><span class="line">600:    test: 0.9227742 best: 0.9227742 (600)   total: 9.37s    remaining: 6.22s</span><br><span class="line">650:    test: 0.9232136 best: 0.9232136 (650)   total: 10.1s    remaining: 5.41s</span><br><span class="line">700:    test: 0.9234202 best: 0.9234202 (700)   total: 10.8s    remaining: 4.61s</span><br><span class="line">750:    test: 0.9238425 best: 0.9238428 (749)   total: 11.6s    remaining: 3.83s</span><br><span class="line">800:    test: 0.9242466 best: 0.9242466 (800)   total: 12.4s    remaining: 3.07s</span><br><span class="line">850:    test: 0.9244801 best: 0.9244826 (849)   total: 13.1s    remaining: 2.3s</span><br><span class="line">900:    test: 0.9246592 best: 0.9246633 (899)   total: 13.8s    remaining: 1.52s</span><br><span class="line">950:    test: 0.9248365 best: 0.9248397 (949)   total: 14.6s    remaining: 752ms</span><br><span class="line">999:    test: 0.9250032 best: 0.9250045 (998)   total: 15.3s    remaining: 0us</span><br><span class="line"></span><br><span class="line">bestTest = 0.9250045138</span><br><span class="line">bestIteration = 998</span><br><span class="line"></span><br><span class="line">Shrink model to first 999 iterations.</span><br><span class="line"> 1) capital-gain                   30.102152</span><br><span class="line"> 2) relationship                   21.504190</span><br><span class="line"> 3) capital-loss                   11.414022</span><br><span class="line"> 4) age                            10.377241</span><br><span class="line"> 5) education-num                  7.234561</span><br><span class="line"> 6) occupation                     6.331733</span><br><span class="line"> 7) hours-per-week                 4.476134</span><br><span class="line"> 8) marital-status                 4.354055</span><br><span class="line"> 9) sex                            1.146389</span><br><span class="line">10) education                      1.092454</span><br><span class="line">11) workclass                      0.776362</span><br><span class="line">12) fnlwgt                         0.577348</span><br><span class="line">13) native-country                 0.382720</span><br><span class="line">14) race                           0.230639</span><br><span class="line">another feature importances with prettified=True</span><br><span class="line"></span><br><span class="line">        Feature Id  Importances</span><br><span class="line">0     capital-gain    30.102152</span><br><span class="line">1     relationship    21.504190</span><br><span class="line">2     capital-loss    11.414022</span><br><span class="line">3              age    10.377241</span><br><span class="line">4    education-num     7.234561</span><br><span class="line">5       occupation     6.331733</span><br><span class="line">6   hours-per-week     4.476134</span><br><span class="line">7   marital-status     4.354055</span><br><span class="line">8              sex     1.146389</span><br><span class="line">9        education     1.092454</span><br><span class="line">10       workclass     0.776362</span><br><span class="line">11          fnlwgt     0.577348</span><br><span class="line">12  native-country     0.382720</span><br><span class="line">13            race     0.230639</span><br><span class="line">&lt;IPython.core.display.HTML object&gt;</span><br><span class="line">MetricVisualizer(layout=Layout(align_self=&#x27;stretch&#x27;, height=&#x27;500px&#x27;))</span><br><span class="line">AUC values:[0.83161836 0.85856642 0.85813673 0.86103314 0.86071689 0.86121893</span><br><span class="line"> 0.86441522 0.86505078 0.8784926  0.87975055 0.88290187 0.88250307</span><br><span class="line"> 0.88799037 0.8881507  0.89029036 0.88999382 0.88988625 0.89090279</span><br><span class="line"> 0.89101198 0.89160979 0.89201995 0.89295319 0.89335747 0.89347394</span><br><span class="line"> 0.89391874 0.89388563 0.89537425 0.89577286 0.89558464 0.89714728</span><br><span class="line"> 0.89720971 0.89743348 0.89766614 0.89780103 0.89835231 0.89859723</span><br><span class="line"> 0.89845935 0.89914869 0.89911805 0.89974913 0.89990595 0.90033138</span><br><span class="line"> 0.90038467 0.90098889 0.90072697 0.90107988 0.90084311 0.90124622</span><br><span class="line"> 0.90129837 0.90169675 0.90207794 0.90213554 0.90252241 0.90278218</span><br><span class="line"> 0.90291333 0.90347889 0.90362643 0.90369515 0.90384743 0.90364836</span><br><span class="line"> 0.90427544 0.90441459 0.90463238 0.90473693 0.90474323 0.9047752</span><br><span class="line"> 0.90479827 0.90473968 0.90509671 0.9052363  0.90524989 0.90552186</span><br><span class="line"> 0.90563292 0.90562407 0.90597002 0.90596054 0.90612973 0.90613532</span><br><span class="line"> 0.90626529 0.90624885 0.90629925 0.9065094  0.90687207 0.90713255</span><br><span class="line"> 0.90713464 0.90714229 0.90716147 0.90720291 0.90736582 0.9074965</span><br><span class="line"> 0.90754282 0.90756655 0.907661   0.90770332 0.9077639  0.90790968</span><br><span class="line"> 0.9079417  0.90798504 0.90802753 0.90811397 0.90819922 0.90826913</span><br><span class="line"> 0.90827529 0.90832273 0.90834522 0.90836268 0.90852687 0.90865518</span><br><span class="line"> 0.90867734 0.90877048 0.9088641  0.90892809 0.90899198 0.90898232</span><br><span class="line"> 0.90901235 0.90917898 0.90931463 0.90933462 0.90946639 0.90955688</span><br><span class="line"> 0.90957899 0.90955768 0.9096148  0.90963834 0.90960947 0.9097182</span><br><span class="line"> 0.90968601 0.90968109 0.90973949 0.90986055 0.90987831 0.90990626</span><br><span class="line"> 0.90988658 0.90996061 0.9100206  0.91016861 0.9102051  0.91031329</span><br><span class="line"> 0.91035212 0.91039234 0.91038859 0.91055811 0.91059551 0.91060905</span><br><span class="line"> 0.91068851 0.91069095 0.91070089 0.91075133 0.9107646  0.91083661</span><br><span class="line"> 0.91087072 0.91088294 0.91089601 0.9109779  0.91109368 0.91112637</span><br><span class="line"> 0.91117719 0.91131483 0.91133695 0.91135528 0.91138891 0.91139388</span><br><span class="line"> 0.91141477 0.91143149 0.91147063 0.91155253 0.91162016 0.91166083</span><br><span class="line"> 0.91172069 0.91181031 0.91196481 0.91200488 0.91207325 0.91211531</span><br><span class="line"> 0.91215074 0.91216651 0.91216438 0.91216644 0.91217042 0.91222321</span><br><span class="line"> 0.91224604 0.91226224 0.91238903 0.91245311 0.91250443 0.9125005</span><br><span class="line"> 0.91256733 0.9126408  0.91267537 0.9127926  0.91283471 0.91296865</span><br><span class="line"> 0.91309914 0.91321599 0.9132311  0.91326122 0.91331664 0.9133272</span><br><span class="line"> 0.91333757 0.91335631 0.91336663 0.91339323 0.91351306 0.91353504</span><br><span class="line"> 0.91364762 0.91371905 0.91374356 0.91382455 0.91383544 0.91387963</span><br><span class="line"> 0.9138874  0.9139162  0.9139656  0.91401361 0.91409119 0.91417138</span><br><span class="line"> 0.91415125 0.91426151 0.91427733 0.91430731 0.91443747 0.91448261</span><br><span class="line"> 0.91453059 0.91459567 0.91462631 0.91465691 0.91466103 0.91475955</span><br><span class="line"> 0.91475329 0.91484831 0.91488644 0.9149258  0.91522573 0.91525917</span><br><span class="line"> 0.91535504 0.91542878 0.91546454 0.91549223 0.91553097 0.91555825</span><br><span class="line"> 0.91559304 0.91562558 0.91568611 0.91569478 0.91571794 0.9157357</span><br><span class="line"> 0.91576043 0.91577251 0.9158588  0.91609757 0.91611192 0.91617368</span><br><span class="line"> 0.91615905 0.91616662 0.91621344 0.91624148 0.91624617 0.916279</span><br><span class="line"> 0.91631196 0.91642947 0.91647835 0.91652667 0.91651392 0.91652581</span><br><span class="line"> 0.91653713 0.91655006 0.91665427 0.91667051 0.916788   0.91681452</span><br><span class="line"> 0.91685526 0.91696372 0.91706001 0.91709748 0.91709928 0.91717672</span><br><span class="line"> 0.91719126 0.91729565 0.91739161 0.91742034 0.9174929  0.91750469</span><br><span class="line"> 0.91754306 0.9175746  0.91757541 0.91759738 0.91761036 0.91759407</span><br><span class="line"> 0.91763139 0.91772489 0.91776103 0.9179556  0.9179898  0.91801864</span><br><span class="line"> 0.91801737 0.91803603 0.91805739 0.91813814 0.91814534 0.91817263</span><br><span class="line"> 0.9181722  0.91824609 0.91827275 0.91829577 0.91829899 0.91831358</span><br><span class="line"> 0.91837373 0.91842195 0.91842025 0.91844374 0.91845804 0.91856584</span><br><span class="line"> 0.91857612 0.91863774 0.91862941 0.91863533 0.91871476 0.91873683</span><br><span class="line"> 0.91873685 0.91873453 0.91876589 0.91877062 0.91877522 0.91875817</span><br><span class="line"> 0.91876122 0.9187661  0.91875142 0.91882763 0.91882948 0.91885122</span><br><span class="line"> 0.91885425 0.91883814 0.91885245 0.91885491 0.91889654 0.91892941</span><br><span class="line"> 0.91899658 0.91898947 0.91903944 0.91905251 0.91906383 0.91905976</span><br><span class="line"> 0.91905803 0.91906125 0.91911411 0.91912297 0.91911189 0.9191422</span><br><span class="line"> 0.91916427 0.91918881 0.91919262 0.9192038  0.91922066 0.91922383</span><br><span class="line"> 0.91924121 0.91924974 0.91929625 0.91931439 0.9193681  0.91936356</span><br><span class="line"> 0.9194005  0.91940401 0.91942551 0.91941168 0.91949196 0.91950447</span><br><span class="line"> 0.91950522 0.91950731 0.91951408 0.91954548 0.919564   0.91956135</span><br><span class="line"> 0.91961966 0.91962117 0.91961662 0.91963093 0.91963782 0.9197918</span><br><span class="line"> 0.91981146 0.91984902 0.91987796 0.91986474 0.91986896 0.91988572</span><br><span class="line"> 0.91999293 0.91999407 0.9200143  0.92006417 0.920051   0.92006654</span><br><span class="line"> 0.92015715 0.92027774 0.92028039 0.92028351 0.92029304 0.9203403</span><br><span class="line"> 0.92041614 0.9204284  0.920495   0.92051366 0.92052067 0.92052967</span><br><span class="line"> 0.92054984 0.92056874 0.92059948 0.9206144  0.92060015 0.92060062</span><br><span class="line"> 0.9206     0.92060142 0.92060772 0.92063425 0.92063752 0.92064007</span><br><span class="line"> 0.92064424 0.92065741 0.92066167 0.92067399 0.92068185 0.92068403</span><br><span class="line"> 0.92072576 0.92073774 0.92074077 0.92074873 0.92073982 0.92076398</span><br><span class="line"> 0.92077724 0.92078624 0.92078373 0.92078809 0.92077483 0.92077691</span><br><span class="line"> 0.92080732 0.92081864 0.92082224 0.92081307 0.92081577 0.92081407</span><br><span class="line"> 0.9208495  0.92085911 0.92088312 0.92088725 0.92088677 0.92088559</span><br><span class="line"> 0.92089568 0.92089648 0.92090354 0.92092367 0.92092732 0.92094607</span><br><span class="line"> 0.92101058 0.92102503 0.92103919 0.92102465 0.92103474 0.92103725</span><br><span class="line"> 0.92102598 0.92102195 0.92102607 0.92103857 0.92103682 0.92103957</span><br><span class="line"> 0.92106103 0.92107088 0.92107722 0.92108452 0.92108708 0.92114306</span><br><span class="line"> 0.92115324 0.92119644 0.9212017  0.92121074 0.92122964 0.92124253</span><br><span class="line"> 0.92124826 0.92127222 0.92129136 0.92131528 0.92131712 0.92132233</span><br><span class="line"> 0.9213274  0.92132897 0.92131902 0.92132323 0.92133725 0.92138855</span><br><span class="line"> 0.92138997 0.92144297 0.92145268 0.92144453 0.92144766 0.92148863</span><br><span class="line"> 0.92148243 0.92148764 0.92149299 0.92150881 0.92149493 0.92149905</span><br><span class="line"> 0.92150045 0.92151196 0.92151603 0.92152768 0.92153251 0.92151722</span><br><span class="line"> 0.92152228 0.92152569 0.92153124 0.92162734 0.92162582 0.92164117</span><br><span class="line"> 0.9216549  0.92165462 0.92171068 0.92171977 0.92172706 0.92172754</span><br><span class="line"> 0.92173966 0.92175084 0.92175719 0.92175633 0.92175221 0.92176424</span><br><span class="line"> 0.92176529 0.92177016 0.92177178 0.92178025 0.92176628 0.92184211</span><br><span class="line"> 0.9218522  0.92185713 0.92185623 0.92186669 0.92191529 0.92194717</span><br><span class="line"> 0.92195285 0.92197383 0.92197056 0.92197052 0.92197658 0.92198013</span><br><span class="line"> 0.92196483 0.92197075 0.92197885 0.92198245 0.92199188 0.92204175</span><br><span class="line"> 0.92204227 0.92209778 0.92210214 0.92210863 0.92211934 0.92216049</span><br><span class="line"> 0.92216462 0.92216983 0.92217963 0.92217537 0.92221117 0.92241212</span><br><span class="line"> 0.92241638 0.92242576 0.92243073 0.92243177 0.92244111 0.92245001</span><br><span class="line"> 0.92246045 0.9224605  0.92249186 0.92249266 0.9225063  0.92253676</span><br><span class="line"> 0.92254249 0.92254519 0.92255234 0.92255675 0.9225657  0.92257275</span><br><span class="line"> 0.92256906 0.92257072 0.92255637 0.92255892 0.922562   0.92256087</span><br><span class="line"> 0.92257162 0.92257129 0.92257129 0.92257015 0.92255466 0.92255267</span><br><span class="line"> 0.92254007 0.92253922 0.92254197 0.92254647 0.92254566 0.9225891</span><br><span class="line"> 0.9225908  0.92258696 0.92259497 0.92259644 0.92275269 0.9227705</span><br><span class="line"> 0.92277424 0.92276742 0.92277045 0.92277491 0.92278784 0.92278968</span><br><span class="line"> 0.9227921  0.92279944 0.92280498 0.92281464 0.92282772 0.92282279</span><br><span class="line"> 0.92295612 0.92295963 0.92295584 0.92297024 0.92295882 0.92296086</span><br><span class="line"> 0.92295636 0.92296015 0.92296214 0.92297611 0.92297597 0.92297367</span><br><span class="line"> 0.92297282 0.9229821  0.92299015 0.92299285 0.92299162 0.92299494</span><br><span class="line"> 0.92304206 0.92307967 0.92308431 0.92310553 0.92310695 0.92310871</span><br><span class="line"> 0.92310894 0.9231188  0.92311927 0.92312131 0.92313343 0.92313457</span><br><span class="line"> 0.92313679 0.92313154 0.92313566 0.92314866 0.92315825 0.92315967</span><br><span class="line"> 0.92320145 0.92320557 0.92321357 0.92322352 0.92323133 0.92323763</span><br><span class="line"> 0.92323815 0.92324663 0.92324834 0.92325137 0.92325492 0.92325402</span><br><span class="line"> 0.92325374 0.92326515 0.92327003 0.92327538 0.92326444 0.92326927</span><br><span class="line"> 0.92326937 0.92325672 0.92327946 0.92327837 0.92327979 0.92328097</span><br><span class="line"> 0.92328386 0.92329125 0.92329248 0.92329977 0.92330783 0.92330854</span><br><span class="line"> 0.92331124 0.92331299 0.92334018 0.92333804 0.92333752 0.92334894</span><br><span class="line"> 0.92334851 0.92334979 0.92335064 0.92335164 0.92336736 0.92336869</span><br><span class="line"> 0.92337068 0.9233623  0.92336433 0.92336395 0.92336964 0.92337428</span><br><span class="line"> 0.92338446 0.92339521 0.92339592 0.92340004 0.92342017 0.92341999</span><br><span class="line"> 0.92342126 0.92342264 0.92341984 0.92341984 0.92341833 0.92340795</span><br><span class="line"> 0.92341307 0.92342212 0.92346853 0.92346801 0.92349373 0.92351225</span><br><span class="line"> 0.92351931 0.92352476 0.92356085 0.92356151 0.92356483 0.92357894</span><br><span class="line"> 0.92361887 0.92361683 0.92362503 0.92362484 0.92364317 0.92366462</span><br><span class="line"> 0.92366391 0.92366415 0.92366709 0.92367481 0.92368707 0.92368769</span><br><span class="line"> 0.92368816 0.92368991 0.92368925 0.92369735 0.92372847 0.92372814</span><br><span class="line"> 0.92372667 0.92373089 0.92373169 0.92373538 0.92376077 0.92376134</span><br><span class="line"> 0.92377977 0.9238052  0.92380307 0.92382703 0.92383556 0.92384276</span><br><span class="line"> 0.92384248 0.92384338 0.92384195 0.92384991 0.92384778 0.92385673</span><br><span class="line"> 0.92385702 0.92385579 0.92388179 0.92390358 0.92390452 0.92392219</span><br><span class="line"> 0.92393938 0.9239624  0.92396657 0.92397055 0.92397022 0.92398855</span><br><span class="line"> 0.92398784 0.92399916 0.92401161 0.92402559 0.92402535 0.92412785</span><br><span class="line"> 0.92413405 0.92415006 0.92416323 0.92416356 0.92416346 0.9241593</span><br><span class="line"> 0.92415797 0.92415541 0.92415636 0.92415508 0.92415357 0.9241574</span><br><span class="line"> 0.92417905 0.92419297 0.92420628 0.92421429 0.92421362 0.92421457</span><br><span class="line"> 0.92422599 0.92422475 0.92422423 0.92422291 0.92422414 0.9242293</span><br><span class="line"> 0.92423915 0.92424469 0.92424659 0.92424834 0.9242482  0.92426392</span><br><span class="line"> 0.92426804 0.9242796  0.92428093 0.92429978 0.92430196 0.92430196</span><br><span class="line"> 0.92432313 0.92432455 0.9243191  0.92431726 0.9243156  0.9243146</span><br><span class="line"> 0.92432185 0.924339   0.92433824 0.92435922 0.92436339 0.92436391</span><br><span class="line"> 0.92437964 0.92437731 0.92438267 0.92438025 0.92437954 0.92437973</span><br><span class="line"> 0.92441307 0.92441795 0.92441701 0.92442023 0.9244314  0.92442975</span><br><span class="line"> 0.92442918 0.92442804 0.92442899 0.92443202 0.92443264 0.92443145</span><br><span class="line"> 0.92444026 0.92445457 0.92445348 0.92445267 0.92445163 0.92445144</span><br><span class="line"> 0.92446295 0.92447209 0.92446982 0.92448261 0.92448014 0.92448966</span><br><span class="line"> 0.92450439 0.92450236 0.92450188 0.92450184 0.92449956 0.92451074</span><br><span class="line"> 0.92451017 0.9245222  0.92452661 0.92452457 0.92453395 0.92453172</span><br><span class="line"> 0.92454541 0.92454967 0.92454584 0.92454304 0.92454058 0.92454039</span><br><span class="line"> 0.92453722 0.92455214 0.92455304 0.92454953 0.92456061 0.92457629</span><br><span class="line"> 0.9245798  0.92457681 0.92459439 0.92460656 0.92462025 0.92461693</span><br><span class="line"> 0.92462337 0.92461906 0.92463341 0.9246309  0.92463697 0.92463474</span><br><span class="line"> 0.92463332 0.92463242 0.92462896 0.92462574 0.92463891 0.92464047</span><br><span class="line"> 0.92464241 0.92464023 0.92464147 0.92465189 0.92465809 0.9246633</span><br><span class="line"> 0.92465923 0.92466605 0.92466898 0.92467012 0.92466695 0.92466572</span><br><span class="line"> 0.92467879 0.92468964 0.92471355 0.92472397 0.92472525 0.9247262</span><br><span class="line"> 0.92473302 0.92472966 0.92473449 0.92473468 0.92473392 0.92473316</span><br><span class="line"> 0.92473132 0.92472805 0.92472582 0.92472492 0.92472293 0.9247263</span><br><span class="line"> 0.92473454 0.92473511 0.92473743 0.92473648 0.92475415 0.92476172</span><br><span class="line"> 0.92475898 0.92477077 0.92479057 0.92479355 0.92479284 0.92480303</span><br><span class="line"> 0.9248143  0.92481302 0.92482448 0.92482211 0.92482301 0.92482368</span><br><span class="line"> 0.92482808 0.92482638 0.92482931 0.92483178 0.92483741 0.92483784</span><br><span class="line"> 0.9248386  0.92483969 0.92483646 0.9248404  0.92485238 0.92485067</span><br><span class="line"> 0.92486796 0.92488321 0.92488009 0.92487786 0.92487805 0.92488516</span><br><span class="line"> 0.92488994 0.92489098 0.92490003 0.92490704 0.92490391 0.92491362</span><br><span class="line"> 0.92492802 0.92493299 0.9249463  0.92494289 0.92493906 0.92493816</span><br><span class="line"> 0.92494223 0.92493996 0.9249382  0.92493849 0.9249491  0.92494697</span><br><span class="line"> 0.92494711 0.92495838 0.92495838 0.92497013 0.92498078 0.92497794</span><br><span class="line"> 0.92497695 0.92497827 0.92497619 0.924976   0.92498211 0.92498495</span><br><span class="line"> 0.92499078 0.92500338 0.92500087 0.92500049 0.92499874 0.92499874</span><br><span class="line"> 0.92499883 0.92499935 0.92500451]</span><br><span class="line">AUC of prediction:0.8603217542453206</span><br></pre></td></tr></table></figure>
<h2 id="人工神经网络-neural-network">2.6 人工神经网络-Neural Network</h2>
神经网络在维基百科上的定义是：NN is a network inspired by biological neural networks (the central nervous systems of animals, in particular the brain) which are used to estimate or approximate functions that can depend on a large number of inputs that are generally unknown.(from wikipedia)
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap79lfscsq013g11c4g1aqu1jb4m.png" width="300"  />
</center>
<h3 id="神经元">2.6.1 神经元</h3>
神经元是神经网络和SVM这类模型的基础模型和来源，它是一个具有如下结构的线性模型：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap6vqg8k1nursgn1kv541nevd9.png" width="300" />
</center>
<p>其输出模式为：</p>
<blockquote>
<p><span class="math display">\[
\begin{array}{l}
output &amp; = &amp; \left\{ \begin{array}{1}
0 &amp; if~ \sum_j w_j x_j + b \leq 0 \\
1 &amp; if~ \sum_j w_j x_j + b&gt; 0
\end{array} \right.
\end{array}
\]</span></p>
</blockquote>
示意图如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap79nd0j1m5cuhbv0ltog1ao313.png" width="400" />
</center>
<h3 id="神经网络的常用结构">2.6.2 神经网络的常用结构</h3>
神经网络由一系列神经元组成，典型的神经网络结构如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7b1i9s156h8n91noe1v0b1kk41g.png" width="500" />
</center>
<p>其中最左边是输入层，包含若干输入神经元，最右边是输出层，包含若干输出神经元，介于输入层和输出层的所有层都叫隐藏层，由于神经元的作用，任何权重的微小变化都会导致输出的微小变化，即这种变化是平滑的。</p>
神经元的各种组合方式得到性质不一的神经网络结构 :
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7hp4el195d12al1d2119h3r8e46.png" width="350"  />
</center>
<center>
前馈神经网络
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1asuka9jl1u479sd1k7l64l11s2m.png" width="350"  />
</center>
<center>
反向传播神经网络
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7k2i4u1qeq14871ge613np5r5d.png" width="350"  />
</center>
<center>
循环神经网络
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7i6rfq1ua917bf12llgol1vcs50.png" width="450"  />
</center>
<center>
卷积神经网络
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7kf21k8c2me14dr1sd1t5d67.png" width="350" />
</center>
<center>
自编码器
</center>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap7kod2dpkn1cqu1oksvmd3ms6t.png" width="600" />
</center>
<center>
Google DeepMind 记忆神经网络(用于AlphaGo)
</center>
<h3 id="一个简单的神经网络例子">2.6.3 一个简单的神经网络例子</h3>
<p>假设随机变量 <span class="math inline">\(x \sim N(0,1)\)</span>, 使用3层神经网络拟合该分布： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib</span><br><span class="line">matplotlib.use(&#x27;Agg&#x27;)</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import random</span><br><span class="line">import math</span><br><span class="line">import keras</span><br><span class="line">from keras.models import Sequential</span><br><span class="line">from keras.layers.core import Dense,Dropout,Activation</span><br><span class="line"></span><br><span class="line">def gd(x,m,s):      </span><br><span class="line">  left=1/(math.sqrt(2*math.pi)*s)      </span><br><span class="line">  right=math.exp(-math.pow(x-m,2)/(2*math.pow(s,2)))      </span><br><span class="line">  return left*right  </span><br><span class="line"></span><br><span class="line">def pt(x, y1, y2):</span><br><span class="line">  if len(x) != len(y1) or len(x) != len(y2):</span><br><span class="line">    print &#x27;input error.&#x27;</span><br><span class="line">    return</span><br><span class="line">  plt.figure(num=1, figsize=(20, 6))</span><br><span class="line">  plt.title(&#x27;NN fitting Gaussian distribution&#x27;, size=14)</span><br><span class="line">  plt.xlabel(&#x27;x&#x27;, size=14)</span><br><span class="line">  plt.ylabel(&#x27;y&#x27;, size=14)</span><br><span class="line">  plt.plot(x, y1, color=&#x27;b&#x27;, linestyle=&#x27;--&#x27;, label=&#x27;Gaussian distribution&#x27;)</span><br><span class="line">  plt.plot(x, y2, color=&#x27;r&#x27;, linestyle=&#x27;-&#x27;, label=&#x27;NN fitting&#x27;)</span><br><span class="line">  plt.legend(loc=&#x27;upper left&#x27;)</span><br><span class="line">  plt.savefig(&#x27;ann.png&#x27;, format=&#x27;png&#x27;)</span><br><span class="line"></span><br><span class="line">def ann(train_d, train_l, prd_d):</span><br><span class="line">  if len(train_d) == 0 or len(train_d) != len(train_l):</span><br><span class="line">    print &#x27;training data error.&#x27;</span><br><span class="line">    return</span><br><span class="line">  model = Sequential()</span><br><span class="line">  model.add(Dense(30, input_dim=1))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line">  model.add(Dense(30))</span><br><span class="line">  model.add(Activation(&#x27;relu&#x27;))</span><br><span class="line"></span><br><span class="line">  model.add(Dense(1, activation=&#x27;sigmoid&#x27;))</span><br><span class="line">  model.compile(loss=&#x27;mse&#x27;,</span><br><span class="line">              optimizer=&#x27;rmsprop&#x27;,</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br><span class="line">  model.fit(train_d,train_l,batch_size=250, nb_epoch=50, validation_split=0.2)</span><br><span class="line">  p = model.predict(prd_d,batch_size=250)</span><br><span class="line">  return p</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">  x = np.linspace(-5, 5, 10000)</span><br><span class="line">  idx = random.sample(x, 900)</span><br><span class="line">  train_d = []</span><br><span class="line">  train_l = []</span><br><span class="line">  for i in idx:</span><br><span class="line">    train_d.append(x[i])</span><br><span class="line">    train_l.append(gd(x[i],0,1))</span><br><span class="line">  </span><br><span class="line">  y1 = []</span><br><span class="line">  y2 = []</span><br><span class="line">  for i in x:</span><br><span class="line">    y1.append(gd(i,0,1))      </span><br><span class="line"></span><br><span class="line">  y2 = ann(np.array(train_d).reshape(len(train_d), 1), np.array(train_l), np.array(x).reshape(len(x), 1))</span><br><span class="line">  pt(x, y1, y2.tolist())</span><br></pre></td></tr></table></figure></p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_2/image_1ap87o3no141a1tnvid984h1vnv7n.png" width="600"  />
</center>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/page/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="张磊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习和思考，以心力提升认知">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/page/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">机器学习与人工智能技术分享-第一章 基本概念</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-09-13 14:44:00 / Modified: 16:52:12" itemprop="dateCreated datePublished" datetime="2021-09-13T14:44:00+08:00">2021-09-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div style="float:left;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4gmqc1l38cpd11e61b97uvs9.png"  width="200" height="260" >
</div>
<div style="float:right;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4qcc01pn16mp7m3149c1dubm.png" width="200" height="260" >
</div>
<div style="float:none;clear:both;">

</div>
<h1 id="一些基本概念">1. 一些基本概念</h1>
<h2 id="生成式模型与判别式模型">1.1 生成式模型与判别式模型</h2>
<p>从概率分布的角度看待模型。 给个例子感觉一下: 如果我想知道一个人A说的是哪个国家的语言，我应该怎么办呢?</p>
<ul>
<li><p>生成式模型</p>
<p>我把每个国家的语言都学一遍，这样我就能很容易知道A说的是哪国语言，并且C、D说的是哪国的我也可以知道，进一步我还能自己讲不同国家语言。</p></li>
<li><p>判别式模型</p>
<p>我只需要学习语言之间的差别是什么，学到了这个界限自然就能区分不同语言，我能说出不同语言的区别，但我可能不会讲。</p></li>
</ul>
<p>如果我有输入数据<span class="math inline">\(x\)</span>，并且想通过标注<span class="math inline">\(y\)</span>去区分不同数据属于哪一类，生成式模型是在学习样本和标注的联合概率分布 <span class="math inline">\(p(x,y)\)</span> 而判别式模型是在学习条件概率 <span class="math inline">\(p(y|x)\)</span>。 生成式模型<span class="math inline">\(p(x,y)\)</span>可以通过贝叶斯公式转化为<span class="math inline">\(p(y|x)=\frac{p(x,y)}{p(x)}\)</span>，并用于分类，而联合概率分布<span class="math inline">\(p(x,y)\)</span>也可用于其他目的，比如用来生成样本对<span class="math inline">\((x,y)\)</span>。</p>
<p>判别式模型的主要任务是找到一个或一系列超平面，利用它(们)划分给定样本<span class="math inline">\(x\)</span>到给定分类<span class="math inline">\(y\)</span>，这也能直白的体现出“判别”模型这个名称。</p>
<p>最后给一个很简单的例子说明一下： 假如我有以下独立同分布的若干样本<span class="math inline">\((x,y)\)</span>，其中<span class="math inline">\(x\)</span>为特征，<span class="math inline">\(y\in\{0,1\}\)</span>为标注,<span class="math inline">\((x,y)\in\{(2,-1),(2,-1),(3,-1),(3,1),(3,1)\}\)</span>，则：</p>
<ul>
<li><p><span class="math inline">\(p(x,y)\)</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(p(x,y)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y=-1\)</span></th>
<th><span class="math inline">\(y=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x=2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(2/5\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x=3\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1/5\)</span></td>
<td><span class="math inline">\(2/5\)</span></td>
</tr>
</tbody>
</table></li>
<li><p><span class="math inline">\(p(y|x)\)</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(p(y|x)\)</span></th>
<th style="text-align: right;"><span class="math inline">\(y=-1\)</span></th>
<th><span class="math inline">\(y=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(x=2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(x=3\)</span></td>
<td style="text-align: right;"><span class="math inline">\(1/3\)</span></td>
<td><span class="math inline">\(2/3\)</span></td>
</tr>
</tbody>
</table></li>
</ul>
<p>一些理论可看：<a target="_blank" rel="noopener" href="http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf">On Discriminative vs Generative classifiers: A comparison of logistic regression and naive Bayes</a>。</p>
<ol type="1">
<li><p>常见生成式模型</p>
<ul>
<li><p>Naive Bayes</p></li>
<li><p>Gaussians</p></li>
<li><p>Mixtures of Gaussians</p></li>
<li><p>Mixtures of Experts</p></li>
<li><p>Mixtures of Multinomials</p></li>
<li><p>HMM</p></li>
<li><p>Markov random fields</p></li>
<li><p>Sigmoidal belief networks</p></li>
<li><p>Bayesian networks</p></li>
</ul></li>
<li><p>常见判别式模型</p>
<ul>
<li><p>Linear regression</p></li>
<li><p>Logistic regression</p></li>
<li><p>SVM</p></li>
<li><p>Perceptron</p></li>
<li><p>Traditional Neural networks</p></li>
<li><p>Nearest neighbor</p></li>
<li><p>Conditional random fields</p></li>
</ul></li>
</ol>
<h2 id="参数学习与非参学习">1.2 参数学习与非参学习</h2>
<p>从参数与样本的关系角度看待模型。</p>
<h3 id="参数学习">1.2.1 参数学习</h3>
<p>参数学习的特点是：</p>
<ol type="1">
<li><p>选择某种形式的函数并通过机器学习用一系列固定个数的参数尽可能表征这些数据的某种模式；</p></li>
<li><p>不管数据量有多大，函数参数的个数是固定的，即参数个数不随着样本量的增大而增加，从关系上说它们相互独立；</p></li>
<li><p>往往对数据有较强的假设，如分布的假设，空间的假设等。</p></li>
<li><p>常用参数学习的模型有：</p>
<ul>
<li><p>Logistic Regression</p></li>
<li><p>Linear Regression</p></li>
<li><p>Polynomial regression</p></li>
<li><p>Linear Discriminant Analysis</p></li>
<li><p>Perceptron</p></li>
<li><p>Naive Bayes</p></li>
<li><p>Simple Neural Networks</p></li>
<li><p>使用线性核的SVM</p></li>
<li><p>Mixture models</p></li>
<li><p>K-means</p></li>
<li><p>Hidden Markov models</p></li>
<li><p>Factor analysis / pPCA / PMF</p></li>
</ul></li>
</ol>
<h3 id="非参学习">1.2.2 非参学习</h3>
<p>注意不要被名字误导，<strong>非参不等于无参</strong>。</p>
<ol type="1">
<li><p>数据决定了函数形式，函数参数个数不固定；</p></li>
<li><p>随着数据量的增加，参数个数一般也会随之增长；</p></li>
<li><p>对数据本身做较少的先验假设。</p></li>
<li><p>一些常用的非参学习模型：</p>
<ul>
<li><p>k-Nearest Neighbors</p></li>
<li><p>Decision Trees like CART and C4.5</p></li>
<li><p>使用非线性核的SVM</p></li>
<li><p>Gradient Boosted Decision Trees</p></li>
<li><p>Gaussian processes for regression</p></li>
<li><p>Dirichlet process mixtures</p></li>
<li><p>infinite HMMs</p></li>
<li><p>infinite latent factor models</p></li>
</ul></li>
</ol>
<p>进一步知识可以看：<a target="_blank" rel="noopener" href="http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf">Parametric vs Nonparametric Models</a>。</p>
<h2 id="监督学习非监督学习与强化学习">1.3 监督学习、非监督学习与强化学习</h2>
<h3 id="监督学习">1.3.1 监督学习</h3>
<p>对于每一个样本都会提供一个明确的学习目标（标注），有自变量也有因变量，学习机接收样本进行学习并通过对该样本预测后的结果和事先给定的目标比较后修正学习过程，这里的每一个样本都是标注好的，所以好处是歧义较低，坏处是万一有一定量样本标错了或者没标会对最终应用效果影响较大。通常监督学习过程如下：</p>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjqpcau16kj17d5iupnob1rco9.png" width="500"/> picture from <a target="_blank" rel="noopener" href="http://en.proft.me/2015/12/24/types-machine-learning-algorithms/">here</a>
</center>
<h3 id="非监督学习">1.3.2 非监督学习</h3>
对于每个样本不提供明确的学习目标（标注），有自变量但无因变量，学习机接收样本后会按事先指定的必要参数，依据某种相似度衡量方式自动学习样本内部的分布模式，好处是没有过多先验假设，能够体现数据内在模式并应用，坏处是有“盲目”性，并会混在噪声数据。比如：常用LDA做主题聚类，但如果使用场景不是降维而是想得到可输出的主题词，基本上没有人肉的干预无法直接使用（虽然整体上看感觉可能不错）。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjrioa912r21h0n1u571vh11go3m.png" width="500"/> picture from <a target="_blank" rel="noopener" href="http://en.proft.me/2015/12/24/types-machine-learning-algorithms/">here</a>
</center>
<h3 id="强化学习">1.3.3 强化学习</h3>
<p>我认为强化学习是最接近人类学习过程的，很多情况下我们无法直接表达什么是正确的什么是错误的（比如：我正在爬山，迈了一大步，又迈了一小步，那么没法儿说我迈了大步正确还是错误），但是可以通过惩罚不好的结果或者奖励好的结果来强化学习的效果（我迈了个大步，导致没有站稳，那么对迈大步做惩罚，然后接下来我会迈小一点）。所以强化学习是一个序列的决策过程，学习机的学习目标是通过在给定状态下选择某种动作，寻找合适动作的策略序列使得它可以获得某种最优结果的过程。 强化学习的几个要素，体现其序列、交互性：</p>
<ul>
<li>环境(environment)：强化学习所处的上下文；</li>
<li>学习器(agent)：与环境的交互并学习的对象，具有主动性；</li>
<li>动作(action)：处于环境下的可行动作集合；</li>
<li>反馈(feedback)：对动作的回报或惩罚；</li>
<li>策略(policy)：学习到的策略链。</li>
</ul>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asjski0i16221ae2rdd1789l3n13.png" width="400"/> picture from <a target="_blank" rel="noopener" href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/followup.html">here</a>
</center>
经典的训练狗的实验就是一种强化学习的过程：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_1/image_1asju6357fv9q891abinifjkf2a.png" width="500" /> picture from <a target="_blank" rel="noopener" href="http://www.krigolsonteaching.com/reinforcement-learning.html">here</a>
</center>
<p>强化学习的有趣应用例如：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://deepmind.com/research/alphago/">AlphaGo</a> <a target="_blank" rel="noopener" href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf">Mastering the Game of Go with Deep Neural Networks and Tree Search</a></li>
<li>Atari 2600 games <a target="_blank" rel="noopener" href="http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html#ref12">Human-level control through deep reinforcement learning</a> <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1507.04296.pdf">Massively Parallel Methods for Deep Reinforcement Learning</a></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://vivounicorn.github.io/page/2021/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E5%85%AB%E7%AB%A0-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="张磊">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="学习和思考，以心力提升认知">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/page/2021/09/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB-%E7%AC%AC%E5%85%AB%E7%AB%A0-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%AF%86%E5%88%AB/" class="post-title-link" itemprop="url">机器学习与人工智能技术分享-第八章 目标检测与识别</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-10 14:25:42" itemprop="dateCreated datePublished" datetime="2021-09-10T14:25:42+08:00">2021-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-09-13 16:16:53" itemprop="dateModified" datetime="2021-09-13T16:16:53+08:00">2021-09-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div style="float:left;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4gmqc1l38cpd11e61b97uvs9.png"  width="200" height="260" >
</div>
<div style="float:right;border:solid 1px 000;margin:2px;">
<img src="https://vivounicorn.github.io/images/image_1ben4qcc01pn16mp7m3149c1dubm.png" width="200" height="260" >
</div>
<div style="float:none;clear:both;">

</div>
<h1 id="目标检测与识别">8. 目标检测与识别</h1>
目标检测的发展历程大致如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bg86igedlru9801vgh8f913g4m.png" width="800"  />
</center>
<h2 id="selective-search">8.1 Selective Search</h2>
对于目标识别任务，比如判断一张图片中有没有车、是什么车，一般需要解决两个问题：目标检测、目标识别。而目标检测任务中通常需要先通过某种方法做图像分割，事先得到候选框；直观的做法是：给定窗口，对整张图片滑动扫描，结束后改变窗口大小重复上面步骤，缺点很明显：重复劳动耗费资源、精度和质量不高等等。 针对上面的问题，一种解决方案是借鉴启发式搜索的方法，充分利用人类的先验知识。J.R.R. Uijlings在《<a target="_blank" rel="noopener" href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf">Selective Search for Object Recoginition</a>》提出一种方法：基于数据驱动，与具体类别无关的多种策略融合的启发式生成方法。图片包含各种丰富信息，例如：大小、形状、颜色、纹理、物体重叠关系等，如果只使用一种信息往往不能解决大部分问题，例如：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga5pfj1d621rq7i851vvprc19.png" width="500"/>
</center>
<p>左边的两只猫可以通过颜色区别而不是通过纹理，右面的变色龙却只能通过纹理区别而不是颜色。</p>
<h3 id="启发式生成设计准则">8.1.1 启发式生成设计准则</h3>
<p>所以概括来说：</p>
<ul>
<li>能够捕捉到各种尺度物体，大的、小的、边界清楚的、边界模糊的等等； 多尺度的例子： <img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga9sm381ben1hhu167411ng1h9f13.png" alt="多尺度例子" /></li>
<li>策略多样性，采用多样的策略集合共同作用；</li>
<li>计算快速，由于生成候选框只是检测第一步，所以计算上它决不能成为瓶颈。</li>
</ul>
<h3 id="selective-search-1">8.1.2 Selective Search</h3>
<p>基于以上准则设计Selective Search算法：</p>
<ul>
<li><p>采用层次分组算法解决尺度问题</p>
<p>引入图像分割中的自下而上分组思想，由于整个过程是层次的，在将整个图合并成一个大的区域的过程中会输出不同尺度的多个子区域。整个过程如下：</p>
<p>1、利用《<a target="_blank" rel="noopener" href="https://cs.brown.edu/~pff/papers/seg-ijcv.pdf">Efficient Graph-Based Image Segmentation</a>》（基本思想：将图像中每个像素表示为图上的一个节点，用于连接不同节点的无向边都有一个权重，这个权重表示两个节点之间的不相似度，通过贪心算法利用最小生成树做图像分割）生成初始候选区域；</p>
<p>2、采用贪心算法合并区域，计算任意两个领域的相似度，把达到阈值的合并，再计算新区域和其所有领域的相似度，循环迭代，直到整个图变成了一个区域，算法如下：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bga9fgjm5ei1r9ks661milsvpm.png" width="800"/></p>
</center></li>
<li><p>多样化策略</p>
<p>三个方面：使用多种颜色空间、使用多种相似度计算方法、搜索起始区域不固定。</p>
<p>1、颜色空间有很多种：RGB、HSV、Lab等等，不是论文重点；</p>
<p>2、相似度衡量算法，结合了4重策略：</p>
<ul>
<li><p>颜色相似度</p>
<p>以RGB为例，使用L1-norm归一化每个图像通道的色彩直方图（bins=25），每个区域被表示为25×3维向量:<span class="math inline">\(C_i=\{c_i^1,...,c_i^n\}\)</span>; 颜色相似度定义为： <span class="math display">\[S_{color}(r_i,r_j)=\sum_{k=1}^nmin(c_i^k,c_j^k)\]</span> 区域合并后对新的区域计算其色彩直方图： <span class="math display">\[C_t=\frac{size(r_i)×C_i+size(r_j)×C_j}{size(r_i)+size(r_j)}\]</span> 新区域的大小为：<span class="math inline">\(size(r_t)=size(r_i)+size(r_j)\)</span></p></li>
<li><p>纹理相似度</p>
<p>使用快速生成的类SIFT特征，对每个颜色通道在8个方向上应用方差为1的高斯滤波器，对每个颜色通道的每个方向提取bins=10的直方图，所以整个纹理向量维度为：3×8×10=240，表示为：<span class="math inline">\(T_i=\{t_i^1,...,t_i^n\}\)</span>; 纹理相似度定义为： <span class="math display">\[S_{texture}(r_i,r_j)=\sum_{k=1}^nmin(t_i^k,t_j^k)\]</span></p></li>
<li><p>大小相似度</p>
<p>该策略希望小的区域能尽早合并，让合并操作比较平滑，防止出现某个大区域逐步吞并其他小区域的情况。相似度定义为： <span class="math display">\[S_{size}=1-\frac{size(r_i)+size(r_j)}{size(im)}\]</span> 其中<span class="math inline">\(size(im)\)</span>为图像包含像素点数目。</p></li>
<li><p>区域规则度相似度</p>
<p>能够框住合并后的两个区域的矩形大小越小说明两个区域的合并越规则，如： 区域规则度相似度定义为： <span class="math display">\[S_{fill}=1-\frac{size(BB_{i,j})-size(r_i)-size(r_j)}{size(im)}\]</span></p></li>
</ul>
<p>最终相似度为所有策略加权和，文中采用等权方式： <span class="math display">\[S_{r_i,r_j}=\alpha_1\cdot S_{color}(r_i,r_j)+\alpha_2\cdot S_{texture}(r_i,r_j)+\alpha_3\cdot S_{size}(r_i,r_j)+\alpha_4\cdot S_{fill}(r_i,r_j)\]</span></p></li>
</ul>
<h3 id="使用selective-search做目标识别">8.1.3 使用Selective Search做目标识别</h3>
训练过程包含：提取候选框、提取特征、生成正负样本、训练模型，图示如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgaclat41i5iddrrsg198m4h529.png" width="800" />
</center>
<p>早期图像特征提取往往是各种HOG特征或BoW特征，现在CNN特征几乎一统天下。 检测定位效果评价采用Average Best Overlap（ABO）和Mean Average Best Overlap（MABO）： <span class="math display">\[
ABO=\frac{1}{|G^c|}\sum_{g_i^c\in G^c}max_{I_j\in L} Overlap(g_i^c,l_j)
\]</span> 其中：<span class="math inline">\(c\)</span>为类别标注、<span class="math inline">\(g_i^c\)</span>为类别<span class="math inline">\(c\)</span>下的ground truth，<span class="math inline">\(L\)</span>为通过Selective Search生成的候选框。 <span class="math display">\[
MABO=\frac{1}{|C|}\sum_{i=1}^n ABO(C_i)
\]</span></p>
<h3 id="代码实践">8.1.4 代码实践</h3>
<p>参见<a target="_blank" rel="noopener" href="https://github.com/vivounicorn/selectivesearch">AlpacaDB</a>。</p>
<ul>
<li>selectivesearch.py <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"><span class="keyword">import</span> skimage.feature</span><br><span class="line"><span class="keyword">import</span> skimage.color</span><br><span class="line"><span class="keyword">import</span> skimage.transform</span><br><span class="line"><span class="keyword">import</span> skimage.util</span><br><span class="line"><span class="keyword">import</span> skimage.segmentation</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># &quot;Selective Search for Object Recognition&quot; by J.R.R. Uijlings et al.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  - Modified version with LBP extractor for texture vectorization</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_generate_segments</span>(<span class="params">im_orig, scale, sigma, min_size</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        segment smallest regions by the algorithm of Felzenswalb and</span></span><br><span class="line"><span class="string">        Huttenlocher</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># open the Image</span></span><br><span class="line">    im_mask = skimage.segmentation.felzenszwalb(</span><br><span class="line">        skimage.util.img_as_float(im_orig), scale=scale, sigma=sigma,</span><br><span class="line">        min_size=min_size)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># merge mask channel to the image as a 4th channel</span></span><br><span class="line">    im_orig = numpy.append(</span><br><span class="line">        im_orig, numpy.zeros(im_orig.shape[:<span class="number">2</span>])[:, :, numpy.newaxis], axis=<span class="number">2</span>)</span><br><span class="line">    im_orig[:, :, <span class="number">3</span>] = im_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> im_orig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_colour</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the sum of histogram intersection of colour</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="built_in">min</span>(a, b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(r1[<span class="string">&quot;hist_c&quot;</span>], r2[<span class="string">&quot;hist_c&quot;</span>])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_texture</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the sum of histogram intersection of texture</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="built_in">min</span>(a, b) <span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(r1[<span class="string">&quot;hist_t&quot;</span>], r2[<span class="string">&quot;hist_t&quot;</span>])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_size</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the size similarity over the image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - (r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;size&quot;</span>]) / imsize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_sim_fill</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate the fill similarity over the image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    bbsize = (</span><br><span class="line">        (<span class="built_in">max</span>(r1[<span class="string">&quot;max_x&quot;</span>], r2[<span class="string">&quot;max_x&quot;</span>]) - <span class="built_in">min</span>(r1[<span class="string">&quot;min_x&quot;</span>], r2[<span class="string">&quot;min_x&quot;</span>]))</span><br><span class="line">        * (<span class="built_in">max</span>(r1[<span class="string">&quot;max_y&quot;</span>], r2[<span class="string">&quot;max_y&quot;</span>]) - <span class="built_in">min</span>(r1[<span class="string">&quot;min_y&quot;</span>], r2[<span class="string">&quot;min_y&quot;</span>]))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> - (bbsize - r1[<span class="string">&quot;size&quot;</span>] - r2[<span class="string">&quot;size&quot;</span>]) / imsize</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_sim</span>(<span class="params">r1, r2, imsize</span>):</span></span><br><span class="line">    <span class="keyword">return</span> (_sim_colour(r1, r2) + _sim_texture(r1, r2)</span><br><span class="line">            + _sim_size(r1, r2, imsize) + _sim_fill(r1, r2, imsize))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_colour_hist</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate colour histogram for each region</span></span><br><span class="line"><span class="string">        the size of output histogram will be BINS * COLOUR_CHANNELS(3)</span></span><br><span class="line"><span class="string">        number of bins is 25 as same as [uijlings_ijcv2013_draft.pdf]</span></span><br><span class="line"><span class="string">        extract HSV</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    BINS = <span class="number">25</span></span><br><span class="line">    hist = numpy.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># extracting one colour channel</span></span><br><span class="line">        c = img[:, colour_channel]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate histogram for each colour and join to the result</span></span><br><span class="line">        hist = numpy.concatenate(</span><br><span class="line">            [hist] + [numpy.histogram(c, BINS, (<span class="number">0.0</span>, <span class="number">255.0</span>))[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L1 normalize</span></span><br><span class="line">    hist = hist / <span class="built_in">len</span>(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_texture_gradient</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate texture gradient for entire image</span></span><br><span class="line"><span class="string">        The original SelectiveSearch algorithm proposed Gaussian derivative</span></span><br><span class="line"><span class="string">        for 8 orientations, but we use LBP instead.</span></span><br><span class="line"><span class="string">        output will be [height(*)][width(*)]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ret = numpy.zeros((img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], img.shape[<span class="number">2</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line">        ret[:, :, colour_channel] = skimage.feature.local_binary_pattern(</span><br><span class="line">            img[:, :, colour_channel], <span class="number">8</span>, <span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_calc_texture_hist</span>(<span class="params">img</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        calculate texture histogram for each region</span></span><br><span class="line"><span class="string">        calculate the histogram of gradient for each colours</span></span><br><span class="line"><span class="string">        the size of output histogram will be</span></span><br><span class="line"><span class="string">            BINS * ORIENTATIONS * COLOUR_CHANNELS(3)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    BINS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    hist = numpy.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> colour_channel <span class="keyword">in</span> (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mask by the colour channel</span></span><br><span class="line">        fd = img[:, colour_channel]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate histogram for each orientation and concatenate them all</span></span><br><span class="line">        <span class="comment"># and join to the result</span></span><br><span class="line">        hist = numpy.concatenate(</span><br><span class="line">            [hist] + [numpy.histogram(fd, BINS, (<span class="number">0.0</span>, <span class="number">1.0</span>))[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># L1 Normalize</span></span><br><span class="line">    hist = hist / <span class="built_in">len</span>(img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_regions</span>(<span class="params">img</span>):</span></span><br><span class="line"></span><br><span class="line">    R = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># get hsv image</span></span><br><span class="line">    hsv = skimage.color.rgb2hsv(img[:, :, :<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 1: count pixel positions</span></span><br><span class="line">    <span class="keyword">for</span> y, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(img):</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, (r, g, b, l) <span class="keyword">in</span> <span class="built_in">enumerate</span>(i):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># initialize a new region</span></span><br><span class="line">            <span class="keyword">if</span> l <span class="keyword">not</span> <span class="keyword">in</span> R:</span><br><span class="line">                R[l] = &#123;</span><br><span class="line">                    <span class="string">&quot;min_x&quot;</span>: <span class="number">0xffff</span>, <span class="string">&quot;min_y&quot;</span>: <span class="number">0xffff</span>,</span><br><span class="line">                    <span class="string">&quot;max_x&quot;</span>: <span class="number">0</span>, <span class="string">&quot;max_y&quot;</span>: <span class="number">0</span>, <span class="string">&quot;labels&quot;</span>: [l]&#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># bounding box</span></span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;min_x&quot;</span>] &gt; x:</span><br><span class="line">                R[l][<span class="string">&quot;min_x&quot;</span>] = x</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;min_y&quot;</span>] &gt; y:</span><br><span class="line">                R[l][<span class="string">&quot;min_y&quot;</span>] = y</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;max_x&quot;</span>] &lt; x:</span><br><span class="line">                R[l][<span class="string">&quot;max_x&quot;</span>] = x</span><br><span class="line">            <span class="keyword">if</span> R[l][<span class="string">&quot;max_y&quot;</span>] &lt; y:</span><br><span class="line">                R[l][<span class="string">&quot;max_y&quot;</span>] = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 2: calculate texture gradient</span></span><br><span class="line">    tex_grad = _calc_texture_gradient(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pass 3: calculate colour histogram of each region</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> R.items():</span><br><span class="line"></span><br><span class="line">        <span class="comment"># colour histogram</span></span><br><span class="line">        masked_pixels = hsv[:, :, :][img[:, :, <span class="number">3</span>] == k]</span><br><span class="line">        R[k][<span class="string">&quot;size&quot;</span>] = <span class="built_in">len</span>(masked_pixels / <span class="number">4</span>)</span><br><span class="line">        R[k][<span class="string">&quot;hist_c&quot;</span>] = _calc_colour_hist(masked_pixels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># texture histogram</span></span><br><span class="line">        R[k][<span class="string">&quot;hist_t&quot;</span>] = _calc_texture_hist(tex_grad[:, :][img[:, :, <span class="number">3</span>] == k])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_neighbours</span>(<span class="params">regions</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersect</span>(<span class="params">a, b</span>):</span></span><br><span class="line">        <span class="keyword">if</span> (a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;min_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;min_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;max_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;max_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;min_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;max_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]) <span class="keyword">or</span> (</span><br><span class="line">            a[<span class="string">&quot;min_x&quot;</span>] &lt; b[<span class="string">&quot;max_x&quot;</span>] &lt; a[<span class="string">&quot;max_x&quot;</span>]</span><br><span class="line">                <span class="keyword">and</span> a[<span class="string">&quot;min_y&quot;</span>] &lt; b[<span class="string">&quot;min_y&quot;</span>] &lt; a[<span class="string">&quot;max_y&quot;</span>]):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    R = regions.items()</span><br><span class="line">    neighbours = []</span><br><span class="line">    <span class="keyword">for</span> cur, a <span class="keyword">in</span> <span class="built_in">enumerate</span>(R[:-<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> R[cur + <span class="number">1</span>:]:</span><br><span class="line">            <span class="keyword">if</span> intersect(a[<span class="number">1</span>], b[<span class="number">1</span>]):</span><br><span class="line">                neighbours.append((a, b))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> neighbours</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_merge_regions</span>(<span class="params">r1, r2</span>):</span></span><br><span class="line">    new_size = r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;size&quot;</span>]</span><br><span class="line">    rt = &#123;</span><br><span class="line">        <span class="string">&quot;min_x&quot;</span>: <span class="built_in">min</span>(r1[<span class="string">&quot;min_x&quot;</span>], r2[<span class="string">&quot;min_x&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;min_y&quot;</span>: <span class="built_in">min</span>(r1[<span class="string">&quot;min_y&quot;</span>], r2[<span class="string">&quot;min_y&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;max_x&quot;</span>: <span class="built_in">max</span>(r1[<span class="string">&quot;max_x&quot;</span>], r2[<span class="string">&quot;max_x&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;max_y&quot;</span>: <span class="built_in">max</span>(r1[<span class="string">&quot;max_y&quot;</span>], r2[<span class="string">&quot;max_y&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: new_size,</span><br><span class="line">        <span class="string">&quot;hist_c&quot;</span>: (</span><br><span class="line">            r1[<span class="string">&quot;hist_c&quot;</span>] * r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;hist_c&quot;</span>] * r2[<span class="string">&quot;size&quot;</span>]) / new_size,</span><br><span class="line">        <span class="string">&quot;hist_t&quot;</span>: (</span><br><span class="line">            r1[<span class="string">&quot;hist_t&quot;</span>] * r1[<span class="string">&quot;size&quot;</span>] + r2[<span class="string">&quot;hist_t&quot;</span>] * r2[<span class="string">&quot;size&quot;</span>]) / new_size,</span><br><span class="line">        <span class="string">&quot;labels&quot;</span>: r1[<span class="string">&quot;labels&quot;</span>] + r2[<span class="string">&quot;labels&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">selective_search</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        im_orig, scale=<span class="number">1.0</span>, sigma=<span class="number">0.8</span>, min_size=<span class="number">50</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Selective Search</span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        im_orig : ndarray</span></span><br><span class="line"><span class="string">            Input image</span></span><br><span class="line"><span class="string">        scale : int</span></span><br><span class="line"><span class="string">            Free parameter. Higher means larger clusters in felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">        sigma : float</span></span><br><span class="line"><span class="string">            Width of Gaussian kernel for felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">        min_size : int</span></span><br><span class="line"><span class="string">            Minimum component size for felzenszwalb segmentation.</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">        img : ndarray</span></span><br><span class="line"><span class="string">            image with region label</span></span><br><span class="line"><span class="string">            region label is stored in the 4th value of each pixel [r,g,b,(region)]</span></span><br><span class="line"><span class="string">        regions : array of dict</span></span><br><span class="line"><span class="string">            [</span></span><br><span class="line"><span class="string">                &#123;</span></span><br><span class="line"><span class="string">                    &#x27;rect&#x27;: (left, top, right, bottom),</span></span><br><span class="line"><span class="string">                    &#x27;labels&#x27;: [...]</span></span><br><span class="line"><span class="string">                &#125;,</span></span><br><span class="line"><span class="string">                ...</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> im_orig.shape[<span class="number">2</span>] == <span class="number">3</span>, <span class="string">&quot;3ch image is expected&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image and get smallest regions</span></span><br><span class="line">    <span class="comment"># region label is stored in the 4th value of each pixel [r,g,b,(region)]</span></span><br><span class="line">    img = _generate_segments(im_orig, scale, sigma, min_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> img <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, &#123;&#125;</span><br><span class="line"></span><br><span class="line">    imsize = img.shape[<span class="number">0</span>] * img.shape[<span class="number">1</span>]</span><br><span class="line">    R = _extract_regions(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># extract neighbouring information</span></span><br><span class="line">    neighbours = _extract_neighbours(R)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate initial similarities</span></span><br><span class="line">    S = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> (ai, ar), (bi, br) <span class="keyword">in</span> neighbours:</span><br><span class="line">        S[(ai, bi)] = _calc_sim(ar, br, imsize)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hierarchal search</span></span><br><span class="line">    <span class="keyword">while</span> S != &#123;&#125;:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get highest similarity</span></span><br><span class="line">        i, j = <span class="built_in">sorted</span>(S.items(), cmp=<span class="keyword">lambda</span> a, b: cmp(a[<span class="number">1</span>], b[<span class="number">1</span>]))[-<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># merge corresponding regions</span></span><br><span class="line">        t = <span class="built_in">max</span>(R.keys()) + <span class="number">1.0</span></span><br><span class="line">        R[t] = _merge_regions(R[i], R[j])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># mark similarities for regions to be removed</span></span><br><span class="line">        key_to_delete = []</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> S.items():</span><br><span class="line">            <span class="keyword">if</span> (i <span class="keyword">in</span> k) <span class="keyword">or</span> (j <span class="keyword">in</span> k):</span><br><span class="line">                key_to_delete.append(k)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># remove old similarities of related regions</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> key_to_delete:</span><br><span class="line">            <span class="keyword">del</span> S[k]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># calculate similarity set with the new region</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">filter</span>(<span class="keyword">lambda</span> a: a != (i, j), key_to_delete):</span><br><span class="line">            n = k[<span class="number">1</span>] <span class="keyword">if</span> k[<span class="number">0</span>] <span class="keyword">in</span> (i, j) <span class="keyword">else</span> k[<span class="number">0</span>]</span><br><span class="line">            S[(t, n)] = _calc_sim(R[t], R[n], imsize)</span><br><span class="line"></span><br><span class="line">    regions = []</span><br><span class="line">    <span class="keyword">for</span> k, r <span class="keyword">in</span> R.items():</span><br><span class="line">        regions.append(&#123;</span><br><span class="line">            <span class="string">&#x27;rect&#x27;</span>: (</span><br><span class="line">                r[<span class="string">&#x27;min_x&#x27;</span>], r[<span class="string">&#x27;min_y&#x27;</span>],</span><br><span class="line">                r[<span class="string">&#x27;max_x&#x27;</span>] - r[<span class="string">&#x27;min_x&#x27;</span>], r[<span class="string">&#x27;max_y&#x27;</span>] - r[<span class="string">&#x27;min_y&#x27;</span>]),</span><br><span class="line">            <span class="string">&#x27;size&#x27;</span>: r[<span class="string">&#x27;size&#x27;</span>],</span><br><span class="line">            <span class="string">&#x27;labels&#x27;</span>: r[<span class="string">&#x27;labels&#x27;</span>]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> img, regions</span><br></pre></td></tr></table></figure></li>
<li>example.py <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> skimage.data</span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> use_plugin,imread</span><br><span class="line"><span class="keyword">import</span> matplotlib.patches <span class="keyword">as</span> mpatches</span><br><span class="line"><span class="keyword">from</span> matplotlib.pyplot <span class="keyword">import</span> savefig</span><br><span class="line"><span class="keyword">import</span> selectivesearch</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># loading astronaut image</span></span><br><span class="line">    <span class="comment">#img = skimage.data.astronaut()</span></span><br><span class="line">    use_plugin(<span class="string">&#x27;pil&#x27;</span>)</span><br><span class="line">    img = imread(<span class="string">&#x27;car.jpg&#x27;</span>, as_grey=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># perform selective search</span></span><br><span class="line">    img_lbl, regions = selectivesearch.selective_search(</span><br><span class="line">        img, scale=<span class="number">500</span>, sigma=<span class="number">0.9</span>, min_size=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    candidates = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> regions:</span><br><span class="line">        <span class="comment"># excluding same rectangle (with different segments)</span></span><br><span class="line">        <span class="keyword">if</span> r[<span class="string">&#x27;rect&#x27;</span>] <span class="keyword">in</span> candidates:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># excluding regions smaller than 2000 pixels</span></span><br><span class="line">        <span class="keyword">if</span> r[<span class="string">&#x27;size&#x27;</span>] &lt; <span class="number">2000</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># distorted rects</span></span><br><span class="line">        x, y, w, h = r[<span class="string">&#x27;rect&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> w / h &gt; <span class="number">1.2</span> <span class="keyword">or</span> h / w &gt; <span class="number">1.2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        candidates.add(r[<span class="string">&#x27;rect&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># draw rectangles on the original image</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    fig, ax = plt.subplots(ncols=<span class="number">1</span>, nrows=<span class="number">1</span>, figsize=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">    ax.imshow(img)</span><br><span class="line">    <span class="keyword">for</span> x, y, w, h <span class="keyword">in</span> candidates:</span><br><span class="line">        <span class="built_in">print</span> x, y, w, h</span><br><span class="line">        rect = mpatches.Rectangle(</span><br><span class="line">            (x, y), w, h, fill=<span class="literal">False</span>, edgecolor=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line">    savefig(<span class="string">&#x27;MyFig.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></li>
</ul>
<a href="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagj3gmmo21cu5v0tsvacou2m.png">car.jpg原图</a>如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagj3gmmo21cu5v0tsvacou2m.png" width="500"/>
</center>
结果图如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgagloviabk1f61cm2ldoco733.png" width="500"/>
</center>
<h2 id="overfeat">8.2 OverFeat</h2>
<p>计算机视觉有三大任务：分类(识别)、定位、检测，从左到右每个任务是下个任务的子任务，所以难度递增。OverFeat是2014年《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1312.6229">OverFeat:Integrated Recognition, Localization and Detection using Convolutional Networks</a>》中提出的一个基于卷积神经网络的特征提取框架，论文的最大亮点在于通过一个统一的框架去解决图像分类、定位、检测问题，并提出<strong>feature map上的一个点可以还原并对应到原图的一个区域</strong>，于是一些在原图上的操作可以转到在feature map上做，这点对以后的检测算法有较深远的影响。它在ImageNet 2013的task 3定位任务中获得第一，在检测和分类任务中也有不错的表现。</p>
<h3 id="overfeat分类任务">8.2.1 OverFeat分类任务</h3>
文中借鉴了AlexNet的结构，并做了些结构改进和提高了线上inference效率，结构如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgcn7re5ia8isa12v2gih4do9.png" width="800"/>
</center>
<p>相对AlexNet，网络结构几乎一样，区别在于：</p>
<blockquote>
<p>去掉了LRN层，不做额外归一化操作</p>
</blockquote>
<blockquote>
<p>使用区域非重叠pooling</p>
</blockquote>
<blockquote>
<p>前两层使用较小的stride，从而产生较大的feature map，提高了模型精度</p>
</blockquote>
<ul>
<li>Offset Pooling 分类任务中一大亮点是提出利用Offset Pooling做多尺度分类的概念，在一维情况的解释如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgdcp5041m4g1ftk6aq1db91tk4m.png" width="600" />
</center></li>
</ul>
<p>a图代表经过第5个卷积层后的feature map有20个神经元，选取stride=3做非重叠pooling，有以下3种方式：（通常我们只使用第一种）</p>
<pre><code>&gt; △=0分组:[1,2,3]，[4,5,6],[7,8,9],...,[16,17,18]
&gt; △=1分组:[2,3,4]，[5,6,7],[8,9,10],...,[17,18,19]
&gt; △=2分组:[3,4,5]，[6,7,8],[9,10,11],...,[18,19,20]</code></pre>
<p>在二维情况下，输入图像在经过FCN及第5个卷积层后得到若干个feature map，使用3x3 filter在feature map上做滑动窗口（注意此时不在原图上做，节省大量计算消耗）。按上图的原理，滑动窗口总共要做9次，从(0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,0), (2,1), (2,2)处分别滑动。得到的feature map分别经过后面的3个FC层，得到多组特征，最后拼接起来得到最终特征向量并用于分类。</p>
<ul>
<li>Inference自适应输入图片大小</li>
</ul>
训练模型时往往采用的是固定大小图片(后面的SPP-net、Fast R-CNN等模型通过SPP或ROI pooling可以允许输入大小可变)，当inference阶段遇到比规定大小更大的图片时怎么办？可以利用Fully Convolutional Networks（《<a target="_blank" rel="noopener" href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Fully Convolutional Networks for Semantic Segmentation</a>》）的思想：把卷积层到全连接层映射看成对整张图的卷积操作，把全连接层到全连接层的映射可以看成采用1x1卷积核的卷积操作。以下图说明：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgdefki817bkpp61od4bq61ch713.png" width="600" />
</center>
<p>绿色代表卷积核，蓝色代表feature map，当输入大于规定尺寸时，在黄色区域会有额外计算，最终的输出也不是一个值而是一个矩阵，可以用各种策略输出最终结果，比如一种简单做法是用矩阵平均值作为最终分类结果。</p>
<h3 id="overfeat定位任务">8.2.2 OverFeat定位任务</h3>
<ul>
<li><p>回归训练</p>
<p>相对于分类问题，定位问题可以与其共享前1~5层网络结构，这种方式也被后面的模型所借鉴，区别是增加了一个<span class="math inline">\(l_2\)</span>的回归损失函数，基本思路是对同一张图缩放产生多尺度图片做输入，用回归网络预测Bounding Box（后面简写为BB）后再做融合，需要注意回归层是与类别相关的，如果有1000个类则有1000个版本，每类一个。回归示意图如下：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgf6dah21ok1hj71cl1h1h1p1j9.png" width="400" /></p>
</center>
<p>第5层pooling结果作为输入，共256个通道，以FCN的思想理解，先走一个4096通道的全连接层再走一个1024通道的全连接层，与前面类似使用Offet Pooing和滑动窗口对每类生成一个4通道矩阵，4个通道分别代表BB的四条边的坐标。</p></li>
<li><p>网络输出</p>
<p>回归网络的输出例子如下，单图下生成多个BB的预测，这些BB倾向于收敛到一个固定位置并且可以定位物体姿势多样化的情况，当然计算复杂度不小，所以没法用到实时检测中。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgf7av4q1fasqp1uimn2c1uvkm.png" width="500"/></p>
</center></li>
<li><p>预测融合策略</p>
<ol type="a">
<li>同一幅图在6种不同缩放尺度下分别输入<strong>分类</strong>网络，每种尺度下选top k类别作为标定，用<span class="math inline">\(C_s\)</span>表示；</li>
<li>对任意尺度<span class="math inline">\(s\)</span>分别输入BB <strong>回归</strong>网络，用<span class="math inline">\(B_s\)</span>表示每个类别对应的BB集合；</li>
<li>将所有<span class="math inline">\(B_s\)</span>合并为大集合<span class="math inline">\(B\)</span>；</li>
<li>重复以下过程直到结束： <span class="math display">\[
  \begin{array}{l}
  (b_1^*,b_2^*)=argmin_{b_1\neq b_2 \in B}\text{match_score}(b_1,b_2)\\
  if \quad \text{match_score}(b_1^*,b_2^*)&gt;t \quad \\
  then \quad stop.\\
  Otherwise \quad set \quad B=B-\{b_1^*,b_2^*\}\cup \text{box_merge}(b_1^*,b_2^*)
  \end{array}
  \]</span> 其中match_score为两个BB的中心点之间的距离及BB重合区域面积之和，box_merge为两个BB坐标均值，过程很好理解：所有分类（如可能有熊、鲸鱼等）的BB被放在一个大集合，多尺度得到的分类集合中，正确分类会占有优势（置信度、匹配度、BB连续度等），随着迭代的过程正确分类的BB被加强，错误分类的BB被减弱直到消失，不过这个方法确实复杂，可以看到在后来的算法有各种改进和替换。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgfb34cc7i713lcnhr3881oqs1g.png" width="600" />
</center></li>
</ol></li>
</ul>
<h3 id="overfeat检测任务">8.2.3 OverFeat检测任务</h3>
<p>与分类类似但需要考虑位置信息，同样采用网络结构共享特征提取，在预测分类中还需要加“背景”这一类。</p>
<h3 id="代码实践-1">8.2.4 代码实践</h3>
<p>可参见：<a target="_blank" rel="noopener" href="https://github.com/sermanet/OverFeat">OverFeat</a></p>
<h2 id="r-cnn">8.3 R-CNN</h2>
<p>过去若干年，目标检测使用的都是滑动窗口的方式，这种方式计算效率较差，另外以往CNN在ImageNet比赛分类问题的表现更加突出，如何利用这些成果以及ImageNet的大量训练数据去借力打力也是一个值得研究的课题。R-CNN由Ross Girshick等人在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a>》中提出，OverFeat从某种程度可以看做R-CNN的特例，R-CNN在图像检测领域有很大的影响力，该算法的亮点在于：使用Selective Search代替传统滑动窗口方式生成候选框并使用CNN提取特征；把分类和回归方法同时应用在检测中；当训练数据不足时，通过预训练利用领域数据（知识）做transfer learning，在对象数据集上再应用fine-tuning继续训练。</p>
<h3 id="iou">8.3.1 IoU</h3>
IoU（intersection over union），是用来衡量Bounding Box定位精度的指标，它的定义类似Jaccard距离，假设A为人工标定的BB，B为预测的BB则： <span class="math display">\[IOU=\frac{area(A \cap B)}{area(A \cup B)}\]</span>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbntg01g031n4o1l4ge7uasv3u.png" width="500" />
</center>
<h3 id="nms">8.3.2 NMS</h3>
NMS（non-maximum suppression）在目标检测中用来依据置信度消除重叠度过高的重复候选框，从而提高检测算法效率。 例如，<a href="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbfv0e1i8n4as1l6qn70ome2n.png">原图</a>为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbfv0e1i8n4as1l6qn70ome2n.png" width="500" />
</center>
原图+候选框为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbl582ucc3981voe1dgg1o8b3h.png" width="500"/>
</center>
执行NMS后为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgnbj2es9mh1m4tkkgmv6tsb34.png" width="500"/>
</center>
<p>代码可参考：<a target="_blank" rel="noopener" href="http://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/">Non-Maximum Suppression for Object Detection in Python</a> <strong>nms.py</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#  Felzenszwalb et al.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">non_max_suppression_slow</span>(<span class="params">boxes, overlapThresh</span>):</span></span><br><span class="line">	<span class="comment"># if there are no boxes, return an empty list</span></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">len</span>(boxes) == <span class="number">0</span>:</span><br><span class="line">		<span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">	<span class="comment"># initialize the list of picked indexes</span></span><br><span class="line">	pick = []</span><br><span class="line"></span><br><span class="line">	<span class="comment"># grab the coordinates of the bounding boxes</span></span><br><span class="line">	x1 = boxes[:,<span class="number">0</span>]</span><br><span class="line">	y1 = boxes[:,<span class="number">1</span>]</span><br><span class="line">	x2 = boxes[:,<span class="number">2</span>]</span><br><span class="line">	y2 = boxes[:,<span class="number">3</span>]</span><br><span class="line">	scores = boxes[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># compute the area of the bounding boxes and sort the bounding</span></span><br><span class="line">	<span class="comment"># boxes by the bottom-right y-coordinate of the bounding box</span></span><br><span class="line">	area = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">	idxs = np.argsort(scores)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># keep looping while some indexes still remain in the indexes</span></span><br><span class="line">	<span class="comment"># list</span></span><br><span class="line">	<span class="keyword">while</span> <span class="built_in">len</span>(idxs) &gt; <span class="number">0</span>:</span><br><span class="line">		<span class="comment"># grab the last index in the indexes list, add the index</span></span><br><span class="line">		<span class="comment"># value to the list of picked indexes, then initialize</span></span><br><span class="line">		<span class="comment"># the suppression list (i.e. indexes that will be deleted)</span></span><br><span class="line">		<span class="comment"># using the last index</span></span><br><span class="line">		last = <span class="built_in">len</span>(idxs) - <span class="number">1</span></span><br><span class="line">		i = idxs[last]</span><br><span class="line">		pick.append(i)</span><br><span class="line">		suppress = [last]</span><br><span class="line"></span><br><span class="line">		<span class="comment"># loop over all indexes in the indexes list</span></span><br><span class="line">		<span class="keyword">for</span> pos <span class="keyword">in</span> xrange(<span class="number">0</span>, last):</span><br><span class="line">			<span class="comment"># grab the current index</span></span><br><span class="line">			j = idxs[pos]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># find the largest (x, y) coordinates for the start of</span></span><br><span class="line">			<span class="comment"># the bounding box and the smallest (x, y) coordinates</span></span><br><span class="line">			<span class="comment"># for the end of the bounding box</span></span><br><span class="line">			xx1 = <span class="built_in">max</span>(x1[i], x1[j])</span><br><span class="line">			yy1 = <span class="built_in">max</span>(y1[i], y1[j])</span><br><span class="line">			xx2 = <span class="built_in">min</span>(x2[i], x2[j])</span><br><span class="line">			yy2 = <span class="built_in">min</span>(y2[i], y2[j])</span><br><span class="line"></span><br><span class="line">			<span class="comment"># compute the width and height of the bounding box</span></span><br><span class="line">			w = <span class="built_in">max</span>(<span class="number">0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">			h = <span class="built_in">max</span>(<span class="number">0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">			<span class="comment"># compute the ratio of overlap between the computed</span></span><br><span class="line">			<span class="comment"># bounding box and the bounding box in the area list</span></span><br><span class="line">			overlap = <span class="built_in">float</span>(w * h) / area[j]</span><br><span class="line"></span><br><span class="line">			<span class="comment"># if there is sufficient overlap, suppress the</span></span><br><span class="line">			<span class="comment"># current bounding box</span></span><br><span class="line">			<span class="keyword">if</span> overlap &gt; overlapThresh:</span><br><span class="line">				suppress.append(pos)</span><br><span class="line"></span><br><span class="line">		<span class="comment"># delete all indexes from the index list that are in the</span></span><br><span class="line">		<span class="comment"># suppression list</span></span><br><span class="line">		idxs = np.delete(idxs, suppress)</span><br><span class="line">	<span class="comment"># return only the bounding boxes that were picked</span></span><br><span class="line">	<span class="keyword">return</span> boxes[pick]</span><br></pre></td></tr></table></figure> <strong>nms_slow.py</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the necessary packages</span></span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nms <span class="keyword">import</span> non_max_suppression_slow</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="comment"># construct a list containing the images that will be examined</span></span><br><span class="line"><span class="comment"># along with their respective bounding boxes</span></span><br><span class="line"><span class="comment"># 最后一位为：分类置信度*100</span></span><br><span class="line">images = [</span><br><span class="line">        (<span class="string">&quot;images/333.jpg&quot;</span>, np.array([</span><br><span class="line">        (<span class="number">285</span>,<span class="number">293</span>,<span class="number">713</span>,<span class="number">679</span>,<span class="number">96</span>),</span><br><span class="line">        (<span class="number">9</span>,<span class="number">309</span>,<span class="number">161</span>,<span class="number">719</span>,<span class="number">90</span>),</span><br><span class="line">        (<span class="number">703</span>,<span class="number">259</span>,<span class="number">959</span>,<span class="number">659</span>,<span class="number">93</span>),</span><br><span class="line">	    (<span class="number">291</span>,<span class="number">309</span>,<span class="number">693</span>,<span class="number">663</span>,<span class="number">90</span>),</span><br><span class="line">        (<span class="number">1</span>,<span class="number">371</span>,<span class="number">155</span>,<span class="number">621</span>,<span class="number">80</span>),        </span><br><span class="line">        (<span class="number">511</span>,<span class="number">347</span>,<span class="number">681</span>,<span class="number">637</span>,<span class="number">89</span>),</span><br><span class="line">        (<span class="number">293</span>,<span class="number">587</span>,<span class="number">721</span>,<span class="number">671</span>,<span class="number">70</span>),</span><br><span class="line">        (<span class="number">757</span>,<span class="number">469</span>,<span class="number">957</span>,<span class="number">641</span>,<span class="number">60</span>)]))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># loop over the images</span></span><br><span class="line"><span class="keyword">for</span> (imagePath, boundingBoxes) <span class="keyword">in</span> images:</span><br><span class="line">	<span class="comment"># load the image and clone it</span></span><br><span class="line">	<span class="built_in">print</span> <span class="string">&quot;[x] %d initial bounding boxes&quot;</span> % (<span class="built_in">len</span>(boundingBoxes))</span><br><span class="line">	image = cv2.imread(imagePath)</span><br><span class="line">	orig = image.copy()</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over the bounding boxes for each image and draw them</span></span><br><span class="line">	<span class="keyword">for</span> (startX, startY, endX, endY, c) <span class="keyword">in</span> boundingBoxes:                </span><br><span class="line">		cv2.rectangle(orig, (startX, startY), (endX, endY), (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># perform non-maximum suppression on the bounding boxes</span></span><br><span class="line">	pick = non_max_suppression_slow(boundingBoxes, <span class="number">0.3</span>)</span><br><span class="line">	<span class="built_in">print</span> <span class="string">&quot;[x] after applying non-maximum, %d bounding boxes&quot;</span> % (<span class="built_in">len</span>(pick))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># loop over the picked bounding boxes and draw them</span></span><br><span class="line">	<span class="keyword">for</span> (startX, startY, endX, endY,c) <span class="keyword">in</span> pick:</span><br><span class="line">		cv2.rectangle(image, (startX, startY), (endX, endY), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># display the images</span></span><br><span class="line">	cv2.imshow(<span class="string">&quot;Original&quot;</span>, orig)</span><br><span class="line">	cv2.imshow(<span class="string">&quot;After NMS&quot;</span>, image)</span><br><span class="line">	cv2.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="map">8.3.3 mAP</h3>
<p>先介绍什么是AP，以PASCAL VOC CHALLENGE 2010以后的定义做说明。 假设<span class="math inline">\(m\)</span>个样本中有<span class="math inline">\(p\)</span>个正例，依据包含正例的个数，可以得到<span class="math inline">\(p\)</span>个recall值，分别为：<span class="math inline">\(1/p，2/p，3/p，...，p/p\)</span>，对于每个recall值<span class="math inline">\(r\)</span>可以计算出对应<span class="math inline">\(r^{&#39;} \geq r\)</span>的最大precision，然后对这<span class="math inline">\(p\)</span>个precision值取平均即得到AP值。 举个例子，假设是否为车的分类，一共有30个测试样本，预测结果及标注如下：</p>
<table>
<thead>
<tr class="header">
<th>编号</th>
<th>预测值</th>
<th>实际值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>0.88</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.76</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.92</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.10</td>
<td>1</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.23</td>
<td>0</td>
</tr>
<tr class="even">
<td>8</td>
<td>0.34</td>
<td>0</td>
</tr>
<tr class="odd">
<td>9</td>
<td>0.35</td>
<td>0</td>
</tr>
<tr class="even">
<td>10</td>
<td>0.66</td>
<td>1</td>
</tr>
<tr class="odd">
<td>11</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>12</td>
<td>0.45</td>
<td>1</td>
</tr>
<tr class="odd">
<td>13</td>
<td>0.93</td>
<td>1</td>
</tr>
<tr class="even">
<td>14</td>
<td>0.97</td>
<td>0</td>
</tr>
<tr class="odd">
<td>15</td>
<td>0.81</td>
<td>1</td>
</tr>
<tr class="even">
<td>16</td>
<td>0.78</td>
<td>0</td>
</tr>
<tr class="odd">
<td>17</td>
<td>0.66</td>
<td>0</td>
</tr>
<tr class="even">
<td>18</td>
<td>0.54</td>
<td>0</td>
</tr>
<tr class="odd">
<td>19</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>20</td>
<td>0.31</td>
<td>0</td>
</tr>
<tr class="odd">
<td>21</td>
<td>0.22</td>
<td>0</td>
</tr>
<tr class="even">
<td>22</td>
<td>0.12</td>
<td>0</td>
</tr>
<tr class="odd">
<td>23</td>
<td>0.02</td>
<td>0</td>
</tr>
<tr class="even">
<td>24</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td>25</td>
<td>0.15</td>
<td>0</td>
</tr>
<tr class="even">
<td>26</td>
<td>0.01</td>
<td>0</td>
</tr>
<tr class="odd">
<td>27</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="even">
<td>28</td>
<td>0.37</td>
<td>0</td>
</tr>
<tr class="odd">
<td>29</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>30</td>
<td>0.99</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>按照预测得分降序排列后如下：</p>
<table>
<thead>
<tr class="header">
<th>编号</th>
<th>预测值</th>
<th>实际值</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>30</td>
<td>0.99</td>
<td>1</td>
</tr>
<tr class="even">
<td>14</td>
<td>0.97</td>
<td>0</td>
</tr>
<tr class="odd">
<td>13</td>
<td>0.93</td>
<td>1</td>
</tr>
<tr class="even">
<td>4</td>
<td>0.92</td>
<td>0</td>
</tr>
<tr class="odd">
<td>1</td>
<td>0.88</td>
<td>1</td>
</tr>
<tr class="even">
<td>15</td>
<td>0.81</td>
<td>1</td>
</tr>
<tr class="odd">
<td>16</td>
<td>0.78</td>
<td>0</td>
</tr>
<tr class="even">
<td>6</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="odd">
<td>27</td>
<td>0.77</td>
<td>1</td>
</tr>
<tr class="even">
<td>2</td>
<td>0.76</td>
<td>0</td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.66</td>
<td>1</td>
</tr>
<tr class="even">
<td>17</td>
<td>0.66</td>
<td>0</td>
</tr>
<tr class="odd">
<td>3</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="even">
<td>11</td>
<td>0.56</td>
<td>0</td>
</tr>
<tr class="odd">
<td>18</td>
<td>0.54</td>
<td>0</td>
</tr>
<tr class="even">
<td>12</td>
<td>0.45</td>
<td>1</td>
</tr>
<tr class="odd">
<td>19</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="even">
<td>29</td>
<td>0.43</td>
<td>1</td>
</tr>
<tr class="odd">
<td>28</td>
<td>0.37</td>
<td>0</td>
</tr>
<tr class="even">
<td>9</td>
<td>0.35</td>
<td>0</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.34</td>
<td>0</td>
</tr>
<tr class="even">
<td>20</td>
<td>0.31</td>
<td>0</td>
</tr>
<tr class="odd">
<td>7</td>
<td>0.23</td>
<td>0</td>
</tr>
<tr class="even">
<td>21</td>
<td>0.22</td>
<td>0</td>
</tr>
<tr class="odd">
<td>25</td>
<td>0.15</td>
<td>0</td>
</tr>
<tr class="even">
<td>22</td>
<td>0.12</td>
<td>0</td>
</tr>
<tr class="odd">
<td>5</td>
<td>0.10</td>
<td>1</td>
</tr>
<tr class="even">
<td>24</td>
<td>0.05</td>
<td>1</td>
</tr>
<tr class="odd">
<td>23</td>
<td>0.02</td>
<td>0</td>
</tr>
<tr class="even">
<td>26</td>
<td>0.01</td>
<td>0</td>
</tr>
</tbody>
</table>
AP计算过程如下(注意与AUC之间的异同)：
<table>
<tr>
<td>
编号
</td>
<td>
预测值
</td>
<td>
实际值
</td>
<td>
Precision
</td>
<td>
Recall（r）
</td>
<td>
Max Precision with Recall（r'≥r）
</td>
<td>
AP
</td>
</tr>
<tr>
<td>
30
</td>
<td>
0.99
</td>
<td>
1
</td>
<td>
1/1=1
</td>
<td>
1/12=0.08
</td>
<td rowspan="2">
1
</td>
<td rowspan="30">
0.609
</td>
</tr>
<tr>
<td>
14
</td>
<td>
0.97
</td>
<td>
0
</td>
<td>
1/2=0.5
</td>
<td>
1/12=0.08
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
13
</td>
<td>
0.93
</td>
<td>
1
</td>
<td>
2/3=0.67
</td>
<td>
2/12=0.17
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
4
</td>
<td>
0.92
</td>
<td>
0
</td>
<td>
2/4=0.5
</td>
<td>
2/12=0.17
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
1
</td>
<td>
0.88
</td>
<td>
1
</td>
<td>
3/5=0.6
</td>
<td>
3/12=0.25
</td>
<td>
0.6
</td>
<td>
</td>
</tr>
<tr>
<td>
15
</td>
<td>
0.81
</td>
<td>
1
</td>
<td>
4/6=0.67
</td>
<td>
4/12=0.33
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
16
</td>
<td>
0.78
</td>
<td>
0
</td>
<td>
4/7=0.57
</td>
<td>
4/12=0.33
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
6
</td>
<td>
0.77
</td>
<td>
1
</td>
<td>
5/8=0.63
</td>
<td>
5/12=0.42
</td>
<td>
0.63
</td>
<td>
</td>
</tr>
<tr>
<td>
27
</td>
<td>
0.77
</td>
<td>
1
</td>
<td>
6/9=0.67
</td>
<td>
6/12=0.5
</td>
<td rowspan="2">
0.67
</td>
<td>
</td>
</tr>
<tr>
<td>
2
</td>
<td>
0.76
</td>
<td>
0
</td>
<td>
6/10=0.6
</td>
<td>
6/12=0.5
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
10
</td>
<td>
0.66
</td>
<td>
1
</td>
<td>
7/11=0.64
</td>
<td>
7/12=0.58
</td>
<td rowspan="5">
0.64
</td>
<td>
</td>
</tr>
<tr>
<td>
17
</td>
<td>
0.66
</td>
<td>
0
</td>
<td>
7/12=0.58
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
3
</td>
<td>
0.56
</td>
<td>
0
</td>
<td>
7/13=0.54
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
11
</td>
<td>
0.56
</td>
<td>
0
</td>
<td>
7/14=0.5
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
18
</td>
<td>
0.54
</td>
<td>
0
</td>
<td>
7/15=0.47
</td>
<td>
7/12=0.58
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
12
</td>
<td>
0.45
</td>
<td>
1
</td>
<td>
8/16=0.5
</td>
<td>
8/12=0.67
</td>
<td>
0.5
</td>
<td>
</td>
</tr>
<tr>
<td>
19
</td>
<td>
0.43
</td>
<td>
1
</td>
<td>
9/17=0.53
</td>
<td>
9/12=0.75
</td>
<td>
0.53
</td>
<td>
</td>
</tr>
<tr>
<td>
29
</td>
<td>
0.43
</td>
<td>
1
</td>
<td>
10/18=0.56
</td>
<td>
10/12=0.83
</td>
<td rowspan="9">
0.56
</td>
<td>
</td>
</tr>
<tr>
<td>
28
</td>
<td>
0.37
</td>
<td>
0
</td>
<td>
10/19=0.53
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
9
</td>
<td>
0.35
</td>
<td>
0
</td>
<td>
10/20=0.5
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
8
</td>
<td>
0.34
</td>
<td>
0
</td>
<td>
10/21=0.48
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
20
</td>
<td>
0.31
</td>
<td>
0
</td>
<td>
10/22=0.45
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
7
</td>
<td>
0.23
</td>
<td>
0
</td>
<td>
10/23=0.43
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
21
</td>
<td>
0.22
</td>
<td>
0
</td>
<td>
10/24=0.42
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
25
</td>
<td>
0.15
</td>
<td>
0
</td>
<td>
10/25=0.4
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
22
</td>
<td>
0.12
</td>
<td>
0
</td>
<td>
10/26=0.38
</td>
<td>
10/12=0.83
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
5
</td>
<td>
0.1
</td>
<td>
1
</td>
<td>
11/27=0.41
</td>
<td>
11/12=0.92
</td>
<td>
0.41
</td>
<td>
</td>
</tr>
<tr>
<td>
24
</td>
<td>
0.05
</td>
<td>
1
</td>
<td>
12/28=0.43
</td>
<td>
12/12=1
</td>
<td rowspan="3">
0.43
</td>
<td>
</td>
</tr>
<tr>
<td>
23
</td>
<td>
0.02
</td>
<td>
0
</td>
<td>
12/29=0.41
</td>
<td>
12/12=1
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td>
26
</td>
<td>
0.01
</td>
<td>
0
</td>
<td>
12/30=0.4
</td>
<td>
12/12=1
</td>
<td>
</td>
<td>
</td>
</tr>
</table>
<p>mAP是所有类别下的AP求算数平均值的结果。</p>
<h3 id="r-cnn原理">8.3.4 R-CNN原理</h3>
<strong>训练阶段</strong> 整个过程分4步：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgfh5oqq50153t9n15a4fr1t.png" width="500"/>
</center>
<ul>
<li>候选框生成阶段 利用Selective Search生成2000个候选框（BB），之前很多年人们用的都是滑动窗口方式。需要注意的是，由于候选框图片大小不一，而后续用于提特征的CNN对输入要求是固定大小的(227×227)，所以需要做预处理，文中实验效果最好的方法是：不论长宽比例直接将图片缩放到227×227大小，并做padding=16的处理以保留上下文信息。</li>
<li>特征提取阶段 利用CNN提取图片特征，文中大部分实验结果采用AlexNet网络结构，小部分采用VGG16，前者训练速度快但精度相对低，后者反之，AlexNet结构如下。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1baou2biq9uhumh1tm1d95du99.png" width="600"/>
</center>
<ul>
<li>有监督预训练 使用ImageNet ILSVRC2012分类任务的1000类训练数据训练一个AlexNet模型，由于CNN主要作用体现在特征提取中，同样是猫狗，在不同数据集上特征是一样的，所以可以在不同问题间共享特征，区别无非在最终任务目标和特征如何组合上；</li>
<li>基于领域知识的fine-tuning 以上述模型做权重初始化，将softmax层1000类输出改为随机初始化权重的N+1类输出（1为背景类，对VOC，N=20），在目标训练集上继续训练，其中正样本为：与ground truth框IoU≥0.5的样本，其余的为负样本。训练时优化器采用学习率为0.001的SGD，样本采用mini-batch方式学习，大小为128，其中每个batch由采用均匀分布随机抽取的针对所有分类的32个正样本和96个负样本（背景）组成。</li>
</ul></li>
<li>训练分类器阶段 每一类做一个线性SVM分类器（为配合候选框特征向量的维度，每个SVM分类器为4096个权重），正样本为：每一类的ground truth，负样本为：与ground truth的IoU≤0.3的候选框（0.3这个阈值是通过在{0，0.1，0.2，0.3，0.4，0.5}集合上做grid search后观察验证集效果得到的）。 例如，对于VOC：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgpup10fl1g1he71goo1o9617jem.png" width="500"/>
</center></li>
<li>训练回归器阶段 主要目的是修正BB减少定位错误，借鉴DPM的方法，使用ridge regression修正BB位置，具体方法为： 假设输入为：候选框与ground truth框对集合，用<span class="math inline">\(\{(P^i,G^i)\}_{i=1,...,N}\)</span>，其中<span class="math inline">\(P_i=(P_x^i,P_y^i,P_w^i,P_h^i)\)</span>，括号中分别为候选框中心点的坐标及候选框宽与高，选取靠近（IoU≥0.6）ground truth的候选框，目标是学习一个映射使得候选框能被修正到ground truth框。利用SIT（scale-invariant translation）和LST（log-space translation）思想去学习这个变换（这里大家可以想想为什么？）： <span class="math display">\[
\begin{array}{l}
\hat{G_x}=P_w\cdot d_x(P)+P_x\\
\hat{G_y}=P_h\cdot d_y(P)+P_y \\
\hat{G_w}=P_w\cdot e^{d_w(P)}\\
\hat{G_h}=P_h\cdot e^{d_h(P)}
\end{array}
 \]</span> 变换函数<span class="math inline">\(d_*(P)\)</span>与AlexNet最后一个pooling层（4096个特征）的输出<span class="math inline">\(\phi_5(P)\)</span>关系为: <span class="math display">\[d_*(P)=w^T_*\phi_5(P)\]</span> 优化目标函数为： <span class="math display">\[w_*=argmin_{\hat{w_*}}\sum_i^N(t_*^i-\hat{w}_*^T\phi_5(P^i))^2+\lambda||\hat{w_*}||^2\]</span> 其中： <span class="math display">\[
\begin{array}{l}
t_x=(G_x-P_x)/P_w\\
t_y=(G_y-P_y)/P_h \\
t_w=log(G_w/P_w)\\
t_h=log(G_h/P_h)
\end{array}
 \]</span></li>
</ul>
<p>以上四个步骤是相互独立的，后验（马后炮）的来看，可以做这些改进：</p>
<p>1、把分类和回归放在一个网络做共享特征；</p>
<p>2、网络结构对输入图片大小自适应；</p>
<p>3、把候选框生成算法也放在同一个网络来做共享特征；</p>
<p>4、分类器抛弃SVM直接融合在神经网络中；</p>
<p>5、不用每个候选框都做一次特征提取。</p>
<p><strong>测试阶段</strong>过程如下：</p>
<ul>
<li>使用SS提取2000个候选框</li>
<li>将候选框大小缩放到227×227</li>
<li>每个候选框输入CNN，产生特征后对每一类做SVM分类输出置信度</li>
<li>对候选框做基于贪心的NMS</li>
<li>每个候选框的BB只做一次预测</li>
</ul>
<h3 id="代码实践-2">8.3.5 代码实践</h3>
<p>作者代码能力极强，具体可见：<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/rcnn">R-CNN: Region-based Convolutional Neural Networks</a>。</p>
<h2 id="spp-net">8.4 SPP-Net</h2>
<p>SPP-Net是何凯明等人在《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.4729">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a>》一文中提出，文章亮点是主要解决了两个问题：</p>
<p>1、允许CNN网络的输入图片大小不固定（后面的FCN也可以解决这个问题）；</p>
<p>2、借鉴OverFeat只对整张图做一次特征提取，一些操作只在feature map上做而不用在原图进行且feature map上的点可以还原到原图上。</p>
<h3 id="问题回顾">8.4.1 问题回顾</h3>
之前的CNN网络的输入都是固定大小的，好处是网络结构相对简单和计算量低，坏处是所有图片都需要做预处理，这个会损失原图信息或引入噪声。训练和预测的一般流程是：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsbrok31sh917c5ju5jvrn1qm.png" width="600" />
</center>
常用的缩放方式有裁剪和缩放，例如：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgs6vv3j1uqh179e1aalshh1r0h9.png" width="600" />
</center>
分析CNN网络结构可以发现，卷积层和pooling层对图片输入大小都没有要求，唯独全连接层需要其输入是固定大小的，所以改进主要针对全连接层的输入，另外通过特征可视化观察到feature map包含了图片的空间信息，所以新方法同样需要包含空间信息，于是文中提出了通过增加SPP层解决问题，新的算法流程变为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgscko9j1q99uf5fkaq31ifv13.png" width="600" />
</center>
<h3 id="spp详解">8.4.2 SPP详解</h3>
可以把这个问题看做如何找到输入可变，输出固定且能保留空间信息的映射问题，问题三个相关变量：feature map的大小、bin的个数（借鉴BoW《<a target="_blank" rel="noopener" href="http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf">Video Google: A Text Retrieval Approach to Object Matching in Videos</a>》的思想，表示固定特征的维度数）、pooling步长。现在feature map的大小不固定但bin的个数固定，于是唯一能自适应可变的就是pooling步长了。 假设：最后一个卷积层产生的feature map大小为<span class="math inline">\(a×a\)</span>，希望产生<span class="math inline">\(n×n\)</span>个bins，则窗口大小为<span class="math inline">\(\lceil\frac{a}{n}\rceil\)</span>，步长为<span class="math inline">\(\lfloor\frac{a}{n}\rfloor\)</span>，例如：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsg5gtkprvdbthhf4793bd1g.png" width="500"/>
</center>
<p>每个bin的pooling方式可以是max pooling或其他pooling。</p>
SPP同样支持多尺度特征，例如4×4、2×2、1×1三种尺度最后拼成21×256维特征向量：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgsg8da2e9abus1i219c61ulb1t.png" width="500"  />
</center>
<h3 id="感受野receptive-field">8.4.3 感受野(Receptive Field)</h3>
感受野来源于生物学，Levine and Shefner在《<a target="_blank" rel="noopener" href="https://www.amazon.co.uk/d/Books/Fundamentals-Sensation-Perception-Michael-Levine/0198524668">Fundamentals of sensation and perception</a>》中将感受野定义为：由于受到刺激导致特定神经元发生反应的区域。比如人在观察某个物体的某个部分时由于受到刺激，物体会投影到视网膜，之后传到给大脑并激活某个区域（橘色的框框住的区域）。
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgunun1usbfjgt1p0o1rhq1fgq9.png" width="500"  />
</center>
CNN的任何一个卷积层或pooling层产生的任何一个feature map上的任何一点都会对应到原始图像上的某个区域，那个区域就是该点的感受野。例如，红、绿、橙三个点的感受野不同：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bgur286f1vmo1f71uau8jh1tp8m.png" width="500"  />
</center>
<p>感受野的大小与以下两个因素有关但<strong>与是否padding无关</strong>： 1、filter的大小； 2、stride的大小。</p>
<h3 id="feature-map与原图对应关系转换">8.4.4 feature map与原图对应关系转换</h3>
<p>由于SPP只对原图做一次特征提取，省去了大量重复劳动，另外由于特征点的可还原性，使得后续对所有对候选框做SPP特征映射操作时只需要在最后一个卷积层产生的feature map上进行即可（否则需要考虑感受野上的所有特征映射将会产生巨大的计算量）。 详情可参考《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1506.06981.pdf">R-CNN minus R</a>》. 简单的转换方法为： 需要对CNN网络的<strong>所有卷积层和pooling层</strong>做padding，使得原图中的任何一点与卷积或pooling后的图上的点一一对应（边缘信息也没有丢失）。</p>
<p>假设：</p>
<p>1、任何一层的核大小为<span class="math inline">\(p\)</span>；</p>
<p>2、每层padding值为<span class="math inline">\(\lfloor\frac{p}{2}\rfloor\)</span>；</p>
<p>3、原图中任何一点坐标为<span class="math inline">\((x,y)\)</span>，该点在任何一个feature map上的位置为<span class="math inline">\((x,^{&#39;},y^{&#39;})\)</span>；</p>
<p>4、从原图到该feature map感受野范围内的所有stride乘积为<span class="math inline">\(S\)</span>。</p>
<p>则： 原图候选框<strong>左上点</strong>的坐标与其在任意feature map上的坐标关系为： <span class="math display">\[
\begin{array}{l}
x^{&#39;}=\lfloor\frac{x}{S}\rfloor+1\\
y^{&#39;}=\lfloor\frac{y}{S}\rfloor+1
\end{array}
\]</span> 原图候选框<strong>右下点</strong>的坐标与其在任意feature map上的坐标关系为： <span class="math display">\[
\begin{array}{l}
x^{&#39;}=\lceil\frac{x}{S}\rceil-1\\
y^{&#39;}=\lceil\frac{y}{S}\rceil-1
\end{array}
\]</span></p>
<p><strong>通用</strong>的转换方法为： <span class="math display">\[
\begin{array}{l}
i_0=\alpha_L(i_L-1)+\beta_L\\
\alpha_L=\prod_{p=1}^L S_p\\
\beta_L=1+\sum_{p=1}^L(\prod_{q=1}^{p-1}S_q)(\frac{F_p-1}{2}-P_p)
\end{array}
\]</span> 其中： <span class="math inline">\(i_0\)</span>是feature map上的特征点<span class="math inline">\(i_L\)</span>在<strong>感受野的中心位置</strong>坐标； <span class="math inline">\(L\)</span>是当前特征点处于由CNN的第几层产生的feature map中； <span class="math inline">\(S_p\)</span>第<span class="math inline">\(p\)</span>层的stride大小； <span class="math inline">\(F_p\)</span>第<span class="math inline">\(p\)</span>层的filter大小； <span class="math inline">\(P_p\)</span>第<span class="math inline">\(p\)</span>层的padding大小。 反过来可以知道原图任何一个候选框在任何一个feature map上的位置。</p>
<p>感受野大小的计算采用Top to Down的方式，从当前层往靠近输入层的方式逐层传递，具体方法为： 假设：待计算感受野的特征点所在feature map所处层为<span class="math inline">\(L\)</span>，<span class="math inline">\(r_0\)</span>为特征点在原图的感受野大小。 则： <span class="math display">\[
\begin{array}{l}
r_L=1;\\
for \quad t=L;t&lt;=1;t--\\
\quad \quad \quad r_{t-1}=(r_{t}-1)*S_{t}+F_{t};\\
return \quad r_0;
\end{array}
\]</span></p>
<p>以下面两幅图为例：</p>
<ul>
<li><p>图一 无padding。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bh4i570957619rpopqks14r4p.png" width="600" /></p>
</center>
<p>绿色点为第2层feature map上坐标为(1,1)的点，则它在原图的中心点为： <span class="math display">\[
\begin{array}{l}
\alpha_2=1*2=2\\
\beta_2=1+(2-1)/2+1*(3-1)/2=2.5\\
i_0=2*(i_2-1)+2.5
\end{array}
\]</span> 中心点坐标为图中<strong>红点</strong>：(2.5,2.5) 感受野大小为4： <span class="math display">\[
\begin{array}{l}
r_2=1\\
r_1=(r_2-1)*2+3=3\\
r_0=(r_1-1)*1+2=4
\end{array}
\]</span></p></li>
<li><p>图二 第一层有padding。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bh4kt6mh1vhbm2b1e161oob2eh16.png" width="600" /></p>
</center>
<p>绿色点为第2层feature map上坐标为(1,1)的点，则它在原图的中心点为： <span class="math display">\[
\begin{array}{l}
\alpha_2=1*3=3\\
\beta_2=1+(2-1)/2+1*((3-1)/2-1)=1.5\\
i_0=3*(i_2-1)+1.5
\end{array}
\]</span> 中心点坐标为图中<strong>红点</strong>：(1.5,1.5) 感受野大小为4： <span class="math display">\[
\begin{array}{l}
r_2=1\\
r_1=(r_2-1)*3+3=3\\
r_0=(r_1-1)*1+2=4
\end{array}
\]</span></p></li>
</ul>
<h3 id="代码实践-3">8.4.5 代码实践</h3>
<ul>
<li>receptivefield.py <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#一层表示为一个三元组： [filter size, stride, padding]</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forword</span>(<span class="params">conv, layerIn</span>):</span></span><br><span class="line">  n_in = layerIn</span><br><span class="line">  k = conv[<span class="number">0</span>]</span><br><span class="line">  s = conv[<span class="number">1</span>]</span><br><span class="line">  p = conv[<span class="number">2</span>]</span><br><span class="line">  <span class="keyword">return</span> math.floor((n_in - k + <span class="number">2</span>*p)/s) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">alexnet</span>():</span></span><br><span class="line">  convnet = [[],[<span class="number">11</span>,<span class="number">4</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">5</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">6</span>,<span class="number">1</span>,<span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]]</span><br><span class="line">  layer_names = [[<span class="string">&#x27;input&#x27;</span>],<span class="string">&#x27;conv1&#x27;</span>,<span class="string">&#x27;pool1&#x27;</span>,<span class="string">&#x27;conv2&#x27;</span>,<span class="string">&#x27;pool2&#x27;</span>,<span class="string">&#x27;conv3&#x27;</span>,<span class="string">&#x27;conv4&#x27;</span>,<span class="string">&#x27;conv5&#x27;</span>,<span class="string">&#x27;pool5&#x27;</span>,<span class="string">&#x27;fc6-conv&#x27;</span>, <span class="string">&#x27;fc7-conv&#x27;</span>]</span><br><span class="line">  <span class="keyword">return</span> [convnet, layer_names]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testnet</span>():</span></span><br><span class="line">  convnet = [[],[<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">3</span>,<span class="number">1</span>]]</span><br><span class="line">  layer_names = [[<span class="string">&#x27;input&#x27;</span>],<span class="string">&#x27;conv1&#x27;</span>,<span class="string">&#x27;conv2&#x27;</span>]</span><br><span class="line">  <span class="keyword">return</span> [convnet, layer_names]</span><br><span class="line"></span><br><span class="line"><span class="comment"># layerid &gt;= 1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receptivefield</span>(<span class="params">net, layerid</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] receptivefield:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  </span><br><span class="line">  rf = <span class="number">1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">reversed</span>(<span class="built_in">range</span>(layerid)):</span><br><span class="line">    filtersize, stride, padding = net[<span class="number">0</span>][i+<span class="number">1</span>]</span><br><span class="line">    rf = (rf - <span class="number">1</span>)*stride + filtersize</span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;                感受野大小为:%d.&#x27;</span> % (<span class="built_in">int</span>(rf))</span><br><span class="line">  <span class="keyword">return</span> rf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">anylayerout</span>(<span class="params">net, layerin, layerid</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] anylayerout:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layerid):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">      fout = forword(net[<span class="number">0</span>][i+<span class="number">1</span>], layerin)</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    fout = forword(net[<span class="number">0</span>][i+<span class="number">1</span>], fout)</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;当前层为:%s, 输出节点维度为:%d.&#x27;</span> % (net[<span class="number">1</span>][layerid], <span class="built_in">int</span>(fout))</span><br><span class="line"></span><br><span class="line"><span class="comment">#x,y&gt;=1</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">receptivefieldcenter</span>(<span class="params">net, layerid, x, y</span>):</span></span><br><span class="line">  <span class="keyword">if</span> layerid &gt; <span class="built_in">len</span>(net[<span class="number">0</span>]):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;[error] receptivefieldcenter:no such layerid!&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  al = <span class="number">1</span></span><br><span class="line">  bl = <span class="number">1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layerid):</span><br><span class="line">    filtersize, stride, padding = net[<span class="number">0</span>][i+<span class="number">1</span>]</span><br><span class="line">    al = al * stride</span><br><span class="line">    ss = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i):</span><br><span class="line">      fsize, std, pad = net[<span class="number">0</span>][j+<span class="number">1</span>]</span><br><span class="line">      ss = ss * std</span><br><span class="line"></span><br><span class="line">    bl = bl + ss * (<span class="built_in">float</span>(filtersize-<span class="number">1</span>)/<span class="number">2</span> - padding)</span><br><span class="line"></span><br><span class="line">  xi0 = al * (x - <span class="number">1</span>) + <span class="built_in">float</span>(bl)</span><br><span class="line">  yi0 = al * (y - <span class="number">1</span>) + bl</span><br><span class="line">  <span class="built_in">print</span> <span class="string">&#x27;                该层上的特征点(%d,%d)在原图的感受野中心坐标为:(%.1f,%.1f).&#x27;</span> % (<span class="built_in">int</span>(x), <span class="built_in">int</span>(y), <span class="built_in">float</span>(xi0), <span class="built_in">float</span>(yi0))</span><br><span class="line">  <span class="keyword">return</span> (xi0, yi0)</span><br><span class="line"></span><br><span class="line"><span class="comment"># net:为某个CNN网络</span></span><br><span class="line"><span class="comment"># insize:为输入层大小</span></span><br><span class="line"><span class="comment"># totallayers：为除了输入层外的所有层个数</span></span><br><span class="line"><span class="comment"># x,y为某层特征点坐标</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printlayer</span>(<span class="params">net, insize, totallayers, x, y</span>):</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(totallayers):</span><br><span class="line">    <span class="comment"># 计算每一层的输出大小</span></span><br><span class="line">    anylayerout(net, insize, i+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算每层的感受野大小</span></span><br><span class="line">    receptivefield(net, i+<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 计算feature map上(x,y)点在原图感受野的中心位置坐标</span></span><br><span class="line">    receptivefieldcenter(net, i+<span class="number">1</span>, x, y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  <span class="comment">#net = testnet() </span></span><br><span class="line">  <span class="comment">#printlayer(net, insize=6, totallayers=2, x=1, y=1)</span></span><br><span class="line">  net = alexnet()</span><br><span class="line">  printlayer(net, insize=<span class="number">227</span>, totallayers=<span class="number">8</span>, x=<span class="number">2</span>, y=<span class="number">3</span>)</span><br></pre></td></tr></table></figure></li>
<li>输出
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhehjb06nst2511lbr19d64jt39.png" width="600" />
</center></li>
</ul>
<h2 id="fast-r-cnn">8.5 Fast R-CNN</h2>
<p>《<a target="_blank" rel="noopener" href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf">Fast R-CNN</a>》的出现解决了R-CNN+SPP中的以下问题：</p>
<ul>
<li>把分类和回归放在一个网络做共享特征，提取的特征向量不用落地</li>
<li>借鉴SPP，网络结构对输入图片大小自适应</li>
<li>抛弃SVM分类器，利用softmax直接融合在神经网络中</li>
<li>借鉴SPP，只做一次全图的特征提取，不用每个候选框都做</li>
</ul>
<h3 id="算法概述">8.5.1 算法概述</h3>
算法基本步骤为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhes1rl71nh81e9ljv41nnbpr23m.png" width="500" />
</center>
<ul>
<li>候选框生成阶段 方法同R-CNN。</li>
<li>特征提取阶段 注意整个网络的输入为两部分：整个图和候选框信息。特征提取会对整张图进行，利用输入的候选框坐标及大小信息可以方便低成本的在任何一个feature map上找到任何一个原图点的特征映射点(方法回看SPP-net)，大大提高了特征提取效率。</li>
<li>RoI pooling阶段 借鉴SPP的思想，对每个候选框生成一个自适应候选框大小的固定长度的ROI（region of interest）特征向量，除此之外，大家还可以想想RoI Pooling的更深层次作用。</li>
<li>多任务学习阶段 把得到的RoI特征向量用全连接层做组合后分别送入两个分支：一个做分类，一个做Bounding Box回归，并为此设计一个多任务损失函数。</li>
</ul>
直观对比R-CNN与Fast R-CNN的<a target="_blank" rel="noopener" href="http://kaiminghe.com/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf">forward pipeline</a>：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bhet2nk1per1nd3c3tg5f1u7m43.png" width="600"/>
</center>
<h3 id="训练阶段">8.5.2 训练阶段</h3>
<ul>
<li><p>RoI pooling层生成说明</p>
<p>RoI pooling是SPP的特殊形式（金字塔层数为1，pooling采用max pooling），具体原理类比SPP即可，feature map通过该层后会产生<span class="math inline">\(H × W\)</span>大小（例如7 × 7）的特征向量，例如： 某个RoI坐标表示为四元组<span class="math inline">\((r,c,h,w)\)</span>，其中<span class="math inline">\(r,c\)</span>为RoI最左上角坐标，<span class="math inline">\(h,w\)</span>为其高与宽，则RoI pooling会划分<span class="math inline">\(H × W\)</span>个大小<span class="math inline">\(为\frac{h}{H} × \frac{w}{W}\)</span>的小网格，之后对每个小网格做max pooling即可。</p></li>
<li><p>RoI pooling层反向传播</p>
<p>RoI pooling的反向传播比较简单，输入feature map上的任意特征元素的梯度信息为：所有由它产生的roi pooling feature map的特征元素所带梯度信息的累加和。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivqa5cb1hbeksa7gbdm123o1g.png" width="500"/></p>
</center>
<p>假设：</p>
<p>1、<span class="math inline">\(x_i \in R\)</span>是 RoI pooling层输入feature map的第<span class="math inline">\(i\)</span>个特征元素；</p>
<p>2、<span class="math inline">\(y_{rj}\)</span>是第<span class="math inline">\(r\)</span>个RoI的roi pooling后得到feature map的第<span class="math inline">\(j\)</span>个特征元素；</p>
<p>3、<span class="math inline">\(R(r,j)\)</span>是第<span class="math inline">\(r\)</span>个RoI通过roi pooling得到的feature map上的第<span class="math inline">\(j\)</span>个输出特征元素对应原feature map上的子图；</p>
<p><span class="math inline">\(i^*_{r,j}=argmax_{i^{\text{&#39;}} \in R(r,j)}x_i^\text{&#39;}\)</span>为在上述子图中做max pooling后得到的原feature map元素索引号。</p>
<p>则反向传播得到的原feature map元素的梯度为： <span class="math display">\[
  \frac{\partial L}{\partial x_i}=\sum_r \sum_j[i=i^*_{r,j}]\frac{\partial L}{\partial y_{rj}}
  \]</span> <span class="math inline">\([x]\)</span>函数表示：如果<span class="math inline">\(x\)</span>为真则返回1，否则返回0。</p></li>
<li><p>多任务损失函数</p>
<p>使用smooth L1函数并融合分类和bounding box回归损失，损失函数如下： <span class="math display">\[
  L(p,u,t^u,v)=L_{cls}(p,u)+\lambda \cdot [u \geq 1]L_{loc}(t^u,v)
  \]</span> 其中: <span class="math display">\[L_{cls}(p,u)=-log \text{ }p_u\]</span> <span class="math display">\[L_{loc}(t^u,v)=\sum_{i \in \{x,y,w,h\}}smooth_{L_1}(t_i^u-v_i)\]</span></p>
<p><span class="math display">\[ smooth_{L_1}(x)=
  \begin{cases}
  0.5x^2&amp; \text{if |x|&lt;1}\\
  |x|-0.5&amp; \text{otherwise}
  \end{cases}
  \]</span> smooth L1函数对异常点不敏感（在|x|值较大时使用线性分段函数而不是二次函数），如图：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivr14vrusab6vouf12a9la11t.png" width="400" /></p>
</center></li>
</ul>
<h3 id="代码实践-4">8.5.3 代码实践</h3>
<p>fast r-cnn完整代码请参考<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/fast-rcnn">rbgirshick/fast-rcnn</a>。</p>
<ul>
<li>RoI Pooling层实现解析 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">// Fast R-CNN</span></span><br><span class="line"><span class="comment">// Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment">// Licensed under The MIT License [see fast-rcnn/LICENSE for details]</span></span><br><span class="line"><span class="comment">// Written by Ross Girshick</span></span><br><span class="line"><span class="comment">// ------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cfloat&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;caffe/fast_rcnn_layers.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::max;</span><br><span class="line"><span class="keyword">using</span> <span class="built_in">std</span>::min;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> caffe &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 以下参数解释以VGG16为例，即进入roi pooling前的网络结构采用经典VGG16.</span></span><br><span class="line"><span class="comment">// 在Layer类中输入数据用bottom表示, 输出数据用top表示</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">ROIPoolForward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> nthreads,			<span class="comment">// 任务数，对应通过roi pooling后的输出feature map的神经元节点总数，</span></span></span></span><br><span class="line"><span class="params"><span class="function">	                            <span class="comment">// 具体为：RoI的个数(m) × channel个数(VGG16的conv5_3的输出为512个) × roi pooling输出宽(配置为7) × roi pooling输出高(配置为7) = 25088×m个</span></span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype* bottom_data,	<span class="comment">// 输入的feature map，原图经过各种卷积、pooling等前向传播后得到（VGG16的conv5_3卷积产生的feature map，大小为：512×14×14）</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype spatial_scale,	<span class="comment">// 由之前所有卷积层的strides相乘得到，在fast rcnn中为1/16，注：从原图往conv5_3的feature map上映射为缩小过程，所以乘以1/16，反之需要乘以16</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> channels,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的channel个数(512)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> height,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的高(14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> width,			<span class="comment">// 输入层（VGG16为卷积层conv5_3）feature map的宽(14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_height,	<span class="comment">// roi pooling输出feature map的高，fast rcnn中配置为h=7  </span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_width,		<span class="comment">// roi pooling输出feature map的宽，fast rcnn中配置为w=7  </span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype* bottom_rois,	<span class="comment">// 输入的roi信息，存储所有rois或一个batch的rois，数据结构为[batch_ind,x1,y1,x2,y2]，包含roi的：索引、左上角坐标及右下角坐标 </span></span></span></span><br><span class="line"><span class="params"><span class="function">	Dtype* top_data,			<span class="comment">// 存储roi pooling后得到的feature map</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">int</span>* argmax_data)</span> </span>&#123;         <span class="comment">// 为每个roi pooling后的feature map元素存储max pooling后对应conv5_3 feature map元素的索引信息，长度等于nthreads</span></span><br><span class="line">    <span class="comment">// index为线程索引，个数为roi pooling后的feature map上所有值的个数，索引范围为：[0,nthreads-1]</span></span><br><span class="line">	CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的W,输出roi pooling后feature map的中的宽的坐标，即feature map的第i=[0,k-1]列  </span></span><br><span class="line">    <span class="keyword">int</span> pw = index % pooled_width;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的H,输出roi pooling后feature map的中的高的坐标，即feature map的第j=[0,k-1]行  </span></span><br><span class="line">    <span class="keyword">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">    <span class="comment">// 该线程对应的top blob（N,C,H,W）中的C,即第c个channel，channel数最大值为输入feature map的channel数（VGG16中为512）.</span></span><br><span class="line">    <span class="keyword">int</span> c = (index / pooled_width / pooled_height) % channels;</span><br><span class="line">    <span class="comment">// 该线程对应的是第几个RoI,一共m个.</span></span><br><span class="line">    <span class="keyword">int</span> n = index / pooled_width / pooled_height / channels;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// [start, end)，指定RoI信息的存储范围，指针每次移动5的倍数是因为包含信息的数据结构大小为5，包含信息为：[batch_ind,x1,y1,x2,y2]，含义同上</span></span><br><span class="line">    bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">    <span class="comment">// 将每个原图的RoI区域映射到feature map(VGG16为conv5_3产生的feature mao)上的坐标,bottom_rois第0个位置存放的是roi索引.</span></span><br><span class="line">    <span class="keyword">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];							</span><br><span class="line">	<span class="comment">// 原图到feature map的映射为乘以1/16，这里采用粗映射而不是上文讲的精确映射，原因你懂的.</span></span><br><span class="line">    <span class="keyword">int</span> roi_start_w = round(bottom_rois[<span class="number">1</span>] * spatial_scale);	</span><br><span class="line">    <span class="keyword">int</span> roi_start_h = round(bottom_rois[<span class="number">2</span>] * spatial_scale);</span><br><span class="line">    <span class="keyword">int</span> roi_end_w = round(bottom_rois[<span class="number">3</span>] * spatial_scale);</span><br><span class="line">    <span class="keyword">int</span> roi_end_h = round(bottom_rois[<span class="number">4</span>] * spatial_scale);</span><br><span class="line">    <span class="comment">// 强制把RoI的宽和高限制在1x1，防止出现映射后的RoI大小为0的情况</span></span><br><span class="line">    <span class="keyword">int</span> roi_width = max(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>); </span><br><span class="line">    <span class="keyword">int</span> roi_height = max(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 根据原图映射得到的roi的高和配置的roi pooling的高(这里大小配置为7)自适应计算bin桶的高度</span></span><br><span class="line">    Dtype bin_size_h = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                       / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_height);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 根据原图映射得到的roi的宽和配置的roi pooling的宽(这里大小配置为7)自适应计算bin桶的宽度</span></span><br><span class="line">    Dtype bin_size_w = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                       / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 计算第(i,j)个bin桶在feature map上的坐标范围，需要依据它们确定后续max pooling的范围</span></span><br><span class="line">    <span class="keyword">int</span> hstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph)</span><br><span class="line">                                        * bin_size_h));</span><br><span class="line">    <span class="keyword">int</span> wstart = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw)</span><br><span class="line">                                        * bin_size_w));</span><br><span class="line">    <span class="keyword">int</span> hend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(ph + <span class="number">1</span>)</span><br><span class="line">                                     * bin_size_h));</span><br><span class="line">    <span class="keyword">int</span> wend = <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(<span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(pw + <span class="number">1</span>)</span><br><span class="line">                                     * bin_size_w));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 确定max pooling具体范围，注意由于RoI取自原图，其左上角不是从(0,0)开始，</span></span><br><span class="line">	<span class="comment">// 所以需要加上 roi_start_h 或 roi_start_w作为偏移量，并且超出feature map尺寸范围的部分会被舍弃  </span></span><br><span class="line">    hstart = min(max(hstart + roi_start_h, <span class="number">0</span>), height);</span><br><span class="line">    hend = min(max(hend + roi_start_h, <span class="number">0</span>), height);</span><br><span class="line">    wstart = min(max(wstart + roi_start_w, <span class="number">0</span>), width);</span><br><span class="line">    wend = min(max(wend + roi_start_w, <span class="number">0</span>), width);</span><br><span class="line">    <span class="keyword">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line">    <span class="comment">// 如果区域为0返回错误代码</span></span><br><span class="line">    Dtype maxval = is_empty ? <span class="number">0</span> : -FLT_MAX;</span><br><span class="line">    <span class="comment">// If nothing is pooled, argmax = -1 causes nothing to be backprop&#x27;d</span></span><br><span class="line">    <span class="keyword">int</span> maxidx = <span class="number">-1</span>;</span><br><span class="line">    bottom_data += (roi_batch_ind * channels + c) * height * width;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 在给定bin桶的区域中做max pooling</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> h = hstart; h &lt; hend; ++h) &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> w = wstart; w &lt; wend; ++w) &#123;</span><br><span class="line">        <span class="keyword">int</span> bottom_index = h * width + w;</span><br><span class="line">        <span class="keyword">if</span> (bottom_data[bottom_index] &gt; maxval) &#123;</span><br><span class="line">          maxval = bottom_data[bottom_index];</span><br><span class="line">          maxidx = bottom_index;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 为某个roi pooling的feature map元素记录其由对conv5_3(VGG16)的feature map做max pooling后产生元素的索引号及值</span></span><br><span class="line">    top_data[index] = maxval;</span><br><span class="line">    argmax_data[index] = maxidx;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Forward_gpu(</span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,	<span class="comment">// 以VGG16为例，bottom[0]为最后一个卷积层conv5_3产生的feature map，shape[1, 512, 14, 14], </span></span><br><span class="line">	                                    <span class="comment">//              bottom[1]为rois数据，shape[roi个数m, 5]</span></span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;	<span class="comment">// top为输出层结构， top-&gt;count() = top.n（RoI的个数) × top.channel(channel数) </span></span><br><span class="line">		                                <span class="comment">//                               × top.w(输出feature map的宽) × top.h(输出feature map的高)</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();</span><br><span class="line">  Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_gpu_data();</span><br><span class="line">  <span class="keyword">int</span>* argmax_data = max_idx_.mutable_gpu_data();</span><br><span class="line">  <span class="keyword">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   参照caffe-fast-rcnn/src/caffe/layers/roi_pooling_layer.cpp中的代码：</span></span><br><span class="line"><span class="comment">   template &lt;typename Dtype&gt;</span></span><br><span class="line"><span class="comment">   void ROIPoolingLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span></span><br><span class="line"><span class="comment">      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;</span></span><br><span class="line"><span class="comment">     channels_ = bottom[0]-&gt;channels();</span></span><br><span class="line"><span class="comment">     height_ = bottom[0]-&gt;height();</span></span><br><span class="line"><span class="comment">     width_ = bottom[0]-&gt;width();</span></span><br><span class="line"><span class="comment">     top[0]-&gt;Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_);</span></span><br><span class="line"><span class="comment">     max_idx_.Reshape(bottom[1]-&gt;num(), channels_, pooled_height_, pooled_width_);</span></span><br><span class="line"><span class="comment">   &#125;*/</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  参照caffe-fast-rcnn/include/caffe/util/device_alternate.hpp中的代码：</span></span><br><span class="line"><span class="comment">  // CUDA_KERNEL_LOOP</span></span><br><span class="line"><span class="comment">  #define CUDA_KERNEL_LOOP(i, n) \</span></span><br><span class="line"><span class="comment">  for (int i = blockIdx.x * blockDim.x + threadIdx.x; \</span></span><br><span class="line"><span class="comment">       i &lt; (n); \</span></span><br><span class="line"><span class="comment">       i += blockDim.x * gridDim.x)</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  // CAFFE_GET_BLOCKS</span></span><br><span class="line"><span class="comment">  // CUDA: number of blocks for threads.</span></span><br><span class="line"><span class="comment">  inline int CAFFE_GET_BLOCKS(const int N) &#123;</span></span><br><span class="line"><span class="comment">       return (N + CAFFE_CUDA_NUM_THREADS - 1) / CAFFE_CUDA_NUM_THREADS;</span></span><br><span class="line"><span class="comment">  &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  // CAFFE_CUDA_NUM_THREADS</span></span><br><span class="line"><span class="comment">  // CUDA: thread number configuration.</span></span><br><span class="line"><span class="comment">  // Use 1024 threads per block, which requires cuda sm_2x or above,</span></span><br><span class="line"><span class="comment">  // or fall back to attempt compatibility (best of luck to you).</span></span><br><span class="line"><span class="comment">  #if __CUDA_ARCH__ &gt;= 200</span></span><br><span class="line"><span class="comment">      const int CAFFE_CUDA_NUM_THREADS = 1024;</span></span><br><span class="line"><span class="comment">  #else</span></span><br><span class="line"><span class="comment">      const int CAFFE_CUDA_NUM_THREADS = 512;</span></span><br><span class="line"><span class="comment">  #endif  </span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"></span><br><span class="line">  ROIPoolForward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">      count, bottom_data, spatial_scale_, channels_, height_, width_,</span><br><span class="line">      pooled_height_, pooled_width_, bottom_rois, top_data, argmax_data);</span><br><span class="line">  CUDA_POST_KERNEL_CHECK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="comment">// 反向传播的过程与论文中&quot;Back-propagation through RoI pooling layers&quot;这一小节的公式完全一致</span></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">ROIPoolBackward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> nthreads,			<span class="comment">// 输入feature map的元素数(VGG16为：512×14×14)</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype* top_diff,		<span class="comment">// roi pooling输出feature map所带的梯度信息∂L/∂y(r,j)</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span>* argmax_data,		<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> num_rois,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> Dtype spatial_scale,  <span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> channels,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> height,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> width,			<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> <span class="keyword">int</span> pooled_height,	<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	<span class="keyword">const</span> <span class="keyword">int</span> pooled_width,		<span class="comment">// 同前向，不解释</span></span></span></span><br><span class="line"><span class="params"><span class="function">	Dtype* bottom_diff,			<span class="comment">// 保留输入feature map每个元素通过梯度反向传播得到的梯度信息</span></span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">const</span> Dtype* bottom_rois)</span> </span>&#123;	<span class="comment">// 同前向，不解释</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 含义同前向，需要注意的是这里表示的是输入feature map的元素数(反向传播嘛)</span></span><br><span class="line">  CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">    <span class="comment">// 同前向，不解释</span></span><br><span class="line">    <span class="keyword">int</span> w = index % width;</span><br><span class="line">    <span class="keyword">int</span> h = (index / width) % height;</span><br><span class="line">    <span class="keyword">int</span> c = (index / width / height) % channels;</span><br><span class="line">    <span class="keyword">int</span> n = index / width / height / channels;</span><br><span class="line">    Dtype gradient = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 同论文中公式，任何一个输入feature map的元素的梯度信息为：</span></span><br><span class="line">	<span class="comment">// 所有max pooling时被该元素落入且该元素值被选中(最大值)的</span></span><br><span class="line">	<span class="comment">// roi pooling feature map元素的梯度信息累加和</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 遍历所有RoI，以判断是否满足上述条件</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> roi_n = <span class="number">0</span>; roi_n &lt; num_rois; ++roi_n) &#123;</span><br><span class="line">      <span class="keyword">const</span> Dtype* offset_bottom_rois = bottom_rois + roi_n * <span class="number">5</span>;</span><br><span class="line">      <span class="keyword">int</span> roi_batch_ind = offset_bottom_rois[<span class="number">0</span>];</span><br><span class="line">      <span class="comment">// 如果RoI的索引号不满足条件则跳过</span></span><br><span class="line">      <span class="keyword">if</span> (n != roi_batch_ind) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 找原图RoI在feature map上的映射位置，解释同前向传播</span></span><br><span class="line">      <span class="keyword">int</span> roi_start_w = round(offset_bottom_rois[<span class="number">1</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_start_h = round(offset_bottom_rois[<span class="number">2</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_end_w = round(offset_bottom_rois[<span class="number">3</span>] * spatial_scale);</span><br><span class="line">      <span class="keyword">int</span> roi_end_h = round(offset_bottom_rois[<span class="number">4</span>] * spatial_scale);</span><br><span class="line">      <span class="comment">// (h,w)不在RoI范围则跳过</span></span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">bool</span> in_roi = (w &gt;= roi_start_w &amp;&amp; w &lt;= roi_end_w &amp;&amp;</span><br><span class="line">                           h &gt;= roi_start_h &amp;&amp; h &lt;= roi_end_h);</span><br><span class="line">      <span class="keyword">if</span> (!in_roi) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> offset = (roi_n * channels + c) * pooled_height * pooled_width;</span><br><span class="line">      <span class="keyword">const</span> Dtype* offset_top_diff = top_diff + offset;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">int</span>* offset_argmax_data = argmax_data + offset;</span><br><span class="line">      <span class="comment">// 同前向</span></span><br><span class="line">      <span class="keyword">int</span> roi_width = max(roi_end_w - roi_start_w + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">int</span> roi_height = max(roi_end_h - roi_start_h + <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 同前向</span></span><br><span class="line">      Dtype bin_size_h = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_height)</span><br><span class="line">                         / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_height);</span><br><span class="line">      Dtype bin_size_w = <span class="keyword">static_cast</span>&lt;Dtype&gt;(roi_width)</span><br><span class="line">                         / <span class="keyword">static_cast</span>&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 类比前向，看做一个逆过程</span></span><br><span class="line">      <span class="keyword">int</span> phstart = <span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(h - roi_start_h) / bin_size_h);</span><br><span class="line">      <span class="keyword">int</span> phend = <span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(h - roi_start_h + <span class="number">1</span>) / bin_size_h);</span><br><span class="line">      <span class="keyword">int</span> pwstart = <span class="built_in">floor</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(w - roi_start_w) / bin_size_w);</span><br><span class="line">      <span class="keyword">int</span> pwend = <span class="built_in">ceil</span>(<span class="keyword">static_cast</span>&lt;Dtype&gt;(w - roi_start_w + <span class="number">1</span>) / bin_size_w);</span><br><span class="line">      phstart = min(max(phstart, <span class="number">0</span>), pooled_height);</span><br><span class="line">      phend = min(max(phend, <span class="number">0</span>), pooled_height);</span><br><span class="line">      pwstart = min(max(pwstart, <span class="number">0</span>), pooled_width);</span><br><span class="line">      pwend = min(max(pwend, <span class="number">0</span>), pooled_width);</span><br><span class="line"></span><br><span class="line">	  <span class="comment">// 累积所有与当前输入feature map上的元素相关的roi pooling元素的梯度信息</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> ph = phstart; ph &lt; phend; ++ph) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> pw = pwstart; pw &lt; pwend; ++pw) &#123;</span><br><span class="line">          <span class="keyword">if</span> (offset_argmax_data[ph * pooled_width + pw] == (h * width + w)) &#123;</span><br><span class="line">            gradient += offset_top_diff[ph * pooled_width + pw];</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">	<span class="comment">// 存储当前输入feature map上元素的反向传播梯度信息</span></span><br><span class="line">    bottom_diff[index] = gradient;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="keyword">void</span> ROIPoolingLayer&lt;Dtype&gt;::Backward_gpu(</span><br><span class="line">	<span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,		<span class="comment">// roi pooling输出feature map</span></span><br><span class="line">      <span class="keyword">const</span> <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&amp; propagate_down,	<span class="comment">// 是否做反向传播，回忆前向传播时的那个bool值</span></span><br><span class="line">	  <span class="keyword">const</span> <span class="built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;	<span class="comment">// roi pooling输入feature map(VGG16中的conv5_3产生的feature map)</span></span><br><span class="line">  <span class="keyword">if</span> (!propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">const</span> Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();		<span class="comment">// 原始RoI信息</span></span><br><span class="line">  <span class="keyword">const</span> Dtype* top_diff = top[<span class="number">0</span>]-&gt;gpu_diff();			<span class="comment">// roi pooling feature map梯度信息</span></span><br><span class="line">  Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();	<span class="comment">// 待写入的输入feature map梯度信息</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> count = bottom[<span class="number">0</span>]-&gt;count();					<span class="comment">// 输入feature map元素总数</span></span><br><span class="line">  caffe_gpu_set(count, Dtype(<span class="number">0.</span>), bottom_diff);		</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span>* argmax_data = max_idx_.gpu_data();</span><br><span class="line">  <span class="comment">// NOLINT_NEXT_LINE(whitespace/operators)</span></span><br><span class="line">  ROIPoolBackward&lt;Dtype&gt;&lt;&lt;&lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS&gt;&gt;&gt;(</span><br><span class="line">      count, top_diff, argmax_data, top[<span class="number">0</span>]-&gt;num(), spatial_scale_, channels_,</span><br><span class="line">      height_, width_, pooled_height_, pooled_width_, bottom_diff, bottom_rois);</span><br><span class="line">  CUDA_POST_KERNEL_CHECK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INSTANTIATE_LAYER_GPU_FUNCS(ROIPoolingLayer);</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace caffe</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p>实现代码参考，GPU版本：<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/caffe-fast-rcnn/blob/bcd9b4eadc7d8fbc433aeefd564e82ec63aaf69c/src/caffe/layers/roi_pooling_layer.cu">roi_pooling_layer.cu</a>和CPU版本：<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/caffe-fast-rcnn/blob/bcd9b4eadc7d8fbc433aeefd564e82ec63aaf69c/src/caffe/layers/roi_pooling_layer.cpp">roi_pooling_layer.cpp</a>。</p>
<p>conv5_3及roi相关层配置： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_2&quot;</span></span><br><span class="line">  top: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">  param &#123;</span><br><span class="line">    lr_mult: <span class="number">2</span></span><br><span class="line">  &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">512</span></span><br><span class="line">    pad: <span class="number">1</span></span><br><span class="line">    kernel_size: <span class="number">3</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;relu5_3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  top: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;roi_pool5&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ROIPooling&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rois&quot;</span></span><br><span class="line">  top: <span class="string">&quot;pool5&quot;</span></span><br><span class="line">  roi_pooling_param &#123;</span><br><span class="line">    pooled_w: <span class="number">7</span></span><br><span class="line">    pooled_h: <span class="number">7</span></span><br><span class="line">    spatial_scale: <span class="number">0.0625</span> <span class="comment"># 1/16</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>一些直观解释
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bivq6gre1al81aqq1cgcflq78m.png" width="800"/>
</center></li>
</ul>
<h2 id="faster-r-cnn">8.6 Faster R-CNN</h2>
<p>《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>》提出了Region Proposal Network(RPN)，解决了基于Region的检测算法需要事先通过Selective Search生成候选框的问题，让候选框生成、分类、bounding box回归公用同一套特征提取网络，从而使这类检测算法真正意义上实现End to End。</p>
<h3 id="算法概述-1">8.6.1 算法概述</h3>
如上所述，Faster R-CNN设计了RPN使得候选框生成可以共用特征提取网络，算法流程如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bj1mie6rheb17fo2hh1sk3js59.png" width="800" />
</center>
<p>RPN负责生成Proposal候选框，其他过程类似Fast R-CNN，同样，生成候选框的扫描过程发生在最后一个卷积层产生的feature map上（而不是扫描原图），通过之前讲的坐标换算关系可以将feature map任意一点映射回原图。</p>
<h3 id="rpn">8.6.2 RPN</h3>
RPN的结构如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjht1v6fjkca6cpa49jh11j926.png" width="450"/>
</center>
<p>1、RPN的输入是特征提取器最后一个卷积(pooling)产生的feature map，例如VGG16为conv5_3产生的512维（channel数）的feature map（图中例子是256维）；</p>
<p>2、之后以m×m大小的滑动窗口扫描feature map，如果feature map大小为h×w，则扫描h×w次（即以每个像素点为中心做一次），文中m的取值为3，取值与具体网络结构有关，感受野的不同导致候选框的初始大小不同；</p>
<p>3、每做一次滑动窗口会生成k个初始候选框，初始候选框的大小与anchor（<strong>原理8.6.3解释</strong>）有关，中心点为滑动窗口中心点，即对一次滑动窗口行为，所有利用anchor生成的候选框都有相同的中心点（图中蓝点），一定注意：这里的anchor及利用它生成的候选框都是<strong>相对于原图的位置</strong>；</p>
<p>4、定义两个分支，第一个分支（左边）是一个二分类器，用来区分当前候选框是否为物体，如果有k个由anchor生成的候选框，则输出2<em>k个值（2维向量为:[是物体的概率，是背景的概率]）；第二个分支（右边）为回归器，用来回归候选框的中心点坐标和宽与高（4维向量[x,y,w,h]），如果有k个由anchor生成的候选框，则输出4</em>k个值，显然这里候选框的生成要短、平、快，精调细选由后续网络来做。</p>
<h3 id="anchor">8.6.3 Anchor</h3>
<p>RPN里很重要的一个概念是anchor，可以把它理解为生成候选框的模板，在RPN里只生成一次，anchor是用原图为参照物，以(0,0,指定宽,指定高)四元组采用不同缩放比例和尺度后产生的候选框模板集合，而候选框由滑动窗口(中心点x，中心点y)利用anchor生成。也可以从逆SPP角度去理解，SPP可以把一个feature map通过多尺度变换为金字塔式的多个feature map，反过来任何一个feature map也可利用多尺度变成多个feature map，这么做的好处是压根儿不用在原图上做各种尺度缩放而只用在feature map上做就好，并且这种变换具有不变性(Translation-Invariant Anchor)：候选框生成及其预测函数具有可复现性，例如通过k-means聚类得到800个anchor，如果重复做一次实验不一定还是原来那800个，这个性质可以降低模型大小以及过拟合的风险。</p>
<p>以16×16大小为，base anchor[0,0,15,15]为例：</p>
1、只使用_ratio_enum生成候选框如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjjioarcna9g52sdk98v1ko72j.png" width="800"/>
</center>
2、只使用_scale_enum生成候选框如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjjiq26o181l1m5r1d6r1ktq1td30.png" width="800"/>
</center>
3、混合使用生成候选框如下： 这种模板生成只需要做一次，之后大家以此为基准做中心点漂移即可。(所有其他像素点横纵坐标总是大于0的)
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjhhinlo1b97tjeralm8r1iddv.png" width="800" />
</center>
<p>代码可参考<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/rpn/generate_anchors.py">generate_anchors.py</a>: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Faster R-CNN</span></span><br><span class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Ross Girshick and Sean Bell</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Verify that we compute the same anchors as Shaoqing&#x27;s matlab implementation:</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    &gt;&gt; load output/rpn_cachedir/faster_rcnn_VOC2007_ZF_stage1_rpn/anchors.mat</span></span><br><span class="line"><span class="comment">#    &gt;&gt; anchors</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#    anchors =</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#       -83   -39   100    56</span></span><br><span class="line"><span class="comment">#      -175   -87   192   104</span></span><br><span class="line"><span class="comment">#      -359  -183   376   200</span></span><br><span class="line"><span class="comment">#       -55   -55    72    72</span></span><br><span class="line"><span class="comment">#      -119  -119   136   136</span></span><br><span class="line"><span class="comment">#      -247  -247   264   264</span></span><br><span class="line"><span class="comment">#       -35   -79    52    96</span></span><br><span class="line"><span class="comment">#       -79  -167    96   184</span></span><br><span class="line"><span class="comment">#      -167  -343   184   360</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#array([[ -83.,  -39.,  100.,   56.],</span></span><br><span class="line"><span class="comment">#       [-175.,  -87.,  192.,  104.],</span></span><br><span class="line"><span class="comment">#       [-359., -183.,  376.,  200.],</span></span><br><span class="line"><span class="comment">#       [ -55.,  -55.,   72.,   72.],</span></span><br><span class="line"><span class="comment">#       [-119., -119.,  136.,  136.],</span></span><br><span class="line"><span class="comment">#       [-247., -247.,  264.,  264.],</span></span><br><span class="line"><span class="comment">#       [ -35.,  -79.,   52.,   96.],</span></span><br><span class="line"><span class="comment">#       [ -79., -167.,   96.,  184.],</span></span><br><span class="line"><span class="comment">#       [-167., -343.,  184.,  360.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成多尺度anchors，默认实现是大小为16，起始anchor位置是(0, 0, 15, 15)[左下角和右上角坐标]，宽高比例为1/2,1,2，尺度缩放倍数为8,16,32。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_anchors</span>(<span class="params">base_size=<span class="number">16</span>, ratios=[<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>],</span></span></span><br><span class="line"><span class="params"><span class="function">                     scales=<span class="number">2</span>**np.arange(<span class="params"><span class="number">3</span>, <span class="number">6</span></span>)</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate anchor (reference) windows by enumerating aspect ratios X</span></span><br><span class="line"><span class="string">    scales wrt a reference (0, 0, 15, 15) window.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 生成起始anchor位置是(0, 0, 15, 15)</span></span><br><span class="line">    base_anchor = np.array([<span class="number">1</span>, <span class="number">1</span>, base_size, base_size]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 枚举1/2,1,2三种宽高缩放比例</span></span><br><span class="line">    ratio_anchors = _ratio_enum(base_anchor, ratios)</span><br><span class="line">    <span class="comment"># 在以上比例的基础上做8,16,32三类尺度缩放，最终生成9个anchor。</span></span><br><span class="line">    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales)</span><br><span class="line">                         <span class="keyword">for</span> i <span class="keyword">in</span> xrange(ratio_anchors.shape[<span class="number">0</span>])])</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"><span class="comment"># 对给定anchor返回宽、高和中心点坐标（anchor存储的是左下角和右上角）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_whctrs</span>(<span class="params">anchor</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Return width, height, x center, and y center for an anchor (window).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w = anchor[<span class="number">2</span>] - anchor[<span class="number">0</span>] + <span class="number">1</span></span><br><span class="line">    h = anchor[<span class="number">3</span>] - anchor[<span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">    x_ctr = anchor[<span class="number">0</span>] + <span class="number">0.5</span> * (w - <span class="number">1</span>)</span><br><span class="line">    y_ctr = anchor[<span class="number">1</span>] + <span class="number">0.5</span> * (h - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> w, h, x_ctr, y_ctr</span><br><span class="line"><span class="comment"># 给定宽、高和中心点，输出anchor的左下角和右上角坐标</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_mkanchors</span>(<span class="params">ws, hs, x_ctr, y_ctr</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Given a vector of widths (ws) and heights (hs) around a center</span></span><br><span class="line"><span class="string">    (x_ctr, y_ctr), output a set of anchors (windows).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    ws = ws[:, np.newaxis]</span><br><span class="line">    hs = hs[:, np.newaxis]</span><br><span class="line">    anchors = np.hstack((x_ctr - <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr - <span class="number">0.5</span> * (hs - <span class="number">1</span>),</span><br><span class="line">                         x_ctr + <span class="number">0.5</span> * (ws - <span class="number">1</span>),</span><br><span class="line">                         y_ctr + <span class="number">0.5</span> * (hs - <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 枚举anchor的三种宽高比 1:2,1:1,2:1 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_ratio_enum</span>(<span class="params">anchor, ratios</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each aspect ratio wrt an anchor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    size = w * h</span><br><span class="line">    size_ratios = size / ratios</span><br><span class="line">    ws = np.<span class="built_in">round</span>(np.sqrt(size_ratios))</span><br><span class="line">    hs = np.<span class="built_in">round</span>(ws * ratios)</span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 枚举anchor的各种尺度，如：anchor为[0 0 15 15],尺度为[8 16 32] </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scale_enum</span>(<span class="params">anchor, scales</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Enumerate a set of anchors for each scale wrt an anchor.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    w, h, x_ctr, y_ctr = _whctrs(anchor)</span><br><span class="line">    ws = w * scales</span><br><span class="line">    hs = h * scales</span><br><span class="line">    anchors = _mkanchors(ws, hs, x_ctr, y_ctr)</span><br><span class="line">    <span class="keyword">return</span> anchors</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    t = time.time()</span><br><span class="line">    a = generate_anchors()</span><br><span class="line">    <span class="built_in">print</span> time.time() - t</span><br><span class="line">    <span class="built_in">print</span> a</span><br><span class="line">    <span class="keyword">from</span> IPython <span class="keyword">import</span> embed; embed()</span><br></pre></td></tr></table></figure></p>
<h3 id="代码实践-5">8.6.4 代码实践</h3>
<p>集中介绍RPN中proposal层的实现，以特征提取网络采用VGG16在poscal_voc数据集上为例。</p>
<ul>
<li><p>网络结构</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/VGG16-fasterrcnn.png" width="800"/></p>
</center></li>
<li><p>RPN配置 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_conv/3x3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;conv5_3&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">512</span></span><br><span class="line">    kernel_size: <span class="number">3</span> pad: <span class="number">1</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_relu/3x3&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;ReLU&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">18</span>   <span class="comment"># 2(bg/fg) * 9(anchors)</span></span><br><span class="line">    kernel_size: <span class="number">1</span> pad: <span class="number">0</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;Convolution&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn/output&quot;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  param &#123; lr_mult: <span class="number">1.0</span> &#125;</span><br><span class="line">  param &#123; lr_mult: <span class="number">2.0</span> &#125;</span><br><span class="line">  convolution_param &#123;</span><br><span class="line">    num_output: <span class="number">36</span>   <span class="comment"># 4 * 9(anchors)</span></span><br><span class="line">    kernel_size: <span class="number">1</span> pad: <span class="number">0</span> stride: <span class="number">1</span></span><br><span class="line">    weight_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;gaussian&quot;</span> std: <span class="number">0.01</span> &#125;</span><br><span class="line">    bias_filler &#123; <span class="built_in">type</span>: <span class="string">&quot;constant&quot;</span> value: <span class="number">0</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">   bottom: <span class="string">&quot;rpn_cls_score&quot;</span></span><br><span class="line">   top: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">   name: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">   <span class="built_in">type</span>: <span class="string">&quot;Reshape&quot;</span></span><br><span class="line">   reshape_param &#123; shape &#123; dim: <span class="number">0</span> dim: <span class="number">2</span> dim: -<span class="number">1</span> dim: <span class="number">0</span> &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&#x27;rpn-data&#x27;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&#x27;Python&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_cls_score&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;gt_boxes&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;im_info&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;data&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_labels&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_targets&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_inside_weights&#x27;</span></span><br><span class="line">  top: <span class="string">&#x27;rpn_bbox_outside_weights&#x27;</span></span><br><span class="line">  python_param &#123;</span><br><span class="line">    module: <span class="string">&#x27;rpn.anchor_target_layer&#x27;</span></span><br><span class="line">    layer: <span class="string">&#x27;AnchorTargetLayer&#x27;</span></span><br><span class="line">    param_str: <span class="string">&quot;&#x27;feat_stride&#x27;: 16&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_loss_cls&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;SoftmaxWithLoss&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_cls_score_reshape&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_labels&quot;</span></span><br><span class="line">  propagate_down: <span class="number">1</span></span><br><span class="line">  propagate_down: <span class="number">0</span></span><br><span class="line">  top: <span class="string">&quot;rpn_cls_loss&quot;</span></span><br><span class="line">  loss_weight: <span class="number">1</span></span><br><span class="line">  loss_param &#123;</span><br><span class="line">    ignore_label: -<span class="number">1</span></span><br><span class="line">    normalize: true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;rpn_loss_bbox&quot;</span></span><br><span class="line">  <span class="built_in">type</span>: <span class="string">&quot;SmoothL1Loss&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_bbox_pred&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;rpn_bbox_targets&quot;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_bbox_inside_weights&#x27;</span></span><br><span class="line">  bottom: <span class="string">&#x27;rpn_bbox_outside_weights&#x27;</span></span><br><span class="line">  top: <span class="string">&quot;rpn_loss_bbox&quot;</span></span><br><span class="line">  loss_weight: <span class="number">1</span></span><br><span class="line">  smooth_l1_loss_param &#123; sigma: <span class="number">3.0</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>准备阶段 配置参数和生成anchor模板： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">setup</span>(<span class="params">self, bottom, top</span>):</span></span><br><span class="line">        <span class="comment"># parse the layer parameter string, which must be valid YAML</span></span><br><span class="line">        layer_params = yaml.load(self.param_str_)</span><br><span class="line">        <span class="comment"># 获取所有特征提取层stride的乘积。（例如VGG为16）</span></span><br><span class="line">        self._feat_stride = layer_params[<span class="string">&#x27;feat_stride&#x27;</span>]</span><br><span class="line">        <span class="comment"># 设置初始尺度变换比例为8、16、32。</span></span><br><span class="line">        anchor_scales = layer_params.get(<span class="string">&#x27;scales&#x27;</span>, (<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>))</span><br><span class="line">        <span class="comment"># 使用上面介绍的方法生成anchor模板。</span></span><br><span class="line">        self._anchors = generate_anchors(scales=np.array(anchor_scales))</span><br><span class="line">        <span class="comment"># anchor数量。（例如：9）</span></span><br><span class="line">        self._num_anchors = self._anchors.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> DEBUG:</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;feat_stride: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(self._feat_stride)</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;anchors:&#x27;</span></span><br><span class="line">            <span class="built_in">print</span> self._anchors</span><br><span class="line"></span><br><span class="line">        <span class="comment"># rois blob: holds R regions of interest, each is a 5-tuple</span></span><br><span class="line">        <span class="comment"># (n, x1, y1, x2, y2) specifying an image batch index n and a</span></span><br><span class="line">        <span class="comment"># rectangle (x1, y1, x2, y2)</span></span><br><span class="line">        top[<span class="number">0</span>].reshape(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># scores blob: holds scores for R regions of interest</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(top) &gt; <span class="number">1</span>:</span><br><span class="line">            top[<span class="number">1</span>].reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p></li>
<li><p>前向传播</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjk8ruf11p2rkalrqph4u1jk53p.png" width="300" /></p>
</center></li>
</ul>
以i为中心利用anchor模板生成anchor过程如下(蓝色为模板，用红色为i中心点生成)：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjhi2u9n1aahsa712s5s2gi621c.png" width="800"  />
</center>
<p>实现上就是中心点i的各个坐标直接加到anchor模板的各个坐标即可（anchor模板是以0为中心点的），代码类似： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A = self._num_anchors</span><br><span class="line">K = shifts.shape[<span class="number">0</span>]</span><br><span class="line">anchors = self._anchors.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">          shifts.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">anchors = anchors.reshape((K * A, <span class="number">4</span>))</span><br></pre></td></tr></table></figure></p>
<h3 id="faster-r-cnn训练流程">8.6.5 Faster R-CNN训练流程</h3>
<p>采用四阶段交替方式训练(4-Step Alternating Training)</p>
<p>1、使用ImageNet预训练模型权重初始化并fine-tuned训练一个RPN；</p>
<p>2、使用ImageNet预训练模型权重初始化并将上一步产生的候选框(proposal)作为输入训练独立的Faster R-CNN检测模型（此时没有卷积网络共享）；</p>
<p>3、生成新的RPN并使用上一步Fast-RCNN模型参数初始化，设置RPN、Fast-RCNN共享的那部分网络权重不做更新，只fine-tuned训练RPN独有的网络层，达到两者共享用于提取特征的卷积层的目的；</p>
<p>4、固定共享的那些卷积层权重，只训练Fast-RCNN独有的网络层。</p>
<p>Faster R-CNN是效果最好的目标检测与分类模型之一，但如果想用于实时监测和前置到客户端则需要做大量模型裁剪、压缩和优化工作，具体做法我以后介绍，目前我们做的比较初步，模型大小压缩到10m左右，准确率损失小于1.5%，线上inference响应时间在500k左右大小图片、k80单机单卡单次请求下为20ms左右（在高并发情况下会通过打batch的方式及其他方法提高并发量）。</p>
<strong>未做优化</strong>的汽车检测demo：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjmrl00f1l1f8pnpg2qkbb1o9.png" width="600" height="400" />
</center>
<figure>
<embed src="https://vivounicorn.github.io/images/ai_chapter_8/output.swf" /><figcaption aria-hidden="true">演示</figcaption>
</figure>
<h3 id="faster-r-cnn-with-caffe">8.6.6 Faster R-CNN with Caffe</h3>
源码地址：<a target="_blank" rel="noopener" href="https://github.com/rbgirshick/py-faster-rcnn">Faster R-CNN</a>（rbgirshick版）。 一定注意，caffe有个问题（我认为是架构上的设计缺陷，这个问题tensorflow就没有）：由于要支持自定义的网络层之类的需求，每个人的caffe版本可能是不一样的，所以在编译时需要注意，比如这里的caffe必须使用0dcd397这个branch，否则编译不通过，因为这里有自定义的proposal层以及相关参数。 目录结构如下：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bjka01lv1t6k184g1pt81r69ek746.png" width="600" height="400" />
</center>
<hr />
<p><strong>Centos 7上编译运行caffe及Faster R-CNN</strong></p>
<ul>
<li><p>编译准备</p>
<p>1、 为你的账号添加sudo权限</p>
<blockquote>
<p>gpasswd -a user_name wheel</p>
</blockquote>
<p>2、安装编译器</p>
<blockquote>
<p>sudo yum install gcc gcc-c++</p>
</blockquote>
<p>3、安装 git</p>
<blockquote>
<p>sudo yum install git</p>
</blockquote>
<p>4、clone代码</p>
<blockquote>
<p>git clone https://github.com/rbgirshick/py-faster-rcnn.git</p>
</blockquote>
<p>5、安装依赖项</p>
<blockquote>
<p>sudo yum install snappy-devel opencv-devel atlas-devel boost-devel protobuf-devel</p>
</blockquote>
<p>6、安装cmake</p>
<blockquote>
<p>sudo yum install cmake</p>
</blockquote>
<p>7、安装automake</p>
<blockquote>
<p>wget http://ftp.gnu.org/gnu/automake/automake-1.14.tar.gz</p>
</blockquote>
<blockquote>
<p>tar -xvf automake-1.14.tar.gz</p>
</blockquote>
<blockquote>
<p>cd automake-1.14</p>
</blockquote>
<blockquote>
<p>./configure</p>
</blockquote>
<blockquote>
<p>make -j</p>
</blockquote>
<blockquote>
<p>sudo make install</p>
</blockquote>
<p>8、安装gflags</p>
<blockquote>
<p>git clone https://github.com/gflags/gflags</p>
</blockquote>
<blockquote>
<p>cd gflags</p>
</blockquote>
<blockquote>
<p>mkdir build &amp;&amp; cd build</p>
</blockquote>
<blockquote>
<p>export CXXFLAGS="-fPIC" &amp;&amp; cmake ..</p>
</blockquote>
<blockquote>
<p>make VERBOSE=1 -j</p>
</blockquote>
<blockquote>
<p>sudo make install</p>
</blockquote>
<p>9、安装glog</p>
<blockquote>
<p>git clone https://github.com/google/glog</p>
</blockquote>
<blockquote>
<p>cd glog</p>
</blockquote>
<blockquote>
<p>./autogen.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install</p>
</blockquote>
<p>10、安装 lmdb</p>
<blockquote>
<p>git clone https://github.com/LMDB/lmdb</p>
</blockquote>
<blockquote>
<p>cd lmdb/libraries/liblmdb</p>
</blockquote>
<blockquote>
<p>make -j</p>
</blockquote>
<blockquote>
<p>sudo make install</p>
</blockquote>
<p>11、安装 hdf5</p>
<blockquote>
<p>wget https://support.hdfgroup.org/ftp/HDF5/current18/src/hdf5-1.8.19.tar.gz</p>
</blockquote>
<blockquote>
<p>tar -xvf hdf5-1.8.19.tar.gz</p>
</blockquote>
<blockquote>
<p>cd hdf5-1.8.19</p>
</blockquote>
<blockquote>
<p>./configure --prefix=/usr/local</p>
</blockquote>
<blockquote>
<p>make -j</p>
</blockquote>
<blockquote>
<p>sudo make install</p>
</blockquote>
<p>12、安装 leveldb</p>
<blockquote>
<p>git clone https://github.com/google/leveldb</p>
</blockquote>
<blockquote>
<p>cd leveldb</p>
</blockquote>
<blockquote>
<p>make -j</p>
</blockquote>
<blockquote>
<p>sudo cp out-shared/libleveldb.so* /usr/local/lib</p>
</blockquote>
<blockquote>
<p>sudo cp out-static/*.a /usr/local/lib</p>
</blockquote>
<blockquote>
<p>sudo cp -r include/* /usr/local/include</p>
</blockquote></li>
<li><p>编译caffe</p>
<p>1、下载源码</p>
<blockquote>
<p>cd py-faster-rcnn</p>
</blockquote>
<blockquote>
<p>git clone https://github.com/rbgirshick/caffe-fast-rcnn.git</p>
</blockquote>
<blockquote>
<p>检查文件/src/caffe/proto/caffe.proto是否与下面文件一致： <img src="https://vivounicorn.github.io/images/ai_chapter_8/caffe.proto" alt="caffe.proto-54.1kB" /></p>
</blockquote>
<p>2、修改配置</p>
<blockquote>
<p>cd caffe-fast-rcnn</p>
</blockquote>
<blockquote>
<p>cp Makefile.config.example Makefile.config</p>
</blockquote>
<blockquote>
<p>vim Makefile.config</p>
</blockquote>
<blockquote>
<p>修改它的几个地方：</p>
</blockquote>
<pre><code>  &gt; 1)、指定CUDA_DIR，如：CUDA_DIR := /usr/local/cuda

  &gt; 2)、BLAS := open

  &gt; 3)、WITH_PYTHON_LAYER := 1</code></pre>
<p>3、编译caffe-fast-rcnn</p>
<blockquote>
<p>make clean</p>
</blockquote>
<blockquote>
<p>make all -j</p>
</blockquote>
<blockquote>
<p>make test -j</p>
</blockquote>
<blockquote>
<p>make runtest -j</p>
</blockquote>
<blockquote>
<p>make pycaffe -j</p>
</blockquote>
<p>4、编译py-faster-rcnn的lib</p>
<blockquote>
<p>cd py-faster-rcnn/lib/</p>
</blockquote>
<blockquote>
<p>make</p>
</blockquote>
<p>5、配置环境变量</p>
<blockquote>
<p>vim ~/.bashrc</p>
</blockquote>
<blockquote>
<p>export PYTHONPATH=/data/liyiran/py-R-FCN/tools/python:$PYTHONPATH</p>
</blockquote>
<blockquote>
<p>source ~/.bashrc</p>
</blockquote></li>
<li><p>运行示例</p>
<p>1、下载pascal_voc数据集</p>
<blockquote>
<p>cd py-faster-rcnn/data</p>
</blockquote>
<blockquote>
<p>wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar</p>
</blockquote>
<blockquote>
<p>tar -xvf VOCtrainval_06-Nov-2007.tar</p>
</blockquote>
<blockquote>
<p>mv VOCtrainval_06-Nov-2007 VOCdevkit2007</p>
</blockquote>
<p>2、下载预训练模型</p>
<blockquote>
<p>cd py-faster-rcnn/model</p>
</blockquote>
<blockquote>
<p>wget https://dl.dropboxusercontent.com/s/gstw7122padlf0l/imagenet_models.tgz?dl=0</p>
</blockquote>
<p>3、使用VGG16，应用于pascal_voc 2007数据集</p>
<blockquote>
<p>sh experiments/scripts/faster_rcnn_end2end.sh 1 VGG16 pascal_voc</p>
</blockquote></li>
</ul>
<h2 id="r-fcn">8.7 R-FCN</h2>
<p>回想之前所有基于Region的检测算法，有一个共同点是：整个网络被分成两部分：共享计算的、与Region无关的全卷积子网络和RoI Pooling之后不共享计算的、与Region相关的子网络(如RPN和BBox Regression网络)。再回想之前所有的分类网络，尤其到残差和GoogLeNet系列，都可以看做是全卷积网络，且在分类问题上的效果已经非常赞了，但当把这些网络直接用于检测问题时，效果往往特别差，甚至不如VGG-16，原因也是明确的：分类问题往往会忽略位置信息，只需要判断是否为某个物体，所以要求提取出来的特征具有平移不变性，不管图片特征放大、缩小还是位移都能很好的适应，而卷积操作、pooling操作都能较好的保持这个性质，并且网络越深模型越对位置不敏感；但在检测问题中，提取的特征还需要能敏锐的捕捉到位置信息，即具备平移变化性，这就尴尬了。为此，大家插入类似RoI Pooling这样的层结构，一方面是的任意大小图片都可以输入，更重要的是一定程度上弥补了位置信息的缺失，所以检测效果也就嗖嗖的上来了。但带来一个副作用是：RoI后每个Region都需要跑一遍后续子网络，计算不共享就导致训练和Inference的速度慢，为此代季峰、何凯明几位提出《<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.06409.pdf">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a>》检测框架，用Position-Sensitive RoI Pooling代替原来的RoI Pooling，共享了所有计算，很好的tradeoff了平移不变性和平移变化性，并且由于是全卷积，训练和Inference的速度更快。</p>
以ResNet-101为例，图片<a target="_blank" rel="noopener" href="https://www.robots.ox.ac.uk/~vgg/rg/slides/vgg_rg_16_feb_2017_rfcn.pdf">来源</a>：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bord2chg3k91e1918ga1lb4dcb9.png" width="500"/>
</center>
<h3 id="算法概述-2">8.7.1 算法概述</h3>
<p>1、核心思想</p>
如上所述，算法核心就是position-sentitive RoI pooling的加入，核心思想是这样的：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bordnnep1lfsh8h13hdu2lo0h1m.png" width="600"/>
</center>
<p>这里的feature map是过去RoI Pooling前的全卷积特征提取子网络，之后接着的（彩色立方体）是position-sensitive feature map，它其实是一个<strong>普通的卷积层</strong>，权重通过position-sensitive RoI Pooling层反向传播时修正。假设position-sensitive feature map（后面简写为ps feature map）的大小为k×k，检测分类数为C+1（1为背景类），则ps feature map的通道数为：k×k×(C+1)，假如K=3，则每一类的 ps feature map会有k×k=9个，每个feature map含有一类位置特征（如：左上、左中、左右、......，下右，图中用不同颜色代表）；接着，通过ps RoI Pooling后，每个RoI Region在C+1的每一类上都会得到一个k×k网格，对每个网格做分类判断，之后所有网格一起投票。最终得到C+1维向量，然后接个softmax做分类。</p>
<p>2、整体结构</p>
考虑RPN子网络，整体结构是这样的：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borduslh1ghka2p1odb2o1fk323.png" width="600" />
</center>
<p>对RPN来说也是类似，每个Bounding Box候选框的位置为一类（左上角坐标、长和宽），ps feature map的通道数为k×k×4。</p>
<p>3、position-sensitive feature map</p>
<p>以ResNet-101作为基础网络结构为例，做以下结构上的更改：</p>
<ul>
<li>去掉GAP层和所有fc层</li>
<li>保留前100层，最后一个卷积层后接一个(1×1)×1024卷积层做降维</li>
</ul>
<p>为了显示编码位置信息，假如ps feature map网格大小k×k，RoI大小为：<span class="math inline">\(w×h\)</span>，则每个bin大小约为：<span class="math inline">\(\frac{w}{k} ×\frac{h}{k}\)</span>，对于第(i,j)个bin（<span class="math inline">\(0\leq i,j\leq k-1\)</span>）做ps RoI Pooling为：</p>
<p><span class="math display">\[
r_c(i,j|\Theta)=\sum_{(x,y)\in bin(i,j)}z_{i,j,c}(x+x_0,y+y_0|\Theta)/n.
\]</span></p>
<p>其中：</p>
<p><span class="math inline">\(r_c(i,j)\)</span>为第c类在第(i,j)个bin的pooling响应值；</p>
<p><span class="math inline">\(z_{i,j,c}\)</span>为是k×k×(C+1)个feature map中的一个；</p>
<p><span class="math inline">\((x_0,y_0)\)</span>为RoI的左上角坐标；</p>
<p><span class="math inline">\(n\)</span>是当前bin中的像素数；</p>
<p><span class="math inline">\(\Theta\)</span>是网络所有可学习参数；</p>
<p>x、y的取值范围为：<span class="math inline">\(\lfloor i\frac{w}{k}\rfloor \leq x \leq \lceil(i+1)\frac{w}{k}\rceil\)</span>，<span class="math inline">\(\lfloor j\frac{h}{k}\rfloor \leq y \leq \lceil(j+1)\frac{h}{k}\rceil\)</span>；</p>
<p>pooling采用average、max甚至其他自定义的操作。</p>
<p>4、损失函数定义</p>
<p>由分类部分和回归部分损失组成：</p>
<p><span class="math display">\[
L(s,t_{x,y,w,h})=L_{cls}(s_{c^*})+\lambda [c^*&gt;0]L_{reg}(t,t^*)
\]</span> 其中：</p>
<p><span class="math inline">\(c^*\)</span>是每一类的label，<span class="math inline">\(c^*=0\)</span>代表背景类；</p>
<p><span class="math inline">\(L_{cls}(s_{c^*})=-log(s_{c^*})=-log(\frac{e^{r_{c^*}(\Theta)}}{\sum_{c=0}^{C}e^{r_{c(\Theta)}}})\)</span>，是交叉熵损失函数；</p>
<p><span class="math inline">\(L_{reg}(t,t^*)=\sum_{i \in \{x,y,w,h\}}smooth_{L_1}(t-t^*)\)</span>，与Fast R-CNN的定义一致；</p>
<p><span class="math inline">\([c^*&gt;0] = \begin{cases}1&amp; \text{if }c^*&gt;0\\0&amp; \text{otherwise}\end{cases}\)</span></p>
<p>5、可视化效果</p>
预测正例：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borjgjtc16vu1od1qk619t61k8f30.png" width="600"/>
</center>
预测负例：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1borjid0t1m1qeeaj281ja31o1j3d.png" width="600" />
</center>
<h3 id="position-sentitive-roi-pooling">8.7.2 position-sentitive RoI pooling</h3>
<ul>
<li>原图及检测图</li>
</ul>
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnq3ig3p88edhnnlq17ml1ng2v.png" width="600"/>
</center>
<ul>
<li>所有分类下的位置敏感特征图
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnq32c2323o12giggg1q6ri5k9.png" width="600" />
</center></li>
</ul>
<h3 id="模型训练">8.7.3 模型训练</h3>
<p>1、训练使用<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1604.03540.pdf">Online Hard Example Mining</a></p>
<p>OHEM是一种boosting策略，目的是使得训练更加高效，简单说，它不是使用简单的抽样策略，而是对容易判断的样本做抑制，对模型不容易判断的样本重复添加。 在检测中，正样本定义为：与ground-truth的<span class="math inline">\(IoU\geq0.5\)</span>，反之为负样本，应用过程为：</p>
<ul>
<li>前向传播：所有候选框在Inference后做损失排序，选取B(一共N个)个损失最高的候选框，当然，由于临近位置的候选框的损失相近，所以还需要对其做NMS(如取IoU=0.7)，然后再选出这B个样本；</li>
<li>反向传播：仅用这B个样本做反向传播更新权重。</li>
</ul>
<p>2、训练参数</p>
<ul>
<li>权重衰减系数：0.0005</li>
<li>动量项取值：0.9</li>
<li>图像被缩放为600像素</li>
<li>每个GPU使用一张图像，选择B=128个候选框做反向传播</li>
<li>利用VOC数据做fine-tune</li>
<li>采用 Faster R-CNN的四步交替法训练</li>
</ul>
<h3 id="代码实践-6">8.7.4 代码实践</h3>
源码可在<a target="_blank" rel="noopener" href="https://github.com/YuwenXiong/py-R-FCN">py-R-FCN</a>下载，需要把下载<a target="_blank" rel="noopener" href="https://github.com/daijifeng001/caffe-rfcn">R-FCN版本caffe</a>，编译方式类似Faster RCNN，目录类似：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1bnmv6i6n181gsds1ea7r1q13v49.png" width="600"/>
</center>
<ul>
<li>PSROIPooling</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br></pre></td><td class="code"><pre><span class="line">// ------------------------------------------------------------------</span><br><span class="line">// R-FCN</span><br><span class="line">// Copyright (c) <span class="number">2016</span> Microsoft</span><br><span class="line">// Licensed under The MIT License [see r-fcn/LICENSE <span class="keyword">for</span> details]</span><br><span class="line">// Written by Yi Li</span><br><span class="line">// ------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"><span class="comment">#include &lt;cfloat&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#include &quot;caffe/rfcn_layers.hpp&quot;</span></span><br><span class="line"><span class="comment">#include &quot;caffe/util/gpu_util.cuh&quot;</span></span><br><span class="line"></span><br><span class="line">using std::<span class="built_in">max</span>;</span><br><span class="line">using std::<span class="built_in">min</span>;</span><br><span class="line"></span><br><span class="line">namespace caffe &#123;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  __global__ void PSROIPoolingForward(</span><br><span class="line">    const <span class="built_in">int</span> nthreads,			// 任务数，对应通过roi pooling后的输出feature <span class="built_in">map</span>的神经元节点总数，RoI的个数(m) × channel个数(<span class="number">21</span>类) × psroi pooling输出宽(配置为<span class="number">7</span>) × psroi pooling输出高(配置为<span class="number">7</span>) = <span class="number">1029</span>×m个</span><br><span class="line">    const Dtype* bottom_data,	// 输入的feature <span class="built_in">map</span>，原图经过各种卷积、pooling等前向传播后得到（ResNet50的rfcn_cls卷积产生的position sensitive feature <span class="built_in">map</span>，大小为：<span class="number">1029</span>×<span class="number">14</span>×<span class="number">14</span>）</span><br><span class="line">    const Dtype spatial_scale,	// 由之前所有卷积层的strides相乘得到，在rfcn中为<span class="number">1</span>/<span class="number">16</span>，注：从原图往rfcn_cls的feature <span class="built_in">map</span>上映射为缩小过程，所以乘以<span class="number">1</span>/<span class="number">16</span>，反之需要乘以<span class="number">16</span></span><br><span class="line">    const <span class="built_in">int</span> channels,			// 输入层（ResNet50为卷积层rfcn_cls）feature <span class="built_in">map</span>的channel个数(k×k×(C+<span class="number">1</span>)=<span class="number">7</span>×<span class="number">7</span>×<span class="number">21</span>=<span class="number">1029</span>)</span><br><span class="line">    const <span class="built_in">int</span> height,			// feature <span class="built_in">map</span>的宽度(<span class="number">14</span>)</span><br><span class="line">	const <span class="built_in">int</span> width,			// feature <span class="built_in">map</span>的高度(<span class="number">14</span>)</span><br><span class="line">    const <span class="built_in">int</span> pooled_height,	// psroi pooling输出feature <span class="built_in">map</span>的高，fast rcnn中配置为h=<span class="number">7</span>  </span><br><span class="line">	const <span class="built_in">int</span> pooled_width,		// psroi pooling输出feature <span class="built_in">map</span>的宽，fast rcnn中配置为w=<span class="number">7</span>  </span><br><span class="line">    const Dtype* bottom_rois,	// 输入的roi信息，存储所有rois或一个batch的rois，数据结构为[batch_ind,x1,y1,x2,y2]，包含roi的：索引、左上角坐标及右下角坐标 </span><br><span class="line">    const <span class="built_in">int</span> output_dim,		// 输出feature <span class="built_in">map</span>的维度，psroipooled_cls_rois为<span class="number">21</span>（<span class="number">21</span>个类别），psroipooled_loc_rois为<span class="number">8</span></span><br><span class="line">    const <span class="built_in">int</span> group_size,		// k=<span class="number">7</span>  </span><br><span class="line">    Dtype* top_data,			// 存储psroi pooling后得到的feature <span class="built_in">map</span></span><br><span class="line">    <span class="built_in">int</span>* mapping_channel) &#123;</span><br><span class="line">								// index为线程索引，个数为psroi pooling后的feature <span class="built_in">map</span>上所有值的个数，索引范围为：[<span class="number">0</span>,nthreads-<span class="number">1</span>]</span><br><span class="line">    CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">      // 该线程对应的top blob（N,C,H,W）中的W,输出roi pooling后feature <span class="built_in">map</span>的中的宽的坐标，即feature <span class="built_in">map</span>的第i=[<span class="number">0</span>,k-<span class="number">1</span>]列  </span><br><span class="line">      <span class="built_in">int</span> pw = index % pooled_width;</span><br><span class="line">	  // 该线程对应的top blob（N,C,H,W）中的H,输出roi pooling后feature <span class="built_in">map</span>的中的高的坐标，即feature <span class="built_in">map</span>的第j=[<span class="number">0</span>,k-<span class="number">1</span>]行 </span><br><span class="line">      <span class="built_in">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">	  // 该线程对应的top blob（N,C,H,W）中的C,即第c个channel，channel数最大值为<span class="number">21</span>（包含背景类的类别数）</span><br><span class="line">      <span class="built_in">int</span> ctop = (index / pooled_width / pooled_height) % output_dim;</span><br><span class="line">	  // 该线程对应的是第几个RoI,一共m个.</span><br><span class="line">      <span class="built_in">int</span> n = index / pooled_width / pooled_height / output_dim;</span><br><span class="line"></span><br><span class="line">      // [start, end)，指定RoI信息的存储范围，指针每次移动<span class="number">5</span>的倍数是因为包含信息的数据结构大小为<span class="number">5</span>，包含信息为：[batch_ind,x1,y1,x2,y2]，含义同上</span><br><span class="line">      bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">	  // 将每个原图的RoI区域映射到feature <span class="built_in">map</span>(VGG16为conv5_3产生的feature mao)上的坐标,bottom_rois第<span class="number">0</span>个位置存放的是roi索引.</span><br><span class="line">      <span class="built_in">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">	  // 原图到feature <span class="built_in">map</span>的映射为乘以<span class="number">1</span>/<span class="number">16</span>，这里采用粗映射而不是上文讲的精确映射，原因你懂的.</span><br><span class="line">      Dtype roi_start_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">1</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_start_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">2</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_end_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">3</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line">      Dtype roi_end_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">4</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line"></span><br><span class="line">      // 强制把RoI的宽和高限制在1x1，防止出现映射后的RoI大小为<span class="number">0</span>的情况</span><br><span class="line">      Dtype roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w, <span class="number">0.1</span>); </span><br><span class="line">      Dtype roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line">      // 根据原图映射得到的roi的高和配置的psroi pooling的高(这里大小配置为<span class="number">7</span>)自适应计算<span class="built_in">bin</span>桶的高度</span><br><span class="line">      Dtype bin_size_h = roi_height / static_cast&lt;Dtype&gt;(pooled_height);</span><br><span class="line">	  // 根据原图映射得到的roi的宽和配置的psroi pooling的宽(这里大小配置为<span class="number">7</span>)自适应计算<span class="built_in">bin</span>桶的宽度</span><br><span class="line">      Dtype bin_size_w = roi_width / static_cast&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">	  // 计算第(i,j)个<span class="built_in">bin</span>桶在feature <span class="built_in">map</span>上的坐标范围，需要依据它们确定后续pooling的范围</span><br><span class="line">      <span class="built_in">int</span> hstart = floor(static_cast&lt;Dtype&gt;(ph) * bin_size_h</span><br><span class="line">                          + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wstart = floor(static_cast&lt;Dtype&gt;(pw)* bin_size_w</span><br><span class="line">                          + roi_start_w);</span><br><span class="line">      <span class="built_in">int</span> hend = ceil(static_cast&lt;Dtype&gt;(ph + <span class="number">1</span>) * bin_size_h</span><br><span class="line">                        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wend = ceil(static_cast&lt;Dtype&gt;(pw + <span class="number">1</span>) * bin_size_w</span><br><span class="line">                        + roi_start_w);</span><br><span class="line">      // 确定<span class="built_in">max</span> pooling具体范围，注意由于RoI取自原图，其左上角不是从(<span class="number">0</span>,<span class="number">0</span>)开始，</span><br><span class="line">	  // 所以需要加上 roi_start_h 或 roi_start_w作为偏移量，并且超出feature <span class="built_in">map</span>尺寸范围的部分会被舍弃  </span><br><span class="line">      hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart, <span class="number">0</span>), height);</span><br><span class="line">      hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend, <span class="number">0</span>), height);</span><br><span class="line">      wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart, <span class="number">0</span>),width);</span><br><span class="line">      wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend, <span class="number">0</span>), width);</span><br><span class="line">      <span class="built_in">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line"></span><br><span class="line">      <span class="built_in">int</span> gw = pw;</span><br><span class="line">      <span class="built_in">int</span> gh = ph;</span><br><span class="line">	  // 计算第C类的(ph,pw)位置索引 = ctop×group_size×group_size + gh×gh×group_size + gw</span><br><span class="line">      // 例如: ps feature <span class="built_in">map</span>上第C[=<span class="number">1</span>]类的第(i,j)[=(<span class="number">1</span>,<span class="number">1</span>)]位置，c=<span class="number">1</span>×<span class="number">7</span>×<span class="number">7</span> + <span class="number">1</span>×<span class="number">1</span>×<span class="number">7</span>+<span class="number">1</span>=<span class="number">57</span></span><br><span class="line">      <span class="built_in">int</span> c = (ctop*group_size + gh)*group_size + gw;</span><br><span class="line">	   </span><br><span class="line">	  // 逐层做average pooling</span><br><span class="line">      bottom_data += (roi_batch_ind * channels + c) * height * width;</span><br><span class="line">      Dtype out_sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="built_in">int</span> h = hstart; h &lt; hend; ++h)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> w = wstart; w &lt; wend; ++w)&#123;</span><br><span class="line">          <span class="built_in">int</span> bottom_index = h*width + w;</span><br><span class="line">          out_sum += bottom_data[bottom_index];</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">	  // 计算第(i,j)<span class="built_in">bin</span>桶在feature <span class="built_in">map</span>上的面积  </span><br><span class="line">      Dtype bin_area = (hend - hstart)*(wend - wstart);</span><br><span class="line">	  // 若第(i,j)<span class="built_in">bin</span>桶宽高非法则设置为<span class="number">0</span>，否则为平均值 </span><br><span class="line">      top_data[index] = is_empty? <span class="number">0.</span> : out_sum/bin_area;</span><br><span class="line">	  // 记录此次迭代计算ps feature <span class="built_in">map</span>上的索引位置  </span><br><span class="line">      mapping_channel[index] = c;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  void PSROIPoolingLayer&lt;Dtype&gt;::Forward_gpu(</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,		// 以ResNet50为例，bottom[<span class="number">0</span>]为最后一个卷积层rfcn_cls产生的feature <span class="built_in">map</span>，shape[<span class="number">1</span>, <span class="number">1029</span>, <span class="number">14</span>, <span class="number">14</span>],</span><br><span class="line">	                                            //                 bottom[<span class="number">1</span>]为rois数据，shape[roi个数m, <span class="number">5</span>]</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) &#123;		// top为输出层结构， top-&gt;count() = top.n（RoI的个数) × top.channel(channel数) </span><br><span class="line">												//                               × top.w(输出feature <span class="built_in">map</span>的宽) × top.h(输出feature <span class="built_in">map</span>的高)</span><br><span class="line">    const Dtype* bottom_data = bottom[<span class="number">0</span>]-&gt;gpu_data();</span><br><span class="line">    const Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();</span><br><span class="line">    Dtype* top_data = top[<span class="number">0</span>]-&gt;mutable_gpu_data();</span><br><span class="line">    <span class="built_in">int</span>* mapping_channel_ptr = mapping_channel_.mutable_gpu_data();</span><br><span class="line">    <span class="built_in">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">    caffe_gpu_set(count, Dtype(<span class="number">0</span>), top_data);</span><br><span class="line">    caffe_gpu_set(count, -<span class="number">1</span>, mapping_channel_ptr);</span><br><span class="line">    // NOLINT_NEXT_LINE(whitespace/operators)</span><br><span class="line">    PSROIPoolingForward&lt;Dtype&gt; &lt;&lt; &lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS &gt;&gt; &gt;(</span><br><span class="line">      count, bottom_data, spatial_scale_, channels_, height_, width_, pooled_height_,</span><br><span class="line">      pooled_width_, bottom_rois, output_dim_, group_size_, top_data, mapping_channel_ptr);</span><br><span class="line">    CUDA_POST_KERNEL_CHECK;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  __global__ void PSROIPoolingBackwardAtomic(</span><br><span class="line">    const <span class="built_in">int</span> nthreads,						// 输入feature <span class="built_in">map</span>的元素数</span><br><span class="line">    const Dtype* top_diff,					// psroi pooling输出feature <span class="built_in">map</span>所带的梯度信息∂L/∂y(r,j)	</span><br><span class="line">    const <span class="built_in">int</span>* mapping_channel,				// 同前向，不解释		</span><br><span class="line">    const <span class="built_in">int</span> num_rois,						// 同前向，不解释</span><br><span class="line">    const Dtype spatial_scale,				// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> channels,						// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> height,						// 同前向，不解释</span><br><span class="line">	const <span class="built_in">int</span> width,						// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> pooled_height,				// 同前向，不解释</span><br><span class="line">	const <span class="built_in">int</span> pooled_width,					// 同前向，不解释</span><br><span class="line">    const <span class="built_in">int</span> output_dim,					// 同前向，不解释</span><br><span class="line">    Dtype* bottom_diff,						// 保留输入feature <span class="built_in">map</span>每个元素通过梯度反向传播得到的梯度信息</span><br><span class="line">    const Dtype* bottom_rois) &#123;				// 同前向，不解释</span><br><span class="line">	// 含义同前向，需要注意的是这里表示的是输入feature <span class="built_in">map</span>的元素数(反向传播嘛)</span><br><span class="line">    CUDA_KERNEL_LOOP(index, nthreads) &#123;</span><br><span class="line">      // 同前向，不解释</span><br><span class="line">      <span class="built_in">int</span> pw = index % pooled_width;</span><br><span class="line">      <span class="built_in">int</span> ph = (index / pooled_width) % pooled_height;</span><br><span class="line">      <span class="built_in">int</span> n = index / pooled_width / pooled_height / output_dim;</span><br><span class="line"></span><br><span class="line">      // 找原图RoI在feature <span class="built_in">map</span>上的映射位置，解释同前向传播</span><br><span class="line">      bottom_rois += n * <span class="number">5</span>;</span><br><span class="line">      <span class="built_in">int</span> roi_batch_ind = bottom_rois[<span class="number">0</span>];</span><br><span class="line">      Dtype roi_start_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">1</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_start_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">2</span>])) * spatial_scale;</span><br><span class="line">      Dtype roi_end_w = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">3</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line">      Dtype roi_end_h = static_cast&lt;Dtype&gt;(<span class="built_in">round</span>(bottom_rois[<span class="number">4</span>]) + <span class="number">1.</span>) * spatial_scale;</span><br><span class="line"></span><br><span class="line">      // 同前向</span><br><span class="line">      Dtype roi_width = <span class="built_in">max</span>(roi_end_w - roi_start_w, <span class="number">0.1</span>); //avoid <span class="number">0</span></span><br><span class="line">      Dtype roi_height = <span class="built_in">max</span>(roi_end_h - roi_start_h, <span class="number">0.1</span>);</span><br><span class="line"></span><br><span class="line">      // 同前向</span><br><span class="line">      Dtype bin_size_h = roi_height / static_cast&lt;Dtype&gt;(pooled_height);</span><br><span class="line">      Dtype bin_size_w = roi_width / static_cast&lt;Dtype&gt;(pooled_width);</span><br><span class="line"></span><br><span class="line">      <span class="built_in">int</span> hstart = floor(static_cast&lt;Dtype&gt;(ph)* bin_size_h</span><br><span class="line">        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wstart = floor(static_cast&lt;Dtype&gt;(pw)* bin_size_w</span><br><span class="line">        + roi_start_w);</span><br><span class="line">      <span class="built_in">int</span> hend = ceil(static_cast&lt;Dtype&gt;(ph + <span class="number">1</span>) * bin_size_h</span><br><span class="line">        + roi_start_h);</span><br><span class="line">      <span class="built_in">int</span> wend = ceil(static_cast&lt;Dtype&gt;(pw + <span class="number">1</span>) * bin_size_w</span><br><span class="line">        + roi_start_w);</span><br><span class="line">      // 同前向</span><br><span class="line">      hstart = <span class="built_in">min</span>(<span class="built_in">max</span>(hstart, <span class="number">0</span>), height);</span><br><span class="line">      hend = <span class="built_in">min</span>(<span class="built_in">max</span>(hend, <span class="number">0</span>), height);</span><br><span class="line">      wstart = <span class="built_in">min</span>(<span class="built_in">max</span>(wstart, <span class="number">0</span>), width);</span><br><span class="line">      wend = <span class="built_in">min</span>(<span class="built_in">max</span>(wend, <span class="number">0</span>), width);</span><br><span class="line">      <span class="built_in">bool</span> is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);</span><br><span class="line"></span><br><span class="line">      // 计算第C类ps feature <span class="built_in">map</span>权重值，梯度信息会被平均分配</span><br><span class="line">      <span class="built_in">int</span> c = mapping_channel[index];</span><br><span class="line">      Dtype* offset_bottom_diff = bottom_diff + (roi_batch_ind * channels + c) * height * width;</span><br><span class="line">      Dtype bin_area = (hend - hstart)*(wend - wstart);</span><br><span class="line">      Dtype diff_val = is_empty ? <span class="number">0.</span> : top_diff[index] / bin_area;</span><br><span class="line">      <span class="keyword">for</span> (<span class="built_in">int</span> h = hstart; h &lt; hend; ++h)&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> w = wstart; w &lt; wend; ++w)&#123;</span><br><span class="line">          <span class="built_in">int</span> bottom_index = h*width + w;</span><br><span class="line">          caffe_gpu_atomic_add(diff_val, offset_bottom_diff + bottom_index);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  template &lt;typename Dtype&gt;</span><br><span class="line">  void PSROIPoolingLayer&lt;Dtype&gt;::Backward_gpu(</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,			// psroi pooling输出feature <span class="built_in">map</span></span><br><span class="line">	  const vector&lt;<span class="built_in">bool</span>&gt;&amp; propagate_down,		// 是否做反向传播，回忆前向传播时的那个<span class="built_in">bool</span>值</span><br><span class="line">	  const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) &#123;		// psroi pooling输入feature <span class="built_in">map</span>(ResNet中的rfcn_cls产生的feature <span class="built_in">map</span>)</span><br><span class="line">    <span class="keyword">if</span> (!propagate_down[<span class="number">0</span>]) &#123;</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    const Dtype* bottom_rois = bottom[<span class="number">1</span>]-&gt;gpu_data();	// 原始RoI信息</span><br><span class="line">    const Dtype* top_diff = top[<span class="number">0</span>]-&gt;gpu_diff();			// psroi pooling feature <span class="built_in">map</span>梯度信息</span><br><span class="line">    Dtype* bottom_diff = bottom[<span class="number">0</span>]-&gt;mutable_gpu_diff();	// 待写入的输入feature <span class="built_in">map</span>梯度信息</span><br><span class="line">    const <span class="built_in">int</span> bottom_count = bottom[<span class="number">0</span>]-&gt;count();		// 输入feature <span class="built_in">map</span>元素总数</span><br><span class="line">    const <span class="built_in">int</span>* mapping_channel_ptr = mapping_channel_.gpu_data();</span><br><span class="line">    caffe_gpu_set(bottom[<span class="number">1</span>]-&gt;count(), Dtype(<span class="number">0</span>), bottom[<span class="number">1</span>]-&gt;mutable_gpu_diff());</span><br><span class="line">    caffe_gpu_set(bottom_count, Dtype(<span class="number">0</span>), bottom_diff);</span><br><span class="line">    const <span class="built_in">int</span> count = top[<span class="number">0</span>]-&gt;count();</span><br><span class="line">    // NOLINT_NEXT_LINE(whitespace/operators)</span><br><span class="line">    PSROIPoolingBackwardAtomic&lt;Dtype&gt; &lt;&lt; &lt;CAFFE_GET_BLOCKS(count), CAFFE_CUDA_NUM_THREADS &gt;&gt; &gt;(</span><br><span class="line">      count, top_diff, mapping_channel_ptr, top[<span class="number">0</span>]-&gt;num(), spatial_scale_,</span><br><span class="line">      channels_, height_, width_, pooled_height_, pooled_width_, output_dim_,</span><br><span class="line">      bottom_diff, bottom_rois);</span><br><span class="line">    CUDA_POST_KERNEL_CHECK;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  INSTANTIATE_LAYER_GPU_FUNCS(PSROIPoolingLayer);</span><br><span class="line"></span><br><span class="line">&#125;  // namespace caffe</span><br></pre></td></tr></table></figure>
<ul>
<li>PS feature map可视化</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*- 2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Demo script showing detections in sample images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">See README.md for installation instructions before running.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;Agg&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> _init_paths</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.config <span class="keyword">import</span> cfg</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.test <span class="keyword">import</span> im_detect</span><br><span class="line"><span class="keyword">from</span> fast_rcnn.nms_wrapper <span class="keyword">import</span> nms</span><br><span class="line"><span class="keyword">from</span> utils.timer <span class="keyword">import</span> Timer</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> caffe, os, sys, cv2</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">CLASSES = (<span class="string">&#x27;__background__&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;pottedplant&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tvmonitor&#x27;</span>)</span><br><span class="line"></span><br><span class="line">NETS = &#123;<span class="string">&#x27;ResNet-101&#x27;</span>: (<span class="string">&#x27;ResNet-101&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;resnet101_rfcn_final.caffemodel&#x27;</span>),</span><br><span class="line">        <span class="string">&#x27;ResNet-50&#x27;</span>: (<span class="string">&#x27;ResNet-50&#x27;</span>,</span><br><span class="line">                  <span class="string">&#x27;resnet50_rfcn_final.caffemodel&#x27;</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parse input arguments.&quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;Faster R-CNN demo&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gpu&#x27;</span>, dest=<span class="string">&#x27;gpu_id&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;GPU device id to use [0]&#x27;</span>,</span><br><span class="line">                        default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cpu&#x27;</span>, dest=<span class="string">&#x27;cpu_mode&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Use CPU mode (overrides --gpu)&#x27;</span>,</span><br><span class="line">                        action=<span class="string">&#x27;store_true&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--net&#x27;</span>, dest=<span class="string">&#x27;demo_net&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Network to use [ResNet-101]&#x27;</span>,</span><br><span class="line">                        choices=NETS.keys(), default=<span class="string">&#x27;ResNet-101&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span>(<span class="params">data, i</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Take an array of shape (n, height, width) or (n, height, width, 3)</span></span><br><span class="line"><span class="string">       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># normalize data for display</span></span><br><span class="line">    data = (data - data.<span class="built_in">min</span>()) / (data.<span class="built_in">max</span>() - data.<span class="built_in">min</span>())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># force the number of filters to be square</span></span><br><span class="line">    n = <span class="built_in">int</span>(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</span><br><span class="line">    padding = (((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]),</span><br><span class="line">               (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>))                 <span class="comment"># add some space between filters</span></span><br><span class="line">               + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>))  <span class="comment"># don&#x27;t pad the last dimension (if there is one)</span></span><br><span class="line">    data = np.pad(data, padding, mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">1</span>)  <span class="comment"># pad with ones (white)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># tile the filters into an image</span></span><br><span class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</span><br><span class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</span><br><span class="line">   </span><br><span class="line">    plt.imshow(data); plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;feature-&#x27;</span> + <span class="built_in">str</span>(i) + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_demo</span>(<span class="params">net, image_name</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;可视化位置敏感特征图.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Load the demo image</span></span><br><span class="line">    im_file = os.path.join(cfg.DATA_DIR, <span class="string">&#x27;demo&#x27;</span>, image_name)</span><br><span class="line">    im = cv2.imread(im_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Detect all object classes and regress object bounds</span></span><br><span class="line">    timer = Timer()</span><br><span class="line">    timer.tic()</span><br><span class="line">    scores, boxes = im_detect(net, im)</span><br><span class="line">    timer.toc()</span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Detection took &#123;:.3f&#125;s for &#x27;</span></span><br><span class="line">           <span class="string">&#x27;&#123;:d&#125; object proposals&#x27;</span>).<span class="built_in">format</span>(timer.total_time, boxes.shape[<span class="number">0</span>])</span><br><span class="line">    conv = net.blobs[<span class="string">&#x27;data&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">    ave = np.average(conv.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>), axis=<span class="number">2</span>)</span><br><span class="line">    plt.imshow(ave); plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.savefig(<span class="string">&#x27;featurex.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Visualize detections for each class</span></span><br><span class="line">    CONF_THRESH = <span class="number">0.8</span></span><br><span class="line">    NMS_THRESH = <span class="number">0.3</span></span><br><span class="line">    <span class="keyword">for</span> cls_ind, cls <span class="keyword">in</span> <span class="built_in">enumerate</span>(CLASSES[<span class="number">1</span>:]):</span><br><span class="line">        cls_ind += <span class="number">1</span> <span class="comment"># because we skipped background</span></span><br><span class="line">        cls_boxes = boxes[:, <span class="number">4</span>:<span class="number">8</span>]</span><br><span class="line">        cls_scores = scores[:, cls_ind]</span><br><span class="line">        dets = np.hstack((cls_boxes,</span><br><span class="line">                          cls_scores[:, np.newaxis])).astype(np.float32)</span><br><span class="line">        keep = nms(dets, NMS_THRESH)</span><br><span class="line">        dets = dets[keep, :]</span><br><span class="line">        <span class="built_in">print</span> cls_ind, <span class="string">&#x27; &#x27;</span>, cls</span><br><span class="line">        <span class="comment"># rfcn_cls[0, 0:49] 是第0类的7×7map，rfcn_cls[0, 49:98] 是第1类的7×7map，以此类推。</span></span><br><span class="line">        feat = net.blobs[<span class="string">&#x27;rfcn_cls&#x27;</span>].data[<span class="number">0</span>, cls_ind*<span class="number">49</span>:(cls_ind+<span class="number">1</span>)*<span class="number">49</span>]</span><br><span class="line">        vis_square(feat, cls)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    cfg.TEST.HAS_RPN = <span class="literal">True</span>  <span class="comment"># Use RPN for proposals</span></span><br><span class="line"></span><br><span class="line">    args = parse_args()</span><br><span class="line"></span><br><span class="line">    prototxt = os.path.join(cfg.MODELS_DIR, NETS[args.demo_net][<span class="number">0</span>],</span><br><span class="line">                            <span class="string">&#x27;rfcn_end2end&#x27;</span>, <span class="string">&#x27;test_agnostic.prototxt&#x27;</span>)</span><br><span class="line">    caffemodel = os.path.join(cfg.DATA_DIR, <span class="string">&#x27;rfcn_models&#x27;</span>,</span><br><span class="line">                              NETS[args.demo_net][<span class="number">33</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(caffemodel):</span><br><span class="line">        <span class="keyword">raise</span> IOError((<span class="string">&#x27;&#123;:s&#125; not found.\n&#x27;</span>).<span class="built_in">format</span>(caffemodel))</span><br><span class="line">    <span class="keyword">if</span> args.cpu_mode:</span><br><span class="line">        caffe.set_mode_cpu()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        caffe.set_mode_gpu()</span><br><span class="line">        caffe.set_device(args.gpu_id)</span><br><span class="line">        cfg.GPU_ID = args.gpu_id</span><br><span class="line">    net = caffe.Net(prototxt, caffemodel, caffe.TEST)</span><br><span class="line">    <span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">        <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(blob.data.shape)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n\nLoaded network &#123;:s&#125;&#x27;</span>.<span class="built_in">format</span>(caffemodel)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Warmup on a dummy image</span></span><br><span class="line">    im = <span class="number">128</span> * np.ones((<span class="number">300</span>, <span class="number">500</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">2</span>):</span><br><span class="line">        _, _= im_detect(net, im)</span><br><span class="line">    im_names = [<span class="string">&#x27;car.jpg&#x27;</span>]</span><br><span class="line">    <span class="keyword">for</span> im_name <span class="keyword">in</span> im_names:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~&#x27;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Demo for data/demo/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(im_name)</span><br><span class="line">        vis_demo(net, im_name)</span><br><span class="line">    <span class="comment"># obtain the output probabilities</span></span><br><span class="line">    output_prob = net.blobs[<span class="string">&#x27;cls_prob&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;probabilities:&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> output_prob</span><br></pre></td></tr></table></figure>
<h2 id="densenet">8.8 DenseNet</h2>
<h3 id="关于神经网络的深度">8.8.1 关于神经网络的深度</h3>
<p>理论上，当我们有足够大量的数据，能够完全体现当前问题的数据分布的时候，我们仅需要一个简单线性模型或最多用个有单隐层的RBF神经网络就可以完美建模。但实际情况是没有那么多数据，那就自然需要一个高复杂度的模型来拟合样本，但如果模型复杂度过高而样本数没有与其达到某种关系，又会造成其泛化性低下，所谓过拟合的问题。实际上，假设未来做testing的数据分布和training的数据分布是一致的，一个有<span class="math inline">\(N\)</span>个神经网络节点、<span class="math inline">\(W\)</span>个权重、线性阈值函数的前馈神经网络在泛化误差<span class="math inline">\(0&lt;\epsilon \le0.125\)</span>的前提下，训练数据规模的下界是：<span class="math inline">\(m\ge O(\frac{W}{\epsilon}log\frac{N}{\epsilon})\)</span>，详情可见论文《<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/154-what-size-net-gives-valid-generalization.pdf">What Size Net Gives Valid Generalization</a>》。</p>
<p>网络的深度则反映了模型的复杂度，深度直接决定了层数而间接影响了节点数和权重数，网络深度的增加意味着能得到更多的抽象特征，但原始输入信号和梯度信息会随着网络深度的增加而消失或无用，所以这又是一个折中权衡，像之前讲的Highway Network、ResNet及其衍生等等模型的思路是通过一个short path的连接让前一层的信号能够传递到后一层，我认为这个思路是开创性的。</p>
<h3 id="densenet思路">8.8.2 DenseNet思路</h3>
《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1608.06993">Densely Connected Convolutional Networks</a>》（CVPR 2017的最佳论文之一）提出的DenseNet则把ResNet的思路做的更加彻底：在一个Dense Block中，任意一个当前层都会与其后面的所有层直接连接，如图：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9b0b69pfu15spn1q1r8e3ug9.png" width="500" />
</center>
<p>假如包括当前层在内后面还有<span class="math inline">\(L\)</span>层，那么从当前层往后产生的直接连接数为：<span class="math inline">\(\frac{L(L+1)}{2}\)</span>。</p>
<p>回顾之前对ResNet的分析以及《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1603.09382">Deep Networks with Stochastic Depth</a>》这篇论文的实验，可以得到以下信息：</p>
<pre><code> 神经网络不一定非得是逐层递进的，任意一层可以接收它前面任意一层的输入而扔掉它前面的其它层，也就是说当前层feature map的提取可以只依赖更前面层的feature map；
 传统前馈神经网络架构可以被看做是有个状态维护机制，在层与层之间传递这个状态，后一层在接收前一层的状态后又加入自己的信息，修改状态后传给下一层；
 ResNet网络在路径选择的思想下展开（见ResNet一章的分析）后，其实也说明它有一定的冗余性，适当的随机Dropout一些层相当于扔掉了一些路径，实际实验看还会提高网络Inference的泛化性。</code></pre>
<p>基于以上认知，作者设计了DenseNet：让每一层都与后面所有层直接连接，达到特征复用的目的；同时这些连接也可以看做网络的全局状态，大家共同维护，不用传来传去；降低每一层feature map数，让网络结构变“窄”，达到去除冗余的目的。</p>
<p>与ResNet比较：</p>
<ul>
<li><p>ResNet采用按照向量每个维度的Element-wise做加和的方式处理连接，而DenseNet采用按照每个通道的Channel-wise做直接向量拼接的方式处理连接。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9idtee10si1p1d1gvm1djp1uikm.png" width="800"/></p>
</center>
<p><strong>PS：注意图中C操作符的位置</strong></p>
<p>DenseNet的前向传播过程可以像这样展开：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9ksjj1pmb1sa6cm92lv1pga52.png" width="800"/></p>
</center>
<p>每一层的输入都包含所有前面层的feature map。</p>
<p>形式化的对比如下：</p>
<p>ResNet：第<span class="math inline">\(l\)</span>层的输出是<span class="math inline">\(x_l=H_l(x_{l-1})+x_{l-1}\)</span></p>
<p>DenseNet：第<span class="math inline">\(l\)</span>层的输出是<span class="math inline">\(x_l=H_l([x_0,x_1,...,x_{l-1}])\)</span></p>
<p>其中：<span class="math inline">\([]\)</span>为向量拼接操作，<span class="math inline">\(H_l\)</span>是一个复合函数，文中是batch normalization (BN)+rectified linear unit (ReLU)+3×3 convolution (Conv)的复合——BN(ReLU(Conv(x)))。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9l3s1j1ogm198q14ed1oc116fo5f.png" width="600" /></p>
</center></li>
<li><p>dense blocks与transition layer DenseNet的拼接操作要求保证feature map大小具有一致性，但由于pooling下采样操作的存在一定会改变feature map的，所以作者用dense blocks+transition layers的方式解决问题：</p>
<p>1、dense blocks内部feature map大小都一致，借鉴Inception结构，利用bottleneck中的1×1卷积降低通道数，即<strong>BN+ReLU+Conv(1x1)+BN+ReLU+Conv(3x3)</strong>操作；</p>
<p>2、dense blocks之间增加transition layer，同样借鉴Inception结构，利用1×1卷积降低通道数，即<strong>BN+ReLU+Conv(1×1)+AvgPooling(2x2)</strong>操作：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9m0fcunr3ou4143msh6160h5s.png" width="800" /></p>
</center>
<p>transition layer可以起到压缩模型的作用：假设dense block有<span class="math inline">\(m\)</span>个feature map，我们让紧接着的transition layer产生<span class="math inline">\(\lfloor \theta m\rfloor\)</span>，这里<span class="math inline">\(0&lt;\theta\le1\)</span>为压缩系数。</p>
<p>宏观来看，整个DenseNet如下：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9mgbktmq3qm6tt17bd1g746p.png" width="800" /></p>
</center></li>
<li><p>利用Growth Rate和复合函数，DenseNet可以做的很“窄”：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/k-growth.png" width="600" /></p>
</center>
<p>假设每个<span class="math inline">\(H_l\)</span>复合函数产生<span class="math inline">\(k\)</span>个feature map，那么第<span class="math inline">\(l\)</span>层的输入feature map数为：<span class="math inline">\(k_0+k\times(l-1)\)</span> ，可见越往后的dense block输入feature map越多，当然由于全局feature map的存在，每层只有 <span class="math inline">\(k\)</span> 个feature map是独有的，其余的都共享。 显然，“窄”的好处是参数少、计算效率高，比较如下：</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9ne9qt9661umllgh1pif1rgc76.png" width="800"/></p>
</center></li>
<li><p>DenseNet结构使得特征更加具有多样性 显然，由于从高到低引入了不同复杂度的特征，使得最终做预测的特征具有很强的多样性，提高模型的泛化性和鲁棒性。</p>
<center>
<p><img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ck9q7n3n1mrnnh555lvddl087j.png" width="800"/></p>
</center></li>
</ul>
<h3 id="代码实践-7">8.8.3 代码实践</h3>
看一个基于keras的简单例子，比较好重现了DenseNet的构建，看的时候对照着DenseNet的前向展开图更好理解原理： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-  </span></span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input, merge, Activation, Dropout, Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers.convolutional <span class="keyword">import</span> Convolution2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.pooling <span class="keyword">import</span> AveragePooling2D, GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> ModelCheckpoint</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment">#增加一层并使用复合函数BN+ReLU+Conv(3x3)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span>(<span class="params">x, nb_channels, kernel_size=<span class="number">3</span>, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    out = BatchNormalization(gamma_regularizer=l2(l2_reg),</span><br><span class="line">                             beta_regularizer=l2(l2_reg))(x)</span><br><span class="line">    out = Activation(<span class="string">&#x27;relu&#x27;</span>)(out)</span><br><span class="line">    out = Convolution2D(nb_channels, kernel_size, kernel_size,</span><br><span class="line">                        border_mode=<span class="string">&#x27;same&#x27;</span>, init=<span class="string">&#x27;he_normal&#x27;</span>,</span><br><span class="line">                        W_regularizer=l2(l2_reg), bias=<span class="literal">False</span>)(out)</span><br><span class="line">    <span class="keyword">if</span> dropout &gt; <span class="number">0</span>:</span><br><span class="line">        out = Dropout(dropout)(out)</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定层数和增长率，增加一个dense block</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dense_block</span>(<span class="params">x, nb_layers, growth_rate, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_layers):</span><br><span class="line">        <span class="comment"># Get layer output</span></span><br><span class="line">        out = add_layer(x, growth_rate, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">        <span class="keyword">if</span> K.image_dim_ordering() == <span class="string">&#x27;tf&#x27;</span>:</span><br><span class="line">            merge_axis = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">elif</span> K.image_dim_ordering() == <span class="string">&#x27;th&#x27;</span>:</span><br><span class="line">            merge_axis = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&#x27;Invalid dim_ordering: &#x27;</span> + K.image_dim_ordering())</span><br><span class="line">        <span class="comment"># Concatenate input with layer ouput</span></span><br><span class="line">        x = merge([x, out], mode=<span class="string">&#x27;concat&#x27;</span>, concat_axis=merge_axis)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#增加一个transition layer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transition_block</span>(<span class="params">x, nb_channels, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span></span>):</span></span><br><span class="line">    x = add_layer(x, nb_channels, kernel_size=<span class="number">1</span>, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">    x = AveragePooling2D()(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment">#指定dense block数量、层数、增长率，构建DenseNet</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">densenet_model</span>(<span class="params">nb_blocks, nb_layers, growth_rate, dropout=<span class="number">0.</span>, l2_reg=<span class="number">1e-4</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                   init_channels=<span class="number">16</span></span>):</span></span><br><span class="line">    n_channels = init_channels</span><br><span class="line">    inputs = Input(shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">    x = Convolution2D(init_channels, <span class="number">3</span>, <span class="number">3</span>, border_mode=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                      init=<span class="string">&#x27;he_normal&#x27;</span>, W_regularizer=l2(l2_reg),</span><br><span class="line">                      bias=<span class="literal">False</span>)(inputs)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_blocks - <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># Create a dense block</span></span><br><span class="line">        x = dense_block(x, nb_layers, growth_rate,</span><br><span class="line">                        dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">        <span class="comment"># Update the number of channels</span></span><br><span class="line">        n_channels += nb_layers*growth_rate</span><br><span class="line">        <span class="comment"># Transition layer</span></span><br><span class="line">        x = transition_block(x, n_channels, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add last dense_block</span></span><br><span class="line">    x = dense_block(x, nb_layers, growth_rate, dropout=dropout, l2_reg=l2_reg)</span><br><span class="line">    <span class="comment"># Add final BN-Relu</span></span><br><span class="line">    x = BatchNormalization(gamma_regularizer=l2(l2_reg),</span><br><span class="line">                             beta_regularizer=l2(l2_reg))(x)</span><br><span class="line">    x = Activation(<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">    <span class="comment"># Global average pooling</span></span><br><span class="line">    x = GlobalAveragePooling2D()(x)</span><br><span class="line">    x = Dense(<span class="number">10</span>, W_regularizer=l2(l2_reg))(x)</span><br><span class="line">    x = Activation(<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line">    model = Model(<span class="built_in">input</span>=inputs, output=x)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#1个dense block，里面共2层，feature map数为3</span></span><br><span class="line">    model = densenet_model(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line">    plot_model(model, to_file=<span class="string">&quot;DenseNet.jpg&quot;</span>, show_shapes=<span class="literal">True</span>) </span><br></pre></td></tr></table></figure> 生成网络结构为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ckcktrsoqnj16k0103c1o78vbi80.png" width="600"/>
</center>
对应的前向展开为：
<center>
<img src="https://vivounicorn.github.io/images/ai_chapter_8/image_1ckckvl6c1jofn1i10ji1666cr58d.png" width="500" />
</center>
<h2 id="mask-r-cnn">8.9 Mask R-CNN</h2>
<p>Mask R-CNN是在《Mask R-CNN》一文中提出，可以看做是Faster R-CNN的升级加强版，结构上也可以理解为：Faster R-CNN+FCN。它是一个通用的检测、识别、语义分割、实例分割的框架，看本章内容前建议先回顾下Faster R-CNN和FCN的内容。</p>
<h2 id="yolo">8.10 YOLO</h2>
<h2 id="ssd">8.11 SSD</h2>
<h2 id="yolo-9000">8.12 YOLO 9000</h2>
<h1 id="references">References</h1>
<p>如有遗漏请提醒我补充：</p>
<p align="left">
1、《Understanding the Bias-Variance Tradeoff》http://scott.fortmann-roe.com/docs/BiasVariance.html
</p>
<p align="left">
2、《Boosting Algorithms as Gradient Descent in Function Space》http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.51.6893&amp;rep=rep1&amp;type=pdf
</p>
<p align="left">
3、《Optimal Action Extraction for Random Forests and Boosted Trees》http://www.cse.wustl.edu/~ychen/public/OAE.pdf
</p>
<p align="left">
4、《Applying Neural Network Ensemble Concepts for Modelling Project Success》http://www.iaarc.org/publications/fulltext/Applying_Neural_Network_Ensemble_Concepts_for_Modelling_Project_Success.pdf
</p>
<p align="left">
5、《Introduction to Boosted Trees》https://homes.cs.washington.edu/~tqchen/data/pdf/BoostedTree.pdf
</p>
<p align="left">
6、《Machine Learning:Perceptrons》http://ml.informatik.uni-freiburg.de/_media/documents/teaching/ss09/ml/perceptrons.pdf
</p>
<p align="left">
7、《An overview of gradient descent optimization algorithms》http://sebastianruder.com/optimizing-gradient-descent/
</p>
<p align="left">
8、《Ad Click Prediction: a View from the Trenches》https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf
</p>
<p align="left">
9、《ADADELTA: AN ADAPTIVE LEARNING RATE METHOD》http://www.matthewzeiler.com/pubs/googleTR2012/googleTR2012.pdf
</p>
<p align="left">
9、《Improving the Convergence of Back-Propagation Learning with Second Order Methods》http://yann.lecun.com/exdb/publis/pdf/becker-lecun-89.pdf
</p>
<p align="left">
10、《ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION》https://arxiv.org/pdf/1412.6980v8.pdf
</p>
<p align="left">
11、《Adaptive Subgradient Methods for Online Learning and Stochastic Optimization》http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf
</p>
<p align="left">
11、《Sparse Allreduce: Efficient Scalable Communication for Power-Law Data》https://arxiv.org/pdf/1312.3020.pdf
</p>
<p align="left">
12、《Asynchronous Parallel Stochastic Gradient Descent》https://arxiv.org/pdf/1505.04956v5.pdf
</p>
<p align="left">
13、《Large Scale Distributed Deep Networks》https://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf
</p>
<p align="left">
14、《Introduction to Optimization —— Second Order Optimization Methods》https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/13-Optimization/04-secondOrderOpt.pdf
</p>
<p align="left">
15、《On the complexity of steepest descent, Newton’s and regularized Newton’s methods for nonconvex unconstrained optimization》http://www.maths.ed.ac.uk/ERGO/pubs/ERGO-09-013.pdf
</p>
<p align="left">
16、《On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes 》http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes.pdf
</p>
<p align="left">
17、《Parametric vs Nonparametric Models》http://mlss.tuebingen.mpg.de/2015/slides/ghahramani/gp-neural-nets15.pdf
</p>
<p align="left">
18、《XGBoost: A Scalable Tree Boosting System》https://arxiv.org/abs/1603.02754
</p>
<p align="left">
19、一个可视化CNN的网站 http://shixialiu.com/publications/cnnvis/demo/
</p>
<p align="left">
20、《Computer vision: LeNet-5, AlexNet, VGG-19, GoogLeNet》http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html
</p>
<p align="left">
21、François Chollet在Quora上的专题问答：https://www.quora.com/session/Fran%C3%A7ois-Chollet/1
</p>
<p align="left">
22、《将Keras作为tensorflow的精简接口》https://keras-cn.readthedocs.io/en/latest/blog/keras_and_tensorflow/
</p>
<p align="left">
23、《Upsampling and Image Segmentation with Tensorflow and TF-Slim》https://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/
</p>
<p align="left">
24、《DENSELY CONNECTED CONVOLUTIONAL NETWORKS》http://www.cs.cornell.edu/~gaohuang/papers/DenseNet-CVPR-Slides.pdf
</p>
<p align="left">
25、https://github.com/vivounicorn/convnet-study
</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">张磊</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张磊</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
